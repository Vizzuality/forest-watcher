diff --git a/node_modules/realm/compiled/node-v64_darwin_x64/realm.node b/node_modules/realm/compiled/node-v64_darwin_x64/realm.node
index f92970b..ec835a9 100755
Binary files a/node_modules/realm/compiled/node-v64_darwin_x64/realm.node and b/node_modules/realm/compiled/node-v64_darwin_x64/realm.node differ
diff --git a/node_modules/realm/lib/index.js b/node_modules/realm/lib/index.js
index 92f0f7b..268e067 100644
--- a/node_modules/realm/lib/index.js
+++ b/node_modules/realm/lib/index.js
@@ -58,9 +58,9 @@ function getContext() {
 
         // Check if its in remote js debugging mode
         // https://stackoverflow.com/a/42839384/3090989
-        if (typeof atob !== 'undefined') {
-            return 'chromedebugger';
-        }
+        // if (typeof atob !== 'undefined') {
+        //     return 'chromedebugger';
+        // }
 
         // Otherwise, we must be in a "normal" react native situation.
         // In that case, the Realm type should have been injected by the native code.
diff --git a/node_modules/realm/vendor/realm-ios/doc/realm/CHANGELOG.md b/node_modules/realm/vendor/realm-ios/doc/realm/CHANGELOG.md
new file mode 100644
index 0000000..91107cf
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/doc/realm/CHANGELOG.md
@@ -0,0 +1,4837 @@
+# 5.23.7 Release notes
+
+### Enhancements
+* Reduce the encrypted page reclaimer's impact on battery life on Apple platforms. ([PR #3461](https://github.com/realm/realm-core/pull/3461)).
+
+### Fixed
+* macOS binaries were built with the incorrect deployment target (10.14 rather than 10.9). ([Cocoa #6299](https://github.com/realm/realm-cocoa/issues/6299), since 5.23.4).
+* Subtable accessors could be double-deleted if the last reference was released from a different
+  thread at the wrong time. This would typically manifest as "pthread_mutex_destroy() failed", but
+  could also result in other kinds of crashes. ([Cocoa #6333](https://github.com/realm/realm-cocoa/issues/6333)).
+* Sorting float or double columns containing NaN values had inconsistent results and would sometimes
+  crash due to out-of-bounds memory accesses. ([Cocoa #6357](https://github.com/realm/realm-cocoa/issues/6357)).
+
+----------------------------------------------
+
+# 5.23.6 Release notes
+
+### Enhancements
+* Performance significantly improved when making a query on the property of a linked table, when the property is indexed.
+
+### Fixed
+* A race between extending the file and activity in the encryption layer could lead to crash and corruption.
+  This race has been fixed. The bug was introduced with version 5.3.0 and may hit on Android, if encryption is
+  in use. It could also affect Linux on file systems where posix prealloc() is unsupported.
+  ([PR #3427](https://github.com/realm/realm-core/issues/3427), since 5.3.0)
+* Null values were not printed correctly when using json serialisation. ([PR #3399](https://github.com/realm/realm-core/issues/3399)).
+* ListOfPrimitives were not printed correctly when using json serialisation. ([#3408](https://github.com/realm/realm-core/issues/3408)).
+
+-----------
+
+### Internals
+* Fixed several warnings found by newer clang compilers. ([#3393](https://github.com/realm/realm-core/issues/3393)).
+
+----------------------------------------------
+
+# 5.23.5 Release notes
+
+### Enhancements
+* None.
+
+### Fixed
+* Chained OR equals queries on an unindexed string column failed to match any results if any of the strings were 64 bytes or longer. ([PR #3386](https://github.com/realm/realm-core/pull/3386), since 5.17.0).
+* Fixed serialization of a query which looks for a null timestamp. This only affects query based sync. ([PR #3389](https://github.com/realm/realm-core/pull/3388), since v5.23.2).
+
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+
+* VersionID comparison operators are now const qualified ([PR #3391](https://github.com/realm/realm-core/pull/3391)).
+* Exception `util::File::AccessError`, and it's derivatives such as `util::File::NotFound`, will now include a stacktrace in the message returned by the `what()` method. ([PR #3394](https://github.com/realm/realm-core/pull/3394))
+
+
+----------------------------------------------
+
+# 5.23.4 Release notes
+
+### Internals
+* The release binaries for Apple platforms are now built with Xcode 10.0 (up from 9.4).
+* Add a Catalyst/UIKit for Mac library to the Cocoa release package.
+
+----------------------------------------------
+
+# 5.23.3 Release notes
+
+### Fixed
+* If a signal interrupted a msync() call, Core would throw an exception. This behavior has new been changed to retry the system call instead. (Issue [#3352](https://github.com/realm/realm-core/issues/3352))
+* Fixed a bug in sum() or average() of == and != queries on integer columns sometimes returning an incorrect result. ([#3356](https://github.com/realm/realm-core/pull/3356), since the beginning).
+
+-----------
+
+### Internals
+* Changed the metrics timers to more precisely report in nanoseconds, instead of seconds. ([#3359](https://github.com/realm/realm-core/issues/3359))
+* Better performance when cloud query metrics are turned on, by not acquiring a backtrace on query serialization errors (permissions queries). ([#3361](https://github.com/realm/realm-core/issues/3361)).
+* Performance improved for queries comparing a constant value to a property over unary link path (eg: "someLink.Id == 42"). ([#3670](https://github.com/realm/realm-core/issues/3370))
+
+----------------------------------------------
+
+# 5.23.2 Release notes
+
+### Fixed
+* Named pipes on Android are now created with 0666 permissions instead of 0600. This fixes a bug on Huawei devices which caused named pipes to change owners during app upgrades causing subsequent `ACCESS DENIED` errors. This should have not practical security implications. (Issue [#3328](https://github.com/realm/realm-core/pull/3328))
+ 
+-----------
+
+### Internals
+* The release binaries for Apple platforms are now built with Xcode 9.4 (up from 9.2).
+* Performance of queries on Timestamp is improved
+
+----------------------------------------------
+
+# 5.23.1 Release notes
+
+### Fixed
+* Fixed the metrics throwing an exception when a query cannot be serialised. Now it reports the exception message as the description.
+ ([#3031](https://github.com/realm/realm-sync/issues/3031), since v3.2.0)
+* Queries involving an indexed int column which were constrained by a LinkList with an order different from the table's order would
+  give incorrect results. ([#3307](https://github.com/realm/realm-core/issues/3307), since v5.19.0)
+* Queries involving an indexed int column had a memory leak if run multiple times. ([#6186](https://github.com/realm/realm-cocoa/issues/6186)), since v5.19.0)
+
+----------------------------------------------
+
+# 5.23.0 Release notes
+
+### Enhancements
+* Add a Swift Package Manager package ([#3308](https://github.com/realm/realm-core/pull/3308)).
+
+### Fixed
+* Constructing an `IncludeDescriptor` made unnecessary table comparisons. This resulted in poor performance for subscriptions
+  using the `includeLinkingObjects` functionality. ([#3311](https://github.com/realm/realm-core/issues/3311), since v5.18.0)
+ 
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* None.
+
+----------------------------------------------
+
+# 5.22.0 Release notes
+
+### Enhancements
+
+* Expose the ability to follow links while printing a TableView in JSON format.
+  TableView::to_json() now supports the same arguments as Table::to_json().
+  ([#3301](https://github.com/realm/realm-core/pull/3301))
+
+### Fixed
+* None.
+ 
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* Fixed an inconsistency in the use of the `REALM_METRICS` compile time option. Now core consumers are able
+  to use `SharedGroup::get_metrics()` regardless of whether or not metrics are compiled in. A null pointer
+  is returned if the feature has been disabled at compile time.
+
+----------------------------------------------
+
+# 5.21.0 Release notes
+
+### Enhancements
+* Added support for unicode characters in realm path and filenames for Windows. Contribution by @rajivshah3.
+  ([#3293](https://github.com/realm/realm-core/pull/3293))
+
+### Fixed
+* None.
+
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* Introduced new feature test macros for address and thread sanitizers in
+  `<realm/util/features.h>`.
+* Added Realm file path to Allocator assertions ([3283](https://github.com/realm/realm-core/issues/3283)).
+
+----------------------------------------------
+
+# 5.20.0 Release notes
+
+### Enhancements
+* Added the ability to convert a std::chrono::time_point to a Timestamp and
+  vice versa. This allows us to make calculations using std::chrono::duration.
+
+### Fixed
+* Slab usage was reported wrong by SlabAlloc::get_total_slab_size() ([#3284](https://github.com/realm/realm-core/pull/3284)
+  This caused ROS to incorectly report "exabytes" of memory used for slab.
+* The control of the page reclaimer did not limit the page reclaimers workload correctly. This could lead
+  to the reclaimer not running as much as intended. This is not believed to have been visible to end users.
+  This bug also caused ROS to occasionally report odd metrics for the reclaimer.
+  ([#3285](https://github.com/realm/realm-core/pull/3285))
+* When opening an encrypted file via SharedGroup::open(), it could wrongly fail and indicate a file corruption
+  although the file was ok.
+  ([#3267](https://github.com/realm/realm-core/issues/3267), since core v5.12.2)
+ 
+----------------------------------------------
+
+# 5.19.1 Release notes
+
+### Fixed
+* Freelist would keep growing with a decreased commit performance as a result.
+  ([2927](https://github.com/realm/realm-sync/issues/2927))
+* Fixed an incorrect debug mode assertion which could be triggered when generating the description of an IncludeDescriptor.
+  ([PR #3276](https://github.com/realm/realm-core/pull/3276) since v5.18.0). 
+----------------------------------------------
+
+# 5.19.0 Release notes
+
+### Enhancements
+* Improved query performance for unindexed integer columns when the query has a chain of OR conditions.
+  This will improve performance of "IN" queries generated by SDKs.
+  ([PR #2888](https://github.com/realm/realm-sync/issues/2888).
+* Use search index in queries on integer columns (equality only). This will improve performance of
+  queries on integer primary key properties for example. ([PR #3272](https://github.com/realm/realm-core/pull/3272)).
+* Number of 8 byte blocks in freelist is minimized. This will result in a shorter freelist.
+
+### Fixed
+* Writing a snapshot to file via Group::write() could produce a file with some parts not
+  reachable from top array (a memory leak). ([#2911](https://github.com/realm/realm-sync/issues/2911))
+* Fixed a bug in queries on a string column with more than two "or" equality conditions when the last condition also had an
+  "and" clause. For example: `first == "a" || (first == "b" && second == 1)` would be incorrectly evaluated as
+  `(first == "a" || first == "b")`. ([#3271](https://github.com/realm/realm-core/pull/3271), since v5.17.0)
+ 
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* None.
+
+----------------------------------------------
+
+# 5.18.0 Release notes
+
+### Enhancements
+* Adds support for a new IncludeDescriptor type which describes arbitrary link paths
+  on a TableView. Applying this to a TableView does not modify the results, but gives
+  users the ability to use the reporting method to find rows in a different table that
+  are connected by backlinks. This is intended for sync subscriptions.
+* Enhances LinksToNode so that it can check links to multiple targets. This can be utilized
+  in permissions check in sync.
+
+### Fixed
+* None.
+ 
+-----------
+
+### Internals
+* The release binaries for Apple platforms are now built with Xcode 9.2 (up from 8.3.3).
+
+----------------------------------------------
+
+# 5.17.0 Release notes
+
+### Enhancements
+* Improved query performance for unindexed string columns when the query has a chain of OR conditions.
+  This will improve performance of "IN" queries generated by SDKs.
+  ([PR #3250](https://github.com/realm/realm-core/pull/3250).
+
+### Fixed
+* Making a query that compares two integer properties could cause a segmentation fault on the server.
+  ([#3253](https://github.com/realm/realm-core/issues/3253))
+ 
+-----------
+
+### Internals
+* The protocol for updating Replication/History is changed. The Replication object will be initialized
+  in every transaction. A new parameter will tell if it is a write- or readtransaction. A new function -
+  History::ensure_updated can be called in places where the history object needs to be up-to-date. The 
+  function will use a flag to ensure that the object is only updated once per transaction.
+
+----------------------------------------------
+
+# 5.16.0 Release notes
+
+### Enhancements
+* Improved performance of encryption and decryption significantly by utilizing hardware optimized encryption functions.
+  ([#293](https://github.com/realm/realm-core-private/issues/293))
+* Added the ability to write a Group with the history stripped.
+  ([#3245](https://github.com/realm/realm-core/pull/3245))
+
+### Fixed
+* Nothing
+
+-----------
+
+### Internals
+* Size of decrypted memory and of currently reserved slab is now available outside of the
+  metrics system (to which they were added in 5.15.0). This allows us to get the current
+  values independently from transactions start or end (the metrics system is only updated
+  at transaction boundaries).
+  ([3240] https://github.com/realm/realm-core/pull/3240)
+* Current target and workload set for the page reclaimer is now also available from `get_decrypted_memory_stats()`
+  ([3246] https://github.com/realm/realm-core/pull/3246)
+* Default heuristic for reclaiming pages holding decrypted data has been changed, now
+  limiting amount to same as current use of the buffer cache. Previously the limit was
+  half of buffer cache usage. This heuristic may still not be good enough for some scenarios
+  and we recommend monitoring and explicitly setting a better target in cases where we reclaim
+  more memory than nescessary.
+  (also [3240] https://github.com/realm/realm-core/pull/3240)
+* Now publishing a TSAN compatible linux build.
+----------------------------------------------
+
+# 5.15.0 Release notes
+
+### Enhancements
+* Metrics history is now capped to a configurable buffer size with a default of 10000 entries.
+  If this is exceeded without being consumed, only the most recent entries are stored. This
+  prevents excessive memory growth if users turn on metrics but don't use it.
+* Metrics transaction objects now store the number of decrypted pages currently in memory.
+* SharedGroup::get_stats includes an optional parameter to get size of currently locked memory.
+* Metrics now exposes the table name of queries which have been run.
+
+### Fixed
+* When shutting down the server you could sometimes experience a crash with "realm::util::Mutex::lock_failed"
+  in the stacktrace.
+  ([#3237](https://github.com/realm/realm-core/pull/3237), since v5.12.5)
+
+### Internal
+* Fix a race between the encryption page reclaim governor running and setting a governor.
+  This only affects applications which actually set the governor to something custom which no one does yet.
+  ([#3239](https://github.com/realm/realm-core/issues/3239), since v5.12.2)
+
+----------------------------------------------
+
+# 5.14.0 Release notes
+
+### Enhancements
+* Add assertion to prevent translating a ref value that is not 8 byte aligned. This will allow
+  us to detect file corruptions at an earlier stage.
+* You can now get size of the commit being built and the size of currently allocated slab area.
+* The amount of memory held by SharedGroup is minimized as most of it will be freed after each commit.
+
+### Fixed
+* Compacting a realm into an encrypted file could take a really long time. The process is now optimized by adjusting the write
+  buffer size relative to the used space in the realm.
+  ([#2754](https://github.com/realm/realm-sync/issues/2754))
+* Creating an object after creating an object with the int primary key of "null" would hit an assertion failure.
+  ([#3227](https://github.com/realm/realm-core/pull/3227)).
+
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* The buffer size used by util::File::Streambuf is now configurable in construction.
+
+----------------------------------------------
+
+# 5.13.0 Release notes
+
+### Enhancements
+* The parser now supports readable timestamps with a 'T' separator in addition to the originally supported "@" separator.
+  For example: "startDate > 1981-11-01T23:59:59:1". ([#3198](https://github.com/realm/realm-core/issues/3198)).
+
+### Fixed
+* If, in debug mode, you try to compute the used space on a newly compacted realm (with empty free list), the program will
+  abort. ([#1171](https://github.com/realm/realm-sync/issues/2724), since v5.12.0)
+ 
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* For convenience, `parser::parse` now accepts a `StringData` type instead of just `std::string`.
+* Parsing a query which uses the 'between' operator now gives a better error message indicating
+  that support is not yet implemented. ([#3198](https://github.com/realm/realm-core/issues/3198)).
+
+----------------------------------------------
+
+# 5.12.7 Release notes
+
+### Enhancements
+* Instead of asserting, an `InvalidDatabase` exception is thrown when a realm file is opened 
+  with an invalid top ref. Name of problematic file is included in exception message.
+
+### Fixed
+* A bug was fixed in `realm::util::DirScanner` that could cause it to sometimes
+  skip directory entries due to faulty error handling around `readdir()`.
+  (Issue [realm-sync#2699](https://github.com/realm/realm-sync/issues/2699), since 5.12.5).
+ 
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* Improved performance on `find_first` for small string arrays (ArrayString). This will improve the table name lookup
+  performance.
+* Upgrade pegtl to 2.6.1. Several issues fixed.
+* Introduced Durability::Unsafe, which disables sync'ing to disk. Using this option, 
+  a platform crash may corrupt the realm file. Use only, if you'r OK with this.
+
+----------------------------------------------
+
+# 5.12.6 Release notes
+
+### Enhancements
+* None.
+
+### Fixed
+* On AWS Lambda we may throw an "Operation not permitted" exception when calling posix_fallocate().
+  A slower workaround has been supplied.
+  ([#3193](https://github.com/realm/realm-core/issues/3293))
+ 
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* None.
+
+----------------------------------------------
+
+# 5.12.5 Release notes
+
+### Enhancements
+* None.
+
+### Fixed
+* When loading the realm binary from within the realm-js SDK, core could hang on Windows as described in
+  https://github.com/realm/realm-js/issues/2169.
+  ([#3188](https://github.com/realm/realm-core/pull/3188, since 5.12.2)
+
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* Fixed warnings reported by GCC 8.
+* Replaced call to the deprecated `readdir_r()` with `readdir()`.
+* Compilation without encryption now possible
+
+----------------------------------------------
+
+# 5.12.4 Release notes
+
+### Enhancements
+* None.
+
+### Fixed
+* A segmentation fault would occur when calling Group:get_used_space() for a realm file
+  with no commits. This method would usually only be called from sync/ROS to calculate
+  and report state size.
+  ([#3182](https://github.com/realm/realm-core/issues/3182), since v5.12.0)
+
+### Breaking changes
+* None.
+
+----------------------------------------------
+
+# 5.12.3 Release notes
+
+### Enhancements
+* None.
+
+### Fixed
+* Added assertions around use of invalid refs and sizes. Helps in narrowing down the causes for
+  asserts like `ref != 0` and `(chunk_pos % 8) == 0`
+
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* None.
+
+----------------------------------------------
+
+# 5.12.2 Release notes
+
+### Enhancements
+* None
+
+### Fixed
+* If encryption was enabled, decrypted pages were not released until the file was closed, causing
+  excessive usage of memory.
+  A page reclaim daemon thread has been added, which will work to release decrypted pages back to
+  the operating system. To control it, a governing function can be installed. The governing function
+  sets the target for the page reclaimer. If no governing function is installed, the system will attempt
+  to keep the memory usage below any of the following:
+
+        - 1/4 of physical memory available on the platform as reported by "/proc/meminfo"
+        - 1/4 of allowed memory available as indicated by "/sys/fs/cgroup/memory/memory_limit_in_bytes"
+        - 1/2 of what is used by the buffer cache as indicated by "/sys/fs/cgroup/memory/memory.stat"
+        - A target directly specified as "target <number of bytes>" in a configuration file specified
+          by the environment variable REALM_PAGE_GOVERNOR_CFG.
+  if none of the above is available, or if a target of -1 is given, the feature is disabled.
+  ([#3123](https://github.com/realm/realm-core/issues/3123))
+
+-----------
+
+### Internals
+* None.
+
+----------------------------------------------
+
+# 5.12.1 Release notes
+
+### Enhancements
+* Illegal freeing of in-file-memory is now detected when freeing is
+  actually done. This will make it easier to find the root cause of
+  some file corruption issues.
+
+### Fixed
+* None.
+
+### Breaking changes
+* None.
+
+-----------
+
+### Internals
+* None.
+
+----------------------------------------------
+
+# 5.12.0 Release notes
+
+### Enhancements
+* Added Group::get_used_space() which will return the size of the data taken up by the current
+  commit. This is in contrast to the number returned by SharedGroup::get_stats() which will
+  return the size of the last commit done in that SharedGroup. If the commits are the same,
+  the number will of course be the same.
+  Issue [#259](https://github.com/realm/realm-core-private/issues/259)
+
+### Fixed
+* None.
+
+### Breaking changes
+* The way the Linux binaries are delivered is changed. They are now distributed
+  like the rest of the binaries with two packages (devel/runtime) per build type.
+  The file names follow this scheme:
+  realm-core-<buildType>-<release>-Linux-{devel|runtime}.tar.gz
+  For Linux the following build types are published: Debug, Release, RelAssert
+  and RelASAN.
+
+-----------
+
+### Internals
+* Replication::get_database_path() is made const.
+* TrivialReplication::get_database_path() is made public.
+* Added better compatibility for custom allocators with standard library
+  containers on GCC 4.9.
+
+----------------------------------------------
+
+# 5.11.3 Release notes
+
+### Compatibility
+* File format: ver. 9
+  Upgrades automatically from previous formats.
+  Can open realms down to file format version 7 in ReadOnly mode (without upgrade).
+
+-----------
+
+### Internals
+* Improved assertion checking in release mode in order to detect any corruption
+  of our freelist earlier and prevent bogus allocations from a corrupted freelist
+  from leading to subsequent corruption of other parts of the file.
+
+----------------------------------------------
+
+# 5.11.2 Release notes
+
+### Compatibility
+* File format: ver. 9
+  Upgrades automatically from previous formats.
+  Can open realms down to file format version 7 in ReadOnly mode (without upgrade).
+
+-----------
+
+### Internals
+* Releases no longer include RPM and DEB packages.
+* Releases now include RelWithDebInfo+ASAN and RelWithDebInfo+Assertions tarballs for linux.
+  [#3112](https://github.com/realm/realm-core/pull/3112).
+
+----------------------------------------------
+
+# 5.11.1 Release notes
+
+### Compatibility
+* File format: ver. 9
+  Upgrades automatically from previous formats.
+  Can open realms down to file format version 7 in ReadOnly mode (without upgrade).
+
+-----------
+
+### Internals
+* Fixed a bug in the use of placement new on MSVC, where the implementation is
+  buggy. This bug only affected version 5.11.0.
+  PR [#3109](https://github.com/realm/realm-core/pull/3109)
+* Made improvements to the custom allocation interfaces introduced in 5.11.0,
+  which should make them more convenient and use slightly less memory.
+  PR [#3108](https://github.com/realm/realm-core/pull/3108)
+
+----------------------------------------------
+
+# 5.11.0 Release notes
+
+### Compatibility
+* File format: ver. 9
+  Upgrades automatically from previous formats.
+  Can open realms down to file format version 7 in ReadOnly mode (without upgrade).
+
+-----------
+
+### Internals
+* Added support for custom heap allocators
+  PR [#3106](https://github.com/realm/realm-core/pull/3106).
+
+----------------------------------------------
+
+# 5.10.3 Release notes
+
+### Fixed
+* When a sort or distinct over links was done on an already-sorted TableView,
+  the link translation map was done using the unsorted rows, resulting in the
+  second sort/distinct being done with the incorrect values.
+  PR [#3102](https://github.com/realm/realm-core/pull/3102).
+
+### Compatibility
+* File format: ver. 9 (upgrades automatically from previous formats)
+
+-----------
+
+### Internals
+
+* Will assert if someone tries to free a null ref.
+  Issue [#254](https://github.com/realm/realm-core-private/issues/254) and the like.
+
+----------------------------------------------
+
+# 5.10.2 Release notes
+
+### Enhancements
+
+* Add an arm64_32 slice to the watchOS build.
+
+----------------------------------------------
+
+# 5.10.1 Release notes
+
+### Internals
+
+* Stack trace also available when throwing std:: exceptions.
+
+----------------------------------------------
+
+# 5.10.0 Release notes
+
+### Enhancements
+
+* Allow compact to take an optional output encryption key.
+  PR [#3090](https://github.com/realm/realm-core/pull/3090).
+
+----------------------------------------------
+
+# 5.9.0 Release notes
+
+### Enhancements
+
+* Allow a version number in Group::write which will cause a file with (sync)
+  history to be written.
+
+-----------
+
+### Internals
+
+* Most exception types now report the stack trace of the point where they were
+  thrown in their `what()` message. This is intended to aid debugging.
+  Additionally, assertion failures on Linux now report their stack traces as
+  well, similar to Apple platforms. Recording stack traces is only supported on
+  Linux (non-Android) and Apple platforms for now.
+
+----------------------------------------------
+
+# 5.8.0 Release notes
+
+### Bugfixes
+
+* Fix a crash on some platforms when using the query parser to look for a string
+  or binary object which has a certain combination of non-printable characters.
+
+### Enhancements
+
+* Support limiting queries via `DescriptorOrdering::set_limit` and by supporting
+  "LIMIT(x)" in string queries.
+  Issue [realm_sync:#2223](https://github.com/realm/realm-sync/issues/2223)
+
+----------------------------------------------
+
+# 5.7.2 Release notes
+
+### Bugfixes
+
+* Fix a use-after-free when an observer is passed to rollback_and_continue_as_read().
+
+### Enhancements
+
+* More informative InvalidDatabase exception messages
+  Issue [#3075](https://github.com/realm/realm-core/issues/3075).
+
+----------------------------------------------
+
+# 5.7.1 Release notes
+
+### Bugfixes
+
+* Fix crash in Group::compute_aggregated_byte_size() when applied on an empty
+  realm file. (Issue #3072)
+
+----------------------------------------------
+
+# 5.7.0 Release notes
+
+### Enhancements
+
+* Improved Group::compute_aggregated_byte_size() allowing us to differentiate
+  between state, history and freelists.
+  (Issue #3063)
+
+----------------------------------------------
+
+# 5.6.5 Release notes
+
+### Enhancements
+
+* Improved scalability for the slab allocator. This allows for larger
+  transactions. (PR #3067)
+
+----------------------------------------------
+
+# 5.6.4 Release notes
+
+### Enhancements
+
+* Add Table::add_row_with_keys(), which allows
+  sync::create_object_with_primary_key() to avoid updating the index twice when
+  creating an object with a string primary key.
+* Improved the performance of setting a link to its current value.
+
+----------------------------------------------
+
+# 5.6.3 Release notes
+
+### Enhancements
+
+* Improved scalability for in-file freelist handling. This reduces
+  commit overhead on large transactions.
+* Improved scalability for in-file allocation during commit.
+* Minimized use of memory mappings and msync() on large commits
+  on devices which can support large address spaces.
+
+----------------------------------------------
+
+# 5.6.2 Release notes
+
+### Bugfixes
+
+* Fix curruption of freelist with more than 2M entries.
+  PR [#3059](https://github.com/realm/realm-core/pull/3059).
+
+----------------------------------------------
+
+# 5.6.1 Release notes
+
+### Bugfixes
+
+* More readable error message in the query parser when requesting an a bad argument.
+* Don't write history information in `SharedGroup::compact()` for
+  non-syncronized Realms.
+
+-----------
+
+### Internals
+
+* Restore -fvisibility-inlines-hidden for the binaries for Apple platforms.
+* Remove a few warnings at compile time.
+* Improve error detection related to memory allocation/release
+
+----------------------------------------------
+
+# 5.6.0 Release notes
+
+### Bugfixes
+
+* In the parser, fix `@links.@count` when applied over lists to return
+  the sum of backlinks for all connected rows in the list.
+* Fix null comparisons in queries not serialising properly in some cases.
+  Also explicitly disable list IN list comparisons since its not supported.
+  PR [#3037](https://github.com/realm/realm-core/pull/3037).
+
+### Enhancements
+
+* `SharedGroup::compact()` now also compacts history information, which means
+  that Sync'ed Realm files can now be compacted (under the usual restrictions;
+  see `group_shared.hpp` for details).
+
+----------------------------------------------
+
+# 5.5.0 Release notes
+
+### Enhancements
+
+* Parser improvements:
+    - Allow an arbitrary prefix on backlink class names of @links queries.
+      This will allow users to query unnamed backlinks using the `@links.Class.property` syntax.
+    - Case insensitive `nil` is now recognised as a synonym to `NULL`.
+    - Add support for `@links.@count` which gives the count of all backlinks to an object.
+      See Issue [#3003](https://github.com/realm/realm-core/issues/3003).
+
+-----------
+
+### Internals
+
+* Apple binaries are now built with Xcode 8.3.3.
+
+----------------------------------------------
+
+# 5.4.2 Release notes
+
+### Bugfixes
+
+* Fix sporadic failures of disk preallocation on APFS.
+  PR [#3028](https://github.com/realm/realm-core/pull/3028).
+
+----------------------------------------------
+
+# 5.4.1 Release notes
+
+### Enhancements
+
+* Reduced the number of files opened when the async commit daemon is not used.
+  PR [#3022](https://github.com/realm/realm-core/pull/3022).
+
+-----------
+
+### Internals
+
+* Exported CMake targets have been renamed to "modern" conventions, e.g.
+  `Realm::Core` and `Realm::QueryParser`.
+
+----------------------------------------------
+
+# 5.4.0 Release notes
+
+### Bugfixes
+
+* Fixed usage of disk space preallocation which would occasionally fail on recent MacOS
+  running with the APFS filesystem. PR [#3013](https://github.com/realm/realm-core/pull/3013).
+  Issue [#3005](https://github.com/realm/realm-core/issues/3005).
+* Fixed a bug in queries containing 'or' at different nesting levels.
+  PR [#3006](https://github.com/realm/realm-core/pull/3006).
+
+### Breaking changes
+
+* None.
+
+### Enhancements
+
+* Added `Table::get_link_type()` as a helper method for getting the link type from link columns.
+  PR [#2987](https://github.com/realm/realm-core/pull/2987).
+
+-----------
+
+### Internals
+
+* Silenced a false positive strict aliasing warning.
+  PR [#3002](https://github.com/realm/realm-core/pull/3002).
+* Assertions will print more information in relase mode.
+  PR [#2982](https://github.com/realm/realm-core/pull/2982).
+
+----------------------------------------------
+
+# 5.3.0 Release notes
+
+### Bugfixes
+
+* Fixed handling of out-of-diskspace. With encryption in use it would ASSERT like
+  `group_writer.cpp:393: [realm-core-5.1.2] Assertion failed: ref + size <= ...`.
+  Without encryption it would give a SIGBUS error. It's unknown if it could corrupt
+  the .realm file.
+* Fix an issue where adding zero rows would add the default value to the keys
+  of any string enum columns. Not affecting end users.
+  PR [#2956](https://github.com/realm/realm-core/pull/2956).
+
+### Enhancements
+
+* Parser improvements:
+    - Support subquery count expressions, for example: "SUBQUERY(list, $x, $x.price > 5 && $x.colour == 'blue').@count > 1"
+        - Subqueries can be nested, but all properties must start with the closest variable (no parent scope properties)
+    - Support queries over unnamed backlinks, for example: "@links.class_Person.items.cost > 10"
+        - Backlinks can be used like lists in expressions including: min, max, sum, avg, count/size, and subqueries
+    - Keypath substitution is supported to allow querying over named backlinks and property aliases, see `KeyPathMapping`
+    - Parsing backlinks can be disabled at runtime by configuring `KeyPathMapping::set_allow_backlinks`
+    - Support for ANY/SOME/ALL/NONE on list properties (parser only). For example: `ALL items.price > 10`
+    - Support for operator 'IN' on list properties (parser only). For example: `'milk' IN ingredients.name`
+    PR [#2989](https://github.com/realm/realm-core/pull/2989).
+
+-----------
+
+### Internals
+
+* Add support for libfuzzer.
+  PR [#2922](https://github.com/realm/realm-core/pull/2922).
+
+----------------------------------------------
+
+# 5.2.0 Release notes
+
+### Bugfixes
+
+* Fix a crash when distinct is applied on two or more properties where
+  the properties contain a link and non-link column.
+  PR [#2979](https://github.com/realm/realm-core/pull/2979).
+
+### Enhancements
+
+* Parser improvements:
+    - Support for comparing two columns of the same type. For example:
+        - `wins > losses`
+        - `account_balance > purchases.@sum.price`
+        - `purchases.@count > max_allowed_items`
+        - `team_name CONTAINS[c] location.city_name`
+    - Support for sort and distinct clauses
+        - At least one query filter is required
+        - Columns are a comma separated value list
+        - Order of sorting can be `ASC, ASCENDING, DESC, DESCENDING` (case insensitive)
+        - `SORT(property1 ASC, property2 DESC)`
+        - `DISTINCT(property1, property2)`
+        - Any number of sort/distinct expressions can be indicated
+    - Better support for NULL synonym in binary and string expressions:
+        - `name == NULL` finds null strings
+        - `data == NULL` finds null binary data
+    - Binary properties can now be queried over links
+    - Binary properties now support the full range of string operators
+      (BEGINSWITH, ENDSWITH, CONTAINS, LIKE)
+    PR [#2979](https://github.com/realm/realm-core/pull/2979).
+
+-----------
+
+### Internals
+
+* The devel-dbg Linux packages now correctly include static libraries instead of shared ones.
+
+----------------------------------------------
+
+# 5.1.2 Release notes
+
+### Bugfixes
+
+* Include the parser libs in the published android packages.
+
+----------------------------------------------
+
+# 5.1.1 Release notes
+
+### Bugfixes
+
+* The `realm-parser` static library now correctly includes both simulator and device architectures on Apple platforms.
+
+----------------------------------------------
+
+# 5.1.0 Release notes
+
+### Enhancements
+
+* Change the allocation scheme to (hopefully) perform better in scenarios
+  with high fragmentation.
+  PR [#2963](https://github.com/realm/realm-core/pull/2963)
+* Avoid excessive bumping of counters in the version management machinery that is
+  responsible for supporting live queries. We now prune version bumping earlier if
+  when we have sequences of changes without queries in between.
+  PR [#2962](https://github.com/realm/realm-core/pull/2962)
+
+----------------------------------------------
+
+# 5.0.1 Release notes
+
+### Bugfixes
+
+* Add a CMake import target for the `realm-parser` library.
+
+----------------------------------------------
+
+# 5.0.0 Release notes
+
+### Bugfixes
+
+* Fix possible corruption or crashes when a `move_row` operates on a subtable.
+  PR [#2927](https://github.com/realm/realm-core/pull/2926).
+* Table::set_int() did not check if the target column was indeed type_Int. It
+  will now assert like the other set methods.
+
+### Breaking changes
+
+* Remove support for the (unused) instructions for moving columns and moving tables.
+  This is not a file format breaking change as the instructions are still recognised,
+  but now a parser error is thrown if either one is seen in the transaction logs.
+  PR [#2926](https://github.com/realm/realm-core/pull/2926).
+
+### Enhancements
+
+* Attempted to fix a false encryption security warning from IBM Bluemix. PR [#2911]
+* Utilities gain `Any` from object store and base64 encoding from sync.
+* Initial support for query serialisation.
+* The query parser from the object store was moved to core.
+  It also gained the following enhancements:
+    - Support @min, @max, @sum, @avg for types: int, double, float
+    - Support @count, @size interchangeably for types list, string, binary
+    - Support operator "LIKE" on strings
+    - Support operators: =>, =<, <>, which are synonymns for >=, <=, and != respectively
+    - Boolean types can now check against “0” or “1” in addition to false and true
+    - Fixed "not" and "or" not being applied to TRUEPREDICATE or FALSEPREDICATE
+    - Add support for comparing binary and string types using a (internal) base64 format: B64”…”
+    - Add support for Timestamps
+      - Internal format “Tseconds:nanoseconds”
+      - Readable format “YYYY-MM-DD@HH:MM:SS:NANOSECONDS”
+        - The nanoseconds part can be optionally omitted
+        - Conversion works for UTC from dates between ~1970-3000 on windows and ~1901-2038 on other platforms
+  PR [#2947](https://github.com/realm/realm-core/pull/2947).
+
+----------------------------------------------
+
+# 4.0.4 Release notes
+
+### Bugfixes
+
+* Publish the release version of Android-armeabi-v7a binary.
+
+----------------------------------------------
+
+# 4.0.3 Release notes
+
+### Bugfixes
+
+* Switch from using a combination of file write and mmap to using only mmap when
+  initializing the lockfile. It is unclear if this counts as a bugfix, because
+  it is unclear if there are still systems out there with problems handling that
+  scenario. The hope is that it will fix some non-reproducible problems related to
+  lockfile initialization.
+  PR [#2902](https://github.com/realm/realm-core/pull/2902)
+* Make calls to posix_fallocate() robust against interruption and report
+  the correct error on failure.
+  PR [#2905](https://github.com/realm/realm-core/pull/2905).
+* Fix an error in `int_multiply_with_overflow_detect()` which would report
+  overflow when no overflow should occur. This could cause out of memory
+  exceptions when the `TransactLogParser` reads strings or binary data > 2GB.
+  PR [#2906](https://github.com/realm/realm-core/pull/2906).
+
+----------------------------------------------
+
+# 4.0.2 Release notes
+
+### Bugfixes
+
+* Fix a race between SharedGroup::compact() and SharedGroup::open(). The race could
+  cause asserts indicating file corruption even if no corruption is caused. It is also
+  possible that it could cause real file corruption, though that is much less likely.
+  PR [#2892](https://github.com/realm/realm-core/pull/2892)
+
+----------------------------------------------
+
+# 4.0.1 Release notes
+
+### Bugfixes
+
+* Fix case insensitive contains query for null strings not returning all results and
+  Fix case insensitive equals query for null strings returning nothing when null strings exist.
+  PR [#2871](https://github.com/realm/realm-core/pull/2871).
+* Added mentioning of bugfix #2853 to this file for Core 4.0.0. (see 4.0.0 below)
+  The mentioning of this fix for 4.0 was originally ommitted.
+
+----------------------------------------------
+
+# 4.0.0 Release notes
+
+### Bugfixes
+
+* Fix a bug in subtable management which caused crashes if a subtable was destroyed
+  on a different thread.
+  PR [#2855](https://github.com/realm/realm-core/pull/2855).
+* Fix corruption caused by `swap_rows()` and `move_column()` operations applied
+  to a StringEnumColumn. Currently unused by bindings.
+  PR [#2780](https://github.com/realm/realm-core/pull/2780).
+
+### Breaking changes
+
+* Add `Table::move_row()`.
+  PR [#2873](https://github.com/realm/realm-core/pull/2873).
+* Changing instruction values for `Table::move_row()` requires a version bump to 9.
+  Version 8 files in read only mode without any history can be opened without upgrading.
+  PR [#2877](https://github.com/realm/realm-core/pull/2877).
+
+### Enhancements
+
+* Add method to recursively delete an object tree
+  PR [#2752](https://github.com/realm/realm-core/pull/2752)
+  Issue [#2718](https://github.com/realm/realm-core/issues/2718)
+* Add method to safely delete or otherwise manipulate realm file
+  and management files.
+  PR [#2864](https://github.com/realm/realm-core/pull/2864)
+
+-----------
+
+### Internals
+
+* A specialised exception realm::OutOfDiskSpace is thrown instead of a generic
+  runtime exception when writing fails because the disk is full or the user exceeds
+  the allotted disk quota.
+  PR [#2861](https://github.com/realm/realm-core/pull/2861).
+
+----------------------------------------------
+
+# 3.2.1 Release notes
+
+### Bugfixes
+
+* Compact now throws an exception if writing fails for some reason
+  instead of ignoring errors and possibly causing corruption.
+  In particular, this solves file truncation causing "bad header" exceptions
+  after a compact operation on a file system that is running out of disk space.
+  PR [#2852](https://github.com/realm/realm-core/pull/2852).
+
+-----------
+
+### Internals
+
+* Moved object store's true and false query expressions down to core.
+  PR [#2857](https://github.com/realm/realm-core/pull/2857).
+
+----------------------------------------------
+
+# 3.2.0 Release notes
+
+### Enhancements
+
+* Added metrics tracking as an optional SharedGroup feature.
+  PR [#2840](https://github.com/realm/realm-core/pull/2840).
+
+-----------
+
+### Internals
+
+* Improve crash durability on windows.
+  PR [#2845](https://github.com/realm/realm-core/pull/2845).
+* Removed incorrect string column type traits, which could cause errors.
+  They were unused. PR [#2846](https://github.com/realm/realm-core/pull/2846).
+
+----------------------------------------------
+
+# 3.1.0 Release notes
+
+### Bugfixes
+
+* A linker error in some configurations was addressed by adding an explicit
+  instantiation of `Table::find_first` for `BinaryData`.
+  [#2823](https://github.com/realm/realm-core/pull/2823)
+
+### Enhancements
+
+* Implemented `realm::util::File::is_dir`, `realm::util::File::resolve`,
+  and `realm::util::DirScanner` on Windows.
+
+----------------------------------------------
+
+# 3.0.0 Release notes
+
+### Bugfixes
+
+* Fixed handle leak on Windows (https://github.com/realm/realm-core/pull/2781)
+* Fixed a use-after-free when a TableRef for a table containing a subtable
+  outlives the owning group.
+
+### Breaking changes
+
+* Added support for compound sort and distinct queries.
+    - Multiple consecutive calls to sort or distinct compound on each other
+      in the order applied rather than replacing the previous one.
+    - The order that sort and distinct are applied can change the query result.
+    - Applying an empty sort or distinct descriptor is now a no-op, this
+      could previously be used to clear a sort or distinct operation.
+  PR [#2644](https://github.com/realm/realm-core/pull/2644)
+* Support for size query on LinkedList removed. This is perhaps not so
+  breaking after all since it is probably not used.
+  PR [#2532](https://github.com/realm/realm-core/pull/2532).
+* Replication interface changed. The search index functions now operate
+  on a descriptor and not a table.
+  PR [#2561](https://github.com/realm/realm-core/pull/2561).
+* New replication instruction: instr_AddRowWithKey
+* Add the old table size to the instr_TableClear replication instruction.
+* Throw a MaximumFileSizeExceeded exception during commits or allocations
+  instead of causing corruption or asserting. This would most likely be
+  seen when creating large Realm files on 32 bit OS.
+  PR [#2795](https://github.com/realm/realm-core/pull/2795).
+
+### Enhancements
+
+* Enhanced support for query in subtables:
+  Query q = table->column<SubTable>(0).list<Int>() == 5;
+  Query q = table->column<SubTable>(0).list<Int>().min() >= 2;
+  Query q = table->column<SubTable>(1).list<String>().begins_with("Bar");
+  PR [#2532](https://github.com/realm/realm-core/pull/2532).
+* Subtable column can now be nullable. You can use `is_null()` and `set_null()`
+  on a subtable element.
+  PR [#2560](https://github.com/realm/realm-core/pull/2560).
+* Support for search index on subtable columns. Only one level of subtables
+  are currently supported, that is, you cannot create a search index in a
+  subtable of a subtable (will throw exception). NOTE: Core versions prior to
+  this version will not be able to open .realm files of this Core version if
+  this Core version has added such indexes. Adding or removing an index will
+  take place for *all* subtables in a subtable column. There is no way to add
+  or remove it from single individual subtables.
+  PR [#2561](https://github.com/realm/realm-core/pull/2561).
+* Support for encryption on Windows (Win32 + UWP).
+  PR [#2643](https://github.com/realm/realm-core/pull/2643).
+* Add Table::add_row_with_key(). Adds a row and fills an integer column with
+  a value in one operation.
+  PR [#2596](https://github.com/realm/realm-core/pull/2596)
+  Issue [#2585](https://github.com/realm/realm-core/issues/2585)
+* Add more overloads with realm::null - PR [#2669](https://github.com/realm/realm-core/pull/2669)
+  - `size_t Table::find_first(size_t col_ndx, null)`
+  - `OutputStream& operator<<(OutputStream& os, const null&)`
+
+-----------
+
+### Internals
+
+* The RuntimeLibrary of the Windows build is changed from MultiThreadedDLL to
+  just MultiThreaded so as to statically link the Visual C++ runtime libraries,
+  removing the onus on end-users to have the correct runtime redistributable
+  package or satellite assembly pack installed. Libraries that link against Core
+  on Windows will have to adjust their compiler flags accordingly.
+  PR [#2611](https://github.com/realm/realm-core/pull/2611).
+* Win32+UWP: Switched from pthread-win32 to native API.
+  PR [#2602](https://github.com/realm/realm-core/pull/2602).
+* Implemented inter-process CondVars on Windows (Win32 + UWP). They should be
+  fair and robust.
+  PR [#2497](https://github.com/realm/realm-core/pull/2497).
+* The archives produced by the packaging process for Mac builds are now
+  .tar.gz files rather than .tar.xz files, with the exception of the aggregate
+  realm-core-cocoa-VERSION.tar.xz archive, which remains as a .tar.xz file.
+
+----------------------------------------------
+
+# 2.9.2 Release notes
+
+### Bugfixes
+
+* Throw a MaximumFileSizeExceeded exception during commits or allocations
+  instead of causing corruption or asserting. This would most likely be
+  seen when creating large Realm files on 32 bit OS.
+  PR [#2795](https://github.com/realm/realm-core/pull/2795).
+
+**Note: This is a hotfix release built on top of 2.9.1. The above fixes are not present in version 3.0.0.**
+
+----------------------------------------------
+
+# 2.9.1 Release notes
+
+### Bugfixes
+
+* A linker error in some configurations was addressed by adding an explicit
+  instantiation of `Table::find_first` for `BinaryData`.
+  [#2823](https://github.com/realm/realm-core/pull/2823).
+
+-----------
+
+### Internals
+
+* The archives produced by the packaging process for Mac builds are now
+  .tar.gz files rather than .tar.xz files, with the exception of the aggregate
+  realm-core-cocoa-VERSION.tar.xz archive, which remains as a .tar.xz file.
+
+**Note: This is a hotfix release built on top of 2.9.0. The above fixes are not present in version 3.0.0.**
+
+----------------------------------------------
+
+# 2.9.0 Release notes
+
+### Bugfixes
+
+* Attempting to open a small unencrypted Realm file with an encryption key would
+  produce an empty encrypted Realm file. Fixed by detecting the case and
+  throwing an exception.
+  PR [#2645](https://github.com/realm/realm-core/pull/2645)
+* Querying SharedGroup::wait_for_change() immediately after a commit()
+  would return instead of waiting for the next change.
+  PR [#2563](https://github.com/realm/realm-core/pull/2563).
+* Opening a second SharedGroup may trigger a file format upgrade if the history
+  schema version is non-zero.
+  Fixes issue [#2724](https://github.com/realm/realm-core/issues/2724).
+  PR [#2726](https://github.com/realm/realm-core/pull/2726).
+* Fix incorrect results from TableView::find_first().
+* Fix crash on rollback of Table::optimize(). Currently unused by bindings.
+  PR [#2753](https://github.com/realm/realm-core/pull/2753).
+* Update frozen TableViews when Table::swap() is called.
+  PR [#2757](https://github.com/realm/realm-core/pull/2757).
+
+### Enhancements
+
+* Add method to get total count of backlinks for a row.
+  PR [#2672](https://github.com/realm/realm-core/pull/2672).
+* Add try_remove_dir() and try_remove_dir_recursive() functions.
+
+-----------
+
+### Internals
+
+* On Apple platforms, use `os_log` instead of `asl_log` when possible.
+  PR [#2722](https://github.com/realm/realm-core/pull/2722).
+
+----------------------------------------------
+
+# 2.8.6 Release notes
+
+### Bugfixes
+* Fixed a bug where case insensitive queries wouldn't return all results.
+  PR [#2675](https://github.com/realm/realm-core/pull/2675).
+
+----------------------------------------------
+
+# 2.8.5 Release notes
+
+### Internals
+
+* `_impl::GroupFriend::get_top_ref()` was added.
+  PR [#2683](https://github.com/realm/realm-core/pull/2683).
+
+----------------------------------------------
+
+# 2.8.4 Release notes
+
+### Bugfixes
+
+* Fixes bug in encryption that could cause deadlocks/hangs and possibly
+  other bugs too.
+  Fixes issue [#2650](https://github.com/realm/realm-core/pull/2650).
+  PR [#2668](https://github.com/realm/realm-core/pull/2668).
+
+-----------
+
+### Internals
+
+* Fix an assert that prevented `Group::commit()` from discarding history from a
+  Realm file opened in nonshared mode (via `Group::open()`, as opposed to
+  `SharedGroup::open()`).
+  PR [#2655](https://github.com/realm/realm-core/pull/2655).
+* Improve ASAN and TSAN build modes (`sh build.sh asan` and `sh build.sh tsan`)
+  such that they do not clobber the files produced during regular builds, and
+  also do not clobber each others files. Also `UNITTEST_THREADS` and
+  `UNITTEST_PROGRESS` options are no longer hard-coded in ASAN and TSAN build
+  modes.
+  PR [#2660](https://github.com/realm/realm-core/pull/2660).
+
+----------------------------------------------
+
+# 2.8.3 Release notes
+
+### Internals
+
+* Disabled a sleep in debug mode that was impairing external tests.
+  PR [#2651](https://github.com/realm/realm-core/pull/2651).
+
+----------------------------------------------
+
+# 2.8.2 Release notes
+
+### Bugfixes
+
+* Now rejecting a Realm file specifying a history schema version that is newer
+  than the one expected by the code.
+  PR [#2642](https://github.com/realm/realm-core/pull/2642).
+* No longer triggering a history schema upgrade when opening an empty Realm file
+  (when `top_ref` is zero).
+  PR [#2642](https://github.com/realm/realm-core/pull/2642).
+
+----------------------------------------------
+
+# 2.8.1 Release notes
+
+### Bugfixes
+
+* Add #include <realm/util/safe_int_ops.hpp> in alloc.hpp.
+  PR [#2622](https://github.com/realm/realm-core/pull/2622).
+* Fix crash in large (>4GB) encrypted Realm files.
+  PR [#2572](https://github.com/realm/realm-core/pull/2572).
+* Fix missing symbols for some overloads of Table::find_first
+  in some configurations.
+  PR [#2624](https://github.com/realm/realm-core/pull/2624).
+
+----------------------------------------------
+
+# 2.8.0 Release notes
+
+### Bugfixes
+
+* Fix a race condition in encrypted files which can lead to
+  crashes on devices using OpenSSL (Android).
+  PR [#2616](https://github.com/realm/realm-core/pull/2616).
+
+### Enhancements
+
+* Enable encryption on watchOS.
+  Cocoa issue [#2876](https://github.com/realm/realm-cocoa/issues/2876).
+  PR [#2598](https://github.com/realm/realm-core/pull/2598).
+* Enforce consistent use of encryption keys across all threads.
+  PR [#2558](https://github.com/realm/realm-core/pull/2558).
+
+----------------------------------------------
+
+# 2.7.0 Release notes
+
+### Bugfixes
+
+* Fix for creating process-shared mutex objects in the wrong kernel object namespace on UWP.
+  PR [#2579](https://github.com/realm/realm-core/pull/2579).
+
+### Enhancements
+
+* Add `Group::compute_aggregated_byte_size()` and
+  `Table::compute_aggregated_byte_size()` for debugging/diagnostics purposes.
+  PR [#2591](https://github.com/realm/realm-core/pull/2591).
+* `Table` and `TableView` refactoring and improvements.
+  PR [#2571](https://github.com/realm/realm-core/pull/2571).
+  * Add a templated version of `Table::set()` to go with `Table::get()`.
+  * Add `TableView::find_first_timestamp()`.
+  * Add `TableView::find_first<T>()`.
+  * Make `Table::find_first<T>()` public and add support for most column types.
+  * Add wrappers for `Table::set<T>()` to `Row`.
+  * Add support for all column types in `Table::get<T>()`.
+
+-----------
+
+### Internals
+
+* Make `Array::stats()` available in release mode builds (not just in debug mode
+  builds).
+  PR [#2591](https://github.com/realm/realm-core/pull/2591).
+
+----------------------------------------------
+
+# 2.6.2 Release notes
+
+### Bugfixes
+
+* Fix for incorrect, redundant string index tree traversal for case insensitive searches
+  for strings with some characters being identical in upper and lower case (e.g. numbers).
+  PR [#2578](https://github.com/realm/realm-core/pull/2578),
+  Cocoa issue [#4895](https://github.com/realm/realm-cocoa/issues/4895)
+
+----------------------------------------------
+
+# 2.6.1 Release notes
+
+### Bugfixes
+
+* `mkfifo` on external storage fails with `EINVAL` on some devices with Android 7.x,
+  which caused crash when opening Realm.
+  PR[#2574](https://github.com/realm/realm-core/pull/2574),
+  Issue [#4461](https://github.com/realm/realm-java/issues/4461).
+
+----------------------------------------------
+
+# 2.6.0 Release notes
+
+### Bugfixes
+
+* Work around a bug in macOS which could cause a deadlock when trying to obtain a shared lock
+  using flock(). PR [#2552](https://github.com/realm/realm-core/pull/2552),
+  issue [#2434](https://github.com/realm/realm-core/issues/2434).
+
+### Enhancements
+
+* Add support for `SharedGroup::try_begin_write()` and corresponding `try_lock()`
+  functionality in low level Mutex classes.
+  PR [#2547](https://github.com/realm/realm-core/pull/2547/files)
+  Fixes issue [#2538](https://github.com/realm/realm-core/issues/2538)
+* New file system utility functions: `util::remove_dir_recursive()` and
+  `util::File::for_each()`. PR [#2556](https://github.com/realm/realm-core/pull/2556).
+* Made case insensitive queries use the new index based case insensitive search.
+  PR [#2486](https://github.com/realm/realm-core/pull/2486)
+
+----------------------------------------------
+
+# 2.5.1 Release notes
+
+### Enhancements
+
+* Restore support for opening version 6 files in read-only mode.
+  PR [#2549](https://github.com/realm/realm-core/pull/2549).
+
+----------------------------------------------
+
+# 2.5.0 Release notes
+
+### Bugfixes
+
+* Fixed a crash when rolling back a transaction which set binary or string data
+  inside a Mixed type.
+  PR [#2501](https://github.com/realm/realm-core/pull/2501).
+* Properly refresh table accessors connected by backlinks to a row that has had
+  a `merge_rows` instruction applied and then rolled back. This could have
+  caused corruption if this scenario was triggered but since sync does not use
+  the `merge_rows` instruction in this way, this is a preventative fix.
+  PR [#2503](https://github.com/realm/realm-core/pull/2503).
+* Fixed an assertion on a corner case of reallocation on large arrays.
+  PR [#2500](https://github.com/realm/realm-core/pull/2500).
+  Fixes issue [#2451](https://github.com/realm/realm-core/issues/2451).
+
+### Breaking changes
+
+* Disable copying of various classes to prevent incorrect use at compile time.
+  PR [#2468](https://github.com/realm/realm-core/pull/2468).
+* History type enumeration value `Replication::hist_Sync` renamed to
+  `Replication::hist_SyncClient`.
+  PR [#2482](https://github.com/realm/realm-core/pull/2482).
+* Bumps file format version from 6 to 7 due to addition of a 10th element into
+  `Group::m_top`. The new element is the history schema version, which is
+  crucial for managing the schema upgrade process of sync-type histories in a
+  way that is independent of core's Realm file format. The bump is necessary due
+  to lack of forwards compatibility. The changes are backwards compatible, and
+  automatic upgrade is implemented.
+  PR [#2481](https://github.com/realm/realm-core/pull/2481).
+* New pure virtual methods `get_history_schema_version()`,
+  `is_upgradable_history_schema()`, and `upgrade_history_schema()` in
+  `Replication` interface.
+  PR [#2481](https://github.com/realm/realm-core/pull/2481).
+
+### Enhancements
+
+* Support setting Mixed(Timestamp) through the transaction logs.
+  PR [#2507](https://github.com/realm/realm-core/pull/2507).
+* Implement comparison of Mixed objects containing Timestamp types.
+  PR [#2507](https://github.com/realm/realm-core/pull/2507).
+* Allow query for size of strings, binaries, linklists and subtables:
+  Query q = table->where().size_equal(2, 5);
+  Query q = table1->column<SubTable>(2).size() == 5;
+  PR [#2504](https://github.com/realm/realm-core/pull/2504).
+* New history type enumeration value `Replication::hist_SyncServer`. This allows
+  for the sync server to start using the same kind of in-Realm history scheme as
+  is currently used by clients.
+  PR [#2482](https://github.com/realm/realm-core/pull/2482).
+
+-----------
+
+### Internals
+
+* `StringIndex` now supports case insensitive searches.
+  PR [#2475](https://github.com/realm/realm-core/pull/2475).
+* `AppendBuffer` gained support for move construction/assignment, and had its
+  growth factor reduced to 1.5.
+  PR [#2462](https://github.com/realm/realm-core/pull/2462).
+* Methods on the `Replication` interface were made virtual to allow override.
+  PR [#2462](https://github.com/realm/realm-core/pull/2462).
+* The order of emission for some instructions in the transaction log was changed
+  with respect to carrying out the effect of the instruction on the database, to
+  allow implementors of the `Replication` interface a semi-consistent view of
+  the database.
+  PR [#2462](https://github.com/realm/realm-core/pull/2462).
+* Lock file format bumped from version 9 to 10 due to introduction of
+  `SharedInfo::history_schema_version`.
+  PR [#2481](https://github.com/realm/realm-core/pull/2481).
+* Removal of obsolete logic and semantics relating to obsolete history type
+  `Replication::hist_OutOfRealm`.
+  PR [#2481](https://github.com/realm/realm-core/pull/2481).
+* Code specific to history type `Replication::hist_InRealm` (class
+  `_impl::InRealmHistory` in particular) was moved from
+  `realm/impl/continuous_transactions_history.hpp` and
+  `realm/impl/continuous_transactions_history.cpp` to `realm/sync/history.cpp`.
+  PR [#2481](https://github.com/realm/realm-core/pull/2481).
+
+----------------------------------------------
+
+# 2.4.0 Release notes
+
+### Bugfixes
+
+* Fixes a bug in chuncked binary column returning null value.
+  PR [#2416](https://github.com/realm/realm-core/pull/2416).
+  Fixes issue [#2418](https://github.com/realm/realm-core/issues/2418).
+* Possibly fixed some cases of extreme file size growth, by preventing starvation
+  when trying to start a write transaction, while simultaneously pinning an older
+  version.
+  PR [#2395](https://github.com/realm/realm-core/pull/2395).
+* Fixed a bug when deleting a column used in a query.
+  PR [#2408](https://github.com/realm/realm-core/pull/2408).
+* Fixed a crash that occurred if you tried to override a binary with a size close
+  to the limit.
+  PR [#2416](https://github.com/realm/realm-core/pull/2416).
+* `seekpos()` and `seekoff()` in `realm::util::MemoryInputStreambuf` now behave
+  correctly when argument is out of range.
+  PR [#2472](https://github.com/realm/realm-core/pull/2472).
+
+### Breaking changes
+
+* The table macros, supporting the typed interface, has been removed.
+  PR [#2392](https://github.com/realm/realm-core/pull/2392).
+* Layout and version change for the .lock file required in order to prevent
+  starvation when waiting to start a write transaction (see above).
+  PR [#2395](https://github.com/realm/realm-core/pull/2395).
+
+### Enhancements
+
+* Now supports case insensitive queries for UWP.
+  PR [#2389](https://github.com/realm/realm-core/pull/2389).
+* Upgraded Visual Studio project to version 2017.
+  PR [#2389](https://github.com/realm/realm-core/pull/2389).
+* Support handover of TableViews and Queries based on SubTables.
+  PR [#2470](https://github.com/realm/realm-core/pull/2470).
+* Enable reading and writing of big blobs via Table interface.
+  Only to be used by Sync. The old interface still has a check on
+  the size of the binary blob.
+  PR [#2416](https://github.com/realm/realm-core/pull/2416).
+
+----------------------------------------------
+
+# 2.3.3 Release notes
+
+### Bugfixes
+
+* Fix a hang in LIKE queries that could occur if the pattern required
+  backtracking. PR [#2477](https://github.com/realm/realm-core/pull/2477).
+* Bug fixed in `GroupWriter::write_group()` where the maximum size of the top
+  array was calculated incorrectly. This bug had the potential to cause
+  corruption in Realm files. PR [#2480](https://github.com/realm/realm-core/pull/2480).
+
+### Enhancements
+
+* Use only a single file descriptor in our emulation of interprocess condition variables
+  on most platforms rather than two. PR [#2460](https://github.com/realm/realm-core/pull/2460). Fixes Cocoa issue [#4676](https://github.com/realm/realm-cocoa/issues/4676).
+
+----------------------------------------------
+
+# 2.3.2 Release notes
+
+### Bugfixes
+* Fixed race condition bug that could cause crashes and corrupted data
+  under rare circumstances with heavy load from multiple threads accessing
+  encrypted data. (sometimes pieces of data from earlier commits could be seen).
+  PR [#2465](https://github.com/realm/realm-core/pull/2465). Fixes issue [#2383](https://github.com/realm/realm-core/issues/2383).
+* Added SharedGroupOptions::set_sys_tmp_dir() and
+  SharedGroupOptions::set_sys_tmp_dir() to solve crash when compacting a Realm
+  file on Android external storage which is caused by invalid default sys_tmp_dir.
+  PR [#2445](https://github.com/realm/realm-core/pull/2445). Fixes Java issue [#4140](https://github.com/realm/realm-java/issues/4140).
+
+-----------
+
+### Internals
+
+* Remove the BinaryData constructor taking a temporary object to prevent some
+  errors in unit tests at compile time. PR [#2446](https://github.com/realm/realm-core/pull/2446).
+* Avoid assertions in aggregate functions for the timestamp type. PR [#2466](https://github.com/realm/realm-core/pull/2466).
+
+----------------------------------------------
+
+# 2.3.1 Release notes
+
+### Bugfixes
+
+* Fixed a bug in handover of detached linked lists. (issue #2378).
+* Fixed a bug in advance_read(): The memory mappings need to be updated and
+  the translation cache in the slab allocator must be invalidated prior to
+  traversing the transaction history. This bug could be reported as corruption
+  in general, or more likely as corruption of the transaction log. It is much
+  more likely to trigger if encryption is enabled. (issue #2383).
+
+### Enhancements
+
+* Avoid copying copy-on-write data structures when the write does not actually
+  change the existing value.
+* Improve performance of deleting all rows in a TableView.
+* Allow the `add_int()` API to be called on a `Row`
+* Don't open the notification pipes on platforms which support the async commit
+  daemon when async commits are not enabled
+
+-----------
+
+### Internals
+
+* Updated OpenSSL to 1.0.2k.
+* Setting environment variable `UNITTEST_XML` to a nonempty value will no longer
+  disable the normal console output while running the test suite. Instead, in
+  that case, reporting will happen both to the console and to the JUnit XML
+  file.
+
+----------------------------------------------
+
+# 2.3.0 Release notes
+
+### Bugfixes
+
+* Fixed various bugs in aggregate methods of Table, TableView and Query for nullable columns
+  (max, min, avg, sum). The results of avg and sum could be wrong and the returned index of
+  the min and max rows could be wrong. Non-nullable columns might not have been affected.
+  One of the bugs are described here https://github.com/realm/realm-core/issues/2357
+* Prevent `stdin` from being accidentally closed during `~InterProcessCondVar()`.
+
+### Breaking changes
+
+* Attempts to open a Realm file with a different history type (Mobile Platform vs
+  Mobile Database) now throws an IncompatibleHistories exception instead of a
+  InvalidDatabase (as requested in issue #2275).
+
+### Enhancements
+* Windows 10 UWP support. Use the new "UWP" configurations in Visual Studio to
+  compile core as a static .lib library for that platform. Also see sample App
+  in the uwp_demo directory that uses the static library (compile the .lib first).
+  Note that it is currently just an internal preview with lots of limitations; see
+  https://github.com/realm/realm-core/issues/2059
+* Added 'void SharedGroup::get_stats(size_t& free_space, size_t& used_space)'
+  allowing access to the size of free and used space (Requested in issue #2281).
+* Optimized Contains queries to use Boyer-Moore algorithm (around 10x speedup on large datasets)
+* Parameter arguments passed to logger methods (e.g., `util::Logger::info()`)
+  are now perfectly forwarded (via perfect forwarding) to `std::stream::operator<<()`.
+
+-----------
+
+### Internals
+
+* Unit tests now support JUnit output format.
+
+----------------------------------------------
+
+# 2.2.1 Release notes
+
+### Enhancements
+
+* Parameter arguments passed to logger methods (e.g., `util::Logger::info()`)
+  are now perfectly forwarded (via perfect forwarding) to
+  `std::stream::operator<<()`.
+
+-----------
+
+### Internals
+
+* Make `_impl::make_error_code(_impl::SimulatedFailure::FailureType)`
+  participate in overload resolution in unqualified ADL contexts like
+  `make_error_code(_impl::SimulatedFailure::sync_client__read_head)` and `ec ==
+  _impl::SimulatedFailure::sync_client__read_head`.
+* `P_tmpdir` should not be used on Android. A better default name for temporary
+  folders has been introduced.
+
+----------------------------------------------
+
+# 2.2.0 Release notes
+
+### Bugfixes
+* Fix possible corruption of realm file in case of more than 1000 entries in a
+  link list (#2289, #2292, #2293, #2295, #2301)
+* Fixed crash in query if a table had been modified so much that payload array
+  leafs had relocated (#2269)
+* Fix a race involving destruction order of InterprocessMutex static variables.
+* Fix a crash when a Query is reimported into the SharedGroup it was exported
+  for handover from.
+* Fix a crash when calling mkfifo on Android 4.x external storage. On 4.x devices,
+  errno is EPERM instead of EACCES.
+* Fix a crash when updating a LinkView accessor from a leaf to an inner node. (#2321)
+
+### Breaking changes
+
+* The return type of `util::File::copy()` has been changed from `bool` to
+  `void`. Errors are now reported via `File::AccessError` exceptions. This
+  greatly increases the utility and robustness of `util::File::copy()`, as it
+  now catches all errors, and reports them in the same style as the other
+  functions in `util::File`.
+
+### Enhancements
+
+* Added support for LIKE queries (wildcard with `?` and `*`)
+* Offer facilities to prevent multiple sync agents per Realm file access session
+  (`Replication::is_sync_agent()` to be overridden by sync-specific
+  implementation). The utilized lock-file flag
+  (`SharedInfo::sync_agent_present`) was added a long time ago, but the
+  completion of detection mechanism got postponed until now.
+* Improve performance of write transactions which free a large amount of
+  existing data.
+* Added `util::File::compare()` for comparing two files for equality.
+
+-----------
+
+### Internals
+
+* Added extra check for double frees in slab allocator.
+* Deprecated Array type parameters in Column<T> and BpTree<T> constructors
+
+----------------------------------------------
+
+# 2.1.4 Release notes
+
+### Bugfixes
+
+* Fix storage of very large refs (MSB set) on 32-bit platforms.
+* Fixed a race between destruction of a global mutex as part of main thread exit
+  and attempt to lock it on a background thread, or conversely attempt to lock a
+  mutex after it has been destroyed. (PR #2238, fixes issues #2238, #2137, #2009)
+
+----------------------------------------------
+
+# 2.1.3 Release notes
+
+### Bugfixes
+
+* Deleting rows through a `TableView` generated wrong instructions by way of
+  `Table::batch_erase_rows()`, which would only be noticed after reapplying the
+  transaction log to a separate Realm file or via synchronization.
+
+-----------
+
+### Internals
+
+* `array_direct.hpp` added to installed headers.
+
+----------------------------------------------
+
+# 2.1.2 Release notes
+
+### Bugfixes
+
+* When adding a nullable column of type Float while other columns existed
+  already, the values of the new column would be non-null. This is now fixed.
+
+----------------------------------------------
+
+# 2.1.1 Release notes
+
+### Internals
+
+* Upgraded to OpenSSL 1.0.2j.
+
+----------------------------------------------
+
+# 2.1.0 Release notes
+
+### Bugfixes
+
+* Fix an assertion failure when upgrading indexed nullable int columns to the
+  new index format.
+* Extra SetUnique instructions are no longer generated in the transaction log
+  when a conflict was resolved locally.
+
+### Breaking changes
+
+* The ChangeLinkTargets instruction was a misnomer and has been renamed to
+  MergeRows.
+
+-----------
+
+### Internals
+
+* Android builds: upgraded to OpenSSL 1.0.1u.
+* The behavior of MergeRows (formerly ChangeLinkTargets) has been simplified to
+  be semantically equivalent to a row swap.
+
+----------------------------------------------
+
+# 2.0.0 Release notes
+
+### Bugfixes
+
+* TimestampColumn::is_nullable() could return a wrong value. Also, when adding a new
+  Float/Double column to a Table with rowcount > 0, the new entries would be non-null
+  even though the column was created as nullable.
+* Update accessors after a change_link_target or set_unique operation, so that users
+  will have the latest data immediately. Previously this would require manually
+  refetching the data or looking for the unique key again.
+
+----------------------------------------------
+
+# 2.0.0-rc9 Release notes
+
+### Internals
+
+* Use Xcode 7.3.1 to build core for Cocoa
+
+----------------------------------------------
+
+# 2.0.0-rc8 Release notes
+
+### Bugfixes
+
+* Fixed a crash related to queries that was introduced in rc7. (#2186)
+* Fixed a bug triggered through set unique of primary keys through
+  the ROS. (#2180)
+
+-----------
+
+### Internals
+
+* Optimized query code on a string column with a search index to address a
+  performance regression observed in the recent format changes to the
+  string index (see #2173)
+
+----------------------------------------------
+
+# 2.0.0-rc7 Release notes
+
+### Bugfixes
+
+* Fixed a race in the handover machinery which could cause crashes following handover
+  of a Query or a TableView. (#2117)
+* Reversed the decision process of resolving primary key conflicts. Instead of
+  letting the newest row win, the oldest row will now always win in order to not
+  lose subsequent changes.
+
+-----------
+
+### Breaking changes
+
+* Changed the format of the StringIndex structure to not recursivly store
+  strings past a certain depth. This fixes crashes when storing strings
+  with a long common prefix in an index. This is a file format breaking change.
+  The file format has been incremented and old Realm files must upgrade.
+  The upgrade will rebuild any StringIndexes to the new format automatically
+  so other than the upgrade, this change should be effectivly invisible to
+  the bindings. (see #2153)
+
+-----------
+
+### Internals
+
+* Removed ("deleted") the default copy constructor for RowBase. This constructor
+  was used by accident by derived classes, which led to a data race. Said race was
+  benign, but would be reported by the thread sanitizer.
+
+----------------------------------------------
+
+# 2.0.0-rc6 Release notes
+
+### Enhancements
+
+* Added debian packages for Ubuntu 16.04.
+
+----------------------------------------------
+
+# 2.0.0-rc4 Release notes
+
+### Bugfixes
+
+* Fixed a bug where find() on a Query constructed from a restricting view
+  did not correctly return an row index into the underlying table.
+  (issue #2127)
+* Fixed a bug where linked tables were not updated after a table move operation, when
+  run through the replicator.
+* Fixed a bug where moving a column to itself caused a crash.
+
+### Breaking changes
+
+* New instruction for `Table::add_int()`, which impacts the transaction log
+  format.
+
+### Enhancements
+
+* Added `Table::add_int()` for implementing CRDT counters.
+
+----------------------------------------------
+
+# 2.0.0-rc3 Release notes
+
+### Bugfixes
+
+* Fixed a bug with link columns incorrectly updating on a `move_last_over`
+  operation when the link points to the same table.
+* Fix subspecs not updating properly after a move operation.
+* Fixed various crashes when using subtables. The crash will occur when the first column
+  of the subtable if of type `col_type_Timestamp` or if it is nullable and of type Bool, Int
+  or OldDateTime. Caused by bad static `get_size_from_ref()` methods of columns. (#2101)
+* Fixed a bug with link columns incorrectly updating on a `move_last_over`
+  operation when the link points to the same table.
+
+### Breaking changes
+
+* Refactored the `SharedGroup` constructors and open methods to use a new
+  `SharedGroupOptions` parameter which stores all options together.
+* BREAKING! Until now, a Query would return indexes into a restricting view if such was
+  present (a view given in the `.where(&view) method`, or it would return indexes into the
+  Table if no restricting view was present. This would make query results useless if you did
+  not know whether or not a restricting view was present. This fix make it *always* return
+  indexes into the Table in all cases. Also, any `begin` and `end` arguments could point into
+  eitherthe View or the Table. These now always point into the Table. Also see
+  https://github.com/realm/realm-core/issues/1565
+
+### Enhancements
+
+* Accessors pointing to subsumed rows are updated to the new row rather than detached.
+
+-----------
+
+### Internals
+
+* When creating a `SharedGroup`, optionally allow setting the temporary
+  directory to when making named pipes fails. This is to fix a bug
+  involving mkfifo on recent android devices (#1959).
+* Bug fixed in test harness: In some cases some tests and checks would be
+  counted twice due to counters not being reset at all the right times.
+
+----------------------------------------------
+
+# 2.0.0-rc2 Release notes
+
+### Enhancements
+
+* Add back log level prefixes for `StderrLogger` and `StreamLogger`
+
+----------------------------------------------
+
+# 2.0.0-rc1 Release notes
+
+### Breaking changes
+
+* API Breaking change: Added log level argument to util::Logger::do_log().
+  Existing implementations can ignore the argument, or use it to add log level
+  info to the log output.
+* API Breaking change: The WriteLogCollector is no longer available.
+  To create a history object for SharedGroup, make_in_realm_history()
+  must now be used instead of make_client_history().
+* The commit logs have been moved into the Realm file. This means we no longer
+  need the .log_a, .log_b and .log files, significantly reducing the number of
+  both files and open file handles. This is a breaking change, since versions
+  without .log files cannot interoperate with earlier versions which still
+  uses separate .log files. (issues #2065, #1354).
+* The version for .lock-file data has been bumped to reflect that this is
+  an API breaking change.
+
+### Enhancements
+
+* Elimination of the .log files also eliminates all locking related to
+  accessing  the .log files, making read-transactions lock-free.
+* The critical phase of commits have been reduced significantly in length.
+  If a process is killed while in the critical phase, any other process
+  working jointly on the same Realm file is barred from updating the Realm
+  file until the next session. Reducing the length of the critical phase
+  reduces the risk of any user experiencing this limitation.
+  (issues #2065, #1354)
+
+-----------
+
+### Internals
+
+* Added support for very large commit history entries. (issues #2038, #2050)
+  This also implies an API change (but to the internal API) to the
+  History::get_changesets() method, which must be taken into account by
+  any derived classes.
+* Support for setting and getting thread names (`util::Thread::set_name()` and
+  `util::Thread::get_name()`) when the platform supports
+  it. `util::Thread::set_name()` is now used by the test harness as a help while
+  debugging. Also, the terminate handler (in `util/terminate.cpp`) writes out
+  the name of the terminating thread if the name is available.
+* Fixed doxygen warnings.
+
+----------------------------------------------
+
+# 2.0.0-rc0 Release notes
+
+### Internals
+
+* Changed instruction log format of Set instructions to be more amenable to the
+addition of future variants.
+* Changed instruction log format of LinkList instructions to include information
+about the size of the list in question prior to carrying out the instruction.
+
+----------------------------------------------
+
+# 1.5.1 Release notes
+
+### Bugfixes
+
+* Fixed java bug #3144 / Core #2014. Management of Descriptor class was
+  not thread safe with respect to destruction/creation/management of
+  accessor tree. Bug could be triggered by destruction of TableView on
+  one thread, while new TableViews where created on a different thread.
+* Fixed incorrect results when updating a backlink TableView after inserting
+  new columns into the source table.
+
+----------------------------------------------
+
+# 1.5.0 Release notes
+
+### Bugfixes
+
+* Fix a race condition that could result in a crash if a `LinkView` was
+  destroyed while another thread was adjusting accessors on a `LinkListColumn`.
+* Fix crashes and general brokenness when constructing a Query, inserting a
+  column into the queried table, and then running the query.
+* Fix crashes and general brokenness when syncing a sorted or distincted
+  TableView after inserting new columns into the source Table.
+
+### Breaking changes
+
+* Added support for sorting and distincting table views through a chain of
+  links. (#1030)
+
+### Enhancements
+
+* Improve performance of sorting on non-nullable columns.
+* Improve overall sort performance.
+
+-----------
+
+### Internals
+
+* Updated the header license to prepare for open sourcing the code.
+
+----------------------------------------------
+
+# 1.4.2 Release notes
+
+### Bugfixes
+
+* Fix a bug with the local mutex for the robust mutex emulation.
+* Reduce the number of file descriptors used in robust mutex emulation,
+  multi instances of InterprocessMutex share the same descriptor. (#1986)
+
+----------------------------------------------
+
+# 1.4.1 Release notes
+
+### Bugfixes
+
+* Fixing util::MemoryInputStream to support tellg() and seekg().
+* Fix truncation of the supplied value when querying for a float or double that
+  is less than a column's value.
+* Workaround for the Blackberry mkfifo bug.
+
+-----------
+
+### Internals
+
+* Removed `realm::util::network` library.
+* Removed event loop library.
+* Reduced the number of open files on Android.
+
+----------------------------------------------
+
+# 1.4.0 Release notes
+
+### Breaking changes
+
+* Throw a logic error (of type `table_has_no_columns`) if an attempt is made to
+  add rows to a table with no columns. (#1897)
+* S: A clear operation is emitted on removal of the last public column of a table.
+
+----------------------------------------------
+
+# 1.3.1 Release notes
+
+### Bugfixes
+
+* Add missing locks when access `Table::m_views` which may lead to some java
+  crashes since java will not guarantee destruction and construction always
+  happen in the same thread. (#1958)
+* Fixed a bug where tableviews created via backlinks were not automatically
+  updated when the source table changed. (#1950)
+
+### Breaking changes
+
+* Throw a logic error (of type `table_has_no_columns`) if an attempt is made to
+  add rows to a table with no columns. (#1897)
+* S: A clear operation is emitted on removal of the last public column of a table.
+
+### Enhancements
+
+* Increased the verbosity of some exception error messages to help debugging.
+
+----------------------------------------------
+
+# 1.3.0 Release notes
+
+### Bugfixes
+
+* Fix a crash when `Group::move_table()` is called before table accessors are
+  initialized. (#1939)
+
+### Breaking changes
+
+* Sorting with `STRING_COMPARE_CORE` now sorts with pre 1.1.2 ordering. Sorting
+  with 1.1.2 order is available by using `STRING_COMPARE_CORE_SIMILAR`. (#1947)
+
+-----------
+
+### Internals
+
+* Performance improvements for `LinkListColumn::get_ptr()`. (#1933)
+
+----------------------------------------------
+
+# 1.2.0 Release notes
+
+### Bugfixes
+
+* Update table views so that rows are not attached after calling Table::clear() (#1837)
+* The SlabAlloctor was not correctly releasing all its stale memory mappings
+  when it was detached. If a SharedGroup was reused to access a database
+  following both a call of compact() and a commit() (the latter potentially
+  by a different SharedGroup), the stale memory mappings would shadow part
+  of the database. This would look like some form of corruption. Specifically
+  issues #1092 and #1601 are known to be symptoms of this bug, but issues
+  #1506 and #1769 are also likely to be caused by it. Note that even though
+  this bug looks like corruption, the database isn't corrupted at all.
+  Reopening it by a different SharedGroup will work fine; Only the SharedGroup
+  that executed the compact() will have a stale view of the file.
+* Check and retry if flock() returns EINTR (issue #1916)
+* The slabs (regions of memory used for temporary storage during a write transaction),
+  did not correctly track changes in file size, if the allocator was detached, the
+  file shrunk and the allocator was re-attached. This scenario can be triggered by
+  compact, or by copying/creating a new realm file which is then smaller than the
+  old one when you re-attach. The bug led to possible allocation of overlapping
+  memory chunks, one of which would then later corrupt the other. To a user this
+  would look like file corruption. It is theoretically possibly, but not likely,
+  that the corrupted datastructure could be succesfully committed leading to a real
+  corruption of the database. The fix is to release all slabs when the allocator
+  is detached. Fixes #1898, #1915, #1918, very likely #1337 and possibly #1822.
+
+### Breaking changes
+
+* Removed the 'stealing' variant of export for handover. It was not a great
+  idea. It was not being used and required locking which we'd like to avoid.
+* S: A concept of log levels was added to `util::Logger`. `util::Logger::log()`
+  now takes a log level argument, and new shorthand methods were added
+  (`debug()`, `info()`, `warn()`, ...). All loggers now have a `level_threshold`
+  property through which they efficiently query for the current log level
+  threshold.
+
+### Enhancements
+
+* Allow SharedGroups to pin specific versions for handover
+* Reduced the object-size overhead of assertions.
+* Fixed a spelling mistake in the message of the `LogicError::wrong_group_state`.
+
+-----------
+
+### Internals
+
+* Non concurrent tests are run on the main process thread. (#1862)
+* S: `REALM_QUOTE()` macro moved from `<realm/version.hpp>` to
+  `<realm/util/features.h>`. This also fixes a dangling reference to
+  `REALM_QUOTE_2()` in `<realm/util/features.h>`.
+* Minimize the amount of additional virtual address space used during Commit().
+  (#1478)
+* New feature in the unit test framework: Ability to specify log level
+  threshold for custom intra test logging (`UNITTEST_LOG_LEVEL`).
+* Switch from `-O3` to `-Os` to compile OpenSSL: https://github.com/android-ndk/ndk/issues/110
+
+----------------------------------------------
+
+
+# 1.1.2 Release notes
+
+### Bugfixes
+
+* S: In the network API (namespace `util::network`), do not report an error to
+  the application if system calls `read()`, `write()`, or `accept()` fail with
+  `EAGAIN` on a socket in nonblocking mode after `poll()` has signalled
+  readiness. Instead, go back and wait for `poll()` to signal readiness again.
+
+### Breaking changes
+
+* Sorting order of strings is now according to more common scheme for special
+  characters (space, dash, etc), and for letters it's now such that visually
+  similiar letters (that is, those that differ only by diacritics, etc) are
+  grouped together. (#1639)
+
+-----------
+
+### Internals
+
+* S: New unit tests `Network_ReadWriteLargeAmount` and
+  `Network_AsyncReadWriteLargeAmount`.
+
+----------------------------------------------
+
+
+# 1.1.1 Release notes
+
+### Bugfixes
+
+* Fixed a recently introduced crash bug on indexed columns (#1869)
+* Implement `TableViewBase`'s copy-assignment operator to prevent link errors when it is used.
+* No longer assert on a "!cfg.session_initiator" in SlabAlloc::attach_file(). This makes issue
+  #1784 go away, but also removes an option to detect and flag if the ".lock" file is deleted
+  while a SharedGroup is attached to the file. Please note: Removal of the ".lock" file while
+  the database is attached may lead to corruption of the database.
+
+### Enhancements
+
+* Improve performance of opening Realm files and making commits when using
+  external writelogs by eliminating some unneeded `fsync()`s.
+
+----------------------------------------------
+
+# 1.1.0 Release notes
+
+### Bugfixes
+
+* Fix for #1846: If an exception is thrown from SlabAlloc::attach_file(), it
+  forgot to unlock a mutex protecting the shared memory mapping. In cases
+  where the last reference to the memory mapping goes out of scope, it would
+  cause the assert "Destruction of mutex in use". Fix is to use unique_lock
+  to ensure the mutex is unlocked before destruction.
+* Fix a crash when `Table::set_string_unique()` is called but the underlying
+  column is actually a StringEnumColumn.
+* Fix an assertion failure when combining a `Query` with no conditions with another `Query`.
+
+### Breaking changes
+
+* S: Type of completion handler arguments changed from `const H&` to `H` for all
+  asynchronous operations offered by the networking API (namespace
+  `util::network`).
+* S: `util::network::deadline_timer::async_wait()` no longer declared `noexcept`
+  (it never should have been).
+
+### Enhancements
+
+* Strictly enforce not allowing search indexes to be created on unsupported column types.
+* S: Event loop API reworked to more closely align with the `util::network` API,
+  and to better provide for multiple alternative implementations (not considered
+  breaking because the event loop API was not yet in use).
+* S: Bugs fixed in the POSIX based implementation (not listed under bug fixes
+  because the event loop API was not yet in use).
+* S: A new Apple CoreFoundation implementation of event loop API was added.
+* S: Movable completion handler objects are no longer copied by the networking
+  API (namespace `util::network`).
+
+-----------
+
+### Internals
+
+* Upgrade build scripts to build as C++14 by default.
+* Corrected two usages of undefined REALM_PLATFORM_ANDROID to REALM_ANDROID.
+  This correctly enables Android log output on termination and allows using
+  robust mutexes on Android platforms. (#1834)
+
+
+----------------------------------------------
+
+# 1.0.2 Release notes
+
+### Internals
+
+* This is functionally the same as 1.0.1. For Xamarin we now do a specialized
+  cocoa build with only iOS support and without bitcode.
+
+----------------------------------------------
+
+# 1.0.1 Release notes
+
+### Bugfixes
+
+* Fix a situation where a failure during SharedGroup::open() could cause stale
+  memory mappings to become accessible for later:
+  In case one of the following exceptions are thrown from SharedGroup::open():
+  - "Bad or incompatible history type",
+  - LogicError::mixed_durability,
+  - LogicError::mixed_history_type,
+  - "File format version deosn't match: "
+  - "Encrypted interprocess sharing is currently unsupported"
+  Then:
+  a) In a single process setting a later attempt to open the file would
+     hit the assert "!cfg.session_initiator" reported in issue #1782.
+  b) In a multiprocess setting, another process would be allowed to run
+     compact(), but the current process would retain its mapping of the
+     old file and attempt to reuse those mappings when a new SharedGroup
+     is opened, which would likely lead to a crash later. In that case, the
+     !cfg.session_initiator would not be triggered.
+  May fix issue #1782.
+
+**Note: This is a hotfix release built on top of 1.0.0
+
+----------------------------------------------
+
+# 1.0.0 Release notes
+
+### Bugfixes
+
+* Fixed move_last_over() replacing null values for binary columns in the moved
+  row with zero-length values.
+
+### Enhancements
+
+* File operations would previously throw `std::runtime_error` for error cases without a
+  specialized exception. They now throw `AccessError` instead and include path information.
+
+-----------
+
+### Internals
+
+* Fixed an error in Query_Sort_And_Requery_Untyped_Monkey2 test which would cause
+  this test to fail sometimes.
+
+----------------------------------------------
+
+# 0.100.4 Release notes
+
+### Bugfixes
+
+* Fix queries over multiple levels of backlinks to work when the tables involved have
+  their backlink columns at different indices.
+
+### Breaking changes
+
+* Reverting the breaking changes wrongly introduced by 0.100.3, so that
+  this release does NOT have breaking changes with respect to 0.100.2
+
+
+----------------------------------------------
+
+# 0.100.3 Release notes (This is a faulty release and should not be used)
+
+### Bugfixes
+
+* Fix initialization of read-only Groups which are sharing file mappings with
+  other read-only Groups for the same path.
+* Fix TableView::clear() to work in imperative mode (issue #1803, #827)
+* Fixed issue with Timestamps before the UNIX epoch not being read correctly in
+  the `TransactLogParser`. Rollbacks and advances with such Timestamps would
+  throw a `BadTransactLog` exception. (#1802)
+
+### Breaking changes
+
+* Search indexes no longer support strings with lengths greater than
+  `Table::max_indexed_string_length`. If you try to add a string with a longer length
+  (through the Table interface), then a `realm::LogicError` will be thrown with type
+  `string_too_long_for_index`. Calling `Table::add_search_index()` will now return a
+  boolean value indicating whether or not the index could be created on the column. If
+  the column contains strings that exceed the maximum allowed length, then
+  `Table::add_search_index()` will return false and the index will not be created, but the data
+  in the underlying column will remain unaffected. This is so that bindings can attempt to
+  create a search index on a column without knowing the lengths of the strings in the column.
+  Realm will continue to operate as before on any search index that already stores strings longer
+  than the maximum allowed length meaning that this change is not file breaking (no upgrade is
+  required). However, as stated above, any new strings that exceed the maximum length will
+  not be allowed into a search index, to insert long strings just turn off the search index
+  (although this could be left up to the user).
+
+### Enhancements
+
+* Distinct is now supported for columns without a search index. Bindings no longer
+  need to ensure that a column has a search index before calling distinct. (#1739)
+
+-----------
+
+### Internals
+
+* Upgrading to OpenSSL 1.0.1t.
+
+----------------------------------------------
+
+# 0.100.2 Release notes
+
+### Bugfixes
+
+* Fix handing over an out of sync TableView that depends on a deleted link list or
+  row so that it doesn't remain perpetually out of sync (#1770).
+* Fix a use-after-free when using a column which was added to an existing table
+  with rows in the same transaction as it was added, which resulted in the
+  automatic migration from DateTime to Timestamp crashing with a stack overflow
+  in some circumstances.
+
+----------------------------------------------
+
+# 0.100.1 Release notes
+
+### Bugfixes:
+
+* Fix for: The commit logs were not properly unmapped and closed when a SharedGroup
+  was closed. If one thread closed and reopened a SharedGroup which was the sole
+  session participant at the time it was closed, while a different SharedGroup opened
+  and closed the database in between, the first SharedGroup could end up reusing it's
+  memory mappings for the commit logs, while the later accesses through a different
+  SharedGroup would operate on a different set of files. This could cause inconsistency
+  between the commit log and the database. In turn, this could lead to crashes during
+  advance_read(), promote_to_write() and possibly commit_and_continue_as_read().
+  Worse, It could also silently lead to accessors pointing to wrong objects which might
+  later open for changes to the database that would be percieved as corrupting. (#1762)
+* Fix for: When commitlogs change in size, all readers (and writers) must update their
+  memory mmapings accordingly. The old mechanism was based on comparing the size of
+  the log file with the previous size and remapping if they differ. Unfortunately, this
+  is not good enough, as the commitlog may first be shrunk, then expanded back to the
+  original size and in this case, the existing mechanism will not trigger remapping.
+  Without remapping in such situations, POSIX considers accesses to the part of the
+  mapping corresponding to deleted/added sections of the file to be undefined. Consequences
+  of this bug could be crashes in advance_read(), promote_to_write() or
+  commit_and_continue_as_read(). Conceivably it could also cause wrong accessor updates
+  leading to accessors pointing to wrong database objects. This, in turn, could lead
+  to what would be percieved as database corruption. (#1764)
+* S: Assertion was sometimes dereferencing a dangling pointer in
+  `util::network::buffered_input_stream::read_oper<H>::recycle_and_execute()`.
+
+### Enhancements:
+
+* S: `util::bind_ptr<>` extended with capability to adopt and release naked
+  pointers.
+* The `SharedGroup` constructor now takes an optional callback function so bindings can
+  be notified when a Realm is upgraded. (#1740)
+
+----------------------------------------------
+
+# 0.100.0 Release notes
+
+### Bugfixes:
+
+* Fix of #1605 (LinkView destruction/creation should be thread-safe) and most
+  likely also #1566 (crash below LinkListColumn::discard_child_accessors...) and
+  possibly also #1164 (crash in SharedGroup destructor on OS X).
+* Copying a `Query` restricted by a `TableView` will now avoid creating a dangling
+  reference to the restricting view if the query owns the view. Dangling references
+  may still occur if the `Query` does not own the restricting `TableView`.
+* Fixed #1747 (valgrind report of unitialized variable).
+* Fixed issue with creation of `ArrayIntNull` with certain default values that would
+  result in an all-null array. (Pull request #1721)
+
+### API breaking changes:
+
+* The return value for LangBindHelper::get_linklist_ptr() and the argument
+  to LangBindHelper::unbind_linklist_ptr has changed from being a 'LinkView*'
+  into a 'const LinkViewRef&'.
+* Fixed a bug, where handing over a TableView based on a Query restricted
+  by another TableView would fail to propagate synchronization status correctly
+  (issue #1698)
+* Fixed TableViews that represent backlinks to track the same row, even if that row
+  moves within its table. (Issue #1710)
+* Fixed incorrect semantics when comparing a LinkList column with a Row using a
+  query expression. (Issue #1713)
+* Fixed TableViews that represent backlinks to not assert beneath `sync_if_needed` when
+  the target row has been deleted.
+* `TableView::depends_on_deleted_linklist` is now `TableView::depends_on_deleted_object`,
+  and will also return true if the target row of a `TableView` that represents backlinks
+  is deleted. (Issue #1710)
+* New nanosecond precision `Timestamp` data and column type replace our current `DateTime`
+  data and column type. (Issue #1476)
+* Notice: Due to the new `Timestamp` data and column type a file upgrade will take place.
+  Read-only Realm files in apps will have to be updated manually.
+
+### Enhancements:
+
+* TableView can now report whether its rows are guaranteed to be in table order. (Issue #1712)
+* `Query::sync_view_if_needed()` allows for bringing a query's restricting view into sync with
+  its underlying data source.
+
+-----------
+
+### Internals:
+
+* Opening a Realm file which already has a management directory no longer throws
+  and catches an exception.
+* The r-value constructor for StringData has been removed because StringIndex does not
+  store any data. This prevents incorrect usage which can lead to strange results.
+
+----------------------------------------------
+
+# 0.99.0 Release notes
+
+### Breaking changes:
+
+* Lock file (`foo.realm.lock`) format bumped.
+* Moved all supporting files (all files except the .realm file) into a
+  separate ".management" subdirectory.
+
+### Bugfixes:
+
+* S: Misbehavior of empty asynchronous write in POSIX networking API.
+* S: Access dangling pointer while handling canceled asynchronous accept
+  in POSIX networking API.
+* Changed group operator== to take table names into account.
+
+### Enhancements:
+
+* Multiple shared groups now share the read-only memory-mapping of
+  the database. This significantly lowers pressure on virtual memory
+  in multithreaded scenarios. Fixes issue #1477.
+* Added emulation of robust mutexes on platforms which do not
+  provide the full posix API for it. This prevents a situation
+  where a crash in one process holding the lock, would leave
+  the database locked. Fixes #1429
+* Added support for queries that traverse backlinks. Fixes #776.
+* Improve the performance of advance_read() over transations that inserted rows
+  when there are live TableViews.
+* The query expression API now supports equality comparisons between
+  `Columns<Link>` and row accessors. This allows for link equality
+  comparisons involving backlinks, and those that traverse multiple
+  levels of links.
+
+* S: Adding `util::network::buffered_input_stream::reset()`.
+
+-----------
+
+### Internals:
+
+* Disabled unittest Shared_RobustAgainstDeathDuringWrite on Linux, as
+  it could run forever.
+* Fixed a few compiler warnings
+* Disabled unittest Shared_WaitForChange again, as it can still run forever
+* New features in the unit test framework: Ability to log to a file (one for
+  each test thread) (`UNITTEST_LOG_TO_FILES`), and an option to abort on first
+  failed check (`UNITTEST_ABORT_ON_FAILURE`). Additionally, logging
+  (`util::Logger`) is now directly available to each unit test.
+* New failure simulation features: Ability to prime for random triggering.
+
+* S: New unit tests: `Network_CancelEmptyWrite`, `Network_ThrowFromHandlers`.
+
+----------------------------------------------
+
+# 0.98.4 Release notes
+
+### Bugfixes:
+
+* Copying a `Query` restricted by a `TableView` will now avoid creating a dangling
+  reference to the restricting view if the query owns the view. Dangling references
+  may still occur if the `Query` does not own the restricting `TableView`. (#1741)
+
+### Enhancements:
+
+* `Query::sync_view_if_needed()` allows for bringing a query's restricting view into sync with
+  its underlying data source. (#1742)
+
+**Note: This is a hotfix release built on top of 0.98.3. The above fixes are
+        not present in version 0.99**
+
+----------------------------------------------
+
+# 0.98.3 Release notes
+
+### Bugfixes:
+
+* Fixed TableViews that represent backlinks to not assert beneath `sync_if_needed` when
+  the target row has been deleted. (Issue #1723)
+
+**Note: This is a hotfix release built on top of 0.98.2. The above fixes are
+        not present in version 0.99**
+
+----------------------------------------------
+
+# 0.98.2 Release notes
+
+### Bugfixes:
+
+* Fixed TableViews that represent backlinks to track the same row, even if that row
+  moves within its table. (Issue #1710)
+* Fixed incorrect semantics when comparing a LinkList column with a Row using a
+  query expression. (Issue #1713)
+
+### API breaking changes:
+
+* `TableView::depends_on_deleted_linklist` is now `TableView::depends_on_deleted_object`,
+  and will also return true if the target row of a `TableView` that represents backlinks
+  is deleted. (Issue #1710)
+
+### Enhancements:
+
+* TableView can now report whether its rows are guaranteed to be in table order. (Issue #1712)
+
+**Note: This is a hotfix release built on top of 0.98.1. The above fixes are
+        not present in version 0.99
+
+----------------------------------------------
+
+# 0.98.1 Release notes
+
+### Bugfixes:
+
+* Fixed a bug, where handing over a TableView based on a Query restricted
+  by another TableView would fail to propagate synchronization status correctly
+  (issue #1698)
+
+**Note: This is a hotfix release. The above bugfix is not present
+        in version 0.99
+
+----------------------------------------------
+
+# 0.98.0 Release notes
+
+### Enhancements:
+
+* Added support for queries that traverse backlinks. Fixes #776. See #1598.
+* The query expression API now supports equality comparisons between
+  `Columns<Link>` and row accessors. This allows for link equality
+  comparisons involving backlinks, and those that traverse multiple
+  levels of links. See #1609.
+
+### Bugfixes:
+
+* Fix a crash that occurred after moving a `Query` that owned a `TableView`.
+  See #1672.
+
+**NOTE: This is a hotfix release which is built on top of [0.97.4].**
+
+-----------------------------------------------
+
+# 0.97.4 Release notes
+
+### Bugfixes:
+
+* #1498: A crash during opening of a Realm could lead to Realm files
+  which could not later be read. The symptom would be a realm file with zeroes
+  in the end but on streaming form (which requires a footer at the end of the
+  file instead). See issue #1638.
+* Linked tables were not updated properly when calling erase with num_rows = 0
+  which could be triggered by rolling back a call to insert with num_rows = 0.
+  See issue #1652.
+* `TableView`s created by `Table::get_backlink_view` are now correctly handled by
+  `TableView`'s move assignment operator. Previously they would crash when used.
+  See issue #1641.
+
+**NOTE: This is a hotfix release which is built on top of [0.97.3].**
+
+----------------------------------------------
+
+# 0.97.3 Release notes
+
+### Bugfixes:
+
+* Update table accessors after table move rollback, issue #1551. This
+  issue could have caused corruption or crashes when tables are moved
+  and then the transaction is rolled back.
+* Detach subspec and enumkey accessors when they are removed
+  via a transaction (ex rollback). This could cause crashes
+  when removing the last column in a table of type link,
+  linklist, backlink, subtable, or enumkey. See #1585.
+* Handing over a detached row accessor no longer crashes.
+
+**NOTE: This is a hotfix release. The above changes are not present in
+versions [0.97.2].**
+
+----------------------------------------------
+
+# 0.97.2 Release notes
+
+### Enhancements:
+
+* Add more information to IncompatibleLockFile.
+
+**NOTE: This is a hotfix release. The above changes are not present in
+versions [0.97.1].**
+
+----------------------------------------------
+
+# 0.97.1 Release notes
+
+### Bugfixes:
+
+* Fix an alignment problem which could cause crash when opening a Realm file
+  on 32-bit IOS devices. (issue 1558)
+
+**NOTE: This is a hotfix release. The above bugfixes are not present in
+versions [0.97.0].**
+
+----------------------------------------------
+
+# 0.97.0 Release notes
+
+### Bugfixes:
+
+* Backlink columns were not being refreshed when the connected link column
+  updated it's index in the table (insert/remove/move column). This is now
+  fixed. See issue #1499.
+* Backlink columns were always inserted at the end of a table, however on a
+  transaction rollback in certain cases, backlink columns were removed from
+  internal (not the end) indices and the roll back should put them back there.
+  This could cause a crash on rollback and was reported in ticket #1502.
+* Bumps table version when `Table::set_null()` called.
+  `TableView::sync_if_needed()` wouldn't be able to see the version changes
+  after `Table::set_null()` was called.
+  (https://github.com/realm/realm-java/issues/2366)
+* Fix an assertion failure in `Query::apply_patch` when handing over
+  certain queries.
+* Fix incorrect results from certain handed-over queries.
+
+### API breaking changes:
+
+* Language bindings can now test if a TableView depends on a deleted LinkList
+  (detached LinkView) using `bool TableViewBase::depends_deleted_linklist()`.
+  See https://github.com/realm/realm-core/issues/1509 and also
+  TEST(Query_ReferDeletedLinkView) in test_query.cpp for details.
+* `LangBindHelper::advance_read()` and friends no longer take a history
+  argument. Access to the history is now gained automatically via
+  `Replication::get_history()`. Applications and bindings should simply delete
+  the history argument at each call site.
+* `SharedGroup::get_current_version()`, `LangBindHelper::get_current_version()`,
+  and `Replication::get_current_version()` were all removed. They are not used
+  by the Cocoa or Android binding, and `SharedGroup::get_current_version()` was
+  never supposed to be public.
+
+### Enhancements:
+
+* Adds support for in-Realm history of changes (`<realm/history.hpp>`), but
+  keeps the current history implementation as the default for now
+  (`<realm/commit_log.hpp>`).
+* New methods `ReadTransaction::get_version()` and
+  `WriteTransaction::get_version()` for getting the version of the bound
+  snapshot during a transaction.
+
+-----------
+
+### Internals:
+
+* Bumps file format version from 3 to 4 due to support for in-Realm history of
+  changes (extra entries in `Group::m_top`). The bump is necessary due to lack
+  of forwards compatibility. The changes are backwards compatible, and automatic
+  upgrade is implemented.
+* Adds checks for consistent use of history types.
+* Removes the "server sync mode" flag from the Realm file header. This feature
+  is now superseded by the more powerful history type consistency checks. This
+  is not considered a file format change, as no released core version will ever
+  set the "server sync mode" flag.
+* The SharedInfo file format version was bumped due to addition of history type
+  information (all concurrent session participants must agree on SharedInfo file
+  format version).
+* Make it possible to open both file format version 3 and 4 files without
+  upgrading. If in-Realm history is required and the current file format version
+  is less than 4, upgrade to version 4. Otherwise, if the current file format
+  version is less than 3, upgrade to version 3.
+* The current file format version is available via
+  `Allocator::get_file_format_version()`.
+* Set Realm file format to zero (not yet decided) when creating a new empty
+  Realm where top-ref is zero. This was done to minimize the number of distinct
+  places in the code dealing with file format upgrade logic.
+* Check that all session participants agree on target Realm file format for that
+  session. File format upgrade required when larger than the actual file format.
+* Eliminate a temporary memory mapping of the SharedInfo file during the Realm
+  opening process.
+* Improved documentation of some of the complicated parts of the Realm opening
+  process.
+* Introducing `RefOrTagged` value type whan can be used to make it safer to work
+  with "tagged integers" in arrays having the "has refs" flag.
+* New features in the unit test framework: Ability to specify number of internal
+  repetitions of the set of selected tests. Also, progress reporting now
+  includes information about which test thread runs which unit test. Also, new
+  test introduction macro `NO_CONCUR_TEST()` for those tests that cannot run
+  concurrently with other tests, or with other executions of themselves. From
+  now on, all unit tests must be able to run multiple times, and must either be
+  fully thread safe, or must be introduced with `NO_CONCUR_TEST()`.
+
+----------------------------------------------
+
+# 0.96.2 Release notes
+
+### Bugfixes:
+
+* `Group::TransactAdvancer::move_group_level_table()` was forgetting some of its
+  duties (move the table accessor). That has been fixed.
+* While generating transaction logs, we didn't always deselect nested
+  accessors. For example, when performing a table-level operation, we didn't
+  deselect a selected link list. In some cases, it didn't matter, but in others
+  it did. The general rule is that an operation on a particular level must
+  deselect every accessor at deeper (more nested) levels. This is important for
+  the merge logic of the sync mechanism, and for transaction log reversal. This
+  has been fixed.
+* While reversing transaction logs, group level operations did not terminate the
+  preceding section of table level operations. Was fixed.
+* Table::clear() issues link nullification instructions for each link that did
+  point to a removed row. It did however issue those instructions after the
+  clear instruction, which is incorrect, as the links do not exist after the
+  clear operation. Was fixed.
+* `SharedGroup::compact()` does a sync before renaming to avoid corrupted db
+  file after compacting.
+
+### Enhancements:
+
+* Add SharedGroup::get_transact_stage().
+
+### Internals:
+
+* Improve documentation of `Group::move_table()` and `LinkView::move()`.
+* Early out from `Group::move_table()` if `from_index == to_index`. This
+  behaviour agrees with `LinkView::move()` and is assumed by other parts of
+  core, and by the merge logic of the sync mechanism.
+* Convert some assertions on arguments of public `Group`, `Table`, and
+  `LinkView` methods to throwing checks.
+* Align argument naming of `Group::move_table()` and `LinkView::move()`.
+
+----------------------------------------------
+
+# 0.96.1 Release notes
+
+### API breaking changes:
+
+* Important for language bindings: Any method on Query and TableView that
+  depends on a deleted LinkView will now return sane return values;
+  Query::find() returns npos, Query::find_all() returns empty TableView,
+  Query::count() returns 0, TableView::sum() returns 0 (TableView created
+  from LinkView::get_sorted_view). So they will no longer throw
+  DeletedLinkView or crash. See TEST(Query_ReferDeletedLinkView) in
+  test_query.cpp for more info.
+
+### Enhancements:
+
+* Memory errors caused by calls to mmap/mremap will now throw a specific
+  AddressSpaceExhausted exception which is a subclass of the previously
+  thrown std::runtime_error. This is so that iOS and Android language
+  bindings can specifically catch this case and handle it differently
+  than the rest of the general std::runtime_errors.
+* Doubled the speed of TableView::clear() when parent table has an
+  indexed column.
+
+----------------------------------------------
+
+# 0.96.0 Release notes
+
+### Bugfixes:
+
+* Handing over a query that includes an expression node will now avoid
+  sharing the expression nodes between `Query` instances. This prevents
+  data races that could give incorrect results or crashes.
+
+### Enhancements:
+
+* Subqueries are now supported via `Table::column(size_t, Query)`.
+  This allows for queries based on the number of rows in the linked table
+  that match the given subquery.
+
+----------------------------------------------
+
+# 0.95.9 Release notes
+
+### Bugfixes:
+
+* Fixed terminate() being called rather than InvalidDatabase being thrown when
+  a non-enrypted file that begins with four zero bytes was opened as an
+  encrypted file.
+
+----------------------------------------------
+
+# 0.95.8 Release notes
+
+### Bugfixes:
+
+* Fixed error when opening encrypted streaming-form files which would be
+  resized on open due to the size not aligning with a chunked mapping section
+  boundary.
+
+### API breaking changes:
+
+* Any attempt to execute a query that depends on a LinkList that has been
+  deleted from its table will now throw `DeletedLinkView` instead of
+  segfaulting. No other changes has been made; you must still verify
+  LinkViewRef::is_attached() before calling any methods on a LinkViewRef, as
+  usual.
+
+### Enhancements:
+
+* Optimized speed of TableView::clear() on an indexed unordered Table. A clear()
+  that before took several minutes with 300000 rows now takes a few seconds.
+
+----------------------------------------------
+
+# 0.95.7 Release notes
+
+### Bugfixes:
+
+* Corrected a bug which caused handover of a query with a restricting
+  view to lose the restricting view.
+
+----------------------------------------------
+
+# 0.95.6 Release notes
+
+### Bugfixes:
+
+* Fixed incorrect initialization of TableViews from queries on LinkViews
+  resulting in `TableView::is_in_sync()` being incorrect until the first time
+  it is brought back into sync.
+* Fixed `TableView` aggregate methods to give the correct result when called on
+  a table view that at one point had detached refs but has since been synced.
+* Fixed another bug in `ColumnBase::build()` which would cause it to produce an
+  invalid B+-tree (incorrect number of elements per child in the compact
+  form). This is a bug that could have been triggered through proper use of our
+  bindings in their current form. In particular, it would have been triggered
+  when adding a new attribute to a class that already has a sufficiently large
+  number of objects in it (> REALM_MAX_BPNODE_SIZE^2 = 1,000,000).
+* Fixed a bug in handover of Queries which use links. The bug was incomplete
+  cloning of the underlying data structure. This bug goes unnoticed as long
+  as the original datastructure is intact and is only seen if the original
+  datastructure is deleted or changed before the handed over query is re-executed
+
+### Enhancements:
+
+* Added support for handing over TableRefs from one thread to another.
+
+-----------
+
+### Internals:
+
+* Add `test_util::to_string()` for convenience. std::to_string() is not
+  available via all Android NDK toolchains.
+* New operation: ChangeLinkTargets. It replaces all links to one row with
+  links to a different row.
+* Regular assertions (REALM_ASSERT()) are no longer enabled by default in
+  release mode. Note that this is a reversion back to the "natural" state of
+  affairs, after a period of having them enabled by default in release mode. The
+  Cocoa binding was the primary target when the assertions were enabled a while
+  back, and steps were taken to explicitely disable those assertions in the
+  Android binding to avoid a performance-wise impact there. It is believed that
+  the assertions are no longer needed in the Cocoa binding, but in case they
+  are, the right approach, going forward, is to enable them specifically for the
+  Cocoa binding. Note that with these changes, the Android binding no longer
+  needs to explicitely disable regular assertions in release mode.
+* Upgraded Android toolchain to R10E and gcc to 4.9 for all architectures.
+
+----------------------------------------------
+
+
+# 0.95.5 Release notes
+
+### Bugfixes:
+
+* Fixed Row accessor updating after an unordered `TableView::clear()`.
+* Fixed bug in `ColumnBase::build()` which would cause it to produce an invalid
+  (too shallow) B+-tree. This is a bug that could have been triggered through
+  proper use of our bindings in their current form. In particular, it would have
+  been triggered when adding a new attribute to a class that already has a
+  sufficiently large number of objects in it (> REALM_MAX_BPNODE_SIZE^2 =
+  1,000,000).
+
+### Enhancements:
+
+* New default constructor added to `BasicRowExpr<>`. A default constructed
+  instance is in the detached state.
+
+----------------------------------------------
+
+# 0.95.4 Release notes
+
+### Bugfixes:
+
+* Fixed incorrect handling of a race between a commit() and a new thread
+  or process opening the database. In debug mode, the race would trigger an
+  assert "cfg.session_initiator || !cfg.is_shared", in release mode it could
+  conceivably result in undefined behaviour.
+* Fixed a segmentation fault in SharedGroup::do_open_2
+* Fixed a bug en ringbuffer handling that could cause readers to get a wrong
+  top pointer - causing later asserts regarding the size of the top array, or
+  asserts reporting mismatch between versions.
+
+### API breaking changes:
+
+* Primary key support has been removed. Instead, new instructions have been
+  introduced: SetIntUnique, SetStringUnique. To implement primary keys, callers
+  should manually check the PK constraint and then emit these instructions in
+  place of the regular SetInt and SetString instructions.
+
+### Enhancements:
+
+* Added TableView::distinct() method. It obeys TableView::sync_if_needed().
+  A call to distinct() will first fully populate the TableView and then perform
+  a distinct algorithm on that (i.e. it will *not* add a secondary distinct filter
+  to any earlier filter applied). See more in TEST(TableView_Distinct) in
+  test_table_view.cpp.
+
+-----------
+
+### Internals:
+
+* Changed `Group::remove_table`, `Group::TransactAdvancer::insert_group_level_table`
+  and `Group::TransactAdvancer::erase_group_level_table` from _move-last-over_ to
+  preserve table ordering within the group.
+
+----------------------------------------------
+
+# 0.95.3 Release notes
+
+### Bugfixes:
+
+* Reverted what was presumably a fix for a race between commit and opening the database (0.95.2).
+
+----------------------------------------------
+
+# 0.95.2 Release notes
+
+### Bugfixes:
+
+* Fixed bug where Query::average() would include the number of nulls in the
+  result.
+* Presumably fixed a race between commit and opening the database.
+
+### Enhancements:
+
+* Recycle memory allocated for asynchronous operations in the networking
+  subsystem (`util::network`).
+
+----------------------------------------------
+
+# 0.95.1 Release notes
+
+### Bugfixes:
+* Fixed bug that would give false search results for queries on integer columns
+  due to bug in bithacks deep inside Array::find()
+
+### Enhancements:
+
+* Added Table::get_version_counter() exposing the versioning counter for the Table
+* Add `TableView::get_query()`.
+
+
+----------------------------------------------
+
+# 0.95.0 Release notes
+
+### Bugfixes:
+
+* When inserting a new non-nullable Binary column to a table that had
+  *existing* rows, then the automatically added values would become null
+* Fixed updating TableViews when applying a transaction log with a table clear.
+* Fewer things are copied in TableView's move constructor.
+* Prevent spurious blocking in networking subsystem (put sockets in nonblocking
+  mode even when used with poll/select).
+* Fixed the shared group being left in an inconsistent state if the transaction
+  log observer threw an exception.
+* Fixed issue with table accessors not being updated properly, when link columns
+  were changed (e.g. in Group::remove_table, when the table had link columns).
+
+### API breaking changes:
+
+* Use `util::Logger` instead of `std::ostream` for logging during changeset
+  replay (`Replication::apply_changeset()`).
+
+### Enhancements:
+
+* Eliminated use of signals in encryption. This also fixes failures related
+  to signals on some devices.
+
+-----------
+
+### Internals:
+
+* More checking and throwing of logical errors in `Table::set_binary()` and
+  `Table::set_link()`.
+
+----------------------------------------------
+
+# 0.94.4 Release notes
+
+### Bugfixes:
+
+* Fixed crash in find_all()
+
+### Enhancements:
+
+* Queries are no longer limited to 16 levels of grouping.
+* New substring operations (ranged insert, erase on values in string columns).
+* Adds schema change notification handler API to Group.
+
+-----------
+
+### Internals:
+
+* New operations: Swap rows, move rows, move column, move group level table.
+* Changes order of nullify instructions that appeared as a result of erase
+  to occur in the transaction log before the erase instruction that caused
+  them.
+* New utility class: DirScanner.
+* New test utility function: quote.
+* New assertion macro: REALM_ASSERT_EX, replacing REALM_ASSERT_n macros.
+
+
+----------------------------------------------
+
+# 0.94.3 Release notes
+
+### Bugfixes:
+
+* Fixed mremap() fallback on Blackberry.
+
+----------------------------------------------
+
+# 0.94.2 Release notes
+
+### Bugfixes:
+
+* Fixed a bug that lead to SharedGroup::compact failing to attach to the newly
+  written file.
+
+----------------------------------------------
+
+# 0.94.1 Release notes
+
+### Bugfixes:
+
+* Fixed a bug in SharedGroup::Compact() which could leave the database in an
+  inconsistent state.
+
+### Enhancements:
+
+* Queries are no longer limited to 16 levels of grouping.
+
+-----------
+
+### Internals:
+
+* Obsolete YAML-based documentation removed.
+* Removed `std::` in front integral types (e.g. `size_t`, `int64_t` etc.)
+
+----------------------------------------------
+
+# 0.94.0 Release notes
+
+### Bugfixes:
+
+* Fixed a crash bug that could be triggered if a Realm is rapidly opened and
+  closed and reopened many times on multiple threads. The bug caused the
+  internal version information structure to overflow, causing an assert or a
+  crash (if assert was disabled).
+* The error handling for `pthread_cond_wait()/pthread_cond_timedwait()`
+  incorrectly attributed the failure to `pthread_mutex_lock()`.
+* The error handling for several File functions incorrectly attributed the
+  failure to `open()`.
+* Added the bitcode marker to iOS Simulator builds so that bitcode for device
+  builds can actually be used.
+* Build with bitcode both enabled and disabled for iOS for compatibility with
+  Xcode 6.
+
+### API breaking changes:
+* None.
+
+### Enhancements:
+* Supports finding non-null links (Link + LinkList) in queries, using
+  syntax like `Query q = table->column<Link>(col).is_not_null();`
+* Comparisons involving unary links on each side of the operator are now
+  supported by query_expression.hpp.
+* Added version chunk information and failure reason for
+  `pthread_mutex_lock()`.
+* Termination routines now always display the library's version before the
+  error message.
+* Automatically clean up stale MemOnly files which were not deleted on close
+  due to the process crashing.
+
+-----------
+
+### Internals:
+
+* All calls to `REALM_TERMINATE` or `util::terminate()` now display the
+  library's version. It is no longer necessary to include `REALM_VER_CHUNK` in
+  calls to those functions.
+* Various bug fixes in `util::network`, most notably, asynchronous operations
+  that complete immediately can now be canceled.
+* Improved documentation in `util::network`.
+* Improved exception safety in `util::network`.
+* `util::network::socket_base::close()` is now `noexcept`.
+* New `util::network::socket_base::cancel()`.
+* Added `util::network::deadline_timer` class.
+* Breaking: Free-standing functions `util::network::write()` and
+  `util::network::async_write()` converted to members of
+  `util::network::socket`.
+
+
+----------------------------------------------
+
+# 0.93.0 Release notes
+
+### Bugfixes:
+* Fixed severe bug in Array allocator that could give asserts like
+  `Assertion failed: value <= 0xFFFFFFL [26000016, 16777215]`, especially
+  for BinaryData columns. This bug could be triggered by using binary data
+  blobs with a size in the range between 8M and 16M.
+* Fixed assert that could happen in rare cases when calling set_null() on an
+  indexed nullable column.
+* Fixed all aggregate methods on Table (min, max, etc) that hadn't been
+  updated/kept in sync for a long while (null support, return_ndx argument,..).
+* Bug in upgrading from version 2 -> 3 (upgrade could be invoked twice for the
+  same file if opened from two places simultaneously)
+* `Spec` and thereby `Descriptor` and `Table` equality has been fixed. Now
+  handles attributes (nullability etc), sub tables, optimized string columns
+  and target link types correctly.
+* A stackoverflow issue in encrypted_file_mapping. Allocing 4k bytes on the
+  stack would cause some random crashes on small stack size configurations.
+* Now includes a statically-linked copy of OpenSSL crypto functions rather
+  than dynamically linking Androids system OpenSSL to avoid bugs introduced
+  by system crypto functions on some devices.
+* Added copy constructor to `BasicRow<Table>` to fix a bug that could lead to
+  unregistered row accessors being created. This bug is also part of a list of
+  blocking issues that prevent the test suite from running when compiled with
+  `-fno-elide-constructors`.
+* A bug in the `Query` copy constructor has been fixed that could cause asserts
+  due to missing capacity extension in one of the object's internal members.
+* `Expression` subclasses now update `Query`s current descriptor after setting
+  the table. This prevents a null dereference when adding further conditions
+  to the query.
+* Fixes a crash due to an assert when rolling back a transaction in which a link
+  or linklist column was removed.
+* A bug in `Query` copying has been fixed. The bug could cause references to
+  Tables which should stay under the supervision of one SharedGroup to leak
+  to another during handover_export() leading to corruption.
+* Query expression operators now give correct results when an argument comes
+  from a link.
+* Fixed a bug in the way the new memory mapping machinery interacted with
+  encryption.
+* Query expression comparisons now give correct results when comparing a linked
+  column with a column in the base table.
+* Fixed assertion failure when TableViewBase::is_row_attached() would return
+  false in a debug build.
+
+### API breaking changes:
+
+* A number of methods in the following classes have been renamed to match the
+  coding guidelines (lowercase, underscore separation):
+    * `Array`, `ArrayBlob`, `ArrayInteger`, `ArrayString`, `BasicArray<T>`;
+    * `Column<T, N>`, `IntegerColumn`, `StringColumn`, `StringEnumColumn`;
+    * `Group`;
+    * `Query`;
+    * `StringIndex`.
+* `TableView::remove()`, `TableView::remove_last()`, and `TableView::clear()`
+  now take an extra argument of type `RemoveMode` which specifies whether rows
+  must be removed in a way that does, or does not maintain the order of the
+  remaining rows in the underlying table. In any case, the order of remaining
+  rows in the table view is maintained. This is listed as an API breaking change
+  because the situation before this change was confusing, to say the least. In
+  particular, `TableView::clear()` would choose between the ordered and the
+  unordered mode based on whether the underlying table had at least one link (or
+  link list) column. You are strongly advised to revisit all call sites and
+  check that they do the right thing. Note that both bindings (Cocoa and
+  Android) are likely to want to use unordered mode everywhere.
+
+### Enhancements:
+* Added argument to Table::average() and TableView::average() that returns number
+  of values that were used for computing the average
+* Full null support everywhere and on all column types. See
+  `TEST(Query_NullShowcase)` in `test_query.cpp` in core repo.
+* Added `Descriptor::get_link_target()`, for completeness.
+* Added extra `allow_file_format_upgrade` argument to `SharedGroup::open()`.
+* Modifying `Descriptor` methods now throw `LogicError` when appropriate (rather
+  than asserting).
+* Allow querying based on the number of rows that a linked list column links to,
+  using expressions like `table->column<LinkList>(0).count() > 5`.
+* New `util::File::AccessError::get_path()` returns the file system path
+  associated with the exception. Note that exception classes
+  `util::File::PermissionDenied`, `util::File::NotFound`, `util::File::Exists`,
+  and `InvalidDatabase` are subclasses of `util::File::AccessError`.
+* Allow queries to include expressions that compute aggregates on columns in linked tables,
+  such as `table->column<LinkList>(0).column<Int>(1).sum() >= 1000`.
+* Added a check for functioning SEGV signals to fail more gracefully when
+  they're broken.
+
+-----------
+
+### Internals:
+
+* Added argument to SharedGroup to prevent automatic file format upgrade. If an
+  upgrade is required, the constructor will throw `FileFormatUpgradeRequired`.
+* Let `LinkColumn` and `LinkListColumn` adhere to the same nullability interface
+  as the rest of the column types.
+* The code coverage CI job now builds with the `-fno-elide-constructors` flag,
+  which should improve the depth of the coverage analysis. All bugs that were
+  blocking the use of this flag have been fixed.
+* SharedGroup no longer needs to remap the database file when it grows. This is
+  a key requirement for reusing the memory mapping across threads.
+* `NOEXCEPT*` macros have been replaced by the C++11 `noexcept` specifier.
+* The `REALM_CONSTEXPR` macro has been replaced by the C++11 `constexpr` keyword.
+* Removed conditional compilation of null string support.
+
+----------------------------------------------
+
+# 0.92.3 Release notes
+
+### Bugfixes:
+
+* Added the bitcode marker to iOS Simulator builds so that bitcode for device
+  builds can actually be used.
+
+**NOTE: This is a hotfix release. The above bugfixes are not present in
+versions [0.93.0].**
+
+----------------------------------------------
+
+# 0.92.2 Release notes
+
+### Bugfixes:
+
+* Fixed assertion failure when TableViewBase::is_row_attached() would return
+  false in a debug build.
+* Fixes a crash due to an assert when rolling back a transaction in which a link
+  or linklist column was removed.
+
+**NOTE: This is a hotfix release.**
+
+-----------
+
+### Internals:
+
+* Now built for Apple platforms with the non-beta version of Xcode 7.
+
+----------------------------------------------
+
+# 0.92.1 Release notes
+
+### Bugfixes:
+
+* Reverted prelinking of static libraries on Apple platforms as it caused
+  `dynamic_cast<>()` and `typeid()` checks to fail in some scenarios, including
+  when sorting by integer or floating point columns.
+
+-----------
+
+### Internals:
+
+* Renamed `Column` to `IntegerColumn` and `TColumn` to `Column`.
+* Renamed `AdaptiveStringColumn` to `StringColumn`.
+* Several column classes were renamed to follow the `XxxColumn` naming scheme
+  (e.g., `ColumnLink` to `LinkColumn`).
+* Removed conditional compilation of replication features.
+* More information from `InvalidDatabase::what()`.
+* Disabled support for the async daemon on iOS and watchOS.
+
+----------------------------------------------
+
+# 0.92.0 Release notes
+
+### Bugfixes:
+
+* The upgraded file format version is written out to disk, eliminating potential
+  deadlocks.
+
+### API breaking changes:
+
+* Support for the following deprecated operations on Table has been removed:
+  insert_int, insert_string, etc., insert_done, and add_int. To insert a value,
+  one must now call insert_empty_row, then set the appropriate values for each
+  column.
+* Changed `LinkView::move` so that the `new_link_ndx` will be the index at which
+  the moved link can be found after the move is completed.
+
+### Enhancements:
+
+* Support for ordered row removal in tables with links. This was done for
+  completeness, and because an ordered insertion in tables with links, when
+  reversed, becomes an ordered removal. Support for ordered insertion in tables
+  with links was added recently because the sync mechanism can produce
+  them. Also added a few missing pieces of support for ordered insertion in
+  tables with links.
+
+-----------
+
+### Internals:
+
+* Added static `Array::create_array()` for creating non-empty arrays, and extend
+  `Array::create()` such that it can create non-empty arrays.
+* The creation of the free-space arrays (`Group::m_free_positions`,
+  `Group::m_free_lengths`, `Group::m_free_versions`) is now always done by
+  `GroupWriter::write_group()`. Previously it was done in various places
+  (`Group::attach()`, `Group::commit()`, `Group::reset_free_space_versions()`).
+* `Group::reset_free_space_versions()` has been eliminated. These days the Realm
+  version is persisted across sessions, so there is no longer any cases where
+  version tracking on free-space chunks needs to be reset.
+* Free-space arrays (`Group::m_free_positions`, `Group::m_free_lengths`,
+  `Group::m_free_versions`) was moved to `GroupWriter`, as they are now only
+  needed during `GroupWriter::write_Group()`. This significantly reduces the
+  "shallow" memory footprint of `Group`.
+* Improved exception safety in `Group::attach()`.
+* `Group::commit()` now throws instead of aborting on an assertion if the group
+  accessor is detached or if it is used in transactional mode (via
+  `SharedGroup`).
+* Instruction encoding changed for `InsertEmptyRows` and `EraseRows` (also used
+  for `move_last_over()`). The third operand is now `prior_num_rows` (the number
+  of rows prior to modification) in all cases. Previously there was a serious
+  confusion about this.
+* Cleaned up the batch removal of rows used by `TableView`.
+* Optimize row removal by skipping cascade mechanism when table has no forward
+  link columns.
+* Virtual `ColumnBase::insert(row_ndx, num_rows, is_append)` was changed to
+  `ColumnBase::insert_rows(row_ndx, num_rows_to_insert,
+  prior_num_rows)`. Virtual `ColumnBase::erase(row_ndx, is_last)` was changed to
+  `ColumnBase::erase_rows(row_ndx, num_rows_to_erase, prior_num_rows)`. Virtual
+  `ColumnBase::move_last_over(row_ndx, last_row_ndx)` was changed to
+  `ColumnBase::move_last_row_over(row_ndx, prior_num_rows)`. Function names were
+  changed to avoid confusing similarity to the various non-virtual operations of
+  the same name on subclasses of `ColumnBase`. `prior_num_rows` is passed
+  because if carries more useful information than
+  `is_append`/`is_last`. `num_rows_to_erase` was added for consistency.
+* On some subclasses of `ColumnBase` a new non-virtual `erase(row_ndx, is_last)`
+  was added for practical reasons; an intended overload of `erase(row_ndx)` for
+  when you know whether the specified row index is the last one.
+* Slight performance improvements in `Array::FindGTE()`.
+* Renamed `Array::FindGTE()` to `Array::find_gte()`.
+
+----------------------------------------------
+
+# 0.91.2 Release notes
+
+### Enhancements:
+
+* Added support for building for watchOS.
+
+----------------------------------------------
+
+# 0.91.1 Release notes
+
+### Bugfixes:
+
+* Fixed a bug in SharedGroup::grab_specific_readlock() which would fail to
+  grab the specified readlock even though the requested version was available
+  in the case where a concurrent cleanup operation had a conflicting request
+  for the same (oldest) entry in the ringbuffer.
+* Fixed a performance regression in TableView::clear().
+
+### API breaking changes:
+
+* Argument `is_backend` removed from from the public version of
+  `SharedGroup::open()`. Fortunately, bindings are not currently calling
+  `SharedGroup::open()`.
+* `File::resize()` no longer calls `fcntl()` with `F_FULLFSYNC`. This feature
+  has been moved to `File::sync()`.
+
+### Enhancements:
+
+* New feature added to disable all forms of 'sync to disk'. This is supposed to
+  be used only during unit testing. See header `disable_sync_to_disk.hpp`.
+* Added `LinkList.swap()` to swap two members of a link list.
+* Added a Query constructor that takes ownership of a TableView.
+
+### Internals:
+
+* On Linux we now call 'sync to disk' after Realm file resizes. Previusly, this
+  was only done on Apple platforms.
+
+----------------------------------------------
+
+# 0.91.0 Release notes
+
+### Bugfixes:
+
+* Fixed assertion when tests are run with `REALM_OLDQUERY_FALLBACK` disabled by
+  updating Value::import to work with DateTime
+* Fix incorrect results when querying for < or <= on ints which requires 64 bits
+  to represent with a CPU that supports SSE 4.2.
+
+### API breaking changes:
+
+* Named exception UnreachableVersion replaced by "unspecified" LogicError
+  exception.
+
+### Enhancements:
+
+* Generic networking API added.
+* Support for transfer/handover of TableViews, Queries, ListViews and Rows
+  between SharedGroups in different threads.  Cooperative handover (where boths
+  threads participate) is supported for arbitrarily nested TableViews and
+  Queries.  Restrictions apply for non-cooperative handover (aka stealing): user
+  must ensure that the producing thread does not trigger a modifying operation
+  on any of the involved TableViews.  For TableViews the handover can be one of
+  *moving*, *copying* or *staying*, reflecting how the actual payload is
+  treated.
+* Support for non-end row insertion in tables with link and link list columns.
+* Improved documentation of functions concerning the initiation and termination
+  of transactions.
+* Improved exception safety in connection with the initiation and termination of
+  transactions.
+* Add support for systems where mremap() exists but fails with ENOTSUP.
+
+### Internals:
+
+* New facility for simulating failures, such as system call failures.
+
+----------------------------------------------
+
+# 0.90.0 Release notes
+
+### API breaking changes:
+
+* Merged lr_nulls into master (support for null in String column and bugfix in
+String index with 0 bytes). If you want to disable all this again, then #define
+REALM_NULL_STRINGS to 0 in features.h. Else API is as follows: Call add_column()
+with nullable = true. You can then use realm::null() in place of any
+StringData (in Query, Table::find(), get(), set(), etc) for that column. You can
+also call Table::is_null(), Table::set_null() and StringData::is_null(). This
+upgrades the database file from version 2 to 3 initially the first time a file
+is opened. NOTE NOTE NOTE: This may take some time. It rebuilds all indexes.
+
+----------------------------------------------
+
+# 0.89.9 Release notes
+
+### Bugfixes:
+
+* The check for functioning SEGV signals threw the exception only once. Now it
+always throws when trying to use encryption.
+
+**NOTE: This is a hotfix release. The above bugfixes are not present in
+versions [0.90.0, 0.92.1].**
+
+----------------------------------------------
+
+# 0.89.8 Release notes
+
+### Enhancements:
+
+* Added a check for functioning SEGV signals to fail more gracefully when
+  they're broken.
+
+**NOTE: This is a hotfix release. The above bugfixes are not present in
+versions [0.90.0, 0.92.1].**
+
+----------------------------------------------
+
+# 0.89.7 Release notes
+
+### Bugfixes:
+
+* A stackoverflow issue in encrypted_file_mapping. Allocing 4k bytes on the
+  stack would cause some random crashes on small stack size configurations.
+* Now includes a statically-linked copy of OpenSSL crypto functions rather
+  than dynamically linking Androids system OpenSSL to avoid bugs introduced
+  by system crypto functions on some devices.
+
+**NOTE: This is a hotfix release. The above bugfixes are not present in
+versions [0.90.0, 0.92.1].**
+
+----------------------------------------------
+
+# 0.89.6 Release notes
+
+### Bugfixes:
+
+* Fixed durability issue in case of power / system failures on Apple
+  platforms. We now use a stronger synchronization (`fcntl(fd, F_FULLFSYNC)`) to
+  stable storage when the file is extended.
+
+----------------------------------------------
+
+# 0.89.5 Release notes
+
+### Bugfixes:
+
+* Fixed errors when a changes to a table with an indexed int column are rolled
+  back or advanced over.
+
+----------------------------------------------
+
+# 0.89.4 Release notes
+
+### Enhancements:
+
+* Detaching (and thus destroying) row acessors and TableViews can now be done
+  safely from any thread.
+* Improved performance of Query::find_all() with assertions enabled.
+
+----------------------------------------------
+
+# 0.89.3 Release notes
+
+### Bugfixes:
+
+* Fixed LinkViews containing incorrect data after a write transaction
+  containing a table clear is rolled back.
+* Fixed errors when a changes to a table with an indexed int column are rolled
+  back.
+
+### Enhancements:
+
+* Changes the mmap doubling treshold on mobile devices from 128MB to 16MB.
+* SharedGroup::compact() will now throw a runtime_error if called in detached state.
+* Make the start index of `ListView::find()` overrideable for finding multiple
+  occurances of a given row in a LinkList.
+* Add `Group::set_cascade_notification_handler()` to simplify tracking changes
+  due to link nullification and cascading deletes.
+
+### Internals:
+
+* Can now be built with encryption enabled on Linux.
+
+----------------------------------------------
+
+# 0.89.1 Release notes
+
+### Bugfixes:
+
+* Fixed bug in "index rebuilding" (would delete the wrong column, causing
+  crash). See https://github.com/realm/realm-core/pull/798 ; "Remove the correct
+  column when removing search indexes #798"
+
+----------------------------------------------
+
+# 0.89.0 Release notes
+
+### Bugfixes:
+
+* Added a check for NUL bytes in indexed strings to avoid corrupting data
+  structures.
+* Fixed bug in SharedGroup::compact(). The bug left the freelist outdated in
+  some situations, which could cause crash later, if work continued on the same
+  shared group. The bug did not affect the data written to the compacted
+  database, but later commits working on the outdated freelist might have. The
+  fix forces proper (re)initialization of the free list.
+* Fixed incorrect results in querying on an indexed string column via a
+  LinkView.
+* Fixed corruption of indexes when using move_last_over() on rows with
+  duplicated values for indexed properties.
+
+### API breaking changes:
+
+* Changed the `tightdb` namespace to `realm`.
+* We switched to C++11, and removed functionality that was duplicated from the
+  C++11 standard library, including `null_ptr` and `util::UniquePtr`.
+
+### Enhancements:
+
+* Improved performance of advance_read() over commits with string or binary data
+  insertions.
+* Improved performance sorting TableView and LinkView.
+* Added Table::remove_search_index().
+
+----------------------------------------------
+
+# 0.88.6 Release notes
+
+### Bugfixes:
+
+* Fixed bug in Integer index that could make it crash or return bad results
+  (String index not affected)
+
+----------------------------------------------
+
+# 0.88.5 Release notes
+
+### Bugfixes:
+
+* Fixed crash when `std::exit()` is called with active encrypted mappings.
+* Fixed writing over 4KB of data to an encrypted file with `Group::write()`.
+* Fixed crash after making commits which produced over 4KB of writelog data with
+  encryption enabled.
+
+-----------
+
+### Internals:
+
+* Switched to using mach exceptions rather than signal() for encrypted mappings
+  on Apple platforms.
+
+----------------------------------------------
+
+# 0.88.4 Release notes
+
+### Bugfixes:
+
+* Fixed out-of-bounds reads when using aggregate functions on sorted TableViews.
+* Fixed issues with ArrayString that *could* be the cause of all the asserts the
+  past few days
+
+-----------
+
+### Internals:
+
+* Many `REALM_ASSERT` invocations replaced by new `REALM_ASSERT_3` macro
+  that prints variable/argument contents on failure. It's not implemented
+  optimally yet.
+
+----------------------------------------------
+
+# 0.88.3 Release notes
+
+### Enhancements:
+
+* Added emulation of inter-process condition variables for use on platforms which
+  do not properly implement them.
+
+----------------------------------------------
+
+# 0.88.2 Release notes
+
+### Bugfixes:
+
+* Fixed duplicated results when querying on a link column with matches at row
+  1000+.
+
+-----------
+
+### Internals:
+
+* Added support for Android ARM64
+
+----------------------------------------------
+
+# 0.88.1 Release notes
+
+### Bugfixes:
+
+* Fix encryption on platforms with non-4KB pages.
+
+----------------------------------------------
+
+# 0.88.0 Release notes
+
+### Enhancements:
+
+* SharedGroup::compact() now appends ".tmp_compaction_space" to the database
+  name in order to get the name of its temporary workspace file instead of
+  ".tmp". It also automatically removes the file in case it already exists
+  before compaction.
+* Add support for comparing string columns to other string columns in queries.
+* `WriteTransaction::has_table()` and `WriteTransaction::rollback()` were
+  added. Previously, only implicit rollback was possible with
+  `WriteTransaction`.
+
+-----------
+
+### Internals:
+
+* All assert failures now print the release version number.
+
+----------------------------------------------
+
+# 0.87.6 Release notes
+
+### Bugfixes:
+
+* Fixed a crashbug which could cause a reading thread to miss accessor updates
+  during advance_read(), if the pending updates consisted of two or more empty
+  commits followed by one or more non-empty commit. The left out accessor
+  updates could lead to inconsistent datastructures which could presumably later
+  cause database corruption.
+
+### Enhancements:
+
+* Adding *null* support to `BinaryData` in exactly the same way as it was added
+  to `StringData`.
+
+----------------------------------------------
+
+# 0.87.5 Release notes
+
+### Bugfixes:
+
+* `AdaptiveStringColumn::find_all()` with an index no longer returns its results
+  twice.
+* Fixed `Table::get_distinct_view()` on tables which have not been modified
+  since they were loaded.
+
+### Enhancements:
+
+* Added `SharedGroup::wait_for_change_release()` which allows you to release a
+  thread waiting inside wait_for_change() on a specific SharedGroup instance.
+* SharedGroup now allows you to coordinate which version of the data a read
+  transaction can see. The type `VersionID` represents a specific commit to the
+  database. A user can obtain the `VersionID` for the active transaction from
+  `SharedGroup::get_version_of_current_transaction()`, and use it to obtain a a
+  transaction accessing that same version from another ShareGroup. This is done
+  by new forms of `SharedGroup::begin_read()`, `SharedGroup::advance_read()`.
+  Operators are provided so that VersionID's may be compared.
+* Creating distinct views on integer, datetime, bool and enum columns is now
+  possible.
+* Add `Table::minimum_datetime()` and `Table::maximum_datetime()`.
+* Extending `Table::get_sorted_view()` to support multi-column sorting.
+
+-----------
+
+### Internals:
+
+* Now uses system OpenSSL on Android rather than a statically-linked copy for
+  encryption.
+
+----------------------------------------------
+
+# 0.87.4 Release notes
+
+### Bugfixes:
+
+* Fixed a crash when calling get_sorted_view() on an empty LinkList.
+
+----------------------------------------------
+
+# 0.87.3 Release notes
+
+### Bugfixes:
+
+* Fixed bug in String and Integer index where find()/find_all() would return a
+  wrong match.
+* Fixed the values of `Table::max_string_size`, and `Table::max_binary_size`.
+* Fixed a bug occuring when claring a table with a search index on a string
+  column with many rows (>1000).
+
+----------------------------------------------
+
+# 0.87.2 Release notes
+
+### Internals:
+
+* Extra assertions in `src/realm/util.file.cpp`.
+
+----------------------------------------------
+
+# 0.87.1 Release notes
+
+### Enhancements:
+
+* Added 'compact' method to SharedGroup for better control of compaction of the
+  database file.
+* The following constants were added: `Group::max_table_name_length`,
+  `Table::max_column_name_length`, `Table::max_string_size`, and
+  `Table::max_binary_size`.
+* Now throwing on overlong table and column names, and on oversized strings and
+  binary data values.
+* Fall back to the old query nodes for String as well as int/double/float.
+* Log assertions failures to the native logging system on android and Apple.
+
+-----------
+
+### Internals:
+
+* There is now three kinds of runtime assertions, `REALM_ASSERT_DEBUG()`,
+  which is retained only in debug-mode builds, `REALM_ASSERT_RELEASE()`, which
+  is also retained in release-mode builds, and finally, `REALM_ASSERT()`,
+  which is normally only retained in debug-mode builds, but may occasionally be
+  retained in release-mode builds too, depending on the specific build
+  configuration.
+* `REALM_ASSERT()` assertions are now enabled in release-mode builds by
+  default.
+
+----------------------------------------------
+
+# 0.87.0 Release notes
+
+### API breaking changes:
+
+* `TransactLogRegistry` is no longer available and must therefore no longer be
+  passed to `LangBindHelper::advance_read()` and
+  `LangBindHelper::promote_to_write()`.
+* The exceptions `PresumablyStaleLockFile` and `LockFileButNoData` are no longer
+  thrown from SharedGroup and has been removed from the API.
+
+### Enhancements:
+
+* Support for implicit transactions has been extended to work between multiple
+  processes.
+* Commitlogs can now be persisted and support server-synchronization
+
+----------------------------------------------
+
+# 0.86.1 Release notes
+
+### Enhancements:
+
+* Added `SharedGroup::get_number_of_versions()` which will report the number of
+  distinct versions kept in the database.
+* Added support for encryption
+* Adding `SharedGroup::wait_for_change()` which allows a thread to sleep until
+  the database changes.
+
+----------------------------------------------
+
+# 0.86.0 Release notes
+
+### Bugfixes:
+
+* Fixed a bug where rollback of an empty transaction could cause a crash.
+
+### API breaking changes:
+
+* Table::erase() can no longer be used with unordered tables. Previously it was
+  allowed if the specified index was the index of the last row in the table. One
+  must now always use Table::move_last_over() with unordered tables. Whether a
+  table is ordered or unordered is entirely decided by the way it is used by the
+  application, and note that only unordered tables are allowed to contain link
+  columns.
+
+### Enhancements:
+
+* TableView::sync_if_needed() now returns a version number. Bindings can compare
+  version numbers returned in order to determine if the TableView has changed.
+* Added not_equal(), equal(), contains(), begins_with(), ends_with() for String
+  columns in the Query expression syntax. They work both case sensitive and
+  insensitive. So now you can write 'size_t m =
+  table1->column<String>(0).contains("A", true).find();'. Works with Links too.
+* Major simplification of ".lock" file handling.  We now leave the ".lock" file
+  behind.
+* Support added for cascading row removal. See `Descriptor::set_link_type()` for
+  details. All previsouly created link columns will effectively have link-type
+  'weak'.
+* Rows can now be removed via a row accessors (`Row::remove()`,
+  `Row::move_last_over()`).
+* Speedup of double/float conditions in query expression of a factor ~5 (uses
+  fallback to old query nodes for double/float too, instead of only for integer
+  conditions).
+
+----------------------------------------------
+
+# 0.85.1 Release notes
+
+### Bugfixes:
+
+* Made Query store a deep copy of user given strings when using the expression
+  syntax
+
+----------------------------------------------
+
+# 0.85.0 Release notes
+
+### Bugfixes:
+
+* Fixed a crash when copying a query checking for equality on an indexed string
+  column.
+* Fixed a stack overflow when too many query conditions were combined with Or().
+
+### API breaking changes:
+
+* Now supports index on Integer, Bool and Date columns; API is the same as for
+  String index
+* `Query::tableview()` removed as it might lead to wrong results - e.g., when
+  sorting a sorted tableview.
+
+### Enhancements:
+
+* Make the durability level settable in the `SharedGroup` constructor and
+  `open()` overloads taking a `Replication`.
+
+----------------------------------------------
+
+# 0.84.0 Release notes
+
+### API breaking changes:
+
+* `Table::set_index()` and `Table::has_index()` renamed to
+  `Table::add_search_index()` and `Table::has_search_index()` respectively, and
+  `Table::add_search_index()` now throws instead of failing in an unspecified
+  way.
+* `Table::find_pkey_string()` replaces `Table::lookup()` and has slightly
+  different semantics. In particular, it now throws instead of failing in an
+  unspecified way.
+
+### Enhancements:
+
+* A row accessor (`Row`) can now be evaluated in boolean context to see whether
+  it is still attached.
+* `Table::try_add_primary_key()` and `Table::remove_primary_key()` added.
+* `Table::find_pkey_int()` added, but not yet backed by an integer search index.
+* Added method `LangBindHelper::rollback_and_continue_as_read()`. This method
+  provides the ability to rollback a write transaction while retaining
+  accessors: Accessors which are detached as part of the rolled back write
+  transaction are *not* automatically re-attached. Accessors that were attached
+  before the write transaction and which are not detached during the write
+  transaction will remain attached after the rollback.
+
+-----------
+
+### Internals:
+
+* Introducing `LogicError` as an alternative to expected exceptions. See
+  https://github.com/Realm/realm/wiki/Exception-safety-guarantees for more
+  on this.
+* Various query related speed improvements.
+* Test suite now passes ASAN (address sanitizer).
+
+----------------------------------------------
+
+# 0.83.1 Release notes
+
+### Bugfixes:
+
+* Fixed bug where a TableView generated from a LinkViewRef did not update when
+  the origin or target table changed.
+
+----------------------------------------------
+
+# 0.83.0 Release notes
+
+### API breaking changes:
+
+* Sorting on LinkView and TableView by multiple columns: Both classes now have
+  get_sorted_view() (returns sorted view) and sort() (in-place sort). Both
+  methods can take either a single column index as argument (as size_t) or a
+  std::vector of columns to sort by multiple columns.
+* You can now query a LinkView by calling Query::where(link_view.get()).... See
+  TEST(LinkList_QueryOnLinkList) in test_link_query_view.cpp for an example.
+  *** IMPORTANT NOTE: Do not call sort() on a LinkView because it does not
+  yet support replication ***. get_sorted_view() works fine though.
+
+-----------
+
+### Internals:
+
+* Made common base class for TableView and LinkView with common shared
+  functionality (so far just sort).
+
+----------------------------------------------
+
+# 0.82.3 Release notes
+
+### Bugfixes:
+
+* Fixed bug in deep copy of Query, causing the experienced crash at end of scope
+  of a Query after add_constraint_to_query() had been executed. The fix may not
+  be optimal as it limits nesting of group/end_group to 16 levels, and also
+  makes Query take 128 extra bytes of space. Asana task has been made.
+
+* Fixed bug that would cause `Group::commit()` and
+  `LangBindHelper::commit_and_continue_as_read()` to fail in the presence of
+  search indexes.
+
+* Bugfix: Replication::m_selected_link_list was not cleared. This bug could lead
+  to general corruption in cases involving link lists.
+
+----------------------------------------------
+
+# 0.82.2 Release notes
+
+### Internals:
+
+* Query must now be deep-copied using the '=' operator instead of using
+  TCopyExpressionTag. Also fixed a bug in this deep-copying.
+
+----------------------------------------------
+
+# 0.82.1 Release notes
+
+### Internals:
+
+* `REALM_MAX_LIST_SIZE` was renamed to `REALM_MAX_BPNODE_SIZE`. `BPNODE`
+  stands for "B+-tree node".
+* `REALM_MAX_BPNODE_SIZE` now defaults to 1000 in both *release* and *debug*
+  mode.
+
+----------------------------------------------
+
+# 0.82.0 Release notes
+
+### API breaking changes:
+
+* `Group::has_table<T>()` removed, because it had awkward and incongruous
+  semantics, and could not be efficiently implemented.
+* The version of `Group::get_table()`, that takes a name argument, can no longer
+  add a table to the group, instead it returns null if there is no table with
+  the spaecified name. Addition is now handled by either `Group::add_table()` or
+  `Group::get_or_add_table()`.
+* `Group::get_table()` and Group::get_table_name() now throw
+  `realm::InvalidArgument` if the specified table index is out of range.
+* Template version of `Group::get_table()` now throws `DescriptorMismatch` if
+  the dynamic type disagrees with the statically specified custom table type.
+* `LangBindHelper::bind_table_ref()` was renamed to
+  `LangBindHelper::bind_table_ptr()`, and `LangBindHelper::unbind_table_ref()`
+  to `LangBindHelper::unbind_table_ptr()`.
+* LangBindHelper functions such as get_table() have been updated to reflect the
+  changed Group API.
+* Exception type `ResourceAllocError` eliminated, as there was no good reason
+  for keeping it (it had no clear role).
+
+### Enhancements:
+
+* `Group::find_table()` added as a way of mapping a table name to the index of
+  table in the group.
+* `Group::add_table()` and `Group::get_or_add_table()` were added.
+* `Group::remove_table()` and `Group::rename_table()` were added.
+* `WriteTransaction::add_table()` and `WriteTransaction::get_or_add_table()`
+  ware added.
+
+----------------------------------------------
+
+# 0.81.0 Release notes
+
+### API breaking changes:
+
+* `Table::get_parent_row_index()` and `Table::get_index_in_group()` together
+  replace `Table::get_index_in_parent()`. This was done to avoid a confusing mix
+  of distinct concepts.
+
+### Enhancements:
+
+* It's now possible to sort a LinkRef according to a column in the target
+  table. Also lets you build a TableView with the sorted result instead. The new
+  methods on LinkViewRef are `sort()` and `get_sorted_view()`
+
+----------------------------------------------
+
+# 0.80.5 Release notes
+
+### Bugfixes:
+
+* Fixed bug in `where(&tv)...find()` where it would fail to find a match, if
+  usig with a TableView, tv.
+* Fixed bug in `Table::remove()` which would leak memory when rows were removed
+  and the table was a link target.
+* Fixed bug that prevented reuse of free-space when using
+  `LangBindHelper::promote_to_write()` and
+  `LangBindHelper::commit_and_continue_as_read()`.
+
+### Enhancements:
+
+* Lets you search for null-links, such as
+  `table2->column<Link>(col_link2).is_null().find()`. Works for `Link` and
+  `LinkedList`.
+
+-----------
+
+### Internals:
+
+* `Group::Verify()` now checks that the managed memory is precisely the
+  combination of the recorded free space and the used space reachable from the
+  root node.
+
+----------------------------------------------
+
+# 0.80.4 Release notes
+
+### Bugfixes:
+
+* Bug fixed that would always leave a link list accessor (`LinkView`) in a
+  corrupt state after a call to `Group::commit()` or
+  `LangBindHelper::commit_and_continue_as_read()`, if the link list was modified
+  during the ended "transaction", and was non-empty either before, after, or
+  both before and after that "transaction".
+
+-----------
+
+### Internals:
+
+* Efficiency of CRUD operations has been greatly improved due to an improvement
+  of SlabAlloc). The cost of end-insertion (MyTable::add()), for example, has
+  been reduced to less than a 10th of its previous cost.
+
+----------------------------------------------
+
+# 0.80.3 Release notes
+
+### Bugfixes:
+
+* Fixed bug in `Table::add_column()` which would produce a corrupt underlying
+  node structure if the table already contains more than N**2 rows, where N is
+  `REALM_MAX_LIST_SIZE` (currently set to 1000).
+* Fixed bugs in `Table::clear()` which would produce a corrupt underlying node
+  structure if the table already contains more than N rows, where N is
+  `REALM_MAX_LIST_SIZE` (currently set to 1000).
+
+### Enhancements:
+
+* Lets you find links that point at a specific row index. Works on Query and
+  Table. Please see `LinkList_QueryFindLinkTarget` in `test_link_query_view.cpp`
+  for usage.
+
+-----------
+
+### Internals:
+
+* Table::Verify() has been heavily extended and now also checks link columns and
+  link lists (debug mode only).
+
+----------------------------------------------
+
+# 0.80.2 Release notes
+
+### Bugfixes:
+
+* Fixed bug causing corrupted table accessor when advancing transaction after last regular column is removed from table with remaining hidden backlink columns.
+* Fixed replication issue causing too many link list selection instructions to be generated.
+
+----------------------------------------------
+
+# 0.80.1 Release notes
+
+### Bugfixes:
+
+* Fixed several bugs in connection to removal of like-type columns.
+* Fixed bug when last regular column is removed from table with remaining hidden backlink columns.
+* Fixed bug causing corrupted table accessor when column are added or removed before alink column.
+
+----------------------------------------------
+
+# 0.80.0 Release notes
+
+### Bugfixes:
+
+* Fixed bug in `TableView::clear()` causing crash if its table contained link columns.
+* Fixed bug which would corrupt subtable accessors when inserting or removing parent table columns.
+* Fixed bug in LinkView::refresh_accessor_tree() causing problems when transaction is advanced after a link list is cleared.
+* Fixed bug causing problems when transaction is advanced after a table with link-like columns is cleared.
+* Fixed bug in connection with cyclic link relationships.
+
+### Enhancements:
+
+* Added methods `LinkView::remove_target_row()` and `LinkView::remove_all_target_rows()`.
+* Support for removing link columns
+
+
+----------------------------------------------
+
+# 0.23.0 Release notes
+
+### Bugfixes:
+* Fixed bug in `TableView::remove()` causing crash or undefined behavior.
+* Fixed bugs in `Table::insert_column()` and `Table::remove_column()` causing crash or undefined behaviour.
+* Fixed corruption bug when a string enumeration column follows a column with attached search index (index flavor mixup).
+* Fixed in `Array::erase()` causing crash in certain row insertion scenarios.
+* Fixed bug in enumerated strings column (corruption was possible when inserting default values).
+* Fixed bug in `Table::update_from_parent()` causing a crash if `Group::commit()` in presence of generated subtable accessor.
+* Fixed several link-related bugs due to confusion about the meaning of `LinkView::m_table`.
+
+### API breaking changes:
+
+* Views can now be be kept synchronized with changes to the tables used to generate the view, use `TableView::sync_if_needed()` to do so. Views are no longer detached when the table they have been generated from are changed. Instead they just go out of sync. See further description in `src/realm/table_view.hpp`.
+* is_attached(), detach(), get_table(), and get_index() moved from BasicRow to RowFuncs. This makes it possible to write `link_list[7].get_index()`, for instance.
+* `LinkView::get_target_row(link_ndx)` was removed as it is now just a shorthand for the equally efficient `LinkView::get(link_ndx).get_index()`.
+* Added missing const versions of `LinkView::get()` and `LinkView::operator[]()`.
+* Confusing `LinkView::get_parent()` removed.
+* Added `LinkView::get_origin_table()` and `LinkView::get_target_table()`.
+
+### Enhancements:
+* Now maximum() and minimum() can return the index of the match and not only the value. Implemented for Query, Table and TableView.
+* Now supports links in Table::to_json. Please see unit tests in the new test_json.cpp file
+* Now supports DateTime Query::maximum_datetime() and DateTime Query::minimum_datetime()
+* Supports links in queries, like `(table1->link(3).column<Int>(0) > 550).find()`.
+* Added support for links and lists of links as column types, to enable relationships between tables.
+* Adding `Table::get_index_in_parent()` and `Group::get_table(std::size_t table_ndx)`. They were needed for implicit transactions.
+* `Table::get_parent_table()` can now also return the index of the column in the parent.
+* Support for row accessors.
+* Table, row, and descriptor accessors are now generally retained and properly adjusted when the parent table is modified.
+* Added methods to find rows by target in TableView and LinkView.
+
+
+-----------
+
+### Internals:
+
+* TableView now creates and stores a deep-copy of its query, in order for the view to refresh itself
+
+----------------------------------------------
+
+0.5.0 Release notes (2014-04-02)
+================================
+
+C++ (core)
+-----------
+The C++ API has been updated and your code will break!
+
+### Bugfixes:
+
+* None.
+
+### API breaking changes:
+
+* None.
+
+### Enhancements:
+
+* Read transactions are now non-blocking and their overhead has been reduced by an order of magnitude.
+
+-----------
+
+### Internals:
+
+* New test suite with support for parallelized testing replaces UnitTest++. See section 'Testing' in `README.md`.
+
+
+----------------------------------------------
+
+
+Realm Changelog:
+==================
+
+Format:
+
+2012-mm-dd
+----------
+! Fixed bug [github issuenr]: ....       (user visible bug fixed       - passed on to release notes)
++ Added feature ....                     (user visible new feature     - passed on to release notes)
+- Removed/deprecated feature/method .... (user visible removed feature - passed on to release notes)
+. Any other notes ....                   (internal changes)
+
+
+2014-05-14 (Lasse Reinhold)
++ Lets you sort a TableView according to a Float, Double or String column (only integral column types possible before)
+
+
+2014-05-08 (Finn Schiermer Andersen)
++ Added negation to the query engine.
+
+
+2014-04-01 (Kristian Spangsege)
++ New framework with support for parallelized unit testing replaces UnitTest++. See section 'Testing' in `README.md`.
+
+
+2014-03-25 (Kristian Spangsege)
+! Fixed bug when clearing table with a float/double column.
+
+
+2014-03-13 (Finn Schiermer Andersen)
+! Fixed missing initialization of empty columns in some scenarios.
+
+
+2014-02-19 (Finn Schiermer Andersen)
+! Fixed space leak in group_writer. Could in some scenarios cause massive increase in database file size.
+
+
+2014-02-17 (Kristian Spangsege)
++ Adding Table::write() as a means to effieciently serialize a table, or part of a table.
+! Fixing table copy bug. The error occured when the table contained strings longer than 64 bytes.
+! Fixing table comparison bug. The error occured when the table has a `float` or a `double` column.
+
+
+2014-02-14 (Kristian Spangsege)
+
+* New test suite with support for parallelized testing replaces UnitTest++. See section 'Testing' in `README.md`.
++ The StringData class now distinguishes `null` from the empty string.
++ Adding StringData::is_null().
+
+
+2014-02-11 (Kristian Spangsege)
++ Group::write(std::ostream&) added. This allows general online streaming of Realm databases in memory for the first time.
++ Adding Table::get_name() which returns the name of the table when the table is a direct member of a group.
+
+
+2014-02-05 (Kenneth Geisshirt)
++ Two new targets in build.sh: get_version and set_version.
+
+
+2014-02-04 (Kristian Spangsege)
++ Introducing Table::get_parent_table() with allows a subtable to know its parent table.
++ Table::rename_subcolumn() and Table::remove_subcolumn() now take an extra argument which is the index of the column to rename. Before the index was specified as part of the path.
++ Introducing Table::insert_column() and Table::insert_subcolumn() for inserting new columns at arbitrary positions.
++ New class `Descriptor` introduced into the public API. It plays the role that `Spec` played before. Class `Spec` is no longer to be considered part of the public API.
++ Table::add_column() now takes a third optinal argument `DescriptorRef* subdesc`.
++ Introducing Table::get_descriptor() and Table::get_subdescriptor()
+- Table::get_spec() and Table::update_from_spec() removed from public API since are part of the now non-public `Spec` API.
+. Table::has_shared_spec() renamed to Table::has_shared_type().
+
+
+2014-01-27 (Brian Munkholm)
+! Fixed bug in Query with subtables. Whith empty subtables query returned incorrect results.
+  In debug mode it could assert when querying a subtable with more columns than the base table.
+
+2014-01-23 (Kenneth Geisshirt)
+! Fixed bug: Subtable queries is validated by Query::validate(). An invalid subtable query can lead to a segfault.
+
+
+2014-01-07 (Kenneth Geisshirt)
++ Table::range() added. The method returns a set of rows as a TableView.
+
+
+2014-01-06 (Kristian Spangsege)
+! 'No parent info in shared specs' conflicts with implementation of `Group::commit()`.
+! `ColumnTable::m_spec_ref` not updated when Spec object is reallocated.
+! `ColumnSubtableParent::m_index` not updated when preceeding columns are removed.
++ Addition of `template<class L> std::size_t Table::add_subcolumn(const util::Tuple<L>&, DataType, StringData)`. This makes it much easier to add columns to subtable specs.
+. `Spec::get_subtable_spec()` now returns `SubspecRef` or `ConstSubspecRef`. This fixes a design bug relating to propagation of constness to subspecs, and it improves the efficiency of access to subspecs by avoiding expensive copying of `Spec` objects.
+. Elimination of `Spec::m_table` and `ColumnTable::m_spec_ref`.
+. `Spec::add_column()` and `Spec::add_subcolumn()` now take a `Table*` as argument.
+
+
+2013-12-17 (Kristian Spangsege)
++ Implicit termination of active transaction when SharedGroup is destroyed.
+. Class `File` and related exceptions such as `File::AccessError` moved to namespace `realm::util`.
+. Table::add_column() optimized. For integer columns, the speedup is by more than a factor of 1000 for large tables.
+
+
+2013-11-07 (Alexander Stigsen)
+. BREAKING CHANGE: Schema now handles attributes separately for better performance when there are many colummns.
+
+
+2013-11-07 (Lasse Reinhold)
++ Added power() operator for next-generation-queries
+
+
+2013-11-07 (Lasse Reinhold)
+! Fixed bug: ng-queries could segfault to bug in Array::get_chunk(). Normal queries and everything else not affected.
+
+
+2013-10-10 (Kenneth Geisshirt)
+. Adding INTERACTIVE mode for the dist-config target in build.sh
+
+
+2013-10-09 (Kenneth Geisshirt)
+. Adding dist-deb target in build.sh for building debian/ubuntu/mint packages. Moreover, the ubuntu/mint version is part of package name so maintaining repositories is easier.
+
+
+2013-09-26 (Brian Munkholm)
++/- Renamed Table::distinct() to Table::get_distinct_view()
++/- Renamed class Date to DateTime. Renamed DataType::type_Date to type_DateTime
++/- Renamed suffix of all methods operating on DateTime from '_date' to '_datetime'.
+
+
+2013-09-26 (Kristian Spangsege)
++ File format support for streaming of output from Group::write() (not yet suported by API.)
++ Support for internal null characters in strings. This applies to table and column names as well.
+
+
+2013-09-19 (Kristian Spangsege)
+. CRUD performance has been greatly improved for large tables, as long as they are kept on the "compact" form. A table is kept on the compact form when every row insertion and removal, since the creation of that table, has occured, and continues to occur at the end (i.e., insert after last row, and remove last row).
+
+
+2013-10-02 (Lasse Reinhold)
+- Renamed find_next(lastmatch) into find(begin_at_table_row) for queries and typed tables.
+
+
+2013-09-12 (Brian Munkholm)
++ Added TableView::row_to_string() and testcases for to_string() and row_to_string()
++ Added row_to_string(), to_string() and to_json() in typed TableView.
+
+
+2013-08-31 (Kristian Spangsege)
++ Database files are now exanded by doubling the size until it reaches 128 MiB. After that, it is expanded in chunks of 128 MiB. Until now, it was always expanded in chunks of 1 MiB.
+
+
+2013-08-28 (Kristian Spangsege)
++ Table::is_valid() renamed to Table::is_attached(). The notion of accessor attachment describes much better what is going on than the notion of validity.
+
+
+2013-08-23 (Kristian Spangsege)
++ Stop throwing from destructors (all), and from SharedGroup::rollback() and SharedGroup::end_read().
++ General stability and error checking improvements.
+! Fixed many bugs relating to Group::commit().
+! Fixed some bugs relating to SharedGroup::commit().
+! Fixed bug in TableViewBase::sort().
+
+
+2013-08-18 (Kenneth Geisshirt)
+! Group::to_string() formatting was incorrect. See https://app.asana.com/0/1441391972580/5659532773181.
+
+
+2013-08-03 (Kristian Spangsege)
++ Table::find_sorted_int() replaced by Table::lower_bound_int() and Table::upper_bound_int() as these are standardized and provide more flexibility.
++ Addition of Table::lower_bound_bool() and Table::upper_bound_bool().
++ Addition of Table::lower_bound_float() and Table::upper_bound_float().
++ Addition of Table::lower_bound_double() and Table::upper_bound_double().
++ Addition of Table::lower_bound_string() and Table::upper_bound_string(). They rely on simple byte-wise lexicographical comparison. No Unicode or locale dependent collation is taken into account. Comparison occurs exactly as defined by std::lexicographical_compare in the C++ STL.
+
+
+2013-07-19 (Dennis Fantoni)
++ Added Table::set_subtable(size_t column_ndx, size_t row_ndx, const Table*)
+
+
+2013-06-25 (Kristian Spangsege)
+. The default group open mode has been changed from Group::mode_Normal
+  (read/write) to Group::mode_ReadOnly. This makes it possible to open
+  a read-only file without specifying a special open mode. Also, since
+  changed groups are generally written to new files, there is rarely a
+  need for the group to be opened in read/write mode.
+. Group::mode_Normal has been renamed to Group::mode_ReadWrite since it is no longer a normal mode.
+. Group::mode_NoCreate has been renamed to Group::mode_ReadWriteNoCreate for clarity.
+
+
+2013-06-05 (Kristian Spangsege)
+. Group::write(path) now throws File::Exists if 'path' already exists in the file system.
+
+
+2013-05-16 (Kristian Spangsege)
++ New SharedGroup::reserve() method added.
+
+
+2013-05-13 (Kenneth Geisshirt)
+. Added "uninstall" target in build.sh for simple uninstallation.
+
+
+2013-05-07 (Kristian Spangsege)
+. Exception File::OpenError renamed to File::AccessError. This affects
+  various methods in Group and SharedGroup.
+
+
+2013-04-23 (Kristian Spangsege)
++ Support for explicit string lengths added. Most method arguments and
+  return values of type 'const char*' have been changed to be of type
+  'StringData'. This new type is defined in
+  <realm/string_data.hpp>. 'StringData' can be implicitly
+  constructed from 'const char*', so no change is required when
+  passing arguments. Source code change is required when dealing with
+  returned strings of type 'const char*'. The following is a complete
+  list:
+    Affected form                      Possible replacement
+    ---------------------------------------------------------------------------
+    group.get_table_name(...)          group.get_table_name(...).data()
+    table.get_column_name()            table.get_column_name().data()
+    table.get_string(...)              table.get_string(...).data()
+    table.get_mixed(...).get_string()  table.get_mixed(...).get_string().data()
+    table[7].string_col                table[7].string_col.c_str()
++ Added support for table[7].string_col.data() and table[7].string_col.size().
++ Full and seamless interoperability with std::string. This comes
+  about from the fact that StringData can be implicitly constructed
+  from, and convert to std::string.
++ Full support for BinaryData in queries.
++ Added BinaryData::data(), BinaryData::size(), BinaryData::operator[]()
++ Added BinaryData::operator==(), BinaryData::operator!=(), BinaryData::operator<()
++ Added BinaryData::begins_with(), BinaryData::ends_with(), BinaryData::contains()
++ Allow BinaryData to be constructed from fixed size array:
+  template<std::size_t N> explicit BinaryData(const char (&)[N])
+- BinaryData::pointer removed, use BinaryData::data() instead.
+- BinaryData::len removed, use BinaryData::size() instead.
+- BinaryData::compare_payload() removed, use BinaryData::operator==() instead.
++ The methods
+    Table::set_binary(std::size_t column_ndx, std::size_t row_ndx, const char* data, std::size_t size)
+    Table::insert_binary(std::size_t column_ndx, std::size_t row_ndx, const char* data, std::size_t size)
+    Table::find_first_binary(std::size_t column_ndx, const char* data, std::size_t size)
+    Table::find_all_binary(std::size_t column_ndx, const char* data, std::size_t size)
+    TableView::set_binary(std::size_t column_ndx, std::size_t row_ndx, const char* data, std::size_t size)
+  have been changed to
+    Table::set_binary(std::size_t column_ndx, std::size_t row_ndx, BinaryData)
+    Table::insert_binary(std::size_t column_ndx, std::size_t row_ndx, BinaryData)
+    Table::find_first_binary(std::size_t column_ndx, BinaryData)
+    Table::find_all_binary(std::size_t column_ndx, BinaryData)
+    TableView::set_binary(std::size_t column_ndx, std::size_t row_ndx, BinaryData)
+  The following changes have been made in the statically
+  typed API:
+    Affected form                  Possible replacement
+    ---------------------------------------------------------
+    table[7].binary_col.pointer()  table[7].binary_col.data()
+    table[7].binary_col.len()      table[7].binary_col.size()
+  These changes were made for consistency with StringData.
++ Added Date::operator<()
++ Return type changed from 'std::time_t' to 'Date' on the following
+  methods:
+    Mixed::get_date()
+    Table::get_date()
+    TableView::get_date()
+  Argument type changed from 'std::time_t' to 'Date' on many methods including these:
+    Mixed::set_date()
+    Table::set_date()
+    Table::insert_date()
+    TableView::set_date()
+  Changes corresponding to these have been made in the statically
+  typed API. These are some of the affected forms:
+    time_t(table[7].date_col)
+    table[7].date_col = val
+    table[7].mixed_col.get_date()
+  These changes were made for consistency, and to improve the
+  isolation of the implementation of 'Date' (it is likely that the
+  implementation of 'Date' will change). 'Date' can be implicitly
+  constructed from std::time_t, but it cannot be implicitly converted
+  to std::time_t (nor is it considered desireable to allow such an
+  implicit conversion). This means that applications will be affected
+  as follows:
+    Affected form                    Possible replacement
+    ---------------------------------------------------------------------------
+    table.get_date(...)              table.get_date(...).get_date()
+    table.get_mixed(...).get_date()  table.get_mixed(...).get_date().get_date()
+    time_t(table[7].date_col)        Date(table[7].date_col).get_date()
+    table[7].date_col.get()          table[7].date_col.get().get_date()
++ Group::write() and Group::write_to_mem() are now 'const'.
++ Group::BufferSpec eliminated. Using BinaryData instead.
+
+
+2013-03-11 (Kristian Spangsege)
++ On Linux and OS X, installed shared libraries now carry a platform
+  dependent API version which is computed from a platform neutral
+  version specifier (same as GNU Libtool). This allows for multiple
+  versions of the shared library to be concurrently installed.
+
+
+2013-02-24 (Kristian Spangsege)
++ Adding copy constructors for Table and BasicTable.
++ Adding Table::copy(), BasicTable::copy() and LangBindHelper::copy_table().
++ Adding BasicTable::create() for symmetry with Table::create().
+
+
+2013-02-21 (Brian Munkholm
+-+ Renamed Group::get_table_count() to Group::size()
+
+
+2013-02-19 (Kristian Spangsege)
++ Type of Group::BufferSpec::m_data changed from <char*> to <const char*>.
+
+
+2013-02-06 (Kristian Spangsege)
++ New enum DataType replaces ColumnType throughout the public API.
+
+
+2013-01-27 (Kristian Spangsege)
++ New Group::Group(unattached_tag) added. Same for SharedGroup.
++ New Group::open(...) methods added. Same for SharedGroup.
++ New Group::is_attached() added. Same for SharedGroup.
++ Classes ReadTransaction and WriteTransaction added for handling safe scoped transaction.
++ Many methods have now been qualified with REALM_NOEXCEPT.
+
+
+2013-01-14 (Kristian Spangsege)
+- Group::set_shared() removed.
+- SharedGroup::is_valid() removed. Errors are now reported as exceptions from the constructor.
+
+
+2013-01-11 (Kristian Spangsege)
++ Simplified open-mode for Group constructor.
+- Group::is_valid() removed. Errors are now reported as exceptions from the constructor.
++ Now using Group::BufferSpec to pass a memory buffer to the Group constructor.
++ Group::write_to_mem() now returns a Group::BufferSpec.
++ Addition of 'bool no_create' arguemnt to SharedGroup constructor.
+
+
+2013-01-08 (Kristian Spangsege)
++ Mixed::set_int() added (same for other value types except subtables).
++ Removed two-argument Mixed constructor for binary data since its signature is expected to be used for strings that are not zero-terminated.
+
+
+2013-01-08 (Brian Munkholm)
+----------
++ New: Added a bunch of methods to support two new column types: float and double.
+
+
+2012-12-16 (Kristian Spangsege)
+----------
++ my_table[i].foo.get() added for all column types except subtables. This is to avoid having to repeat the explicit column type in cast expressions when the actual value is needed.
++ my_table[i].foo.set(...) added for all column types except subtables. This is for completeness.
++ When passing a file name to a Group or a SharedGroup constructor, the type is now a std::string. This is made possible by allowing exception handling. It simplifies the implementation in a few places, and in general it simplifies application code.
++ A 'tag' argument has ben added to the Group constructor that takes a memory buffer as argument. Without this change, two Group constructors were way too similar.
+
+
+2012-12-06 (Brian Munkholm)
+----------
++ 16 New Table:get_string_length(col_ndx, row_ndx) added in Dynamic Table. Missing in Typed Table.
+
+
+2012-12-06 (Kristian Spangsege)
+----------
+. "C" API moved to its own repository "realm_c".
+
+
+2012-12-03 (Brian Munkholm)
+----------
++ 15 Updated Group() constructor to take an optional 3'rd parameter 'take_ownership', which allows the caller to keep owenership of the provided data: Group::Group(const char* buffer, size_t len, bool take_ownership=true).
+
+
+2012-11-13 (Kristian Spangsege)
+----------
++ 14 Renamed Table::count() to Table::count_int()
+
+
+2012-11-21
+----------
++ Added ShareGroup::has_changed() to detect if there has been changes to the db since last transaction.
+
+
+2012-11-12 (Kristian Spangsege)
+----------
+! Fixed a memory leak when using Table::create()
+
+
+2012-10-24 (Kristian Spangsege)
+----------
++ 13 Added Table::has_shared_spec().
+
+
+2012-10-10 (Kristian Spangsege)
+----------
+! Fix a problem with MyTable::Query copy constructor that caused access to deallocated memory due to a pointer that was not updated.
+
+
+2012-10-02 (Kristian Spangsege)
+----------
++ New program 'realm-config'. Use it to query about the CFLAGs and/or LDFLAGs to use when linking agains the Realm core library.
+
+
+2012-10-01 (Brian Munkholm)
+----------
++ 12 Added double Table::average(size_t column_ndx) const
+
+
+2012-09-07 (Alexander Stigsen)
+----------
++ File format updated with bigger header and reordered column type [BREAKING]
++ Index is now enabled for string columns (handles string_enum columns as well).
++ 11 Added Table::count_string(size_t column_ndx, const char* target) const;
++ 11 Added Table accessor size_t count(const char* target) const to highlevel interface
++ 11 Spec::add_column(...) now takes an optional parameter for attribute (like indexed).
++ 11 Added Table::to_string() and Group::to_string() for prettified string dump.
+
+
+2012-08-14 (Brian Munkholm)
+----------
++ 10 Renamed FindAllMulti() to find_all_multe(). And SetThreads() to set_threads()
++ 10 Renamed cols() to column().
++ 10 Renamed get_subspec() to get_subtable_spec().
++ 10 Renamed parent() to end_subtable().
+
+
+2012-08-01 (Kristian Spangsege)
+----------
++ 9 Date::operator==(const Date&) and Date::operator!=(const Date&) added.
++ 9 BinaryData::operator==(const BinaryData&) and BinaryData::operator!=(const BinaryData&) added.
++ 9 Operators added for comparison between a value of type Mixed and a value of one of the possible types that a Mixed can contain. Operators are added for both orders of the two arguments.
++ 8 Comparison operators added for "foo" == my_table[i].str and "foo" != my_table[i].str. We already had a comparison operator for the reverse order case, my_table[i].str == "foo".
++ 7 my_table[i].mixed.get_subtable_size() added.
+
+
+2012-07-27 (Kristian Spangsege)
+----------
++ 6 realm::is_a<MyTable>(const Table&) added.
++ 6 realm::unchecked_cast<MyTable>(TableRef) added.
++ 6 realm::checked_cast<MyTable>(TableRef) added.
++ 6 my_table[i].mixed.set_subtable() added.
++ 6 my_table[i].mixed.set_subtable<MySubtable>() added.
++ 6 my_table[i].mixed.is_subtable<MyTable>() added (inefficient, do we want it at all?).
++ 6 my_table[i].mixed.get_subtable<MySubtable>() added (unsafe/unchecked, do we want it at all?).
+
+
+2012-07-24 (Kristian Spangsege)
+----------
++  New macro REALM_DEBUG to control compilation mode.
+    The library (including all headers) is no longer affected in any way by the definition status of NDEBUG or _DEBUG.
+    When we (Realm) compile the library in debug mode, we must define this macro.
+    We will deliver two versions of the library, one for release mode, and one for debug mode.
+    If the customer wishes to use the debugging version of the library, he must do two things:
+    1) Define REALM_DEBUG in any translation unit that includes a Realm header.
+    2) Use the version of the library that is compiled for debug mode (librealm_d.a).
++ 5 Removed obsolete constructor Mixed(ColumnType). Use Mixed(subtable_tag) instead, since this has no runtime overhead.
+
+
+2012-07-19 (Kristian Spangsege)
+----------
++ 4 Table::create() added. Use this to create a freestanding top-level table with dynamic lifetime (determined by reference counting).
++   TableRef::reset() added to set a table reference to null.
+
+
+2012-07-15 (Kristian Spangsege)
+----------
++ 3 Spec::compare() renamed to Spec::operator==(), and made generally available, not only while compiling in debug mode.
++ 3 Spec::operator!=() added.
++ 3 Table::compare() renamed to Table::operator==(), and made generally available, not only while compiling in debug mode.
++ 3 Table::operator!=() added.
++ 3 MyTable::compare() renamed to MyTable::operator==(), and made generally available, not only while compiling in debug mode.
++ 3 MyTable::operator!=() added.
++ 3 Group::operator==() and Group::operator!=() added.
+. Array::Compare() and Column::Compare() made generally available, not only while compiling in debug mode.
+
+
+2012-07-09 (Kristian Spangsege)
+----------
++ 1 Table::is_valid() added. Most language bindings must check this flag before calling any member function on any table.
++ 1 MyTable::is_valid() added.
++   See documentation for Table::is_valid() for more details on when a table becomes invalid, and when it does not.
++   Destroying a Group will invalidate all table wrappers (instances of Table) as well as all direct and indirect subtable wrappers.
++   Any modifying operation on a table will generally invalidate all direct and indirect subtable wrappers.
++ 2 my_table[i].mixed.is_subtable() added.
++ 2 my_table[i].mixed.get_subtable() added.
+
+
+2012-07-08 (Kristian Spangsege)
+----------
+. LangBindHelper::new_table() now returns null on memory allocation error. This may change in the future to instead throw an exception.
+
+
+2012-06-27
+----------
+-+ Table::sorted(...) changed name to get_sorted_view(...)
+- Removed Table::find_pos_int(...) from public API
+
++ Added a the following methods to a TableView:
+    template<class E> void set_enum(size_t column_ndx, size_t row_ndx, E value);
+    ColumnType  get_mixed_type(size_t column_ndx, size_t row_ndx) const;
+    size_t      get_subtable_size(size_t column_ndx, size_t row_ndx) const;
+    void        clear_subtable(size_t column_ndx, size_t row_ndx);
+    size_t      find_first_bool(size_t column_ndx, bool value) const;
+    size_t      find_first_date(size_t column_ndx, time_t value) const;
+    void        add_int(size_t column_ndx, int64_t value);
+    TableView      find_all_bool(size_t column_ndx, bool value);
+    ConstTableView find_all_bool(size_t column_ndx, bool value) const; (for class TableView and ConstTableView)
+    TableView      find_all_date(size_t column_ndx, time_t value);
+    ConstTableView find_all_date(size_t column_ndx, time_t value) const; (for class TableView and ConstTableView)
+
+2012-06-??
+----------
+- Group() interfaced changed. Now with multiple options. default option changed from readonly...
++ Generated C++ highlevel API for tables with up to 15 columns
diff --git a/node_modules/realm/vendor/realm-ios/doc/realm/LICENSE b/node_modules/realm/vendor/realm-ios/doc/realm/LICENSE
new file mode 100644
index 0000000..02277e8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/doc/realm/LICENSE
@@ -0,0 +1,204 @@
+TABLE OF CONTENTS
+
+1. Apache License version 2.0
+2. Export Compliance
+
+-------------------------------------------------------------------------------
+
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+EXPORT COMPLIANCE
+
+You understand that the Software may contain cryptographic functions that may be
+subject to export restrictions, and you represent and warrant that you are not
+(i) located in a jurisdiction that is subject to United States economic
+sanctions (“Prohibited Jurisdiction”), including Cuba, Iran, North Korea,
+Sudan, Syria or the Crimea region, (ii) a person listed on any U.S. government
+blacklist (to include the List of Specially Designated Nationals and Blocked
+Persons or the Consolidated Sanctions List administered by the U.S. Department
+of the Treasury’s Office of Foreign Assets Control, or the Denied Persons List
+or Entity List administered by the U.S. Department of Commerce)
+(“Sanctioned Person”), or (iii) controlled or 50% or more owned by a Sanctioned
+Person.
+
+You agree to comply with all export, re-export and import restrictions and
+regulations of the U.S. Department of Commerce or other agency or authority of
+the United States or other applicable countries. You also agree not to transfer,
+or authorize the transfer of, directly or indirectly, of the Software to any
+Prohibited Jurisdiction, or otherwise in violation of any such restrictions or
+regulations.
diff --git a/node_modules/realm/vendor/realm-ios/download-realm.lock b/node_modules/realm/vendor/realm-ios/download-realm.lock
new file mode 100644
index 0000000..7dc59e4
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/download-realm.lock
@@ -0,0 +1,3 @@
+SYNC_SERVER_FOLDER=sync
+SYNC_ARCHIVE=realm-sync-cocoa-4.9.1.tar.gz
+SYNC_ARCHIVE_ROOT=core
diff --git a/node_modules/realm/vendor/realm-ios/include/realm.hpp b/node_modules/realm/vendor/realm-ios/include/realm.hpp
new file mode 100644
index 0000000..7ede53f
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm.hpp
@@ -0,0 +1,30 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_HPP
+#define REALM_HPP
+
+#include <realm/group_shared.hpp>
+#include <realm/descriptor.hpp>
+#include <realm/link_view.hpp>
+#include <realm/table_view.hpp>
+#include <realm/query.hpp>
+#include <realm/query_engine.hpp>
+#include <realm/query_expression.hpp>
+
+#endif // REALM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/alloc.hpp b/node_modules/realm/vendor/realm-ios/include/realm/alloc.hpp
new file mode 100644
index 0000000..157d244
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/alloc.hpp
@@ -0,0 +1,387 @@
+﻿/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ALLOC_HPP
+#define REALM_ALLOC_HPP
+
+#include <cstdint>
+#include <cstddef>
+#include <atomic>
+
+#include <realm/util/features.h>
+#include <realm/util/terminate.hpp>
+#include <realm/util/assert.hpp>
+
+namespace realm {
+
+class Allocator;
+
+class Replication;
+
+using ref_type = size_t;
+
+int_fast64_t from_ref(ref_type) noexcept;
+ref_type to_ref(int_fast64_t) noexcept;
+int64_t to_int64(size_t value) noexcept;
+
+class MemRef {
+public:
+    MemRef() noexcept;
+    ~MemRef() noexcept;
+
+    MemRef(char* addr, ref_type ref, Allocator& alloc) noexcept;
+    MemRef(ref_type ref, Allocator& alloc) noexcept;
+
+    char* get_addr();
+    ref_type get_ref();
+    void set_ref(ref_type ref);
+    void set_addr(char* addr);
+
+private:
+    char* m_addr;
+    ref_type m_ref;
+#if REALM_ENABLE_MEMDEBUG
+    // Allocator that created m_ref. Used to verify that the ref is valid whenever you call
+    // get_ref()/get_addr and that it e.g. has not been free'ed
+    const Allocator* m_alloc = nullptr;
+#endif
+};
+
+
+/// The common interface for Realm allocators.
+///
+/// A Realm allocator must associate a 'ref' to each allocated
+/// object and be able to efficiently map any 'ref' to the
+/// corresponding memory address. The 'ref' is an integer and it must
+/// always be divisible by 8. Also, a value of zero is used to
+/// indicate a null-reference, and must therefore never be returned by
+/// Allocator::alloc().
+///
+/// The purpose of the 'refs' is to decouple the memory reference from
+/// the actual address and thereby allowing objects to be relocated in
+/// memory without having to modify stored references.
+///
+/// \sa SlabAlloc
+class Allocator {
+public:
+    /// The specified size must be divisible by 8, and must not be
+    /// zero.
+    ///
+    /// \throw std::bad_alloc If insufficient memory was available.
+    MemRef alloc(size_t size);
+
+    /// Calls do_realloc().
+    ///
+    /// Note: The underscore has been added because the name `realloc`
+    /// would conflict with a macro on the Windows platform.
+    MemRef realloc_(ref_type, const char* addr, size_t old_size, size_t new_size);
+
+    /// Calls do_free().
+    ///
+    /// Note: The underscore has been added because the name `free
+    /// would conflict with a macro on the Windows platform.
+    void free_(ref_type, const char* addr) noexcept;
+
+    /// Shorthand for free_(mem.get_ref(), mem.get_addr()).
+    void free_(MemRef mem) noexcept;
+
+    /// Calls do_translate().
+    char* translate(ref_type ref) const noexcept;
+
+    /// Returns true if, and only if the object at the specified 'ref'
+    /// is in the immutable part of the memory managed by this
+    /// allocator. The method by which some objects become part of the
+    /// immuatble part is entirely up to the class that implements
+    /// this interface.
+    bool is_read_only(ref_type) const noexcept;
+
+    /// Returns a simple allocator that can be used with free-standing
+    /// Realm objects (such as a free-standing table). A
+    /// free-standing object is one that is not part of a Group, and
+    /// therefore, is not part of an actual database.
+    static Allocator& get_default() noexcept;
+
+    virtual ~Allocator() noexcept;
+
+    // Disable copying. Copying an allocator can produce double frees.
+    Allocator(const Allocator&) = delete;
+    Allocator& operator=(const Allocator&) = delete;
+
+    virtual void verify() const = 0;
+
+#ifdef REALM_DEBUG
+    /// Terminate the program precisely when the specified 'ref' is
+    /// freed (or reallocated). You can use this to detect whether the
+    /// ref is freed (or reallocated), and even to get a stacktrace at
+    /// the point where it happens. Call watch(0) to stop watching
+    /// that ref.
+    void watch(ref_type ref)
+    {
+        m_debug_watch = ref;
+    }
+#endif
+
+    Replication* get_replication() noexcept;
+
+protected:
+    size_t m_baseline = 0; // Separation line between immutable and mutable refs.
+
+    Replication* m_replication = nullptr;
+
+    ref_type m_debug_watch = 0;
+
+    /// The specified size must be divisible by 8, and must not be
+    /// zero.
+    ///
+    /// \throw std::bad_alloc If insufficient memory was available.
+    virtual MemRef do_alloc(const size_t size) = 0;
+
+    /// The specified size must be divisible by 8, and must not be
+    /// zero.
+    ///
+    /// The default version of this function simply allocates a new
+    /// chunk of memory, copies over the old contents, and then frees
+    /// the old chunk.
+    ///
+    /// \throw std::bad_alloc If insufficient memory was available.
+    virtual MemRef do_realloc(ref_type, char* addr, size_t old_size, size_t new_size) = 0;
+
+    /// Release the specified chunk of memory.
+    virtual void do_free(ref_type, char* addr) noexcept = 0;
+
+    /// Map the specified \a ref to the corresponding memory
+    /// address. Note that if is_read_only(ref) returns true, then the
+    /// referenced object is to be considered immutable, and it is
+    /// then entirely the responsibility of the caller that the memory
+    /// is not modified by way of the returned memory pointer.
+    virtual char* do_translate(ref_type ref) const noexcept = 0;
+
+    Allocator() noexcept;
+
+    // FIXME: This really doesn't belong in an allocator, but it is the best
+    // place for now, because every table has a pointer leading here. It would
+    // be more obvious to place it in Group, but that would add a runtime overhead,
+    // and access is time critical.
+    //
+    // This means that multiple threads that allocate Realm objects through the
+    // default allocator will share this variable, which is a logical design flaw
+    // that can make sync_if_needed() re-run queries even though it is not required.
+    // It must be atomic because it's shared.
+    std::atomic<uint_fast64_t> m_table_versioning_counter;
+    std::atomic<uint_fast64_t> m_latest_observed_counter;
+
+    /// Bump the global version counter. This method should be called when
+    /// version bumping is initiated. Then following calls to should_propagate_version()
+    /// can be used to prune the version bumping.
+    void bump_global_version() noexcept;
+
+    /// Determine if the "local_version" is out of sync, so that it should
+    /// be updated. In that case: also update it. Called from Table::bump_version
+    /// to control propagation of version updates on tables within the group.
+    bool should_propagate_version(uint_fast64_t& local_version) noexcept;
+
+    /// Note the current global version has been observed.
+    void observe_version() noexcept;
+
+    friend class Table;
+    friend class Group;
+};
+
+inline void Allocator::bump_global_version() noexcept
+{
+    if (m_latest_observed_counter == m_table_versioning_counter)
+        m_table_versioning_counter += 1;
+}
+
+
+inline void Allocator::observe_version() noexcept
+{
+    if (m_latest_observed_counter != m_table_versioning_counter)
+        m_latest_observed_counter.store(m_table_versioning_counter, std::memory_order_relaxed);
+}
+
+
+inline bool Allocator::should_propagate_version(uint_fast64_t& local_version) noexcept
+{
+    if (local_version != m_table_versioning_counter) {
+        local_version = m_table_versioning_counter;
+        return true;
+    }
+    else {
+        return false;
+    }
+}
+
+
+// Implementation:
+
+inline int_fast64_t from_ref(ref_type v) noexcept
+{
+    // Check that v is divisible by 8 (64-bit aligned).
+    REALM_ASSERT_DEBUG(v % 8 == 0);
+
+    static_assert(std::is_same<ref_type, size_t>::value,
+                  "If ref_type changes, from_ref and to_ref should probably be updated");
+
+    // Make sure that we preserve the bit pattern of the ref_type (without sign extension).
+    return util::from_twos_compl<int_fast64_t>(uint_fast64_t(v));
+}
+
+inline ref_type to_ref(int_fast64_t v) noexcept
+{
+    // Check that v is divisible by 8 (64-bit aligned).
+    REALM_ASSERT_DEBUG(v % 8 == 0);
+
+    // C++11 standard, paragraph 4.7.2 [conv.integral]:
+    // If the destination type is unsigned, the resulting value is the least unsigned integer congruent to the source
+    // integer (modulo 2n where n is the number of bits used to represent the unsigned type). [ Note: In a two's
+    // complement representation, this conversion is conceptual and there is no change in the bit pattern (if there is
+    // no truncation). - end note ]
+    static_assert(std::is_unsigned<ref_type>::value,
+                  "If ref_type changes, from_ref and to_ref should probably be updated");
+    return ref_type(v);
+}
+
+inline int64_t to_int64(size_t value) noexcept
+{
+    //    FIXME: Enable once we get clang warning flags correct
+    //    REALM_ASSERT_DEBUG(value <= std::numeric_limits<int64_t>::max());
+    return static_cast<int64_t>(value);
+}
+
+
+inline MemRef::MemRef() noexcept
+    : m_addr(nullptr)
+    , m_ref(0)
+{
+}
+
+inline MemRef::~MemRef() noexcept
+{
+}
+
+inline MemRef::MemRef(char* addr, ref_type ref, Allocator& alloc) noexcept
+    : m_addr(addr)
+    , m_ref(ref)
+{
+    static_cast<void>(alloc);
+#if REALM_ENABLE_MEMDEBUG
+    m_alloc = &alloc;
+#endif
+}
+
+inline MemRef::MemRef(ref_type ref, Allocator& alloc) noexcept
+    : m_addr(alloc.translate(ref))
+    , m_ref(ref)
+{
+    static_cast<void>(alloc);
+#if REALM_ENABLE_MEMDEBUG
+    m_alloc = &alloc;
+#endif
+}
+
+inline char* MemRef::get_addr()
+{
+#if REALM_ENABLE_MEMDEBUG
+    // Asserts if the ref has been freed
+    m_alloc->translate(m_ref);
+#endif
+    return m_addr;
+}
+
+inline ref_type MemRef::get_ref()
+{
+#if REALM_ENABLE_MEMDEBUG
+    // Asserts if the ref has been freed
+    m_alloc->translate(m_ref);
+#endif
+    return m_ref;
+}
+
+inline void MemRef::set_ref(ref_type ref)
+{
+#if REALM_ENABLE_MEMDEBUG
+    // Asserts if the ref has been freed
+    m_alloc->translate(ref);
+#endif
+    m_ref = ref;
+}
+
+inline void MemRef::set_addr(char* addr)
+{
+    m_addr = addr;
+}
+
+inline MemRef Allocator::alloc(size_t size)
+{
+    return do_alloc(size);
+}
+
+inline MemRef Allocator::realloc_(ref_type ref, const char* addr, size_t old_size, size_t new_size)
+{
+#ifdef REALM_DEBUG
+    if (ref == m_debug_watch)
+        REALM_TERMINATE("Allocator watch: Ref was reallocated");
+#endif
+    return do_realloc(ref, const_cast<char*>(addr), old_size, new_size);
+}
+
+inline void Allocator::free_(ref_type ref, const char* addr) noexcept
+{
+#ifdef REALM_DEBUG
+    if (ref == m_debug_watch)
+        REALM_TERMINATE("Allocator watch: Ref was freed");
+#endif
+    return do_free(ref, const_cast<char*>(addr));
+}
+
+inline void Allocator::free_(MemRef mem) noexcept
+{
+    free_(mem.get_ref(), mem.get_addr());
+}
+
+inline char* Allocator::translate(ref_type ref) const noexcept
+{
+    return do_translate(ref);
+}
+
+inline bool Allocator::is_read_only(ref_type ref) const noexcept
+{
+    REALM_ASSERT_DEBUG(ref != 0);
+    REALM_ASSERT_DEBUG(m_baseline != 0); // Attached SlabAlloc
+    return ref < m_baseline;
+}
+
+inline Allocator::Allocator() noexcept
+{
+    m_table_versioning_counter = 0;
+    m_latest_observed_counter = 0;
+}
+
+inline Allocator::~Allocator() noexcept
+{
+}
+
+inline Replication* Allocator::get_replication() noexcept
+{
+    return m_replication;
+}
+
+} // namespace realm
+
+#endif // REALM_ALLOC_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/alloc_slab.hpp b/node_modules/realm/vendor/realm-ios/include/realm/alloc_slab.hpp
new file mode 100644
index 0000000..e07edea
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/alloc_slab.hpp
@@ -0,0 +1,745 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ALLOC_SLAB_HPP
+#define REALM_ALLOC_SLAB_HPP
+
+#include <cstdint> // unint8_t etc
+#include <vector>
+#include <map>
+#include <string>
+#include <atomic>
+
+#include <realm/util/features.h>
+#include <realm/util/file.hpp>
+#include <realm/alloc.hpp>
+#include <realm/disable_sync_to_disk.hpp>
+
+namespace realm {
+
+// Pre-declarations
+class Group;
+class GroupWriter;
+
+
+/// Thrown by Group and SharedGroup constructors if the specified file
+/// (or memory buffer) does not appear to contain a valid Realm
+/// database.
+struct InvalidDatabase;
+
+
+/// The allocator that is used to manage the memory of a Realm
+/// group, i.e., a Realm database.
+///
+/// Optionally, it can be attached to an pre-existing database (file
+/// or memory buffer) which then becomes an immuatble part of the
+/// managed memory.
+///
+/// To attach a slab allocator to a pre-existing database, call
+/// attach_file() or attach_buffer(). To create a new database
+/// in-memory, call attach_empty().
+///
+/// For efficiency, this allocator manages its mutable memory as a set
+/// of slabs.
+class SlabAlloc : public Allocator {
+public:
+    ~SlabAlloc() noexcept override;
+    SlabAlloc();
+
+    // Disable copying. Copying an allocator can produce double frees.
+    SlabAlloc(const SlabAlloc&) = delete;
+    SlabAlloc& operator=(const SlabAlloc&) = delete;
+
+    /// \struct Config
+    /// \brief Storage for combining setup flags for initialization to
+    /// the SlabAlloc.
+    ///
+    /// \var Config::is_shared
+    /// Must be true if, and only if we are called on behalf of SharedGroup.
+    ///
+    /// \var Config::read_only
+    /// Open the file in read-only mode. This implies \a Config::no_create.
+    ///
+    /// \var Config::no_create
+    /// Fail if the file does not already exist.
+    ///
+    /// \var Config::skip_validate
+    /// Skip validation of file header. In a
+    /// set of overlapping SharedGroups, only the first one (the one
+    /// that creates/initlializes the coordination file) may validate
+    /// the header, otherwise it will result in a race condition.
+    ///
+    /// \var Config::encryption_key
+    /// 32-byte key to use to encrypt and decrypt the backing storage,
+    /// or nullptr to disable encryption.
+    ///
+    /// \var Config::session_initiator
+    /// If set, the caller is the session initiator and
+    /// guarantees exclusive access to the file. If attaching in
+    /// read/write mode, the file is modified: files on streaming form
+    /// is changed to non-streaming form, and if needed the file size
+    /// is adjusted to match mmap boundaries.
+    /// Must be set to false if is_shared is false.
+    ///
+    /// \var Config::clear_file
+    /// Always initialize the file as if it was a newly
+    /// created file and ignore any pre-existing contents. Requires that
+    /// Config::session_initiator be true as well.
+    struct Config {
+        bool is_shared = false;
+        bool read_only = false;
+        bool no_create = false;
+        bool skip_validate = false;
+        bool session_initiator = false;
+        bool clear_file = false;
+        bool disable_sync = false;
+        const char* encryption_key = nullptr;
+    };
+
+    struct Retry {
+    };
+
+    /// \brief Attach this allocator to the specified file.
+    ///
+    /// It is an error if this function is called at a time where the specified
+    /// Realm file (file system inode) is modified asynchronously.
+    ///
+    /// In non-shared mode (when this function is called on behalf of a
+    /// free-standing Group instance), it is the responsibility of the
+    /// application to ensure that the Realm file is not modified concurrently
+    /// from any other thread or process.
+    ///
+    /// In shared mode (when this function is called on behalf of a SharedGroup
+    /// instance), the caller (SharedGroup::do_open()) must take steps to ensure
+    /// cross-process mutual exclusion.
+    ///
+    /// Except for \a file_path, the parameters are passed in through a
+    /// configuration object.
+    ///
+    /// \return The `ref` of the root node, or zero if there is none.
+    ///
+    /// Please note that attach_file can fail to attach to a file due to a
+    /// collision with a writer extending the file. This can only happen if the
+    /// caller is *not* the session initiator. When this happens, attach_file()
+    /// throws SlabAlloc::Retry, and the caller must retry the call. The caller
+    /// should check if it has become the session initiator before retrying.
+    /// This can happen if the conflicting thread (or process) terminates or
+    /// crashes before the next retry.
+    ///
+    /// \throw util::File::AccessError
+    /// \throw SlabAlloc::Retry
+    ref_type attach_file(const std::string& file_path, Config& cfg);
+
+    /// Get the attached file. Only valid when called on an allocator with
+    /// an attached file.
+    util::File& get_file();
+
+    /// Attach this allocator to the specified memory buffer.
+    ///
+    /// It is an error to call this function on an attached
+    /// allocator. Doing so will result in undefined behavor.
+    ///
+    /// \return The `ref` of the root node, or zero if there is none.
+    ///
+    /// \sa own_buffer()
+    ///
+    /// \throw InvalidDatabase
+    ref_type attach_buffer(const char* data, size_t size);
+
+    /// Reads file format from file header. Must be called from within a write
+    /// transaction.
+    int get_committed_file_format_version() const noexcept;
+
+    bool is_file_on_streaming_form() const
+    {
+        const Header& header = *reinterpret_cast<const Header*>(m_data);
+        return is_file_on_streaming_form(header);
+    }
+
+    /// Attach this allocator to an empty buffer.
+    ///
+    /// It is an error to call this function on an attached
+    /// allocator. Doing so will result in undefined behavor.
+    void attach_empty();
+
+    /// Detach from a previously attached file or buffer.
+    ///
+    /// This function does not reset free space tracking. To
+    /// completely reset the allocator, you must also call
+    /// reset_free_space_tracking().
+    ///
+    /// This function has no effect if the allocator is already in the
+    /// detached state (idempotency).
+    void detach() noexcept;
+
+    class DetachGuard;
+
+    /// If a memory buffer has been attached using attach_buffer(),
+    /// mark it as owned by this slab allocator. Behaviour is
+    /// undefined if this function is called on a detached allocator,
+    /// one that is not attached using attach_buffer(), or one for
+    /// which this function has already been called during the latest
+    /// attachment.
+    void own_buffer() noexcept;
+
+    /// Returns true if, and only if this allocator is currently
+    /// in the attached state.
+    bool is_attached() const noexcept;
+
+    /// Returns true if, and only if this allocator is currently in
+    /// the attached state and attachment was not established using
+    /// attach_empty().
+    bool nonempty_attachment() const noexcept;
+
+    /// Reserve disk space now to avoid allocation errors at a later
+    /// point in time, and to minimize on-disk fragmentation. In some
+    /// cases, less fragmentation translates into improved
+    /// performance. On flash or SSD-drives this is likely a waste.
+    ///
+    /// Note: File::prealloc() may misbehave under race conditions (see
+    /// documentation of File::prealloc()). For that reason, to avoid race
+    /// conditions, when this allocator is used in a transactional mode, this
+    /// function may be called only when the caller has exclusive write
+    /// access. In non-transactional mode it is the responsibility of the user
+    /// to ensure non-concurrent file mutation.
+    ///
+    /// This function will call File::sync().
+    ///
+    /// It is an error to call this function on an allocator that is not
+    /// attached to a file. Doing so will result in undefined behavior.
+    void resize_file(size_t new_file_size);
+
+#ifdef REALM_DEBUG
+    /// Deprecated method, only called from a unit test
+    ///
+    /// WARNING: This method is NOT thread safe on multiple platforms; see
+    /// File::prealloc().
+    ///
+    /// Reserve disk space now to avoid allocation errors at a later point in
+    /// time, and to minimize on-disk fragmentation. In some cases, less
+    /// fragmentation translates into improved performance. On SSD-drives
+    /// preallocation is likely a waste.
+    ///
+    /// When supported by the system, a call to this function will make the
+    /// database file at least as big as the specified size, and cause space on
+    /// the target device to be allocated (note that on many systems on-disk
+    /// allocation is done lazily by default). If the file is already bigger
+    /// than the specified size, the size will be unchanged, and on-disk
+    /// allocation will occur only for the initial section that corresponds to
+    /// the specified size.
+    ///
+    /// This function will call File::sync() if it changes the size of the file.
+    ///
+    /// It is an error to call this function on an allocator that is not
+    /// attached to a file. Doing so will result in undefined behavior.
+    void reserve_disk_space(size_t size_in_bytes);
+#endif
+
+    /// Get the size of the attached database file or buffer in number
+    /// of bytes. This size is not affected by new allocations. After
+    /// attachment, it can only be modified by a call to update_reader_view().
+    ///
+    /// It is an error to call this function on a detached allocator,
+    /// or one that was attached using attach_empty(). Doing so will
+    /// result in undefined behavior.
+    size_t get_baseline() const noexcept;
+
+    /// Get the total amount of managed memory. This is the baseline plus the
+    /// sum of the sizes of the allocated slabs. It includes any free space.
+    ///
+    /// It is an error to call this function on a detached
+    /// allocator. Doing so will result in undefined behavior.
+    size_t get_total_size() const noexcept;
+
+    /// Mark all mutable memory (ref-space outside the attached file) as free
+    /// space.
+    void reset_free_space_tracking();
+
+    /// Update the readers view of the file:
+    ///
+    /// Remap the attached file such that a prefix of the specified
+    /// size becomes available in memory. If sucessfull,
+    /// get_baseline() will return the specified new file size.
+    ///
+    /// It is an error to call this function on a detached allocator,
+    /// or one that was not attached using attach_file(). Doing so
+    /// will result in undefined behavior.
+    ///
+    /// The file_size argument must be aligned to a *section* boundary:
+    /// The database file is logically split into sections, each section
+    /// guaranteed to be mapped as a contiguous address range. The allocation
+    /// of memory in the file must ensure that no allocation crosses the
+    /// boundary between two sections.
+    ///
+    /// Clears any allocator specicific caching of address translations
+    /// and force any later address translations to trigger decryption if required.
+    void update_reader_view(size_t file_size);
+
+    /// Returns true initially, and after a call to reset_free_space_tracking()
+    /// up until the point of the first call to SlabAlloc::alloc(). Note that a
+    /// call to SlabAlloc::alloc() corresponds to a mutation event.
+    bool is_free_space_clean() const noexcept;
+
+    /// Returns the amount of memory requested by calls to SlabAlloc::alloc().
+    size_t get_commit_size() const
+    {
+        return m_commit_size;
+    }
+
+    /// Returns the total amount of memory currently allocated in slab area
+    size_t get_allocated_size() const noexcept;
+
+    /// Returns total amount of slab for all slab allocators
+    static size_t get_total_slab_size() noexcept;
+
+    /// Hooks used to keep the encryption layer informed of the start and stop
+    /// of transactions.
+    void note_reader_start(const void* reader_id);
+    void note_reader_end(const void* reader_id) noexcept;
+
+    void verify() const override;
+#ifdef REALM_DEBUG
+    void enable_debug(bool enable)
+    {
+        m_debug_out = enable;
+    }
+    bool is_all_free() const;
+    void print() const;
+#endif
+    struct MappedFile;
+
+protected:
+    MemRef do_alloc(const size_t size) override;
+    MemRef do_realloc(ref_type, char*, size_t old_size, size_t new_size) override;
+    // FIXME: It would be very nice if we could detect an invalid free operation in debug mode
+    void do_free(ref_type, char*) noexcept override;
+    char* do_translate(ref_type) const noexcept override;
+
+    /// Returns the first section boundary *above* the given position.
+    size_t get_upper_section_boundary(size_t start_pos) const noexcept;
+
+    /// Returns the first section boundary *at or below* the given position.
+    size_t get_lower_section_boundary(size_t start_pos) const noexcept;
+
+    /// Returns true if the given position is at a section boundary
+    bool matches_section_boundary(size_t pos) const noexcept;
+
+    /// Returns the index of the section holding a given address.
+    /// The section index is determined solely by the minimal section size,
+    /// and does not necessarily reflect the mapping. A mapping may
+    /// cover multiple sections - the initial mapping often does.
+    size_t get_section_index(size_t pos) const noexcept;
+
+    /// Reverse: get the base offset of a section at a given index. Since the
+    /// computation is very time critical, this method just looks it up in
+    /// a table. The actual computation and setup of that table is done
+    /// during initialization with the help of compute_section_base() below.
+    inline size_t get_section_base(size_t index) const noexcept;
+
+    /// Actually compute the starting offset of a section. Only used to initialize
+    /// a table of predefined results, which are then used by get_section_base().
+    size_t compute_section_base(size_t index) const noexcept;
+
+    /// Find a possible allocation of 'request_size' that will fit into a section
+    /// which is inside the range from 'start_pos' to 'start_pos'+'free_chunk_size'
+    /// If found return the position, if not return 0.
+    size_t find_section_in_range(size_t start_pos, size_t free_chunk_size, size_t request_size) const noexcept;
+
+private:
+    void internal_invalidate_cache() noexcept;
+    enum AttachMode {
+        attach_None,        // Nothing is attached
+        attach_OwnedBuffer, // We own the buffer (m_data = nullptr for empty buffer)
+        attach_UsersBuffer, // We do not own the buffer
+        attach_SharedFile,  // On behalf of SharedGroup
+        attach_UnsharedFile // Not on behalf of SharedGroup
+    };
+
+    // A slab is a dynamically allocated contiguous chunk of memory used to
+    // extend the amount of space available for database node
+    // storage. Inter-node references are represented as file offsets
+    // (a.k.a. "refs"), and each slab creates an apparently seamless extension
+    // of this file offset addressable space. Slabs are stored as rows in the
+    // Slabs table in order of ascending file offsets.
+    struct Slab {
+        ref_type ref_end;
+        std::unique_ptr<char[]> addr;
+        size_t size;
+
+        Slab(ref_type r, size_t s);
+        Slab(Slab&& slab)
+            : ref_end(slab.ref_end)
+            , addr(std::move(slab.addr))
+            , size(slab.size)
+        {
+            slab.size = 0;
+        }
+        ~Slab();
+    };
+
+    struct Chunk { // describes a freed in-file block
+        ref_type ref;
+        size_t size;
+    };
+
+    // free blocks that are in the slab area are managed using the following structures:
+    // - FreeBlock: Placed at the start of any free space. Holds the 'ref' corresponding to
+    //              the start of the space, and prev/next links used to place it in a size-specific
+    //              freelist.
+    // - BetweenBlocks: Structure sitting between any two free OR allocated spaces.
+    //                  describes the size of the space before and after.
+    // Each slab (area obtained from the underlying system) has a terminating BetweenBlocks
+    // at the beginning and at the end of the Slab.
+    struct FreeBlock {
+        ref_type ref;    // ref for this entry. Saves a reverse translate / representing links as refs
+        FreeBlock* prev; // circular doubly linked list
+        FreeBlock* next;
+        void clear_links()
+        {
+            prev = next = nullptr;
+        }
+        void unlink();
+    };
+    struct BetweenBlocks { // stores sizes and used/free status of blocks before and after.
+        int32_t block_before_size; // negated if block is in use,
+        int32_t block_after_size;  // positive if block is free - and zero at end
+    };
+
+    Config m_cfg;
+    using FreeListMap = std::map<int, FreeBlock*>;  // log(N) addressing for larger blocks
+    FreeListMap m_block_map;
+
+    // abstract notion of a freelist - used to hide whether a freelist
+    // is residing in the small blocks or the large blocks structures.
+    struct FreeList {
+        int size = 0; // size of every element in the list, 0 if not found
+        FreeListMap::iterator it;
+        bool found_something()
+        {
+            return size != 0;
+        }
+        bool found_exact(int sz)
+        {
+            return size == sz;
+        }
+    };
+
+    // simple helper functions for accessing/navigating blocks and betweenblocks (TM)
+    BetweenBlocks* bb_before(FreeBlock* entry) const {
+        return reinterpret_cast<BetweenBlocks*>(entry) - 1;
+    }
+    BetweenBlocks* bb_after(FreeBlock* entry) const {
+        auto bb = bb_before(entry);
+        size_t sz = bb->block_after_size;
+        char* addr = reinterpret_cast<char*>(entry) + sz;
+        return reinterpret_cast<BetweenBlocks*>(addr);
+    }
+    FreeBlock* block_before(BetweenBlocks* bb) const {
+        size_t sz = bb->block_before_size;
+        if (sz <= 0)
+            return nullptr; // only blocks that are not in use
+        char* addr = reinterpret_cast<char*>(bb) - sz;
+        return reinterpret_cast<FreeBlock*>(addr);
+    }
+    FreeBlock* block_after(BetweenBlocks* bb) const {
+        if (bb->block_after_size <= 0)
+            return nullptr;
+        return reinterpret_cast<FreeBlock*>(bb + 1);
+    }
+    int size_from_block(FreeBlock* entry) const {
+        return bb_before(entry)->block_after_size;
+    }
+    void mark_allocated(FreeBlock* entry);
+    // mark the entry freed in bordering BetweenBlocks. Also validate size.
+    void mark_freed(FreeBlock* entry, int size);
+
+    // hook for the memory verifier in Group.
+    template<typename Func>
+    void for_all_free_entries(Func f) const;
+
+    // Main entry points for alloc/free:
+    FreeBlock* allocate_block(int size);
+    void free_block(ref_type ref, FreeBlock* addr);
+
+    // Searching/manipulating freelists
+    FreeList find(int size);
+    FreeList find_larger(FreeList hint, int size);
+    FreeBlock* pop_freelist_entry(FreeList list);
+    void push_freelist_entry(FreeBlock* entry);
+    void remove_freelist_entry(FreeBlock* element);
+    void rebuild_freelists_from_slab();
+    void clear_freelists();
+
+    // grow the slab area to accommodate the requested size.
+    // returns a free block large enough to handle the request.
+    FreeBlock* grow_slab_for(int request_size);
+    // create a single free chunk with "BetweenBlocks" at both ends and a
+    // single free chunk between them. This free chunk will be of size:
+    //   slab_size - 2 * sizeof(BetweenBlocks)
+    FreeBlock* slab_to_entry(const Slab& slab, ref_type ref_start);
+
+    // breaking/merging of blocks
+    FreeBlock* get_prev_block_if_mergeable(FreeBlock* block);
+    FreeBlock* get_next_block_if_mergeable(FreeBlock* block);
+    // break 'block' to give it 'new_size'. Return remaining block.
+    // If the block is too small to split, return nullptr.
+    FreeBlock* break_block(FreeBlock* block, int new_size);
+    FreeBlock* merge_blocks(FreeBlock* first, FreeBlock* second);
+
+    // Values of each used bit in m_flags
+    enum {
+        flags_SelectBit = 1,
+    };
+
+    // 24 bytes
+    struct Header {
+        uint64_t m_top_ref[2]; // 2 * 8 bytes
+        // Info-block 8-bytes
+        uint8_t m_mnemonic[4];    // "T-DB"
+        uint8_t m_file_format[2]; // See `library_file_format`
+        uint8_t m_reserved;
+        // bit 0 of m_flags is used to select between the two top refs.
+        uint8_t m_flags;
+    };
+
+    // 16 bytes
+    struct StreamingFooter {
+        uint64_t m_top_ref;
+        uint64_t m_magic_cookie;
+    };
+
+    static_assert(sizeof(Header) == 24, "Bad header size");
+    static_assert(sizeof(StreamingFooter) == 16, "Bad footer size");
+
+    static const Header empty_file_header;
+    static void init_streaming_header(Header*, int file_format_version);
+
+    static const uint_fast64_t footer_magic_cookie = 0x3034125237E526C8ULL;
+
+    // The mappings are shared, if they are from a file
+    std::shared_ptr<MappedFile> m_file_mappings;
+
+    // We are caching local copies of all the additional mappings to allow
+    // for lock-free lookup during ref->address translation (we do not need
+    // to cache the first mapping, because it is immutable) (well, all the
+    // mappings are immutable, but the array holding them is not - it may
+    // have to be relocated)
+    std::unique_ptr<std::shared_ptr<const util::File::Map<char>>[]> m_local_mappings;
+    size_t m_num_local_mappings = 0;
+
+    const char* m_data = nullptr;
+    size_t m_initial_chunk_size = 0;
+    size_t m_initial_section_size = 0;
+    int m_section_shifts = 0;
+    std::unique_ptr<size_t[]> m_section_bases;
+    size_t m_num_section_bases = 0;
+    AttachMode m_attach_mode = attach_None;
+    enum FeeeSpaceState {
+        free_space_Clean,
+        free_space_Dirty,
+        free_space_Invalid,
+    };
+
+    /// When set to free_space_Invalid, the free lists are no longer
+    /// up-to-date. This happens if do_free() or
+    /// reset_free_space_tracking() fails, presumably due to
+    /// std::bad_alloc being thrown during updating of the free space
+    /// list. In this this case, alloc(), realloc_(), and
+    /// get_free_read_only() must throw. This member is deliberately
+    /// placed here (after m_attach_mode) in the hope that it leads to
+    /// less padding between members due to alignment requirements.
+    FeeeSpaceState m_free_space_state = free_space_Clean;
+
+    typedef std::vector<Slab> Slabs;
+    using Chunks = std::map<ref_type, size_t>;
+    Slabs m_slabs;
+    Chunks m_free_read_only;
+    size_t m_commit_size = 0;
+
+    bool m_debug_out = false;
+    struct hash_entry {
+        ref_type ref = 0;
+        const char* addr = nullptr;
+        size_t version = 0;
+    };
+    mutable hash_entry cache[256];
+    mutable size_t version = 1;
+
+    /// Throws if free-lists are no longer valid.
+    size_t consolidate_free_read_only();
+    /// Throws if free-lists are no longer valid.
+    const Chunks& get_free_read_only() const;
+
+    /// Throws InvalidDatabase if the file is not a Realm file, if the file is
+    /// corrupted, or if the specified encryption key is incorrect. This
+    /// function will not detect all forms of corruption, though.
+    void validate_buffer(const char* data, size_t len, const std::string& path);
+    void throw_header_exception(std::string msg, const Header& header, const std::string& path);
+
+    static bool is_file_on_streaming_form(const Header& header);
+    /// Read the top_ref from the given buffer and set m_file_on_streaming_form
+    /// if the buffer contains a file in streaming form
+    static ref_type get_top_ref(const char* data, size_t len);
+
+    // Gets the path of the attached file, or other relevant debugging info.
+    std::string get_file_path_for_assertions() const;
+
+    class ChunkRefEq;
+    class ChunkRefEndEq;
+    class SlabRefEndEq;
+    static bool ref_less_than_slab_ref_end(ref_type, const Slab&) noexcept;
+
+    Replication* get_replication() const noexcept
+    {
+        return m_replication;
+    }
+    void set_replication(Replication* r) noexcept
+    {
+        m_replication = r;
+    }
+
+    friend class Group;
+    friend class SharedGroup;
+    friend class GroupWriter;
+};
+
+inline void SlabAlloc::internal_invalidate_cache() noexcept
+{
+    ++version;
+}
+
+class SlabAlloc::DetachGuard {
+public:
+    DetachGuard(SlabAlloc& alloc) noexcept
+        : m_alloc(&alloc)
+    {
+    }
+    ~DetachGuard() noexcept;
+    SlabAlloc* release() noexcept;
+
+private:
+    SlabAlloc* m_alloc;
+};
+
+
+// Implementation:
+
+struct InvalidDatabase : util::File::AccessError {
+    InvalidDatabase(const std::string& msg, const std::string& path)
+        : util::File::AccessError(msg, path)
+    {
+    }
+};
+
+inline void SlabAlloc::own_buffer() noexcept
+{
+    REALM_ASSERT_3(m_attach_mode, ==, attach_UsersBuffer);
+    REALM_ASSERT(m_data);
+    REALM_ASSERT(m_file_mappings == nullptr);
+    m_attach_mode = attach_OwnedBuffer;
+}
+
+inline bool SlabAlloc::is_attached() const noexcept
+{
+    return m_attach_mode != attach_None;
+}
+
+inline bool SlabAlloc::nonempty_attachment() const noexcept
+{
+    return is_attached() && m_data;
+}
+
+inline size_t SlabAlloc::get_baseline() const noexcept
+{
+    REALM_ASSERT_DEBUG(is_attached());
+    return m_baseline;
+}
+
+inline bool SlabAlloc::is_free_space_clean() const noexcept
+{
+    return m_free_space_state == free_space_Clean;
+}
+
+inline SlabAlloc::DetachGuard::~DetachGuard() noexcept
+{
+    if (m_alloc)
+        m_alloc->detach();
+}
+
+inline SlabAlloc* SlabAlloc::DetachGuard::release() noexcept
+{
+    SlabAlloc* alloc = m_alloc;
+    m_alloc = nullptr;
+    return alloc;
+}
+
+inline bool SlabAlloc::ref_less_than_slab_ref_end(ref_type ref, const Slab& slab) noexcept
+{
+    return ref < slab.ref_end;
+}
+
+inline size_t SlabAlloc::get_upper_section_boundary(size_t start_pos) const noexcept
+{
+    return get_section_base(1 + get_section_index(start_pos));
+}
+
+inline size_t SlabAlloc::get_lower_section_boundary(size_t start_pos) const noexcept
+{
+    return get_section_base(get_section_index(start_pos));
+}
+
+inline bool SlabAlloc::matches_section_boundary(size_t pos) const noexcept
+{
+    return pos == get_lower_section_boundary(pos);
+}
+
+inline size_t SlabAlloc::get_section_base(size_t index) const noexcept
+{
+    return m_section_bases[index];
+}
+
+template<typename Func>
+void SlabAlloc::for_all_free_entries(Func f) const
+{
+    ref_type ref = m_baseline;
+    for (auto& e : m_slabs) {
+        BetweenBlocks* bb = reinterpret_cast<BetweenBlocks*>(e.addr.get());
+        REALM_ASSERT(bb->block_before_size == 0);
+        while (1) {
+            int size = bb->block_after_size;
+            f(ref, sizeof(BetweenBlocks));
+            ref += sizeof(BetweenBlocks);
+            if (size == 0) {
+                break;
+            }
+            if (size > 0) { // freeblock.
+                f(ref, size);
+                bb = reinterpret_cast<BetweenBlocks*>(reinterpret_cast<char*>(bb) + sizeof(BetweenBlocks) + size);
+                ref += size;
+            }
+            else {
+                bb = reinterpret_cast<BetweenBlocks*>(reinterpret_cast<char*>(bb) + sizeof(BetweenBlocks) - size);
+                ref -= size;
+            }
+        }
+    }
+}
+
+} // namespace realm
+
+#endif // REALM_ALLOC_SLAB_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array.hpp
new file mode 100644
index 0000000..a948943
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array.hpp
@@ -0,0 +1,3128 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+/*
+Searching: The main finding function is:
+    template <class cond, Action action, size_t bitwidth, class Callback>
+    void find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState *state, Callback callback) const
+
+    cond:       One of Equal, NotEqual, Greater, etc. classes
+    Action:     One of act_ReturnFirst, act_FindAll, act_Max, act_CallbackIdx, etc, constants
+    Callback:   Optional function to call for each search result. Will be called if action == act_CallbackIdx
+
+    find() will call find_action_pattern() or find_action() that again calls match() for each search result which
+    optionally calls callback():
+
+        find() -> find_action() -------> bool match() -> bool callback()
+             |                            ^
+             +-> find_action_pattern()----+
+
+    If callback() returns false, find() will exit, otherwise it will keep searching remaining items in array.
+*/
+
+#ifndef REALM_ARRAY_HPP
+#define REALM_ARRAY_HPP
+
+#include <cmath>
+#include <cstdlib> // size_t
+#include <algorithm>
+#include <utility>
+#include <vector>
+#include <ostream>
+
+#include <cstdint> // unint8_t etc
+
+#include <realm/util/assert.hpp>
+#include <realm/util/file_mapper.hpp>
+#include <realm/utilities.hpp>
+#include <realm/alloc.hpp>
+#include <realm/string_data.hpp>
+#include <realm/query_conditions.hpp>
+#include <realm/column_fwd.hpp>
+#include <realm/array_direct.hpp>
+
+/*
+    MMX: mmintrin.h
+    SSE: xmmintrin.h
+    SSE2: emmintrin.h
+    SSE3: pmmintrin.h
+    SSSE3: tmmintrin.h
+    SSE4A: ammintrin.h
+    SSE4.1: smmintrin.h
+    SSE4.2: nmmintrin.h
+*/
+#ifdef REALM_COMPILER_SSE
+#include <emmintrin.h>             // SSE2
+#include <realm/realm_nmmintrin.h> // SSE42
+#endif
+
+namespace realm {
+
+enum Action {
+    act_ReturnFirst,
+    act_Sum,
+    act_Max,
+    act_Min,
+    act_Count,
+    act_FindAll,
+    act_CallIdx,
+    act_CallbackIdx,
+    act_CallbackVal,
+    act_CallbackNone,
+    act_CallbackBoth,
+    act_Average
+};
+
+template <class T>
+inline T no0(T v)
+{
+    return v == 0 ? 1 : v;
+}
+
+/// Special index value. It has various meanings depending on
+/// context. It is returned by some search functions to indicate 'not
+/// found'. It is similar in function to std::string::npos.
+const size_t npos = size_t(-1);
+
+const size_t max_array_size = 0x00ffffffL;            // Maximum number of elements in an array
+const size_t max_array_payload_aligned = 0x07ffffc0L; // Maximum number of bytes that the payload of an array can be
+
+/// Alias for realm::npos.
+const size_t not_found = npos;
+
+// Pre-definitions
+class Array;
+class StringColumn;
+class GroupWriter;
+template <class T>
+class QueryState;
+namespace _impl {
+class ArrayWriterBase;
+}
+
+
+struct MemStats {
+    size_t allocated = 0;
+    size_t used = 0;
+    size_t array_count = 0;
+};
+
+#ifdef REALM_DEBUG
+template <class C, class T>
+std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, MemStats stats);
+#endif
+
+
+// Stores a value obtained from Array::get(). It is a ref if the least
+// significant bit is clear, otherwise it is a tagged integer. A tagged interger
+// is obtained from a logical integer value by left shifting by one bit position
+// (multiplying by two), and then setting the least significant bit to
+// one. Clearly, this means that the maximum value that can be stored as a
+// tagged integer is 2**63 - 1.
+class RefOrTagged {
+public:
+    bool is_ref() const noexcept;
+    bool is_tagged() const noexcept;
+    ref_type get_as_ref() const noexcept;
+    uint_fast64_t get_as_int() const noexcept;
+
+    static RefOrTagged make_ref(ref_type) noexcept;
+    static RefOrTagged make_tagged(uint_fast64_t) noexcept;
+
+private:
+    int_fast64_t m_value;
+    RefOrTagged(int_fast64_t) noexcept;
+    friend class Array;
+};
+
+
+class ArrayParent {
+public:
+    virtual ~ArrayParent() noexcept
+    {
+    }
+
+protected:
+    virtual void update_child_ref(size_t child_ndx, ref_type new_ref) = 0;
+
+    virtual ref_type get_child_ref(size_t child_ndx) const noexcept = 0;
+
+    // Used only by Array::to_dot().
+    virtual std::pair<ref_type, size_t> get_to_dot_parent(size_t ndx_in_parent) const = 0;
+
+    friend class Array;
+};
+
+struct TreeInsertBase {
+    size_t m_split_offset;
+    size_t m_split_size;
+};
+
+/// Provides access to individual array nodes of the database.
+///
+/// This class serves purely as an accessor, it assumes no ownership of the
+/// referenced memory.
+///
+/// An array accessor can be in one of two states: attached or unattached. It is
+/// in the attached state if, and only if is_attached() returns true. Most
+/// non-static member functions of this class have undefined behaviour if the
+/// accessor is in the unattached state. The exceptions are: is_attached(),
+/// detach(), create(), init_from_ref(), init_from_mem(), init_from_parent(),
+/// has_parent(), get_parent(), set_parent(), get_ndx_in_parent(),
+/// set_ndx_in_parent(), adjust_ndx_in_parent(), and get_ref_from_parent().
+///
+/// An array accessor contains information about the parent of the referenced
+/// array node. This 'reverse' reference is not explicitely present in the
+/// underlying node hierarchy, but it is needed when modifying an array. A
+/// modification may lead to relocation of the underlying array node, and the
+/// parent must be updated accordingly. Since this applies recursivly all the
+/// way to the root node, it is essential that the entire chain of parent
+/// accessors is constructed and propperly maintained when a particular array is
+/// modified.
+///
+/// The parent reference (`pointer to parent`, `index in parent`) is updated
+/// independently from the state of attachment to an underlying node. In
+/// particular, the parent reference remains valid and is unannfected by changes
+/// in attachment. These two aspects of the state of the accessor is updated
+/// independently, and it is entirely the responsibility of the caller to update
+/// them such that they are consistent with the underlying node hierarchy before
+/// calling any method that modifies the underlying array node.
+///
+/// FIXME: This class currently has fragments of ownership, in particular the
+/// constructors that allocate underlying memory. On the other hand, the
+/// destructor never frees the memory. This is a problematic situation, because
+/// it so easily becomes an obscure source of leaks. There are three options for
+/// a fix of which the third is most attractive but hardest to implement: (1)
+/// Remove all traces of ownership semantics, that is, remove the constructors
+/// that allocate memory, but keep the trivial copy constructor. For this to
+/// work, it is important that the constness of the accessor has nothing to do
+/// with the constness of the underlying memory, otherwise constness can be
+/// violated simply by copying the accessor. (2) Disallov copying but associate
+/// the constness of the accessor with the constness of the underlying
+/// memory. (3) Provide full ownership semantics like is done for Table
+/// accessors, and provide a proper copy constructor that really produces a copy
+/// of the array. For this to work, the class should assume ownership if, and
+/// only if there is no parent. A copy produced by a copy constructor will not
+/// have a parent. Even if the original was part of a database, the copy will be
+/// free-standing, that is, not be part of any database. For intra, or inter
+/// database copying, one would have to also specify the target allocator.
+class Array : public ArrayParent {
+public:
+    //    void state_init(int action, QueryState *state);
+    //    bool match(int action, size_t index, int64_t value, QueryState *state);
+
+    /// Create an array accessor in the unattached state.
+    explicit Array(Allocator&) noexcept;
+
+    ~Array() noexcept override
+    {
+    }
+
+    enum Type {
+        type_Normal,
+
+        /// This array is the main array of an innner node of a B+-tree as used
+        /// in table columns.
+        type_InnerBptreeNode,
+
+        /// This array may contain refs to subarrays. An element whose least
+        /// significant bit is zero, is a ref pointing to a subarray. An element
+        /// whose least significant bit is one, is just a value. It is the
+        /// responsibility of the application to ensure that non-ref values have
+        /// their least significant bit set. This will generally be done by
+        /// shifting the desired vlue to the left by one bit position, and then
+        /// setting the vacated bit to one.
+        type_HasRefs
+    };
+
+    /// Create a new integer array of the specified type and size, and filled
+    /// with the specified value, and attach this accessor to it. This does not
+    /// modify the parent reference information of this accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated underlying
+    /// node. It is not owned by the accessor.
+    void create(Type, bool context_flag = false, size_t size = 0, int_fast64_t value = 0);
+
+    /// Reinitialize this array accessor to point to the specified new
+    /// underlying memory. This does not modify the parent reference information
+    /// of this accessor.
+    void init_from_ref(ref_type) noexcept;
+
+    /// Same as init_from_ref(ref_type) but avoid the mapping of 'ref' to memory
+    /// pointer.
+    void init_from_mem(MemRef) noexcept;
+
+    /// Same as `init_from_ref(get_ref_from_parent())`.
+    void init_from_parent() noexcept;
+
+    /// Update the parents reference to this child. This requires, of course,
+    /// that the parent information stored in this child is up to date. If the
+    /// parent pointer is set to null, this function has no effect.
+    void update_parent();
+
+    /// Called in the context of Group::commit() to ensure that attached
+    /// accessors stay valid across a commit. Please note that this works only
+    /// for non-transactional commits. Accessors obtained during a transaction
+    /// are always detached when the transaction ends.
+    ///
+    /// Returns true if, and only if the array has changed. If the array has not
+    /// changed, then its children are guaranteed to also not have changed.
+    bool update_from_parent(size_t old_baseline) noexcept;
+
+    /// Change the type of an already attached array node.
+    ///
+    /// The effect of calling this function on an unattached accessor is
+    /// undefined.
+    void set_type(Type);
+
+    /// Construct a complete copy of this array (including its subarrays) using
+    /// the specified target allocator and return just the reference to the
+    /// underlying memory.
+    MemRef clone_deep(Allocator& target_alloc) const;
+
+    /// Construct an empty integer array of the specified type, and return just
+    /// the reference to the underlying memory.
+    static MemRef create_empty_array(Type, bool context_flag, Allocator&);
+
+    /// Construct an integer array of the specified type and size, and return
+    /// just the reference to the underlying memory. All elements will be
+    /// initialized to the specified value.
+    static MemRef create_array(Type, bool context_flag, size_t size, int_fast64_t value, Allocator&);
+
+    /// Construct a shallow copy of the specified slice of this array using the
+    /// specified target allocator. Subarrays will **not** be cloned. See
+    /// slice_and_clone_children() for an alternative.
+    MemRef slice(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+    /// Construct a deep copy of the specified slice of this array using the
+    /// specified target allocator. Subarrays will be cloned.
+    MemRef slice_and_clone_children(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+    // Parent tracking
+    bool has_parent() const noexcept;
+    ArrayParent* get_parent() const noexcept;
+
+    /// Setting a new parent affects ownership of the attached array node, if
+    /// any. If a non-null parent is specified, and there was no parent
+    /// originally, then the caller passes ownership to the parent, and vice
+    /// versa. This assumes, of course, that the change in parentship reflects a
+    /// corresponding change in the list of children in the affected parents.
+    void set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept;
+
+    size_t get_ndx_in_parent() const noexcept;
+    void set_ndx_in_parent(size_t) noexcept;
+    void adjust_ndx_in_parent(int diff) noexcept;
+
+    /// Get the ref of this array as known to the parent. The caller must ensure
+    /// that the parent information ('pointer to parent' and 'index in parent')
+    /// is correct before calling this function.
+    ref_type get_ref_from_parent() const noexcept;
+
+    bool is_attached() const noexcept;
+
+    /// Detach from the underlying array node. This method has no effect if the
+    /// accessor is currently unattached (idempotency).
+    void detach() noexcept;
+
+    size_t size() const noexcept;
+    bool is_empty() const noexcept;
+    Type get_type() const noexcept;
+
+
+    static void add_to_column(IntegerColumn* column, int64_t value);
+
+    void insert(size_t ndx, int_fast64_t value);
+    void add(int_fast64_t value);
+
+    // Used from ArrayBlob
+    size_t blob_size() const noexcept;
+    ref_type blob_replace(size_t begin, size_t end, const char* data, size_t data_size, bool add_zero_term);
+
+    /// This function is guaranteed to not throw if the current width is
+    /// sufficient for the specified value (e.g. if you have called
+    /// ensure_minimum_width(value)) and get_alloc().is_read_only(get_ref())
+    /// returns false (noexcept:array-set). Note that for a value of zero, the
+    /// first criterion is trivially satisfied.
+    void set(size_t ndx, int64_t value);
+
+    void set_as_ref(size_t ndx, ref_type ref);
+
+    template <size_t w>
+    void set(size_t ndx, int64_t value);
+
+    int64_t get(size_t ndx) const noexcept;
+
+    template <size_t w>
+    int64_t get(size_t ndx) const noexcept;
+
+    void get_chunk(size_t ndx, int64_t res[8]) const noexcept;
+
+    template <size_t w>
+    void get_chunk(size_t ndx, int64_t res[8]) const noexcept;
+
+    ref_type get_as_ref(size_t ndx) const noexcept;
+
+    RefOrTagged get_as_ref_or_tagged(size_t ndx) const noexcept;
+    void set(size_t ndx, RefOrTagged);
+    void add(RefOrTagged);
+    void ensure_minimum_width(RefOrTagged);
+
+    int64_t front() const noexcept;
+    int64_t back() const noexcept;
+
+    /// Remove the element at the specified index, and move elements at higher
+    /// indexes to the next lower index.
+    ///
+    /// This function does **not** destroy removed subarrays. That is, if the
+    /// erased element is a 'ref' pointing to a subarray, then that subarray
+    /// will not be destroyed automatically.
+    ///
+    /// This function guarantees that no exceptions will be thrown if
+    /// get_alloc().is_read_only(get_ref()) would return false before the
+    /// call. This is automatically guaranteed if the array is used in a
+    /// non-transactional context, or if the array has already been successfully
+    /// modified within the current write transaction.
+    void erase(size_t ndx);
+
+    /// Same as erase(size_t), but remove all elements in the specified
+    /// range.
+    ///
+    /// Please note that this function does **not** destroy removed subarrays.
+    ///
+    /// This function guarantees that no exceptions will be thrown if
+    /// get_alloc().is_read_only(get_ref()) would return false before the call.
+    void erase(size_t begin, size_t end);
+
+    /// Reduce the size of this array to the specified number of elements. It is
+    /// an error to specify a size that is greater than the current size of this
+    /// array. The effect of doing so is undefined. This is just a shorthand for
+    /// calling the ranged erase() function with appropriate arguments.
+    ///
+    /// Please note that this function does **not** destroy removed
+    /// subarrays. See clear_and_destroy_children() for an alternative.
+    ///
+    /// This function guarantees that no exceptions will be thrown if
+    /// get_alloc().is_read_only(get_ref()) would return false before the call.
+    void truncate(size_t new_size);
+
+    /// Reduce the size of this array to the specified number of elements. It is
+    /// an error to specify a size that is greater than the current size of this
+    /// array. The effect of doing so is undefined. Subarrays will be destroyed
+    /// recursively, as if by a call to `destroy_deep(subarray_ref, alloc)`.
+    ///
+    /// This function is guaranteed not to throw if
+    /// get_alloc().is_read_only(get_ref()) returns false.
+    void truncate_and_destroy_children(size_t new_size);
+
+    /// Remove every element from this array. This is just a shorthand for
+    /// calling truncate(0).
+    ///
+    /// Please note that this function does **not** destroy removed
+    /// subarrays. See clear_and_destroy_children() for an alternative.
+    ///
+    /// This function guarantees that no exceptions will be thrown if
+    /// get_alloc().is_read_only(get_ref()) would return false before the call.
+    void clear();
+
+    /// Remove every element in this array. Subarrays will be destroyed
+    /// recursively, as if by a call to `destroy_deep(subarray_ref,
+    /// alloc)`. This is just a shorthand for calling
+    /// truncate_and_destroy_children(0).
+    ///
+    /// This function guarantees that no exceptions will be thrown if
+    /// get_alloc().is_read_only(get_ref()) would return false before the call.
+    void clear_and_destroy_children();
+
+    /// If neccessary, expand the representation so that it can store the
+    /// specified value.
+    void ensure_minimum_width(int_fast64_t value);
+
+    /// This one may change the represenation of the array, so be carefull if
+    /// you call it after ensure_minimum_width().
+    void set_all_to_zero();
+
+    /// Add \a diff to the element at the specified index.
+    void adjust(size_t ndx, int_fast64_t diff);
+
+    /// Add \a diff to all the elements in the specified index range.
+    void adjust(size_t begin, size_t end, int_fast64_t diff);
+
+    /// Add signed \a diff to all elements that are greater than, or equal to \a
+    /// limit.
+    void adjust_ge(int_fast64_t limit, int_fast64_t diff);
+
+    //@{
+    /// These are similar in spirit to std::move() and std::move_backward from
+    /// `<algorithm>`. \a dest_begin must not be in the range [`begin`,`end`), and
+    /// \a dest_end must not be in the range (`begin`,`end`].
+    ///
+    /// These functions are guaranteed to not throw if
+    /// `get_alloc().is_read_only(get_ref())` returns false.
+    void move(size_t begin, size_t end, size_t dest_begin);
+    void move_backward(size_t begin, size_t end, size_t dest_end);
+    //@}
+
+    /// move_rotate moves one element from \a from to be located at index \a to,
+    /// shifting all elements inbetween by one.
+    ///
+    /// If \a from is larger than \a to, the elements inbetween are shifted down.
+    /// If \a to is larger than \a from, the elements inbetween are shifted up.
+    ///
+    /// This function is guaranteed to not throw if
+    /// `get_alloc().is_read_only(get_ref())` returns false.
+    void move_rotate(size_t from, size_t to, size_t num_elems = 1);
+
+    //@{
+    /// Find the lower/upper bound of the specified value in a sequence of
+    /// integers which must already be sorted ascendingly.
+    ///
+    /// For an integer value '`v`', lower_bound_int(v) returns the index '`l`'
+    /// of the first element such that `get(l) &ge; v`, and upper_bound_int(v)
+    /// returns the index '`u`' of the first element such that `get(u) &gt;
+    /// v`. In both cases, if no such element is found, the returned value is
+    /// the number of elements in the array.
+    ///
+    ///     3 3 3 4 4 4 5 6 7 9 9 9
+    ///     ^     ^     ^     ^     ^
+    ///     |     |     |     |     |
+    ///     |     |     |     |      -- Lower and upper bound of 15
+    ///     |     |     |     |
+    ///     |     |     |      -- Lower and upper bound of 8
+    ///     |     |     |
+    ///     |     |      -- Upper bound of 4
+    ///     |     |
+    ///     |      -- Lower bound of 4
+    ///     |
+    ///      -- Lower and upper bound of 1
+    ///
+    /// These functions are similar to std::lower_bound() and
+    /// std::upper_bound().
+    ///
+    /// We currently use binary search. See for example
+    /// http://www.tbray.org/ongoing/When/200x/2003/03/22/Binary.
+    ///
+    /// FIXME: It may be worth considering if overall efficiency can be improved
+    /// by doing a linear search for short sequences.
+    size_t lower_bound_int(int64_t value) const noexcept;
+    size_t upper_bound_int(int64_t value) const noexcept;
+    //@}
+
+    /// \brief Search the \c Array for a value greater or equal than \a target,
+    /// starting the search at the \a start index. If \a indirection is
+    /// provided, use it as a look-up table to iterate over the \c Array.
+    ///
+    /// If \a indirection is not provided, then the \c Array must be sorted in
+    /// ascending order. If \a indirection is provided, then its values should
+    /// point to indices in this \c Array in such a way that iteration happens
+    /// in ascending order.
+    ///
+    /// Behaviour is undefined if:
+    /// - a value in \a indirection is out of bounds for this \c Array;
+    /// - \a indirection does not contain at least as many elements as this \c
+    ///   Array;
+    /// - sorting conditions are not respected;
+    /// - \a start is greater than the number of elements in this \c Array or
+    ///   \a indirection (if provided).
+    ///
+    /// \param target the smallest value to search for
+    /// \param start the offset at which to start searching in the array
+    /// \param indirection an \c Array containing valid indices of values in
+    ///        this \c Array, sorted in ascending order
+    /// \return the index of the value if found, or realm::not_found otherwise
+    size_t find_gte(const int64_t target, size_t start, size_t end = size_t(-1)) const;
+
+    void preset(int64_t min, int64_t max, size_t num_items);
+    void preset(size_t bitwidth, size_t num_items);
+
+    int64_t sum(size_t start = 0, size_t end = size_t(-1)) const;
+    size_t count(int64_t value) const noexcept;
+
+    bool maximum(int64_t& result, size_t start = 0, size_t end = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    bool minimum(int64_t& result, size_t start = 0, size_t end = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    /// This information is guaranteed to be cached in the array accessor.
+    bool is_inner_bptree_node() const noexcept;
+
+    /// Returns true if type is either type_HasRefs or type_InnerColumnNode.
+    ///
+    /// This information is guaranteed to be cached in the array accessor.
+    bool has_refs() const noexcept;
+    void set_has_refs(bool) noexcept;
+
+    /// This information is guaranteed to be cached in the array accessor.
+    ///
+    /// Columns and indexes can use the context bit to differentiate leaf types.
+    bool get_context_flag() const noexcept;
+    void set_context_flag(bool) noexcept;
+
+    ref_type get_ref() const noexcept;
+    MemRef get_mem() const noexcept;
+
+    /// Destroy only the array that this accessor is attached to, not the
+    /// children of that array. See non-static destroy_deep() for an
+    /// alternative. If this accessor is already in the detached state, this
+    /// function has no effect (idempotency).
+    void destroy() noexcept;
+
+    /// Recursively destroy children (as if calling
+    /// clear_and_destroy_children()), then put this accessor into the detached
+    /// state (as if calling detach()), then free the allocated memory. If this
+    /// accessor is already in the detached state, this function has no effect
+    /// (idempotency).
+    void destroy_deep() noexcept;
+
+    /// Shorthand for `destroy(MemRef(ref, alloc), alloc)`.
+    static void destroy(ref_type ref, Allocator& alloc) noexcept;
+
+    /// Destroy only the specified array node, not its children. See also
+    /// destroy_deep(MemRef, Allocator&).
+    static void destroy(MemRef, Allocator&) noexcept;
+
+    /// Shorthand for `destroy_deep(MemRef(ref, alloc), alloc)`.
+    static void destroy_deep(ref_type ref, Allocator& alloc) noexcept;
+
+    /// Destroy the specified array node and all of its children, recursively.
+    ///
+    /// This is done by freeing the specified array node after calling
+    /// destroy_deep() for every contained 'ref' element.
+    static void destroy_deep(MemRef, Allocator&) noexcept;
+
+    Allocator& get_alloc() const noexcept
+    {
+        return m_alloc;
+    }
+
+    // Serialization
+
+    /// Returns the ref (position in the target stream) of the written copy of
+    /// this array, or the ref of the original array if \a only_if_modified is
+    /// true, and this array is unmodified (Alloc::is_read_only()).
+    ///
+    /// The number of bytes that will be written by a non-recursive invocation
+    /// of this function is exactly the number returned by get_byte_size().
+    ///
+    /// \param out The destination stream (writer).
+    ///
+    /// \param deep If true, recursively write out subarrays, but still subject
+    /// to \a only_if_modified.
+    ///
+    /// \param only_if_modified Set to `false` to always write, or to `true` to
+    /// only write the array if it has been modified.
+    ref_type write(_impl::ArrayWriterBase& out, bool deep, bool only_if_modified) const;
+
+    /// Same as non-static write() with `deep` set to true. This is for the
+    /// cases where you do not already have an array accessor available.
+    static ref_type write(ref_type, Allocator&, _impl::ArrayWriterBase&, bool only_if_modified);
+
+    // Main finding function - used for find_first, find_all, sum, max, min, etc.
+    bool find(int cond, Action action, int64_t value, size_t start, size_t end, size_t baseindex,
+              QueryState<int64_t>* state, bool nullable_array = false, bool find_null = false) const;
+
+    // Templated find function to avoid conversion to and from integer represenation of condition
+    template <class cond>
+    bool find(Action action, int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+              bool nullable_array = false, bool find_null = false) const
+    {
+        if (action == act_ReturnFirst) {
+            REALM_TEMPEX3(return find, cond, act_ReturnFirst, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        else if (action == act_Sum) {
+            REALM_TEMPEX3(return find, cond, act_Sum, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        else if (action == act_Min) {
+            REALM_TEMPEX3(return find, cond, act_Min, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        else if (action == act_Max) {
+            REALM_TEMPEX3(return find, cond, act_Max, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        else if (action == act_Count) {
+            REALM_TEMPEX3(return find, cond, act_Count, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        else if (action == act_FindAll) {
+            REALM_TEMPEX3(return find, cond, act_FindAll, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        else if (action == act_CallbackIdx) {
+            REALM_TEMPEX3(return find, cond, act_CallbackIdx, m_width,
+                                 (value, start, end, baseindex, state, CallbackDummy(), nullable_array, find_null))
+        }
+        REALM_ASSERT_DEBUG(false);
+        return false;
+    }
+
+
+    /*
+    bool find(int cond, Action action, null, size_t start, size_t end, size_t baseindex,
+              QueryState<int64_t>* state) const;
+    */
+
+    template <class cond, Action action, size_t bitwidth, class Callback>
+    bool find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+              Callback callback, bool nullable_array = false, bool find_null = false) const;
+
+    // This is the one installed into the m_vtable->finder slots.
+    template <class cond, Action action, size_t bitwidth>
+    bool find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state) const;
+
+    template <class cond, Action action, class Callback>
+    bool find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+              Callback callback, bool nullable_array = false, bool find_null = false) const;
+
+    /*
+    template <class cond, Action action, class Callback>
+    bool find(null, size_t start, size_t end, size_t baseindex,
+              QueryState<int64_t>* state, Callback callback) const;
+    */
+
+    // Optimized implementation for release mode
+    template <class cond, Action action, size_t bitwidth, class Callback>
+    bool find_optimized(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                        Callback callback, bool nullable_array = false, bool find_null = false) const;
+
+    // Called for each search result
+    template <Action action, class Callback>
+    bool find_action(size_t index, util::Optional<int64_t> value, QueryState<int64_t>* state,
+                     Callback callback) const;
+
+    template <Action action, class Callback>
+    bool find_action_pattern(size_t index, uint64_t pattern, QueryState<int64_t>* state, Callback callback) const;
+
+    // Wrappers for backwards compatibility and for simple use without
+    // setting up state initialization etc
+    template <class cond>
+    size_t find_first(int64_t value, size_t start = 0, size_t end = size_t(-1)) const;
+
+    void find_all(IntegerColumn* result, int64_t value, size_t col_offset = 0, size_t begin = 0,
+                  size_t end = size_t(-1)) const;
+
+    size_t find_first(int64_t value, size_t begin = 0, size_t end = size_t(-1)) const;
+
+    // Non-SSE find for the four functions Equal/NotEqual/Less/Greater
+    template <class cond, Action action, size_t bitwidth, class Callback>
+    bool compare(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                 Callback callback) const;
+
+    // Non-SSE find for Equal/NotEqual
+    template <bool eq, Action action, size_t width, class Callback>
+    inline bool compare_equality(int64_t value, size_t start, size_t end, size_t baseindex,
+                                 QueryState<int64_t>* state, Callback callback) const;
+
+    // Non-SSE find for Less/Greater
+    template <bool gt, Action action, size_t bitwidth, class Callback>
+    bool compare_relation(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                          Callback callback) const;
+
+    template <class cond, Action action, size_t foreign_width, class Callback, size_t width>
+    bool compare_leafs_4(const Array* foreign, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                         Callback callback) const;
+
+    template <class cond, Action action, class Callback, size_t bitwidth, size_t foreign_bitwidth>
+    bool compare_leafs(const Array* foreign, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                       Callback callback) const;
+
+    template <class cond, Action action, class Callback>
+    bool compare_leafs(const Array* foreign, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                       Callback callback) const;
+
+    template <class cond, Action action, size_t width, class Callback>
+    bool compare_leafs(const Array* foreign, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                       Callback callback) const;
+
+// SSE find for the four functions Equal/NotEqual/Less/Greater
+#ifdef REALM_COMPILER_SSE
+    template <class cond, Action action, size_t width, class Callback>
+    bool find_sse(int64_t value, __m128i* data, size_t items, QueryState<int64_t>* state, size_t baseindex,
+                  Callback callback) const;
+
+    template <class cond, Action action, size_t width, class Callback>
+    REALM_FORCEINLINE bool find_sse_intern(__m128i* action_data, __m128i* data, size_t items,
+                                           QueryState<int64_t>* state, size_t baseindex, Callback callback) const;
+
+#endif
+
+    template <size_t width>
+    inline bool test_zero(uint64_t value) const; // Tests value for 0-elements
+
+    template <bool eq, size_t width>
+    size_t find_zero(uint64_t v) const; // Finds position of 0/non-zero element
+
+    template <size_t width, bool zero>
+    uint64_t cascade(uint64_t a) const; // Sets lowermost bits of zero or non-zero elements
+
+    template <bool gt, size_t width>
+    int64_t
+    find_gtlt_magic(int64_t v) const; // Compute magic constant needed for searching for value 'v' using bit hacks
+
+    template <size_t width>
+    inline int64_t lower_bits() const; // Return chunk with lower bit set in each element
+
+    size_t first_set_bit(unsigned int v) const;
+    size_t first_set_bit64(int64_t v) const;
+
+    template <size_t w>
+    int64_t get_universal(const char* const data, const size_t ndx) const;
+
+    // Find value greater/less in 64-bit chunk - only works for positive values
+    template <bool gt, Action action, size_t width, class Callback>
+    bool find_gtlt_fast(uint64_t chunk, uint64_t magic, QueryState<int64_t>* state, size_t baseindex,
+                        Callback callback) const;
+
+    // Find value greater/less in 64-bit chunk - no constraints
+    template <bool gt, Action action, size_t width, class Callback>
+    bool find_gtlt(int64_t v, uint64_t chunk, QueryState<int64_t>* state, size_t baseindex, Callback callback) const;
+
+    ref_type bptree_leaf_insert(size_t ndx, int64_t, TreeInsertBase& state);
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static int_fast64_t get(const char* header, size_t ndx) noexcept;
+
+    /// Like get(const char*, size_t) but gets two consecutive
+    /// elements.
+    static std::pair<int64_t, int64_t> get_two(const char* header, size_t ndx) noexcept;
+
+    static void get_three(const char* data, size_t ndx, ref_type& v0, ref_type& v1, ref_type& v2) noexcept;
+
+    /// The meaning of 'width' depends on the context in which this
+    /// array is used.
+    size_t get_width() const noexcept
+    {
+        return m_width;
+    }
+
+    static char* get_data_from_header(char*) noexcept;
+    static char* get_header_from_data(char*) noexcept;
+    static const char* get_data_from_header(const char*) noexcept;
+
+    enum WidthType {
+        wtype_Bits = 0,
+        wtype_Multiply = 1,
+        wtype_Ignore = 2,
+    };
+
+    static bool get_is_inner_bptree_node_from_header(const char*) noexcept;
+    static bool get_hasrefs_from_header(const char*) noexcept;
+    static bool get_context_flag_from_header(const char*) noexcept;
+    static WidthType get_wtype_from_header(const char*) noexcept;
+    static uint_least8_t get_width_from_header(const char*) noexcept;
+    static size_t get_size_from_header(const char*) noexcept;
+
+    static Type get_type_from_header(const char*) noexcept;
+
+    /// Get the number of bytes currently in use by this array. This
+    /// includes the array header, but it does not include allocated
+    /// bytes corresponding to excess capacity. The result is
+    /// guaranteed to be a multiple of 8 (i.e., 64-bit aligned).
+    ///
+    /// This number is exactly the number of bytes that will be
+    /// written by a non-recursive invocation of write().
+    size_t get_byte_size() const noexcept;
+
+    /// Get the maximum number of bytes that can be written by a
+    /// non-recursive invocation of write() on an array with the
+    /// specified number of elements, that is, the maximum value that
+    /// can be returned by get_byte_size().
+    static size_t get_max_byte_size(size_t num_elems) noexcept;
+
+    /// FIXME: Belongs in IntegerArray
+    static size_t calc_aligned_byte_size(size_t size, int width);
+
+    class MemUsageHandler {
+    public:
+        virtual void handle(ref_type ref, size_t allocated, size_t used) = 0;
+    };
+
+    void report_memory_usage(MemUsageHandler&) const;
+
+    void stats(MemStats& stats_dest) const noexcept;
+
+#ifdef REALM_DEBUG
+    void print() const;
+    void verify() const;
+    typedef size_t (*LeafVerifier)(MemRef, Allocator&);
+    void verify_bptree(LeafVerifier) const;
+    typedef void (*LeafDumper)(MemRef, Allocator&, std::ostream&, int level);
+    void dump_bptree_structure(std::ostream&, int level, LeafDumper) const;
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+    class ToDotHandler {
+    public:
+        virtual void to_dot(MemRef leaf_mem, ArrayParent*, size_t ndx_in_parent, std::ostream&) = 0;
+        ~ToDotHandler()
+        {
+        }
+    };
+    void bptree_to_dot(std::ostream&, ToDotHandler&) const;
+    void to_dot_parent_edge(std::ostream&) const;
+#endif
+
+    static const int header_size = 8; // Number of bytes used by header
+
+    // The encryption layer relies on headers always fitting within a single page.
+    static_assert(header_size == 8, "Header must always fit in entirely on a page");
+
+    Array& operator=(const Array&) = delete; // not allowed
+    Array(const Array&) = delete; // not allowed
+protected:
+    typedef bool (*CallbackDummy)(int64_t);
+
+protected:
+    // Includes array header. Not necessarily 8-byte aligned.
+    virtual size_t calc_byte_len(size_t num_items, size_t width) const;
+
+    virtual size_t calc_item_count(size_t bytes, size_t width) const noexcept;
+
+    bool get_is_inner_bptree_node_from_header() const noexcept;
+    bool get_hasrefs_from_header() const noexcept;
+    bool get_context_flag_from_header() const noexcept;
+    WidthType get_wtype_from_header() const noexcept;
+    uint_least8_t get_width_from_header() const noexcept;
+    size_t get_size_from_header() const noexcept;
+
+    // Undefined behavior if m_alloc.is_read_only(m_ref) returns true
+    size_t get_capacity_from_header() const noexcept;
+
+    void set_header_is_inner_bptree_node(bool value) noexcept;
+    void set_header_hasrefs(bool value) noexcept;
+    void set_header_context_flag(bool value) noexcept;
+    void set_header_wtype(WidthType value) noexcept;
+    void set_header_width(int value) noexcept;
+    void set_header_size(size_t value) noexcept;
+    void set_header_capacity(size_t value) noexcept;
+
+    static void set_header_is_inner_bptree_node(bool value, char* header) noexcept;
+    static void set_header_hasrefs(bool value, char* header) noexcept;
+    static void set_header_context_flag(bool value, char* header) noexcept;
+    static void set_header_wtype(WidthType value, char* header) noexcept;
+    static void set_header_width(int value, char* header) noexcept;
+    static void set_header_size(size_t value, char* header) noexcept;
+    static void set_header_capacity(size_t value, char* header) noexcept;
+
+    static void init_header(char* header, bool is_inner_bptree_node, bool has_refs, bool context_flag,
+                            WidthType width_type, int width, size_t size, size_t capacity) noexcept;
+
+
+    // This returns the minimum value ("lower bound") of the representable values
+    // for the given bit width. Valid widths are 0, 1, 2, 4, 8, 16, 32, and 64.
+    template <size_t width>
+    static int_fast64_t lbound_for_width() noexcept;
+
+    static int_fast64_t lbound_for_width(size_t width) noexcept;
+
+    // This returns the maximum value ("inclusive upper bound") of the representable values
+    // for the given bit width. Valid widths are 0, 1, 2, 4, 8, 16, 32, and 64.
+    template <size_t width>
+    static int_fast64_t ubound_for_width() noexcept;
+
+    static int_fast64_t ubound_for_width(size_t width) noexcept;
+
+    template <size_t width>
+    void set_width() noexcept;
+    void set_width(size_t) noexcept;
+    void alloc(size_t init_size, size_t width);
+    void copy_on_write();
+
+private:
+    void do_copy_on_write(size_t minimum_size = 0);
+    void do_ensure_minimum_width(int_fast64_t);
+
+    template <size_t w>
+    int64_t sum(size_t start, size_t end) const;
+
+    template <bool max, size_t w>
+    bool minmax(int64_t& result, size_t start, size_t end, size_t* return_ndx) const;
+
+    template <size_t w>
+    size_t find_gte(const int64_t target, size_t start, size_t end) const;
+
+    template <size_t w>
+    size_t adjust_ge(size_t start, size_t end, int_fast64_t limit, int_fast64_t diff);
+
+protected:
+    /// The total size in bytes (including the header) of a new empty
+    /// array. Must be a multiple of 8 (i.e., 64-bit aligned).
+    static const size_t initial_capacity = 128;
+
+    /// It is an error to specify a non-zero value unless the width
+    /// type is wtype_Bits. It is also an error to specify a non-zero
+    /// size if the width type is wtype_Ignore.
+    static MemRef create(Type, bool context_flag, WidthType, size_t size, int_fast64_t value, Allocator&);
+
+    static MemRef clone(MemRef header, Allocator& alloc, Allocator& target_alloc);
+
+    /// Get the address of the header of this array.
+    char* get_header() noexcept;
+
+    /// Same as get_byte_size().
+    static size_t get_byte_size_from_header(const char*) noexcept;
+
+    // Undefined behavior if array is in immutable memory
+    static size_t get_capacity_from_header(const char*) noexcept;
+
+    // Overriding method in ArrayParent
+    void update_child_ref(size_t, ref_type) override;
+
+    // Overriding method in ArrayParent
+    ref_type get_child_ref(size_t) const noexcept override;
+
+    void destroy_children(size_t offset = 0) noexcept;
+
+    std::pair<ref_type, size_t> get_to_dot_parent(size_t ndx_in_parent) const override;
+
+    bool is_read_only() const noexcept;
+
+protected:
+    // Getters and Setters for adaptive-packed arrays
+    typedef int64_t (Array::*Getter)(size_t) const; // Note: getters must not throw
+    typedef void (Array::*Setter)(size_t, int64_t);
+    typedef bool (Array::*Finder)(int64_t, size_t, size_t, size_t, QueryState<int64_t>*) const;
+    typedef void (Array::*ChunkGetter)(size_t, int64_t res[8]) const; // Note: getters must not throw
+
+    struct VTable {
+        Getter getter;
+        ChunkGetter chunk_getter;
+        Setter setter;
+        Finder finder[cond_VTABLE_FINDER_COUNT]; // one for each active function pointer
+    };
+    template <size_t w>
+    struct VTableForWidth;
+
+protected:
+    /// Takes a 64-bit value and returns the minimum number of bits needed
+    /// to fit the value. For alignment this is rounded up to nearest
+    /// log2. Posssible results {0, 1, 2, 4, 8, 16, 32, 64}
+    static size_t bit_width(int64_t value);
+
+    void report_memory_usage_2(MemUsageHandler&) const;
+
+private:
+    Getter m_getter = nullptr; // cached to avoid indirection
+    const VTable* m_vtable = nullptr;
+
+public:
+    // FIXME: Should not be public
+    char* m_data = nullptr; // Points to first byte after header
+
+#if REALM_ENABLE_MEMDEBUG
+    // If m_no_relocation is false, then copy_on_write() will always relocate this array, regardless if it's
+    // required or not. If it's true, then it will never relocate, which is currently only expeted inside
+    // GroupWriter::write_group() due to a unique chicken/egg problem (see description there).
+    bool m_no_relocation = false;
+#endif
+
+protected:
+    int64_t m_lbound; // min number that can be stored with current m_width
+    int64_t m_ubound; // max number that can be stored with current m_width
+
+    size_t m_size = 0;     // Number of elements currently stored.
+    size_t m_capacity = 0; // Number of elements that fit inside the allocated memory.
+
+    Allocator& m_alloc;
+
+private:
+    size_t m_ref;
+    ArrayParent* m_parent = nullptr;
+    size_t m_ndx_in_parent = 0; // Ignored if m_parent is null.
+
+protected:
+    uint_least8_t m_width = 0;   // Size of an element (meaning depend on type of array).
+    bool m_is_inner_bptree_node; // This array is an inner node of B+-tree.
+    bool m_has_refs;             // Elements whose first bit is zero are refs to subarrays.
+    bool m_context_flag;         // Meaning depends on context.
+
+private:
+    ref_type do_write_shallow(_impl::ArrayWriterBase&) const;
+    ref_type do_write_deep(_impl::ArrayWriterBase&, bool only_if_modified) const;
+    static size_t calc_byte_size(WidthType wtype, size_t size, uint_least8_t width) noexcept;
+
+    friend class SlabAlloc;
+    friend class GroupWriter;
+    friend class StringColumn;
+};
+
+
+// Implementation:
+
+class QueryStateBase {
+    virtual void dyncast()
+    {
+    }
+};
+
+template <>
+class QueryState<int64_t> : public QueryStateBase {
+public:
+    int64_t m_state;
+    size_t m_match_count;
+    size_t m_limit;
+    size_t m_minmax_index; // used only for min/max, to save index of current min/max value
+
+    template <Action action>
+    bool uses_val()
+    {
+        if (action == act_Max || action == act_Min || action == act_Sum)
+            return true;
+        else
+            return false;
+    }
+
+    void init(Action action, IntegerColumn* akku, size_t limit)
+    {
+        m_match_count = 0;
+        m_limit = limit;
+        m_minmax_index = not_found;
+
+        if (action == act_Max)
+            m_state = -0x7fffffffffffffffLL - 1LL;
+        else if (action == act_Min)
+            m_state = 0x7fffffffffffffffLL;
+        else if (action == act_ReturnFirst)
+            m_state = not_found;
+        else if (action == act_Sum)
+            m_state = 0;
+        else if (action == act_Count)
+            m_state = 0;
+        else if (action == act_FindAll)
+            m_state = reinterpret_cast<int64_t>(akku);
+        else if (action == act_CallbackIdx) {
+        }
+        else {
+            REALM_ASSERT_DEBUG(false);
+        }
+    }
+
+    template <Action action, bool pattern>
+    inline bool match(size_t index, uint64_t indexpattern, int64_t value)
+    {
+        if (pattern) {
+            if (action == act_Count) {
+                // If we are close to 'limit' argument in query, we cannot count-up a complete chunk. Count up single
+                // elements instead
+                if (m_match_count + 64 >= m_limit)
+                    return false;
+
+                m_state += fast_popcount64(indexpattern);
+                m_match_count = size_t(m_state);
+                return true;
+            }
+            // Other aggregates cannot (yet) use bit pattern for anything. Make Array-finder call with pattern = false
+            // instead
+            return false;
+        }
+
+        ++m_match_count;
+
+        if (action == act_Max) {
+            if (value > m_state) {
+                m_state = value;
+                m_minmax_index = index;
+            }
+        }
+        else if (action == act_Min) {
+            if (value < m_state) {
+                m_state = value;
+                m_minmax_index = index;
+            }
+        }
+        else if (action == act_Sum)
+            m_state += value;
+        else if (action == act_Count) {
+            m_state++;
+            m_match_count = size_t(m_state);
+        }
+        else if (action == act_FindAll) {
+            Array::add_to_column(reinterpret_cast<IntegerColumn*>(m_state), index);
+        }
+        else if (action == act_ReturnFirst) {
+            m_state = index;
+            return false;
+        }
+        else {
+            REALM_ASSERT_DEBUG(false);
+        }
+        return (m_limit > m_match_count);
+    }
+
+    template <Action action, bool pattern>
+    inline bool match(size_t index, uint64_t indexpattern, util::Optional<int64_t> value)
+    {
+        // FIXME: This is a temporary hack for nullable integers.
+        if (value) {
+            return match<action, pattern>(index, indexpattern, *value);
+        }
+
+        // If value is null, the only sensible actions are count, find_all, and return first.
+        // Max, min, and sum should all have no effect.
+        if (action == act_Count) {
+            m_state++;
+            m_match_count = size_t(m_state);
+        }
+        else if (action == act_FindAll) {
+            Array::add_to_column(reinterpret_cast<IntegerColumn*>(m_state), index);
+        }
+        else if (action == act_ReturnFirst) {
+            m_match_count++;
+            m_state = index;
+            return false;
+        }
+        return m_limit > m_match_count;
+    }
+};
+
+// Used only for Basic-types: currently float and double
+template <class R>
+class QueryState : public QueryStateBase {
+public:
+    R m_state;
+    size_t m_match_count;
+    size_t m_limit;
+    size_t m_minmax_index; // used only for min/max, to save index of current min/max value
+
+    template <Action action>
+    bool uses_val()
+    {
+        return (action == act_Max || action == act_Min || action == act_Sum || action == act_Count);
+    }
+
+    void init(Action action, Array*, size_t limit)
+    {
+        REALM_ASSERT((std::is_same<R, float>::value || std::is_same<R, double>::value));
+        m_match_count = 0;
+        m_limit = limit;
+        m_minmax_index = not_found;
+
+        if (action == act_Max)
+            m_state = -std::numeric_limits<R>::infinity();
+        else if (action == act_Min)
+            m_state = std::numeric_limits<R>::infinity();
+        else if (action == act_Sum)
+            m_state = 0.0;
+        else {
+            REALM_ASSERT_DEBUG(false);
+        }
+    }
+
+    template <Action action, bool pattern, typename resulttype>
+    inline bool match(size_t index, uint64_t /*indexpattern*/, resulttype value)
+    {
+        if (pattern)
+            return false;
+
+        static_assert(action == act_Sum || action == act_Max || action == act_Min || action == act_Count,
+                      "Search action not supported");
+
+        if (action == act_Count) {
+            ++m_match_count;
+        }
+        else if (!null::is_null_float(value)) {
+            ++m_match_count;
+            if (action == act_Max) {
+                if (value > m_state) {
+                    m_state = value;
+                    m_minmax_index = index;
+                }
+            }
+            else if (action == act_Min) {
+                if (value < m_state) {
+                    m_state = value;
+                    m_minmax_index = index;
+                }
+            }
+            else if (action == act_Sum)
+                m_state += value;
+            else {
+                REALM_ASSERT_DEBUG(false);
+            }
+        }
+
+        return (m_limit > m_match_count);
+    }
+};
+
+inline bool RefOrTagged::is_ref() const noexcept
+{
+    return (m_value & 1) == 0;
+}
+
+inline bool RefOrTagged::is_tagged() const noexcept
+{
+    return !is_ref();
+}
+
+inline ref_type RefOrTagged::get_as_ref() const noexcept
+{
+    // to_ref() is defined in <alloc.hpp>
+    return to_ref(m_value);
+}
+
+inline uint_fast64_t RefOrTagged::get_as_int() const noexcept
+{
+    // The bitwise AND is there in case uint_fast64_t is wider than 64 bits.
+    return (uint_fast64_t(m_value) & 0xFFFFFFFFFFFFFFFFULL) >> 1;
+}
+
+inline RefOrTagged RefOrTagged::make_ref(ref_type ref) noexcept
+{
+    // from_ref() is defined in <alloc.hpp>
+    int_fast64_t value = from_ref(ref);
+    return RefOrTagged(value);
+}
+
+inline RefOrTagged RefOrTagged::make_tagged(uint_fast64_t i) noexcept
+{
+    REALM_ASSERT(i < (1ULL << 63));
+    int_fast64_t value = util::from_twos_compl<int_fast64_t>((i << 1) | 1);
+    return RefOrTagged(value);
+}
+
+inline RefOrTagged::RefOrTagged(int_fast64_t value) noexcept
+    : m_value(value)
+{
+}
+
+inline Array::Array(Allocator& allocator) noexcept
+    : m_alloc(allocator)
+{
+}
+
+inline void Array::create(Type type, bool context_flag, size_t length, int_fast64_t value)
+{
+    MemRef mem = create_array(type, context_flag, length, value, m_alloc); // Throws
+    init_from_mem(mem);
+}
+
+
+inline void Array::init_from_ref(ref_type ref) noexcept
+{
+    REALM_ASSERT_DEBUG(ref);
+    char* header = m_alloc.translate(ref);
+    init_from_mem(MemRef(header, ref, m_alloc));
+}
+
+
+inline void Array::init_from_parent() noexcept
+{
+    ref_type ref = get_ref_from_parent();
+    init_from_ref(ref);
+}
+
+
+inline Array::Type Array::get_type() const noexcept
+{
+    if (m_is_inner_bptree_node) {
+        REALM_ASSERT_DEBUG(m_has_refs);
+        return type_InnerBptreeNode;
+    }
+    if (m_has_refs)
+        return type_HasRefs;
+    return type_Normal;
+}
+
+
+inline void Array::get_chunk(size_t ndx, int64_t res[8]) const noexcept
+{
+    REALM_ASSERT_DEBUG(ndx < m_size);
+    (this->*(m_vtable->chunk_getter))(ndx, res);
+}
+
+
+inline int64_t Array::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_DEBUG(is_attached());
+    REALM_ASSERT_DEBUG(ndx < m_size);
+    return (this->*m_getter)(ndx);
+
+    // Two ideas that are not efficient but may be worth looking into again:
+    /*
+        // Assume correct width is found early in REALM_TEMPEX, which is the case for B tree offsets that
+        // are probably either 2^16 long. Turns out to be 25% faster if found immediately, but 50-300% slower
+        // if found later
+        REALM_TEMPEX(return get, (ndx));
+    */
+    /*
+        // Slightly slower in both of the if-cases. Also needs an matchcount m_size check too, to avoid
+        // reading beyond array.
+        if (m_width >= 8 && m_size > ndx + 7)
+            return get<64>(ndx >> m_shift) & m_widthmask;
+        else
+            return (this->*(m_vtable->getter))(ndx);
+    */
+}
+
+inline int64_t Array::front() const noexcept
+{
+    return get(0);
+}
+
+inline int64_t Array::back() const noexcept
+{
+    return get(m_size - 1);
+}
+
+inline ref_type Array::get_as_ref(size_t ndx) const noexcept
+{
+    REALM_ASSERT_DEBUG(is_attached());
+    REALM_ASSERT_DEBUG(m_has_refs);
+    int64_t v = get(ndx);
+    return to_ref(v);
+}
+
+inline RefOrTagged Array::get_as_ref_or_tagged(size_t ndx) const noexcept
+{
+    REALM_ASSERT(has_refs());
+    return RefOrTagged(get(ndx));
+}
+
+inline void Array::set(size_t ndx, RefOrTagged ref_or_tagged)
+{
+    REALM_ASSERT(has_refs());
+    set(ndx, ref_or_tagged.m_value); // Throws
+}
+
+inline void Array::add(RefOrTagged ref_or_tagged)
+{
+    REALM_ASSERT(has_refs());
+    add(ref_or_tagged.m_value); // Throws
+}
+
+inline void Array::ensure_minimum_width(RefOrTagged ref_or_tagged)
+{
+    REALM_ASSERT(has_refs());
+    ensure_minimum_width(ref_or_tagged.m_value); // Throws
+}
+
+inline bool Array::is_inner_bptree_node() const noexcept
+{
+    return m_is_inner_bptree_node;
+}
+
+inline bool Array::has_refs() const noexcept
+{
+    return m_has_refs;
+}
+
+inline void Array::set_has_refs(bool value) noexcept
+{
+    if (m_has_refs != value) {
+        REALM_ASSERT(!is_read_only());
+        m_has_refs = value;
+        set_header_hasrefs(value);
+    }
+}
+
+inline bool Array::get_context_flag() const noexcept
+{
+    return m_context_flag;
+}
+
+inline void Array::set_context_flag(bool value) noexcept
+{
+    if (m_context_flag != value) {
+        REALM_ASSERT(!is_read_only());
+        m_context_flag = value;
+        set_header_context_flag(value);
+    }
+}
+
+inline ref_type Array::get_ref() const noexcept
+{
+    return m_ref;
+}
+
+inline MemRef Array::get_mem() const noexcept
+{
+    return MemRef(get_header_from_data(m_data), m_ref, m_alloc);
+}
+
+inline void Array::destroy() noexcept
+{
+    if (!is_attached())
+        return;
+    char* header = get_header_from_data(m_data);
+    m_alloc.free_(m_ref, header);
+    m_data = nullptr;
+}
+
+inline void Array::destroy_deep() noexcept
+{
+    if (!is_attached())
+        return;
+
+    if (m_has_refs)
+        destroy_children();
+
+    char* header = get_header_from_data(m_data);
+    m_alloc.free_(m_ref, header);
+    m_data = nullptr;
+}
+
+inline ref_type Array::write(_impl::ArrayWriterBase& out, bool deep, bool only_if_modified) const
+{
+    REALM_ASSERT(is_attached());
+
+    if (only_if_modified && m_alloc.is_read_only(m_ref))
+        return m_ref;
+
+    if (!deep || !m_has_refs)
+        return do_write_shallow(out); // Throws
+
+    return do_write_deep(out, only_if_modified); // Throws
+}
+
+inline ref_type Array::write(ref_type ref, Allocator& alloc, _impl::ArrayWriterBase& out, bool only_if_modified)
+{
+    if (only_if_modified && alloc.is_read_only(ref))
+        return ref;
+
+    Array array(alloc);
+    array.init_from_ref(ref);
+
+    if (!array.m_has_refs)
+        return array.do_write_shallow(out); // Throws
+
+    return array.do_write_deep(out, only_if_modified); // Throws
+}
+
+inline void Array::add(int_fast64_t value)
+{
+    insert(m_size, value);
+}
+
+inline void Array::erase(size_t ndx)
+{
+    // This can throw, but only if array is currently in read-only
+    // memory.
+    move(ndx + 1, size(), ndx);
+
+    // Update size (also in header)
+    --m_size;
+    set_header_size(m_size);
+}
+
+
+inline void Array::erase(size_t begin, size_t end)
+{
+    if (begin != end) {
+        // This can throw, but only if array is currently in read-only memory.
+        move(end, size(), begin); // Throws
+
+        // Update size (also in header)
+        m_size -= end - begin;
+        set_header_size(m_size);
+    }
+}
+
+inline void Array::clear()
+{
+    truncate(0); // Throws
+}
+
+inline void Array::clear_and_destroy_children()
+{
+    truncate_and_destroy_children(0);
+}
+
+inline void Array::destroy(ref_type ref, Allocator& alloc) noexcept
+{
+    destroy(MemRef(ref, alloc), alloc);
+}
+
+inline void Array::destroy(MemRef mem, Allocator& alloc) noexcept
+{
+    alloc.free_(mem);
+}
+
+inline void Array::destroy_deep(ref_type ref, Allocator& alloc) noexcept
+{
+    destroy_deep(MemRef(ref, alloc), alloc);
+}
+
+inline void Array::destroy_deep(MemRef mem, Allocator& alloc) noexcept
+{
+    if (!get_hasrefs_from_header(mem.get_addr())) {
+        alloc.free_(mem);
+        return;
+    }
+    Array array(alloc);
+    array.init_from_mem(mem);
+    array.destroy_deep();
+}
+
+
+inline void Array::adjust(size_t ndx, int_fast64_t diff)
+{
+    REALM_ASSERT_3(ndx, <=, m_size);
+    if (diff != 0) {
+        // FIXME: Should be optimized
+        int_fast64_t v = get(ndx);
+        set(ndx, int64_t(v + diff)); // Throws
+    }
+}
+
+inline void Array::adjust(size_t begin, size_t end, int_fast64_t diff)
+{
+    if (diff != 0) {
+        // FIXME: Should be optimized
+        for (size_t i = begin; i != end; ++i)
+            adjust(i, diff); // Throws
+    }
+}
+
+
+//-------------------------------------------------
+
+inline bool Array::get_is_inner_bptree_node_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return (int(h[4]) & 0x80) != 0;
+}
+inline bool Array::get_hasrefs_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return (int(h[4]) & 0x40) != 0;
+}
+inline bool Array::get_context_flag_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return (int(h[4]) & 0x20) != 0;
+}
+inline Array::WidthType Array::get_wtype_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return WidthType((int(h[4]) & 0x18) >> 3);
+}
+inline uint_least8_t Array::get_width_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return uint_least8_t((1 << (int(h[4]) & 0x07)) >> 1);
+}
+inline size_t Array::get_size_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return (size_t(h[5]) << 16) + (size_t(h[6]) << 8) + h[7];
+}
+inline size_t Array::get_capacity_from_header(const char* header) noexcept
+{
+    typedef unsigned char uchar;
+    const uchar* h = reinterpret_cast<const uchar*>(header);
+    return (size_t(h[0]) << 19) + (size_t(h[1]) << 11) + (h[2] << 3);
+}
+
+
+inline char* Array::get_data_from_header(char* header) noexcept
+{
+    return header + header_size;
+}
+inline char* Array::get_header_from_data(char* data) noexcept
+{
+    return data - header_size;
+}
+inline const char* Array::get_data_from_header(const char* header) noexcept
+{
+    return get_data_from_header(const_cast<char*>(header));
+}
+
+
+inline bool Array::get_is_inner_bptree_node_from_header() const noexcept
+{
+    return get_is_inner_bptree_node_from_header(get_header_from_data(m_data));
+}
+inline bool Array::get_hasrefs_from_header() const noexcept
+{
+    return get_hasrefs_from_header(get_header_from_data(m_data));
+}
+inline bool Array::get_context_flag_from_header() const noexcept
+{
+    return get_context_flag_from_header(get_header_from_data(m_data));
+}
+inline Array::WidthType Array::get_wtype_from_header() const noexcept
+{
+    return get_wtype_from_header(get_header_from_data(m_data));
+}
+inline uint_least8_t Array::get_width_from_header() const noexcept
+{
+    return get_width_from_header(get_header_from_data(m_data));
+}
+inline size_t Array::get_size_from_header() const noexcept
+{
+    return get_size_from_header(get_header_from_data(m_data));
+}
+inline size_t Array::get_capacity_from_header() const noexcept
+{
+    return get_capacity_from_header(get_header_from_data(m_data));
+}
+
+
+inline void Array::set_header_is_inner_bptree_node(bool value, char* header) noexcept
+{
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[4] = uchar((int(h[4]) & ~0x80) | int(value) << 7);
+}
+
+inline void Array::set_header_hasrefs(bool value, char* header) noexcept
+{
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[4] = uchar((int(h[4]) & ~0x40) | int(value) << 6);
+}
+
+inline void Array::set_header_context_flag(bool value, char* header) noexcept
+{
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[4] = uchar((int(h[4]) & ~0x20) | int(value) << 5);
+}
+
+inline void Array::set_header_wtype(WidthType value, char* header) noexcept
+{
+    // Indicates how to calculate size in bytes based on width
+    // 0: bits      (width/8) * size
+    // 1: multiply  width * size
+    // 2: ignore    1 * size
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[4] = uchar((int(h[4]) & ~0x18) | int(value) << 3);
+}
+
+inline void Array::set_header_width(int value, char* header) noexcept
+{
+    // Pack width in 3 bits (log2)
+    int w = 0;
+    while (value) {
+        ++w;
+        value >>= 1;
+    }
+    REALM_ASSERT_3(w, <, 8);
+
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[4] = uchar((int(h[4]) & ~0x7) | w);
+}
+
+inline void Array::set_header_size(size_t value, char* header) noexcept
+{
+    REALM_ASSERT_3(value, <=, max_array_size);
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[5] = uchar((value >> 16) & 0x000000FF);
+    h[6] = uchar((value >> 8) & 0x000000FF);
+    h[7] = uchar(value & 0x000000FF);
+}
+
+// Note: There is a copy of this function is test_alloc.cpp
+inline void Array::set_header_capacity(size_t value, char* header) noexcept
+{
+    REALM_ASSERT_3(value, <=, (0xffffff << 3));
+    typedef unsigned char uchar;
+    uchar* h = reinterpret_cast<uchar*>(header);
+    h[0] = uchar((value >> 19) & 0x000000FF);
+    h[1] = uchar((value >> 11) & 0x000000FF);
+    h[2] = uchar(value >> 3 & 0x000000FF);
+}
+
+
+inline void Array::set_header_is_inner_bptree_node(bool value) noexcept
+{
+    set_header_is_inner_bptree_node(value, get_header_from_data(m_data));
+}
+inline void Array::set_header_hasrefs(bool value) noexcept
+{
+    set_header_hasrefs(value, get_header_from_data(m_data));
+}
+inline void Array::set_header_context_flag(bool value) noexcept
+{
+    set_header_context_flag(value, get_header_from_data(m_data));
+}
+inline void Array::set_header_wtype(WidthType value) noexcept
+{
+    set_header_wtype(value, get_header_from_data(m_data));
+}
+inline void Array::set_header_width(int value) noexcept
+{
+    set_header_width(value, get_header_from_data(m_data));
+}
+inline void Array::set_header_size(size_t value) noexcept
+{
+    set_header_size(value, get_header_from_data(m_data));
+}
+inline void Array::set_header_capacity(size_t value) noexcept
+{
+    set_header_capacity(value, get_header_from_data(m_data));
+}
+
+
+inline Array::Type Array::get_type_from_header(const char* header) noexcept
+{
+    if (get_is_inner_bptree_node_from_header(header))
+        return type_InnerBptreeNode;
+    if (get_hasrefs_from_header(header))
+        return type_HasRefs;
+    return type_Normal;
+}
+
+
+inline char* Array::get_header() noexcept
+{
+    return get_header_from_data(m_data);
+}
+
+inline size_t Array::calc_byte_size(WidthType wtype, size_t size, uint_least8_t width) noexcept
+{
+    size_t num_bytes = 0;
+    switch (wtype) {
+        case wtype_Bits: {
+            // Current assumption is that size is at most 2^24 and that width is at most 64.
+            // In that case the following will never overflow. (Assuming that size_t is at least 32 bits)
+            REALM_ASSERT_3(size, <, 0x1000000);
+            size_t num_bits = size * width;
+            num_bytes = (num_bits + 7) >> 3;
+            break;
+        }
+        case wtype_Multiply: {
+            num_bytes = size * width;
+            break;
+        }
+        case wtype_Ignore:
+            num_bytes = size;
+            break;
+    }
+
+    // Ensure 8-byte alignment
+    num_bytes = (num_bytes + 7) & ~size_t(7);
+
+    num_bytes += header_size;
+
+    return num_bytes;
+}
+
+inline size_t Array::get_byte_size() const noexcept
+{
+    const char* header = get_header_from_data(m_data);
+    WidthType wtype = get_wtype_from_header(header);
+    size_t num_bytes = calc_byte_size(wtype, m_size, m_width);
+
+    REALM_ASSERT_7(m_alloc.is_read_only(m_ref), ==, true, ||, num_bytes, <=, get_capacity_from_header(header));
+
+    return num_bytes;
+}
+
+
+inline size_t Array::get_byte_size_from_header(const char* header) noexcept
+{
+    size_t size = get_size_from_header(header);
+    uint_least8_t width = get_width_from_header(header);
+    WidthType wtype = get_wtype_from_header(header);
+    size_t num_bytes = calc_byte_size(wtype, size, width);
+
+    return num_bytes;
+}
+
+
+inline void Array::init_header(char* header, bool is_inner_bptree_node, bool has_refs, bool context_flag,
+                               WidthType width_type, int width, size_t size, size_t capacity) noexcept
+{
+    // Note: Since the header layout contains unallocated bit and/or
+    // bytes, it is important that we put the entire header into a
+    // well defined state initially.
+    std::fill(header, header + header_size, 0);
+    set_header_is_inner_bptree_node(is_inner_bptree_node, header);
+    set_header_hasrefs(has_refs, header);
+    set_header_context_flag(context_flag, header);
+    set_header_wtype(width_type, header);
+    set_header_width(width, header);
+    set_header_size(size, header);
+    set_header_capacity(capacity, header);
+}
+
+
+//-------------------------------------------------
+
+inline MemRef Array::clone_deep(Allocator& target_alloc) const
+{
+    char* header = get_header_from_data(m_data);
+    return clone(MemRef(header, m_ref, m_alloc), m_alloc, target_alloc); // Throws
+}
+
+inline MemRef Array::create_empty_array(Type type, bool context_flag, Allocator& alloc)
+{
+    size_t size = 0;
+    int_fast64_t value = 0;
+    return create_array(type, context_flag, size, value, alloc); // Throws
+}
+
+inline MemRef Array::create_array(Type type, bool context_flag, size_t size, int_fast64_t value, Allocator& alloc)
+{
+    return create(type, context_flag, wtype_Bits, size, value, alloc); // Throws
+}
+
+inline bool Array::has_parent() const noexcept
+{
+    return m_parent != nullptr;
+}
+
+inline ArrayParent* Array::get_parent() const noexcept
+{
+    return m_parent;
+}
+
+inline void Array::set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept
+{
+    m_parent = parent;
+    m_ndx_in_parent = ndx_in_parent;
+}
+
+inline size_t Array::get_ndx_in_parent() const noexcept
+{
+    return m_ndx_in_parent;
+}
+
+inline void Array::set_ndx_in_parent(size_t ndx) noexcept
+{
+    m_ndx_in_parent = ndx;
+}
+
+inline void Array::adjust_ndx_in_parent(int diff) noexcept
+{
+    // Note that `diff` is promoted to an unsigned type, and that
+    // C++03 still guarantees the expected result regardless of the
+    // sizes of `int` and `decltype(m_ndx_in_parent)`.
+    m_ndx_in_parent += diff;
+}
+
+inline ref_type Array::get_ref_from_parent() const noexcept
+{
+    ref_type ref = m_parent->get_child_ref(m_ndx_in_parent);
+    return ref;
+}
+
+inline bool Array::is_attached() const noexcept
+{
+    return m_data != nullptr;
+}
+
+inline void Array::detach() noexcept
+{
+    m_data = nullptr;
+}
+
+inline size_t Array::size() const noexcept
+{
+    REALM_ASSERT_DEBUG(is_attached());
+    return m_size;
+}
+
+inline bool Array::is_empty() const noexcept
+{
+    return size() == 0;
+}
+
+inline size_t Array::get_max_byte_size(size_t num_elems) noexcept
+{
+    int max_bytes_per_elem = 8;
+    return header_size + num_elems * max_bytes_per_elem;
+}
+
+inline void Array::update_parent()
+{
+    if (m_parent)
+        m_parent->update_child_ref(m_ndx_in_parent, m_ref);
+}
+
+
+inline void Array::update_child_ref(size_t child_ndx, ref_type new_ref)
+{
+    set(child_ndx, new_ref);
+}
+
+inline ref_type Array::get_child_ref(size_t child_ndx) const noexcept
+{
+    return get_as_ref(child_ndx);
+}
+
+inline bool Array::is_read_only() const noexcept
+{
+    REALM_ASSERT_DEBUG(is_attached());
+    return m_alloc.is_read_only(m_ref);
+}
+
+inline void Array::copy_on_write()
+{
+#if REALM_ENABLE_MEMDEBUG
+    // We want to relocate this array regardless if there is a need or not, in order to catch use-after-free bugs.
+    // Only exception is inside GroupWriter::write_group() (see explanation at the definition of the m_no_relocation
+    // member)
+    if (!m_no_relocation) {
+#else
+    if (is_read_only()) {
+#endif
+        do_copy_on_write();
+    }
+}
+
+inline void Array::ensure_minimum_width(int_fast64_t value)
+{
+    if (value >= m_lbound && value <= m_ubound)
+        return;
+    do_ensure_minimum_width(value);
+}
+
+
+//*************************************************************************************
+// Finding code                                                                       *
+//*************************************************************************************
+
+template <size_t w>
+int64_t Array::get(size_t ndx) const noexcept
+{
+    return get_universal<w>(m_data, ndx);
+}
+
+template <size_t w>
+int64_t Array::get_universal(const char* data, size_t ndx) const
+{
+    if (w == 0) {
+        return 0;
+    }
+    else if (w == 1) {
+        size_t offset = ndx >> 3;
+        return (data[offset] >> (ndx & 7)) & 0x01;
+    }
+    else if (w == 2) {
+        size_t offset = ndx >> 2;
+        return (data[offset] >> ((ndx & 3) << 1)) & 0x03;
+    }
+    else if (w == 4) {
+        size_t offset = ndx >> 1;
+        return (data[offset] >> ((ndx & 1) << 2)) & 0x0F;
+    }
+    else if (w == 8) {
+        return *reinterpret_cast<const signed char*>(data + ndx);
+    }
+    else if (w == 16) {
+        size_t offset = ndx * 2;
+        return *reinterpret_cast<const int16_t*>(data + offset);
+    }
+    else if (w == 32) {
+        size_t offset = ndx * 4;
+        return *reinterpret_cast<const int32_t*>(data + offset);
+    }
+    else if (w == 64) {
+        size_t offset = ndx * 8;
+        return *reinterpret_cast<const int64_t*>(data + offset);
+    }
+    else {
+        REALM_ASSERT_DEBUG(false);
+        return int64_t(-1);
+    }
+}
+
+/*
+find() (calls find_optimized()) will call match() for each search result.
+
+If pattern == true:
+    'indexpattern' contains a 64-bit chunk of elements, each of 'width' bits in size where each element indicates a
+    match if its lower bit is set, otherwise it indicates a non-match. 'index' tells the database row index of the
+    first element. You must return true if you chose to 'consume' the chunk or false if not. If not, then Array-finder
+    will afterwards call match() successive times with pattern == false.
+
+If pattern == false:
+    'index' tells the row index of a single match and 'value' tells its value. Return false to make Array-finder break
+    its search or return true to let it continue until 'end' or 'limit'.
+
+Array-finder decides itself if - and when - it wants to pass you an indexpattern. It depends on array bit width, match
+frequency, and whether the arithemetic and computations for the given search criteria makes it feasible to construct
+such a pattern.
+*/
+
+// These wrapper functions only exist to enable a possibility to make the compiler see that 'value' and/or 'index' are
+// unused, such that caller's computation of these values will not be made. Only works if find_action() and
+// find_action_pattern() rewritten as macros. Note: This problem has been fixed in next upcoming array.hpp version
+template <Action action, class Callback>
+bool Array::find_action(size_t index, util::Optional<int64_t> value, QueryState<int64_t>* state,
+                        Callback callback) const
+{
+    if (action == act_CallbackIdx)
+        return callback(index);
+    else
+        return state->match<action, false>(index, 0, value);
+}
+template <Action action, class Callback>
+bool Array::find_action_pattern(size_t index, uint64_t pattern, QueryState<int64_t>* state, Callback callback) const
+{
+    static_cast<void>(callback);
+    if (action == act_CallbackIdx) {
+        // Possible future optimization: call callback(index) like in above find_action(), in a loop for each bit set
+        // in 'pattern'
+        return false;
+    }
+    return state->match<action, true>(index, pattern, 0);
+}
+
+
+template <size_t width, bool zero>
+uint64_t Array::cascade(uint64_t a) const
+{
+    // Takes a chunk of values as argument and sets the least significant bit for each
+    // element which is zero or non-zero, depending on the template parameter.
+    // Example for zero=true:
+    // width == 4 and a = 0x5fd07a107610f610
+    // will return:       0x0001000100010001
+
+    // static values needed for fast population count
+    const uint64_t m1 = 0x5555555555555555ULL;
+
+    if (width == 1) {
+        return zero ? ~a : a;
+    }
+    else if (width == 2) {
+        // Masks to avoid spillover between segments in cascades
+        const uint64_t c1 = ~0ULL / 0x3 * 0x1;
+
+        a |= (a >> 1) & c1; // cascade ones in non-zeroed segments
+        a &= m1;            // isolate single bit in each segment
+        if (zero)
+            a ^= m1; // reverse isolated bits if checking for zeroed segments
+
+        return a;
+    }
+    else if (width == 4) {
+        const uint64_t m = ~0ULL / 0xF * 0x1;
+
+        // Masks to avoid spillover between segments in cascades
+        const uint64_t c1 = ~0ULL / 0xF * 0x7;
+        const uint64_t c2 = ~0ULL / 0xF * 0x3;
+
+        a |= (a >> 1) & c1; // cascade ones in non-zeroed segments
+        a |= (a >> 2) & c2;
+        a &= m; // isolate single bit in each segment
+        if (zero)
+            a ^= m; // reverse isolated bits if checking for zeroed segments
+
+        return a;
+    }
+    else if (width == 8) {
+        const uint64_t m = ~0ULL / 0xFF * 0x1;
+
+        // Masks to avoid spillover between segments in cascades
+        const uint64_t c1 = ~0ULL / 0xFF * 0x7F;
+        const uint64_t c2 = ~0ULL / 0xFF * 0x3F;
+        const uint64_t c3 = ~0ULL / 0xFF * 0x0F;
+
+        a |= (a >> 1) & c1; // cascade ones in non-zeroed segments
+        a |= (a >> 2) & c2;
+        a |= (a >> 4) & c3;
+        a &= m; // isolate single bit in each segment
+        if (zero)
+            a ^= m; // reverse isolated bits if checking for zeroed segments
+
+        return a;
+    }
+    else if (width == 16) {
+        const uint64_t m = ~0ULL / 0xFFFF * 0x1;
+
+        // Masks to avoid spillover between segments in cascades
+        const uint64_t c1 = ~0ULL / 0xFFFF * 0x7FFF;
+        const uint64_t c2 = ~0ULL / 0xFFFF * 0x3FFF;
+        const uint64_t c3 = ~0ULL / 0xFFFF * 0x0FFF;
+        const uint64_t c4 = ~0ULL / 0xFFFF * 0x00FF;
+
+        a |= (a >> 1) & c1; // cascade ones in non-zeroed segments
+        a |= (a >> 2) & c2;
+        a |= (a >> 4) & c3;
+        a |= (a >> 8) & c4;
+        a &= m; // isolate single bit in each segment
+        if (zero)
+            a ^= m; // reverse isolated bits if checking for zeroed segments
+
+        return a;
+    }
+
+    else if (width == 32) {
+        const uint64_t m = ~0ULL / 0xFFFFFFFF * 0x1;
+
+        // Masks to avoid spillover between segments in cascades
+        const uint64_t c1 = ~0ULL / 0xFFFFFFFF * 0x7FFFFFFF;
+        const uint64_t c2 = ~0ULL / 0xFFFFFFFF * 0x3FFFFFFF;
+        const uint64_t c3 = ~0ULL / 0xFFFFFFFF * 0x0FFFFFFF;
+        const uint64_t c4 = ~0ULL / 0xFFFFFFFF * 0x00FFFFFF;
+        const uint64_t c5 = ~0ULL / 0xFFFFFFFF * 0x0000FFFF;
+
+        a |= (a >> 1) & c1; // cascade ones in non-zeroed segments
+        a |= (a >> 2) & c2;
+        a |= (a >> 4) & c3;
+        a |= (a >> 8) & c4;
+        a |= (a >> 16) & c5;
+        a &= m; // isolate single bit in each segment
+        if (zero)
+            a ^= m; // reverse isolated bits if checking for zeroed segments
+
+        return a;
+    }
+    else if (width == 64) {
+        return (a == 0) == zero;
+    }
+    else {
+        REALM_ASSERT_DEBUG(false);
+        return uint64_t(-1);
+    }
+}
+
+// This is the main finding function for Array. Other finding functions are just wrappers around this one.
+// Search for 'value' using condition cond (Equal, NotEqual, Less, etc) and call find_action() or
+// find_action_pattern() for each match. Break and return if find_action() returns false or 'end' is reached.
+
+// If nullable_array is set, then find_optimized() will treat the array is being nullable, i.e. it will skip the
+// first entry and compare correctly against null, etc.
+//
+// If find_null is set, it means that we search for a null. In that case, `value` is ignored. If find_null is set,
+// then nullable_array must be set too.
+template <class cond, Action action, size_t bitwidth, class Callback>
+bool Array::find_optimized(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                           Callback callback, bool nullable_array, bool find_null) const
+{
+    REALM_ASSERT(!(find_null && !nullable_array));
+    REALM_ASSERT_DEBUG(start <= m_size && (end <= m_size || end == size_t(-1)) && start <= end);
+
+    size_t start2 = start;
+    cond c;
+
+    if (end == npos)
+        end = nullable_array ? size() - 1 : size();
+
+    if (nullable_array) {
+        if (std::is_same<cond, Equal>::value) {
+            // In case of Equal it is safe to use the optimized logic. We just have to fetch the null value
+            // if this is what we are looking for. And we have to adjust the indexes to compensate for the
+            // null value at position 0.
+            if (find_null) {
+                value = get(0);
+            }
+            else {
+                // If the value to search for is equal to the null value, the value cannot be in the array
+                if (value == get(0)) {
+                    return true;
+                }
+            }
+            start2++;
+            end++;
+            baseindex--;
+        }
+        else {
+            // We were called by find() of a nullable array. So skip first entry, take nulls in count, etc, etc. Fixme:
+            // Huge speed optimizations are possible here! This is a very simple generic method.
+            auto null_value = get(0);
+            for (; start2 < end; start2++) {
+                int64_t v = get<bitwidth>(start2 + 1);
+                bool value_is_null = (v == null_value);
+                if (c(v, value, value_is_null, find_null)) {
+                    util::Optional<int64_t> v2(value_is_null ? util::none : util::make_optional(v));
+                    if (!find_action<action, Callback>(start2 + baseindex, v2, state, callback))
+                        return false; // tell caller to stop aggregating/search
+                }
+            }
+            return true; // tell caller to continue aggregating/search (on next array leafs)
+        }
+    }
+
+
+    // Test first few items with no initial time overhead
+    if (start2 > 0) {
+        if (m_size > start2 && c(get<bitwidth>(start2), value) && start2 < end) {
+            if (!find_action<action, Callback>(start2 + baseindex, get<bitwidth>(start2), state, callback))
+                return false;
+        }
+
+        ++start2;
+
+        if (m_size > start2 && c(get<bitwidth>(start2), value) && start2 < end) {
+            if (!find_action<action, Callback>(start2 + baseindex, get<bitwidth>(start2), state, callback))
+                return false;
+        }
+
+        ++start2;
+
+        if (m_size > start2 && c(get<bitwidth>(start2), value) && start2 < end) {
+            if (!find_action<action, Callback>(start2 + baseindex, get<bitwidth>(start2), state, callback))
+                return false;
+        }
+
+        ++start2;
+
+        if (m_size > start2 && c(get<bitwidth>(start2), value) && start2 < end) {
+            if (!find_action<action, Callback>(start2 + baseindex, get<bitwidth>(start2), state, callback))
+                return false;
+        }
+
+        ++start2;
+    }
+
+    if (!(m_size > start2 && start2 < end))
+        return true;
+
+    if (end == size_t(-1))
+        end = m_size;
+
+    // Return immediately if no items in array can match (such as if cond == Greater && value == 100 &&
+    // m_ubound == 15)
+    if (!c.can_match(value, m_lbound, m_ubound))
+        return true;
+
+    // optimization if all items are guaranteed to match (such as cond == NotEqual && value == 100 && m_ubound == 15)
+    if (c.will_match(value, m_lbound, m_ubound)) {
+        size_t end2;
+
+        if (action == act_CallbackIdx)
+            end2 = end;
+        else {
+            REALM_ASSERT_DEBUG(state->m_match_count < state->m_limit);
+            size_t process = state->m_limit - state->m_match_count;
+            end2 = end - start2 > process ? start2 + process : end;
+        }
+        if (action == act_Sum || action == act_Max || action == act_Min) {
+            int64_t res;
+            size_t res_ndx = 0;
+            if (action == act_Sum)
+                res = Array::sum(start2, end2);
+            if (action == act_Max)
+                Array::maximum(res, start2, end2, &res_ndx);
+            if (action == act_Min)
+                Array::minimum(res, start2, end2, &res_ndx);
+
+            find_action<action, Callback>(res_ndx + baseindex, res, state, callback);
+            // find_action will increment match count by 1, so we need to `-1` from the number of elements that
+            // we performed the fast Array methods on.
+            state->m_match_count += end2 - start2 - 1;
+        }
+        else if (action == act_Count) {
+            state->m_state += end2 - start2;
+        }
+        else {
+            for (; start2 < end2; start2++)
+                if (!find_action<action, Callback>(start2 + baseindex, get<bitwidth>(start2), state, callback))
+                    return false;
+        }
+        return true;
+    }
+
+    // finder cannot handle this bitwidth
+    REALM_ASSERT_3(m_width, !=, 0);
+
+#if defined(REALM_COMPILER_SSE)
+    // Only use SSE if payload is at least one SSE chunk (128 bits) in size. Also note taht SSE doesn't support
+    // Less-than comparison for 64-bit values.
+    if ((!(std::is_same<cond, Less>::value && m_width == 64)) && end - start2 >= sizeof(__m128i) && m_width >= 8 &&
+        (sseavx<42>() || (sseavx<30>() && std::is_same<cond, Equal>::value && m_width < 64))) {
+
+        // find_sse() must start2 at 16-byte boundary, so search area before that using compare_equality()
+        __m128i* const a = reinterpret_cast<__m128i*>(round_up(m_data + start2 * bitwidth / 8, sizeof(__m128i)));
+        __m128i* const b = reinterpret_cast<__m128i*>(round_down(m_data + end * bitwidth / 8, sizeof(__m128i)));
+
+        if (!compare<cond, action, bitwidth, Callback>(
+                value, start2, (reinterpret_cast<char*>(a) - m_data) * 8 / no0(bitwidth), baseindex, state, callback))
+            return false;
+
+        // Search aligned area with SSE
+        if (b > a) {
+            if (sseavx<42>()) {
+                if (!find_sse<cond, action, bitwidth, Callback>(
+                        value, a, b - a, state,
+                        baseindex + ((reinterpret_cast<char*>(a) - m_data) * 8 / no0(bitwidth)), callback))
+                    return false;
+            }
+            else if (sseavx<30>()) {
+
+                if (!find_sse<Equal, action, bitwidth, Callback>(
+                        value, a, b - a, state,
+                        baseindex + ((reinterpret_cast<char*>(a) - m_data) * 8 / no0(bitwidth)), callback))
+                    return false;
+            }
+        }
+
+        // Search remainder with compare_equality()
+        if (!compare<cond, action, bitwidth, Callback>(
+                value, (reinterpret_cast<char*>(b) - m_data) * 8 / no0(bitwidth), end, baseindex, state, callback))
+            return false;
+
+        return true;
+    }
+    else {
+        return compare<cond, action, bitwidth, Callback>(value, start2, end, baseindex, state, callback);
+    }
+#else
+    return compare<cond, action, bitwidth, Callback>(value, start2, end, baseindex, state, callback);
+#endif
+}
+
+template <size_t width>
+inline int64_t Array::lower_bits() const
+{
+    if (width == 1)
+        return 0xFFFFFFFFFFFFFFFFULL;
+    else if (width == 2)
+        return 0x5555555555555555ULL;
+    else if (width == 4)
+        return 0x1111111111111111ULL;
+    else if (width == 8)
+        return 0x0101010101010101ULL;
+    else if (width == 16)
+        return 0x0001000100010001ULL;
+    else if (width == 32)
+        return 0x0000000100000001ULL;
+    else if (width == 64)
+        return 0x0000000000000001ULL;
+    else {
+        REALM_ASSERT_DEBUG(false);
+        return int64_t(-1);
+    }
+}
+
+// Tests if any chunk in 'value' is 0
+template <size_t width>
+inline bool Array::test_zero(uint64_t value) const
+{
+    uint64_t hasZeroByte;
+    uint64_t lower = lower_bits<width>();
+    uint64_t upper = lower_bits<width>() * 1ULL << (width == 0 ? 0 : (width - 1ULL));
+    hasZeroByte = (value - lower) & ~value & upper;
+    return hasZeroByte != 0;
+}
+
+// Finds first zero (if eq == true) or non-zero (if eq == false) element in v and returns its position.
+// IMPORTANT: This function assumes that at least 1 item matches (test this with test_zero() or other means first)!
+template <bool eq, size_t width>
+size_t Array::find_zero(uint64_t v) const
+{
+    size_t start = 0;
+    uint64_t hasZeroByte;
+    // Warning free way of computing (1ULL << width) - 1
+    uint64_t mask = (width == 64 ? ~0ULL : ((1ULL << (width == 64 ? 0 : width)) - 1ULL));
+
+    if (eq == (((v >> (width * start)) & mask) == 0)) {
+        return 0;
+    }
+
+    // Bisection optimization, speeds up small bitwidths with high match frequency. More partions than 2 do NOT pay
+    // off because the work done by test_zero() is wasted for the cases where the value exists in first half, but
+    // useful if it exists in last half. Sweet spot turns out to be the widths and partitions below.
+    if (width <= 8) {
+        hasZeroByte = test_zero<width>(v | 0xffffffff00000000ULL);
+        if (eq ? !hasZeroByte : (v & 0x00000000ffffffffULL) == 0) {
+            // 00?? -> increasing
+            start += 64 / no0(width) / 2;
+            if (width <= 4) {
+                hasZeroByte = test_zero<width>(v | 0xffff000000000000ULL);
+                if (eq ? !hasZeroByte : (v & 0x0000ffffffffffffULL) == 0) {
+                    // 000?
+                    start += 64 / no0(width) / 4;
+                }
+            }
+        }
+        else {
+            if (width <= 4) {
+                // ??00
+                hasZeroByte = test_zero<width>(v | 0xffffffffffff0000ULL);
+                if (eq ? !hasZeroByte : (v & 0x000000000000ffffULL) == 0) {
+                    // 0?00
+                    start += 64 / no0(width) / 4;
+                }
+            }
+        }
+    }
+
+    while (eq == (((v >> (width * start)) & mask) != 0)) {
+        // You must only call find_zero() if you are sure that at least 1 item matches
+        REALM_ASSERT_3(start, <=, 8 * sizeof(v));
+        start++;
+    }
+
+    return start;
+}
+
+// Generate a magic constant used for later bithacks
+template <bool gt, size_t width>
+int64_t Array::find_gtlt_magic(int64_t v) const
+{
+    uint64_t mask1 = (width == 64 ? ~0ULL : ((1ULL << (width == 64 ? 0 : width)) -
+                                             1ULL)); // Warning free way of computing (1ULL << width) - 1
+    uint64_t mask2 = mask1 >> 1;
+    uint64_t magic = gt ? (~0ULL / no0(mask1) * (mask2 - v)) : (~0ULL / no0(mask1) * v);
+    return magic;
+}
+
+template <bool gt, Action action, size_t width, class Callback>
+bool Array::find_gtlt_fast(uint64_t chunk, uint64_t magic, QueryState<int64_t>* state, size_t baseindex,
+                           Callback callback) const
+{
+    // Tests if a a chunk of values contains values that are greater (if gt == true) or less (if gt == false) than v.
+    // Fast, but limited to work when all values in the chunk are positive.
+
+    uint64_t mask1 = (width == 64 ? ~0ULL : ((1ULL << (width == 64 ? 0 : width)) -
+                                             1ULL)); // Warning free way of computing (1ULL << width) - 1
+    uint64_t mask2 = mask1 >> 1;
+    uint64_t m = gt ? (((chunk + magic) | chunk) & ~0ULL / no0(mask1) * (mask2 + 1))
+                    : ((chunk - magic) & ~chunk & ~0ULL / no0(mask1) * (mask2 + 1));
+    size_t p = 0;
+    while (m) {
+        if (find_action_pattern<action, Callback>(baseindex, m >> (no0(width) - 1), state, callback))
+            break; // consumed, so do not call find_action()
+
+        size_t t = first_set_bit64(m) / no0(width);
+        p += t;
+        if (!find_action<action, Callback>(p + baseindex, (chunk >> (p * width)) & mask1, state, callback))
+            return false;
+
+        if ((t + 1) * width == 64)
+            m = 0;
+        else
+            m >>= (t + 1) * width;
+        p++;
+    }
+
+    return true;
+}
+
+// clang-format off
+template <bool gt, Action action, size_t width, class Callback>
+bool Array::find_gtlt(int64_t v, uint64_t chunk, QueryState<int64_t>* state, size_t baseindex, Callback callback) const
+{
+    // Find items in 'chunk' that are greater (if gt == true) or smaller (if gt == false) than 'v'. Fixme, __forceinline can make it crash in vS2010 - find out why
+    if (width == 1) {
+        for (size_t t = 0; t < 64; t++) {
+            if (gt ? static_cast<int64_t>(chunk & 0x1) > v : static_cast<int64_t>(chunk & 0x1) < v) {if (!find_action<action, Callback>( t + baseindex, static_cast<int64_t>(chunk & 0x1), state, callback)) return false;}
+            chunk >>= 1;
+        }
+    }
+    else if (width == 2) {
+        // Alot (50% +) faster than loop/compiler-unrolled loop
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 0 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 1 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 2 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 3 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 4 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 5 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 6 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 7 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 8 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 9 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 10 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 11 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 12 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 13 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 14 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 15 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 16 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 17 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 18 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 19 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 20 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 21 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 22 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 23 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 24 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 25 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 26 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 27 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 28 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 29 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 30 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+        if (gt ? static_cast<int64_t>(chunk & 0x3) > v : static_cast<int64_t>(chunk & 0x3) < v) {if (!find_action<action, Callback>( 31 + baseindex, static_cast<int64_t>(chunk & 0x3), state, callback)) return false;}
+        chunk >>= 2;
+    }
+    else if (width == 4) {
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 0 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 1 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 2 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 3 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 4 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 5 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 6 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 7 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 8 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 9 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 10 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 11 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 12 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 13 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 14 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+        if (gt ? static_cast<int64_t>(chunk & 0xf) > v : static_cast<int64_t>(chunk & 0xf) < v) {if (!find_action<action, Callback>( 15 + baseindex, static_cast<int64_t>(chunk & 0xf), state, callback)) return false;}
+        chunk >>= 4;
+    }
+    else if (width == 8) {
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 0 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 1 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 2 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 3 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 4 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 5 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 6 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+        if (gt ? static_cast<int8_t>(chunk) > v : static_cast<int8_t>(chunk) < v) {if (!find_action<action, Callback>( 7 + baseindex, static_cast<int8_t>(chunk), state, callback)) return false;}
+        chunk >>= 8;
+    }
+    else if (width == 16) {
+
+        if (gt ? static_cast<short int>(chunk >> 0 * 16) > v : static_cast<short int>(chunk >> 0 * 16) < v) {if (!find_action<action, Callback>( 0 + baseindex, static_cast<short int>(chunk >> 0 * 16), state, callback)) return false;};
+        if (gt ? static_cast<short int>(chunk >> 1 * 16) > v : static_cast<short int>(chunk >> 1 * 16) < v) {if (!find_action<action, Callback>( 1 + baseindex, static_cast<short int>(chunk >> 1 * 16), state, callback)) return false;};
+        if (gt ? static_cast<short int>(chunk >> 2 * 16) > v : static_cast<short int>(chunk >> 2 * 16) < v) {if (!find_action<action, Callback>( 2 + baseindex, static_cast<short int>(chunk >> 2 * 16), state, callback)) return false;};
+        if (gt ? static_cast<short int>(chunk >> 3 * 16) > v : static_cast<short int>(chunk >> 3 * 16) < v) {if (!find_action<action, Callback>( 3 + baseindex, static_cast<short int>(chunk >> 3 * 16), state, callback)) return false;};
+    }
+    else if (width == 32) {
+        if (gt ? static_cast<int>(chunk) > v : static_cast<int>(chunk) < v) {if (!find_action<action, Callback>( 0 + baseindex, static_cast<int>(chunk), state, callback)) return false;}
+        chunk >>= 32;
+        if (gt ? static_cast<int>(chunk) > v : static_cast<int>(chunk) < v) {if (!find_action<action, Callback>( 1 + baseindex, static_cast<int>(chunk), state, callback)) return false;}
+        chunk >>= 32;
+    }
+    else if (width == 64) {
+        if (gt ? static_cast<int64_t>(v) > v : static_cast<int64_t>(v) < v) {if (!find_action<action, Callback>( 0 + baseindex, static_cast<int64_t>(v), state, callback)) return false;};
+    }
+
+    return true;
+}
+// clang-format on
+
+/// Find items in this Array that are equal (eq == true) or different (eq = false) from 'value'
+template <bool eq, Action action, size_t width, class Callback>
+inline bool Array::compare_equality(int64_t value, size_t start, size_t end, size_t baseindex,
+                                    QueryState<int64_t>* state, Callback callback) const
+{
+    REALM_ASSERT_DEBUG(start <= m_size && (end <= m_size || end == size_t(-1)) && start <= end);
+
+    size_t ee = round_up(start, 64 / no0(width));
+    ee = ee > end ? end : ee;
+    for (; start < ee; ++start)
+        if (eq ? (get<width>(start) == value) : (get<width>(start) != value)) {
+            if (!find_action<action, Callback>(start + baseindex, get<width>(start), state, callback))
+                return false;
+        }
+
+    if (start >= end)
+        return true;
+
+    if (width != 32 && width != 64) {
+        const int64_t* p = reinterpret_cast<const int64_t*>(m_data + (start * width / 8));
+        const int64_t* const e = reinterpret_cast<int64_t*>(m_data + (end * width / 8)) - 1;
+        const uint64_t mask = (width == 64 ? ~0ULL : ((1ULL << (width == 64 ? 0 : width)) -
+                                                      1ULL)); // Warning free way of computing (1ULL << width) - 1
+        const uint64_t valuemask =
+            ~0ULL / no0(mask) * (value & mask); // the "== ? :" is to avoid division by 0 compiler error
+
+        while (p < e) {
+            uint64_t chunk = *p;
+            uint64_t v2 = chunk ^ valuemask;
+            start = (p - reinterpret_cast<int64_t*>(m_data)) * 8 * 8 / no0(width);
+            size_t a = 0;
+
+            while (eq ? test_zero<width>(v2) : v2) {
+
+                if (find_action_pattern<action, Callback>(start + baseindex, cascade<width, eq>(v2), state, callback))
+                    break; // consumed
+
+                size_t t = find_zero<eq, width>(v2);
+                a += t;
+
+                if (a >= 64 / no0(width))
+                    break;
+
+                if (!find_action<action, Callback>(a + start + baseindex, get<width>(start + a), state, callback))
+                    return false;
+                v2 >>= (t + 1) * width;
+                a += 1;
+            }
+
+            ++p;
+        }
+
+        // Loop ended because we are near end or end of array. No need to optimize search in remainder in this case
+        // because end of array means that
+        // lots of search work has taken place prior to ending here. So time spent searching remainder is relatively
+        // tiny
+        start = (p - reinterpret_cast<int64_t*>(m_data)) * 8 * 8 / no0(width);
+    }
+
+    while (start < end) {
+        if (eq ? get<width>(start) == value : get<width>(start) != value) {
+            if (!find_action<action, Callback>(start + baseindex, get<width>(start), state, callback))
+                return false;
+        }
+        ++start;
+    }
+
+    return true;
+}
+
+// There exists a couple of find() functions that take more or less template arguments. Always call the one that
+// takes as most as possible to get best performance.
+
+// This is the one installed into the m_vtable->finder slots.
+template <class cond, Action action, size_t bitwidth>
+bool Array::find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state) const
+{
+    return find<cond, action, bitwidth>(value, start, end, baseindex, state, CallbackDummy());
+}
+
+template <class cond, Action action, class Callback>
+bool Array::find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                 Callback callback, bool nullable_array, bool find_null) const
+{
+    REALM_TEMPEX4(return find, cond, action, m_width, Callback,
+                         (value, start, end, baseindex, state, callback, nullable_array, find_null));
+}
+
+template <class cond, Action action, size_t bitwidth, class Callback>
+bool Array::find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                 Callback callback, bool nullable_array, bool find_null) const
+{
+    return find_optimized<cond, action, bitwidth, Callback>(value, start, end, baseindex, state, callback,
+                                                            nullable_array, find_null);
+}
+
+#ifdef REALM_COMPILER_SSE
+// 'items' is the number of 16-byte SSE chunks. Returns index of packed element relative to first integer of first
+// chunk
+template <class cond, Action action, size_t width, class Callback>
+bool Array::find_sse(int64_t value, __m128i* data, size_t items, QueryState<int64_t>* state, size_t baseindex,
+                     Callback callback) const
+{
+    __m128i search = {0};
+
+    if (width == 8)
+        search = _mm_set1_epi8(static_cast<char>(value));
+    else if (width == 16)
+        search = _mm_set1_epi16(static_cast<short int>(value));
+    else if (width == 32)
+        search = _mm_set1_epi32(static_cast<int>(value));
+    else if (width == 64) {
+        if (std::is_same<cond, Less>::value)
+            REALM_ASSERT(false);
+        else
+            search = _mm_set_epi64x(value, value);
+    }
+
+    return find_sse_intern<cond, action, width, Callback>(data, &search, items, state, baseindex, callback);
+}
+
+// Compares packed action_data with packed data (equal, less, etc) and performs aggregate action (max, min, sum,
+// find_all, etc) on value inside action_data for first match, if any
+template <class cond, Action action, size_t width, class Callback>
+REALM_FORCEINLINE bool Array::find_sse_intern(__m128i* action_data, __m128i* data, size_t items,
+                                              QueryState<int64_t>* state, size_t baseindex, Callback callback) const
+{
+    size_t i = 0;
+    __m128i compare_result = {0};
+    unsigned int resmask;
+
+    // Search loop. Unrolling it has been tested to NOT increase performance (apparently mem bound)
+    for (i = 0; i < items; ++i) {
+        // equal / not-equal
+        if (std::is_same<cond, Equal>::value || std::is_same<cond, NotEqual>::value) {
+            if (width == 8)
+                compare_result = _mm_cmpeq_epi8(action_data[i], *data);
+            if (width == 16)
+                compare_result = _mm_cmpeq_epi16(action_data[i], *data);
+            if (width == 32)
+                compare_result = _mm_cmpeq_epi32(action_data[i], *data);
+            if (width == 64) {
+                compare_result = _mm_cmpeq_epi64(action_data[i], *data); // SSE 4.2 only
+            }
+        }
+
+        // greater
+        else if (std::is_same<cond, Greater>::value) {
+            if (width == 8)
+                compare_result = _mm_cmpgt_epi8(action_data[i], *data);
+            if (width == 16)
+                compare_result = _mm_cmpgt_epi16(action_data[i], *data);
+            if (width == 32)
+                compare_result = _mm_cmpgt_epi32(action_data[i], *data);
+            if (width == 64)
+                compare_result = _mm_cmpgt_epi64(action_data[i], *data);
+        }
+        // less
+        else if (std::is_same<cond, Less>::value) {
+            if (width == 8)
+                compare_result = _mm_cmplt_epi8(action_data[i], *data);
+            else if (width == 16)
+                compare_result = _mm_cmplt_epi16(action_data[i], *data);
+            else if (width == 32)
+                compare_result = _mm_cmplt_epi32(action_data[i], *data);
+            else
+                REALM_ASSERT(false);
+        }
+
+        resmask = _mm_movemask_epi8(compare_result);
+
+        if (std::is_same<cond, NotEqual>::value)
+            resmask = ~resmask & 0x0000ffff;
+
+        size_t s = i * sizeof(__m128i) * 8 / no0(width);
+
+        while (resmask != 0) {
+
+            uint64_t upper = lower_bits<width / 8>() << (no0(width / 8) - 1);
+            uint64_t pattern =
+                resmask &
+                upper; // fixme, bits at wrong offsets. Only OK because we only use them in 'count' aggregate
+            if (find_action_pattern<action, Callback>(s + baseindex, pattern, state, callback))
+                break;
+
+            size_t idx = first_set_bit(resmask) * 8 / no0(width);
+            s += idx;
+            if (!find_action<action, Callback>(
+                    s + baseindex, get_universal<width>(reinterpret_cast<char*>(action_data), s), state, callback))
+                return false;
+            resmask >>= (idx + 1) * no0(width) / 8;
+            ++s;
+        }
+    }
+
+    return true;
+}
+#endif // REALM_COMPILER_SSE
+
+template <class cond, Action action, class Callback>
+bool Array::compare_leafs(const Array* foreign, size_t start, size_t end, size_t baseindex,
+                          QueryState<int64_t>* state, Callback callback) const
+{
+    cond c;
+    REALM_ASSERT_3(start, <=, end);
+    if (start == end)
+        return true;
+
+
+    int64_t v;
+
+    // We can compare first element without checking for out-of-range
+    v = get(start);
+    if (c(v, foreign->get(start))) {
+        if (!find_action<action, Callback>(start + baseindex, v, state, callback))
+            return false;
+    }
+
+    start++;
+
+    if (start + 3 < end) {
+        v = get(start);
+        if (c(v, foreign->get(start)))
+            if (!find_action<action, Callback>(start + baseindex, v, state, callback))
+                return false;
+
+        v = get(start + 1);
+        if (c(v, foreign->get(start + 1)))
+            if (!find_action<action, Callback>(start + 1 + baseindex, v, state, callback))
+                return false;
+
+        v = get(start + 2);
+        if (c(v, foreign->get(start + 2)))
+            if (!find_action<action, Callback>(start + 2 + baseindex, v, state, callback))
+                return false;
+
+        start += 3;
+    }
+    else if (start == end) {
+        return true;
+    }
+
+    bool r;
+    REALM_TEMPEX4(r = compare_leafs, cond, action, m_width, Callback,
+                  (foreign, start, end, baseindex, state, callback))
+    return r;
+}
+
+
+template <class cond, Action action, size_t width, class Callback>
+bool Array::compare_leafs(const Array* foreign, size_t start, size_t end, size_t baseindex,
+                          QueryState<int64_t>* state, Callback callback) const
+{
+    size_t fw = foreign->m_width;
+    bool r;
+    REALM_TEMPEX5(r = compare_leafs_4, cond, action, width, Callback, fw,
+                  (foreign, start, end, baseindex, state, callback))
+    return r;
+}
+
+
+template <class cond, Action action, size_t width, class Callback, size_t foreign_width>
+bool Array::compare_leafs_4(const Array* foreign, size_t start, size_t end, size_t baseindex,
+                            QueryState<int64_t>* state, Callback callback) const
+{
+    cond c;
+    char* foreign_m_data = foreign->m_data;
+
+    if (width == 0 && foreign_width == 0) {
+        if (c(0, 0)) {
+            while (start < end) {
+                if (!find_action<action, Callback>(start + baseindex, 0, state, callback))
+                    return false;
+                start++;
+            }
+        }
+        else {
+            return true;
+        }
+    }
+
+
+#if defined(REALM_COMPILER_SSE)
+    if (sseavx<42>() && width == foreign_width && (width == 8 || width == 16 || width == 32)) {
+        // We can only use SSE if both bitwidths are equal and above 8 bits and all values are signed
+        // and the two arrays are aligned the same way
+        if ((reinterpret_cast<size_t>(m_data) & 0xf) == (reinterpret_cast<size_t>(foreign_m_data) & 0xf)) {
+            while (start < end && (((reinterpret_cast<size_t>(m_data) & 0xf) * 8 + start * width) % (128) != 0)) {
+                int64_t v = get_universal<width>(m_data, start);
+                int64_t fv = get_universal<foreign_width>(foreign_m_data, start);
+                if (c(v, fv)) {
+                    if (!find_action<action, Callback>(start + baseindex, v, state, callback))
+                        return false;
+                }
+                start++;
+            }
+            if (start == end)
+                return true;
+
+
+            size_t sse_items = (end - start) * width / 128;
+            size_t sse_end = start + sse_items * 128 / no0(width);
+
+            while (start < sse_end) {
+                __m128i* a = reinterpret_cast<__m128i*>(m_data + start * width / 8);
+                __m128i* b = reinterpret_cast<__m128i*>(foreign_m_data + start * width / 8);
+
+                bool continue_search =
+                    find_sse_intern<cond, action, width, Callback>(a, b, 1, state, baseindex + start, callback);
+
+                if (!continue_search)
+                    return false;
+
+                start += 128 / no0(width);
+            }
+        }
+    }
+#endif
+
+    while (start < end) {
+        int64_t v = get_universal<width>(m_data, start);
+        int64_t fv = get_universal<foreign_width>(foreign_m_data, start);
+
+        if (c(v, fv)) {
+            if (!find_action<action, Callback>(start + baseindex, v, state, callback))
+                return false;
+        }
+
+        start++;
+    }
+
+    return true;
+}
+
+
+template <class cond, Action action, size_t bitwidth, class Callback>
+bool Array::compare(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                    Callback callback) const
+{
+    bool ret = false;
+
+    if (std::is_same<cond, Equal>::value)
+        ret = compare_equality<true, action, bitwidth, Callback>(value, start, end, baseindex, state, callback);
+    else if (std::is_same<cond, NotEqual>::value)
+        ret = compare_equality<false, action, bitwidth, Callback>(value, start, end, baseindex, state, callback);
+    else if (std::is_same<cond, Greater>::value)
+        ret = compare_relation<true, action, bitwidth, Callback>(value, start, end, baseindex, state, callback);
+    else if (std::is_same<cond, Less>::value)
+        ret = compare_relation<false, action, bitwidth, Callback>(value, start, end, baseindex, state, callback);
+    else
+        REALM_ASSERT_DEBUG(false);
+
+    return ret;
+}
+
+template <bool gt, Action action, size_t bitwidth, class Callback>
+bool Array::compare_relation(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                             Callback callback) const
+{
+    REALM_ASSERT(start <= m_size && (end <= m_size || end == size_t(-1)) && start <= end);
+    uint64_t mask = (bitwidth == 64 ? ~0ULL : ((1ULL << (bitwidth == 64 ? 0 : bitwidth)) -
+                                               1ULL)); // Warning free way of computing (1ULL << width) - 1
+
+    size_t ee = round_up(start, 64 / no0(bitwidth));
+    ee = ee > end ? end : ee;
+    for (; start < ee; start++) {
+        if (gt ? (get<bitwidth>(start) > value) : (get<bitwidth>(start) < value)) {
+            if (!find_action<action, Callback>(start + baseindex, get<bitwidth>(start), state, callback))
+                return false;
+        }
+    }
+
+    if (start >= end)
+        return true; // none found, continue (return true) regardless what find_action() would have returned on match
+
+    const int64_t* p = reinterpret_cast<const int64_t*>(m_data + (start * bitwidth / 8));
+    const int64_t* const e = reinterpret_cast<int64_t*>(m_data + (end * bitwidth / 8)) - 1;
+
+    // Matches are rare enough to setup fast linear search for remaining items. We use
+    // bit hacks from http://graphics.stanford.edu/~seander/bithacks.html#HasLessInWord
+
+    if (bitwidth == 1 || bitwidth == 2 || bitwidth == 4 || bitwidth == 8 || bitwidth == 16) {
+        uint64_t magic = find_gtlt_magic<gt, bitwidth>(value);
+
+        // Bit hacks only work if searched item has its most significant bit clear for 'greater than' or
+        // 'item <= 1 << bitwidth' for 'less than'
+        if (value != int64_t((magic & mask)) && value >= 0 && bitwidth >= 2 &&
+            value <= static_cast<int64_t>((mask >> 1) - (gt ? 1 : 0))) {
+            // 15 ms
+            while (p < e) {
+                uint64_t upper = lower_bits<bitwidth>() << (no0(bitwidth) - 1);
+
+                const int64_t v = *p;
+                size_t idx;
+
+                // Bit hacks only works if all items in chunk have their most significant bit clear. Test this:
+                upper = upper & v;
+
+                if (!upper) {
+                    idx = find_gtlt_fast<gt, action, bitwidth, Callback>(
+                        v, magic, state, (p - reinterpret_cast<int64_t*>(m_data)) * 8 * 8 / no0(bitwidth) + baseindex,
+                        callback);
+                }
+                else
+                    idx = find_gtlt<gt, action, bitwidth, Callback>(
+                        value, v, state, (p - reinterpret_cast<int64_t*>(m_data)) * 8 * 8 / no0(bitwidth) + baseindex,
+                        callback);
+
+                if (!idx)
+                    return false;
+                ++p;
+            }
+        }
+        else {
+            // 24 ms
+            while (p < e) {
+                int64_t v = *p;
+                if (!find_gtlt<gt, action, bitwidth, Callback>(
+                        value, v, state, (p - reinterpret_cast<int64_t*>(m_data)) * 8 * 8 / no0(bitwidth) + baseindex,
+                        callback))
+                    return false;
+                ++p;
+            }
+        }
+        start = (p - reinterpret_cast<int64_t*>(m_data)) * 8 * 8 / no0(bitwidth);
+    }
+
+    // matchcount logic in SIMD no longer pays off for 32/64 bit ints because we have just 4/2 elements
+
+    // Test unaligned end and/or values of width > 16 manually
+    while (start < end) {
+        if (gt ? get<bitwidth>(start) > value : get<bitwidth>(start) < value) {
+            if (!find_action<action, Callback>(start + baseindex, get<bitwidth>(start), state, callback))
+                return false;
+        }
+        ++start;
+    }
+    return true;
+}
+
+template <class cond>
+size_t Array::find_first(int64_t value, size_t start, size_t end) const
+{
+    REALM_ASSERT(start <= m_size && (end <= m_size || end == size_t(-1)) && start <= end);
+    QueryState<int64_t> state;
+    state.init(act_ReturnFirst, nullptr,
+               1); // todo, would be nice to avoid this in order to speed up find_first loops
+    Finder finder = m_vtable->finder[cond::condition];
+    (this->*finder)(value, start, end, 0, &state);
+
+    return static_cast<size_t>(state.m_state);
+}
+
+//*************************************************************************************
+// Finding code ends                                                                  *
+//*************************************************************************************
+
+
+} // namespace realm
+
+#endif // REALM_ARRAY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_basic.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_basic.hpp
new file mode 100644
index 0000000..6b9c212
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_basic.hpp
@@ -0,0 +1,120 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_BASIC_HPP
+#define REALM_ARRAY_BASIC_HPP
+
+#include <realm/array.hpp>
+
+namespace realm {
+
+/// A BasicArray can currently only be used for simple unstructured
+/// types like float, double.
+template <class T>
+class BasicArray : public Array {
+public:
+    explicit BasicArray(Allocator&) noexcept;
+    ~BasicArray() noexcept override
+    {
+    }
+
+    // Disable copying, this is not allowed.
+    BasicArray& operator=(const BasicArray&) = delete;
+    BasicArray(const BasicArray&) = delete;
+
+    T get(size_t ndx) const noexcept;
+    bool is_null(size_t ndx) const noexcept;
+    void add(T value);
+    void set(size_t ndx, T value);
+    void set_null(size_t ndx);
+    void insert(size_t ndx, T value);
+    void erase(size_t ndx);
+    void truncate(size_t size);
+    void clear();
+
+    size_t find_first(T value, size_t begin = 0, size_t end = npos) const;
+    void find_all(IntegerColumn* result, T value, size_t add_offset = 0, size_t begin = 0, size_t end = npos) const;
+
+    size_t count(T value, size_t begin = 0, size_t end = npos) const;
+    bool maximum(T& result, size_t begin = 0, size_t end = npos) const;
+    bool minimum(T& result, size_t begin = 0, size_t end = npos) const;
+
+    /// Compare two arrays for equality.
+    bool compare(const BasicArray<T>&) const;
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static T get(const char* header, size_t ndx) noexcept;
+
+    ref_type bptree_leaf_insert(size_t ndx, T, TreeInsertBase& state);
+
+    size_t lower_bound(T value) const noexcept;
+    size_t upper_bound(T value) const noexcept;
+
+    /// Construct a basic array of the specified size and return just
+    /// the reference to the underlying memory. All elements will be
+    /// initialized to `T()`.
+    static MemRef create_array(size_t size, Allocator&);
+
+    static MemRef create_array(Array::Type leaf_type, bool context_flag, size_t size, T value, Allocator&);
+
+    /// Create a new empty array and attach this accessor to it. This
+    /// does not modify the parent reference information of this
+    /// accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated
+    /// underlying node. It is not owned by the accessor.
+    void create(Array::Type = type_Normal, bool context_flag = false);
+
+    /// Construct a copy of the specified slice of this basic array
+    /// using the specified target allocator.
+    MemRef slice(size_t offset, size_t size, Allocator& target_alloc) const;
+    MemRef slice_and_clone_children(size_t offset, size_t size, Allocator& target_alloc) const;
+
+#ifdef REALM_DEBUG
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+#endif
+
+private:
+    size_t find(T target, size_t begin, size_t end) const;
+
+    size_t calc_byte_len(size_t count, size_t width) const override;
+    virtual size_t calc_item_count(size_t bytes, size_t width) const noexcept override;
+
+    template <bool find_max>
+    bool minmax(T& result, size_t begin, size_t end) const;
+
+    /// Calculate the total number of bytes needed for a basic array
+    /// with the specified number of elements. This includes the size
+    /// of the header. The result will be upwards aligned to the
+    /// closest 8-byte boundary.
+    static size_t calc_aligned_byte_size(size_t size);
+};
+
+
+// Class typedefs for BasicArray's: ArrayFloat and ArrayDouble
+typedef BasicArray<float> ArrayFloat;
+typedef BasicArray<double> ArrayDouble;
+
+} // namespace realm
+
+#include <realm/array_basic_tpl.hpp>
+
+#endif // REALM_ARRAY_BASIC_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_basic_tpl.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_basic_tpl.hpp
new file mode 100644
index 0000000..5ce37fd
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_basic_tpl.hpp
@@ -0,0 +1,467 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_BASIC_TPL_HPP
+#define REALM_ARRAY_BASIC_TPL_HPP
+
+#include <algorithm>
+#include <limits>
+#include <stdexcept>
+#include <iomanip>
+
+#include <realm/impl/destroy_guard.hpp>
+
+namespace realm {
+
+template <class T>
+inline BasicArray<T>::BasicArray(Allocator& allocator) noexcept
+    : Array(allocator)
+{
+}
+
+template <class T>
+inline MemRef BasicArray<T>::create_array(size_t init_size, Allocator& allocator)
+{
+    size_t byte_size_0 = calc_aligned_byte_size(init_size); // Throws
+    // Adding zero to Array::initial_capacity to avoid taking the
+    // address of that member
+    size_t byte_size = std::max(byte_size_0, Array::initial_capacity + 0); // Throws
+
+    MemRef mem = allocator.alloc(byte_size); // Throws
+
+    bool is_inner_bptree_node = false;
+    bool has_refs = false;
+    bool context_flag = false;
+    int width = sizeof(T);
+    init_header(mem.get_addr(), is_inner_bptree_node, has_refs, context_flag, wtype_Multiply, width, init_size,
+                byte_size);
+
+    return mem;
+}
+
+
+template <class T>
+inline MemRef BasicArray<T>::create_array(Array::Type type, bool context_flag, size_t init_size, T value,
+                                          Allocator& allocator)
+{
+    REALM_ASSERT(type == Array::type_Normal);
+    REALM_ASSERT(!context_flag);
+    MemRef mem = create_array(init_size, allocator);
+    if (init_size) {
+        // GCC 7.x emits a false-positive strict aliasing warning for this code. Suppress it, since it
+        // clutters up the build output.  See <https://github.com/realm/realm-core/issues/2665> for details.
+        REALM_DIAG_PUSH();
+        REALM_DIAG(ignored "-Wstrict-aliasing");
+
+        BasicArray<T> tmp(allocator);
+        tmp.init_from_mem(mem);
+        T* p = reinterpret_cast<T*>(tmp.m_data);
+        T* end = p + init_size;
+        while (p < end) {
+            *p++ = value;
+        }
+
+        REALM_DIAG_POP();
+    }
+    return mem;
+}
+
+
+template <class T>
+inline void BasicArray<T>::create(Array::Type type, bool context_flag)
+{
+    REALM_ASSERT(type == Array::type_Normal);
+    REALM_ASSERT(!context_flag);
+    size_t length = 0;
+    MemRef mem = create_array(length, get_alloc()); // Throws
+    init_from_mem(mem);
+}
+
+
+template <class T>
+MemRef BasicArray<T>::slice(size_t offset, size_t slice_size, Allocator& target_alloc) const
+{
+    REALM_ASSERT(is_attached());
+
+    // FIXME: This can be optimized as a single contiguous copy
+    // operation.
+    BasicArray array_slice(target_alloc);
+    _impl::ShallowArrayDestroyGuard dg(&array_slice);
+    array_slice.create(); // Throws
+    size_t begin = offset;
+    size_t end = offset + slice_size;
+    for (size_t i = begin; i != end; ++i) {
+        T value = get(i);
+        array_slice.add(value); // Throws
+    }
+    dg.release();
+    return array_slice.get_mem();
+}
+
+template <class T>
+MemRef BasicArray<T>::slice_and_clone_children(size_t offset, size_t slice_size, Allocator& target_alloc) const
+{
+    // BasicArray<T> never contains refs, so never has children.
+    return slice(offset, slice_size, target_alloc);
+}
+
+
+template <class T>
+inline void BasicArray<T>::add(T value)
+{
+    insert(m_size, value);
+}
+
+
+template <class T>
+inline T BasicArray<T>::get(size_t ndx) const noexcept
+{
+    return *(reinterpret_cast<const T*>(m_data) + ndx);
+}
+
+
+template <class T>
+inline bool BasicArray<T>::is_null(size_t ndx) const noexcept
+{
+    // FIXME: This assumes BasicArray will only ever be instantiated for float-like T.
+    static_assert(realm::is_any<T, float, double>::value, "T can only be float or double");
+    auto x = get(ndx);
+    return null::is_null_float(x);
+}
+
+
+template <class T>
+inline T BasicArray<T>::get(const char* header, size_t ndx) noexcept
+{
+    const char* data = get_data_from_header(header);
+    // This casting assumes that T can be aliged on an 8-bype
+    // boundary (since data is aligned on an 8-byte boundary.)
+    return *(reinterpret_cast<const T*>(data) + ndx);
+}
+
+
+template <class T>
+inline void BasicArray<T>::set(size_t ndx, T value)
+{
+    REALM_ASSERT_3(ndx, <, m_size);
+    if (get(ndx) == value)
+        return;
+
+    // Check if we need to copy before modifying
+    copy_on_write(); // Throws
+
+    // Set the value
+    T* data = reinterpret_cast<T*>(m_data) + ndx;
+    *data = value;
+}
+
+template <class T>
+inline void BasicArray<T>::set_null(size_t ndx)
+{
+    // FIXME: This assumes BasicArray will only ever be instantiated for float-like T.
+    set(ndx, null::get_null_float<T>());
+}
+
+template <class T>
+void BasicArray<T>::insert(size_t ndx, T value)
+{
+    REALM_ASSERT_3(ndx, <=, m_size);
+
+    // Check if we need to copy before modifying
+    copy_on_write(); // Throws
+
+    // Make room for the new value
+    alloc(m_size + 1, m_width); // Throws
+
+    // Move values below insertion
+    if (ndx != m_size) {
+        char* src_begin = m_data + ndx * m_width;
+        char* src_end = m_data + m_size * m_width;
+        char* dst_end = src_end + m_width;
+        std::copy_backward(src_begin, src_end, dst_end);
+    }
+
+    // Set the value
+    T* data = reinterpret_cast<T*>(m_data) + ndx;
+    *data = value;
+
+    ++m_size;
+}
+
+template <class T>
+void BasicArray<T>::erase(size_t ndx)
+{
+    REALM_ASSERT_3(ndx, <, m_size);
+
+    // Check if we need to copy before modifying
+    copy_on_write(); // Throws
+
+    // move data under deletion up
+    if (ndx < m_size - 1) {
+        char* dst_begin = m_data + ndx * m_width;
+        const char* src_begin = dst_begin + m_width;
+        const char* src_end = m_data + m_size * m_width;
+        realm::safe_copy_n(src_begin, src_end - src_begin, dst_begin);
+    }
+
+    // Update size (also in header)
+    --m_size;
+    set_header_size(m_size);
+}
+
+template <class T>
+void BasicArray<T>::truncate(size_t to_size)
+{
+    REALM_ASSERT(is_attached());
+    REALM_ASSERT_3(to_size, <=, m_size);
+
+    copy_on_write(); // Throws
+
+    // Update size in accessor and in header. This leaves the capacity
+    // unchanged.
+    m_size = to_size;
+    set_header_size(to_size);
+}
+
+template <class T>
+inline void BasicArray<T>::clear()
+{
+    truncate(0); // Throws
+}
+
+template <class T>
+bool BasicArray<T>::compare(const BasicArray<T>& a) const
+{
+    size_t n = size();
+    if (a.size() != n)
+        return false;
+    const T* data_1 = reinterpret_cast<const T*>(m_data);
+    const T* data_2 = reinterpret_cast<const T*>(a.m_data);
+    return realm::safe_equal(data_1, data_1 + n, data_2);
+}
+
+
+template <class T>
+size_t BasicArray<T>::calc_byte_len(size_t for_size, size_t) const
+{
+    // FIXME: Consider calling `calc_aligned_byte_size(size)`
+    // instead. Note however, that calc_byte_len() is supposed to return
+    // the unaligned byte size. It is probably the case that no harm
+    // is done by returning the aligned version, and most callers of
+    // calc_byte_len() will actually benefit if calc_byte_len() was
+    // changed to always return the aligned byte size.
+    return header_size + for_size * sizeof(T);
+}
+
+template <class T>
+size_t BasicArray<T>::calc_item_count(size_t bytes, size_t) const noexcept
+{
+    size_t bytes_without_header = bytes - header_size;
+    return bytes_without_header / sizeof(T);
+}
+
+template <class T>
+size_t BasicArray<T>::find(T value, size_t begin, size_t end) const
+{
+    if (end == npos)
+        end = m_size;
+    REALM_ASSERT(begin <= m_size && end <= m_size && begin <= end);
+    const T* data = reinterpret_cast<const T*>(m_data);
+    const T* i = std::find(data + begin, data + end, value);
+    return i == data + end ? not_found : size_t(i - data);
+}
+
+template <class T>
+inline size_t BasicArray<T>::find_first(T value, size_t begin, size_t end) const
+{
+    return this->find(value, begin, end);
+}
+
+template <class T>
+void BasicArray<T>::find_all(IntegerColumn* result, T value, size_t add_offset, size_t begin, size_t end) const
+{
+    size_t first = begin - 1;
+    for (;;) {
+        first = this->find(value, first + 1, end);
+        if (first == not_found)
+            break;
+
+        Array::add_to_column(result, first + add_offset);
+    }
+}
+
+template <class T>
+size_t BasicArray<T>::count(T value, size_t begin, size_t end) const
+{
+    if (end == npos)
+        end = m_size;
+    REALM_ASSERT(begin <= m_size && end <= m_size && begin <= end);
+    const T* data = reinterpret_cast<const T*>(m_data);
+    return std::count(data + begin, data + end, value);
+}
+
+#if 0
+// currently unused
+template <class T>
+double BasicArray<T>::sum(size_t begin, size_t end) const
+{
+    if (end == npos)
+        end = m_size;
+    REALM_ASSERT(begin <= m_size && end <= m_size && begin <= end);
+    const T* data = reinterpret_cast<const T*>(m_data);
+    return std::accumulate(data + begin, data + end, double(0));
+}
+#endif
+
+template <class T>
+template <bool find_max>
+bool BasicArray<T>::minmax(T& result, size_t begin, size_t end) const
+{
+    if (end == npos)
+        end = m_size;
+    if (m_size == 0)
+        return false;
+    REALM_ASSERT(begin < m_size && end <= m_size && begin < end);
+
+    T m = get(begin);
+    ++begin;
+    for (; begin < end; ++begin) {
+        T val = get(begin);
+        if (find_max ? val > m : val < m)
+            m = val;
+    }
+    result = m;
+    return true;
+}
+
+template <class T>
+bool BasicArray<T>::maximum(T& result, size_t begin, size_t end) const
+{
+    return minmax<true>(result, begin, end);
+}
+
+template <class T>
+bool BasicArray<T>::minimum(T& result, size_t begin, size_t end) const
+{
+    return minmax<false>(result, begin, end);
+}
+
+
+template <class T>
+ref_type BasicArray<T>::bptree_leaf_insert(size_t ndx, T value, TreeInsertBase& state)
+{
+    size_t leaf_size = size();
+    REALM_ASSERT_3(leaf_size, <=, REALM_MAX_BPNODE_SIZE);
+    if (leaf_size < ndx)
+        ndx = leaf_size;
+    if (REALM_LIKELY(leaf_size < REALM_MAX_BPNODE_SIZE)) {
+        insert(ndx, value);
+        return 0; // Leaf was not split
+    }
+
+    // Split leaf node
+    BasicArray<T> new_leaf(get_alloc());
+    new_leaf.create(); // Throws
+    if (ndx == leaf_size) {
+        new_leaf.add(value);
+        state.m_split_offset = ndx;
+    }
+    else {
+        // FIXME: Could be optimized by first resizing the target
+        // array, then copy elements with std::copy().
+        for (size_t i = ndx; i != leaf_size; ++i)
+            new_leaf.add(get(i));
+        truncate(ndx);
+        add(value);
+        state.m_split_offset = ndx + 1;
+    }
+    state.m_split_size = leaf_size + 1;
+    return new_leaf.get_ref();
+}
+
+template <class T>
+inline size_t BasicArray<T>::lower_bound(T value) const noexcept
+{
+    const T* begin = reinterpret_cast<const T*>(m_data);
+    const T* end = begin + size();
+    return std::lower_bound(begin, end, value) - begin;
+}
+
+template <class T>
+inline size_t BasicArray<T>::upper_bound(T value) const noexcept
+{
+    const T* begin = reinterpret_cast<const T*>(m_data);
+    const T* end = begin + size();
+    return std::upper_bound(begin, end, value) - begin;
+}
+
+template <class T>
+inline size_t BasicArray<T>::calc_aligned_byte_size(size_t size)
+{
+    size_t max = std::numeric_limits<size_t>::max();
+    size_t max_2 = max & ~size_t(7); // Allow for upwards 8-byte alignment
+    if (size > (max_2 - header_size) / sizeof(T))
+        throw util::overflow_error("Byte size overflow");
+    size_t byte_size = header_size + size * sizeof(T);
+    REALM_ASSERT_3(byte_size, >, 0);
+    size_t aligned_byte_size = ((byte_size - 1) | 7) + 1; // 8-byte alignment
+    return aligned_byte_size;
+}
+
+
+#ifdef REALM_DEBUG
+
+// LCOV_EXCL_START
+template <class T>
+void BasicArray<T>::to_dot(std::ostream& out, StringData title) const
+{
+    ref_type ref = get_ref();
+    if (title.size() != 0) {
+        out << "subgraph cluster_" << ref << " {\n";
+        out << " label = \"" << title << "\";\n";
+        out << " color = white;\n";
+    }
+
+    out << "n" << std::hex << ref << std::dec << "[shape=none,label=<";
+    out << "<TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\" CELLPADDING=\"4\"><TR>\n";
+
+    // Header
+    out << "<TD BGCOLOR=\"lightgrey\"><FONT POINT-SIZE=\"7\"> ";
+    out << "0x" << std::hex << ref << std::dec << "<BR/>";
+    out << "</FONT></TD>\n";
+
+    // Values
+    size_t n = m_size;
+    for (size_t i = 0; i != n; ++i)
+        out << "<TD>" << get(i) << "</TD>\n";
+
+    out << "</TR></TABLE>>];\n";
+
+    if (title.size() != 0)
+        out << "}\n";
+
+    to_dot_parent_edge(out);
+}
+// LCOV_EXCL_STOP
+
+#endif // REALM_DEBUG
+
+
+} // namespace realm
+
+#endif // REALM_ARRAY_BASIC_TPL_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_binary.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_binary.hpp
new file mode 100644
index 0000000..347c7be
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_binary.hpp
@@ -0,0 +1,259 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_BINARY_HPP
+#define REALM_ARRAY_BINARY_HPP
+
+#include <realm/binary_data.hpp>
+#include <realm/array_blob.hpp>
+#include <realm/array_integer.hpp>
+#include <realm/exceptions.hpp>
+
+namespace realm {
+
+/*
+STORAGE FORMAT
+---------------------------------------------------------------------------------------
+ArrayBinary stores binary elements using two ArrayInteger and one ArrayBlob. The ArrayBlob can only store one
+single concecutive array of bytes (contrary to its 'Array' name that misleadingly indicates it could store multiple
+elements).
+
+Assume we have the strings "a", "", "abc", null, "ab". Then the three arrays will contain:
+
+ArrayInteger    m_offsets   1, 1, 5, 5, 6
+ArrayBlob       m_blob      aabcab
+ArrayInteger    m_nulls     0, 0, 0, 1, 0 // 1 indicates null, 0 indicates non-null
+
+So for each element the ArrayInteger, the ArrayInteger points into the ArrayBlob at the position of the first
+byte of the next element.
+
+m_nulls is always present (except for old database files; see below), so any ArrayBinary is always nullable!
+The nullable property (such as throwing exception upon set(null) on non-nullable column, etc) is handled on
+column level only.
+
+DATABASE FILE VERSION CHANGES
+---------------------------------------------------------------------------------------
+Old database files do not have any m_nulls array. To be backwardscompatible, many methods will have tests like
+`if(Array::size() == 3)` and have a backwards compatible code paths for these (e.g. avoid writing to m_nulls
+in set(), etc). This way no file format upgrade is needed to support nulls for BinaryData.
+*/
+
+class ArrayBinary : public Array {
+public:
+    explicit ArrayBinary(Allocator&) noexcept;
+    ~ArrayBinary() noexcept override
+    {
+    }
+
+    // Disable copying, this is not allowed.
+    ArrayBinary& operator=(const ArrayBinary&) = delete;
+    ArrayBinary(const ArrayBinary&) = delete;
+
+    /// Create a new empty binary array and attach this accessor to
+    /// it. This does not modify the parent reference information of
+    /// this accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated
+    /// underlying node. It is not owned by the accessor.
+    void create();
+
+    // Old database files will not have the m_nulls array, so we need code paths for
+    // backwards compatibility for these cases.
+    bool legacy_array_type() const noexcept;
+
+    //@{
+    /// Overriding functions of Array
+    void init_from_ref(ref_type) noexcept;
+    void init_from_mem(MemRef) noexcept;
+    void init_from_parent() noexcept;
+    //@}
+
+    bool is_empty() const noexcept;
+    size_t size() const noexcept;
+
+    BinaryData get(size_t ndx) const noexcept;
+    size_t read(size_t ndx, size_t pos, char* buffer, size_t max_size) const noexcept;
+
+    void add(BinaryData value, bool add_zero_term = false);
+    void set(size_t ndx, BinaryData value, bool add_zero_term = false);
+    void insert(size_t ndx, BinaryData value, bool add_zero_term = false);
+    void erase(size_t ndx);
+    void truncate(size_t new_size);
+    void clear();
+    void destroy();
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static BinaryData get(const char* header, size_t ndx, Allocator&) noexcept;
+
+    ref_type bptree_leaf_insert(size_t ndx, BinaryData, bool add_zero_term, TreeInsertBase& state);
+
+    static size_t get_size_from_header(const char*, Allocator&) noexcept;
+
+    /// Construct a binary array of the specified size and return just
+    /// the reference to the underlying memory. All elements will be
+    /// initialized to the binary value `defaults`, which can be either
+    /// null or zero-length non-null (value with size > 0 is not allowed as
+    /// initialization value).
+    static MemRef create_array(size_t size, Allocator&, BinaryData defaults);
+
+    /// Construct a copy of the specified slice of this binary array
+    /// using the specified target allocator.
+    MemRef slice(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+#ifdef REALM_DEBUG
+    void to_dot(std::ostream&, bool is_strings, StringData title = StringData()) const;
+#endif
+    bool update_from_parent(size_t old_baseline) noexcept;
+
+private:
+    ArrayInteger m_offsets;
+    ArrayBlob m_blob;
+    ArrayInteger m_nulls;
+};
+
+
+// Implementation:
+
+inline ArrayBinary::ArrayBinary(Allocator& allocator) noexcept
+    : Array(allocator)
+    , m_offsets(allocator)
+    , m_blob(allocator)
+    , m_nulls(allocator)
+{
+    m_offsets.set_parent(this, 0);
+    m_blob.set_parent(this, 1);
+    m_nulls.set_parent(this, 2);
+}
+
+inline void ArrayBinary::create()
+{
+    size_t init_size = 0;
+    BinaryData defaults = BinaryData{};                          // This init value is ignored because size = 0
+    MemRef mem = create_array(init_size, get_alloc(), defaults); // Throws
+    init_from_mem(mem);
+}
+
+inline void ArrayBinary::init_from_ref(ref_type ref) noexcept
+{
+    REALM_ASSERT(ref);
+    char* header = get_alloc().translate(ref);
+    init_from_mem(MemRef(header, ref, m_alloc));
+}
+
+inline void ArrayBinary::init_from_parent() noexcept
+{
+    ref_type ref = get_ref_from_parent();
+    init_from_ref(ref);
+}
+
+inline bool ArrayBinary::is_empty() const noexcept
+{
+    return m_offsets.is_empty();
+}
+
+// Old database files will not have the m_nulls array, so we need code paths for
+// backwards compatibility for these cases. We can test if m_nulls exists by looking
+// at number of references in this ArrayBinary.
+inline bool ArrayBinary::legacy_array_type() const noexcept
+{
+    if (Array::size() == 3)
+        return false; // New database file
+    else if (Array::size() == 2)
+        return true; // Old database file
+    else
+        REALM_ASSERT(false); // Should never happen
+    return false;
+}
+
+inline size_t ArrayBinary::size() const noexcept
+{
+    return m_offsets.size();
+}
+
+inline BinaryData ArrayBinary::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_offsets.size());
+
+    if (!legacy_array_type() && m_nulls.get(ndx)) {
+        return BinaryData();
+    }
+    else {
+        size_t begin = ndx ? to_size_t(m_offsets.get(ndx - 1)) : 0;
+        size_t end = to_size_t(m_offsets.get(ndx));
+
+        BinaryData bd = BinaryData(m_blob.get(begin), end - begin);
+        // Old database file (non-nullable column should never return null)
+        REALM_ASSERT(!bd.is_null());
+        return bd;
+    }
+}
+
+inline void ArrayBinary::truncate(size_t new_size)
+{
+    REALM_ASSERT_3(new_size, <, m_offsets.size());
+
+    size_t sz = new_size ? to_size_t(m_offsets.get(new_size - 1)) : 0;
+
+    m_offsets.truncate(new_size);
+    m_blob.truncate(sz);
+    if (!legacy_array_type())
+        m_nulls.truncate(new_size);
+}
+
+inline void ArrayBinary::clear()
+{
+    m_blob.clear();
+    m_offsets.clear();
+    if (!legacy_array_type())
+        m_nulls.clear();
+}
+
+inline void ArrayBinary::destroy()
+{
+    m_blob.destroy();
+    m_offsets.destroy();
+    if (!legacy_array_type())
+        m_nulls.destroy();
+    Array::destroy();
+}
+
+inline size_t ArrayBinary::get_size_from_header(const char* header, Allocator& alloc) noexcept
+{
+    ref_type offsets_ref = to_ref(Array::get(header, 0));
+    const char* offsets_header = alloc.translate(offsets_ref);
+    return Array::get_size_from_header(offsets_header);
+}
+
+inline bool ArrayBinary::update_from_parent(size_t old_baseline) noexcept
+{
+    bool res = Array::update_from_parent(old_baseline);
+    if (res) {
+        m_blob.update_from_parent(old_baseline);
+        m_offsets.update_from_parent(old_baseline);
+        if (!legacy_array_type())
+            m_nulls.update_from_parent(old_baseline);
+    }
+    return res;
+}
+
+} // namespace realm
+
+#endif // REALM_ARRAY_BINARY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_blob.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_blob.hpp
new file mode 100644
index 0000000..556d40a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_blob.hpp
@@ -0,0 +1,146 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_BLOB_HPP
+#define REALM_ARRAY_BLOB_HPP
+
+#include <realm/array.hpp>
+
+namespace realm {
+
+
+class ArrayBlob : public Array {
+public:
+    static constexpr size_t max_binary_size = 0xFFFFF8 - Array::header_size;
+
+    explicit ArrayBlob(Allocator&) noexcept;
+    ~ArrayBlob() noexcept override
+    {
+    }
+
+    // Disable copying, this is not allowed.
+    ArrayBlob& operator=(const ArrayBlob&) = delete;
+    ArrayBlob(const ArrayBlob&) = delete;
+
+    const char* get(size_t index) const noexcept;
+    BinaryData get_at(size_t& pos) const noexcept;
+    bool is_null(size_t index) const noexcept;
+    ref_type add(const char* data, size_t data_size, bool add_zero_term = false);
+    void insert(size_t pos, const char* data, size_t data_size, bool add_zero_term = false);
+    ref_type replace(size_t begin, size_t end, const char* data, size_t data_size, bool add_zero_term = false);
+    void erase(size_t begin, size_t end);
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static const char* get(const char* header, size_t index) noexcept;
+
+    /// Create a new empty blob (binary) array and attach this
+    /// accessor to it. This does not modify the parent reference
+    /// information of this accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated
+    /// underlying node. It is not owned by the accessor.
+    void create();
+
+    /// Construct a blob of the specified size and return just the
+    /// reference to the underlying memory. All bytes will be
+    /// initialized to zero.
+    static MemRef create_array(size_t init_size, Allocator&);
+
+#ifdef REALM_DEBUG
+    void verify() const;
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+#endif
+
+private:
+    size_t calc_byte_len(size_t for_size, size_t width) const override;
+    size_t calc_item_count(size_t bytes, size_t width) const noexcept override;
+};
+
+
+// Implementation:
+
+// Creates new array (but invalid, call init_from_ref() to init)
+inline ArrayBlob::ArrayBlob(Allocator& allocator) noexcept
+    : Array(allocator)
+{
+}
+
+inline bool ArrayBlob::is_null(size_t index) const noexcept
+{
+    return (get(index) == nullptr);
+}
+
+inline const char* ArrayBlob::get(size_t index) const noexcept
+{
+    return m_data + index;
+}
+
+inline ref_type ArrayBlob::add(const char* data, size_t data_size, bool add_zero_term)
+{
+    return replace(m_size, m_size, data, data_size, add_zero_term);
+}
+
+inline void ArrayBlob::insert(size_t pos, const char* data, size_t data_size, bool add_zero_term)
+{
+    replace(pos, pos, data, data_size, add_zero_term);
+}
+
+inline void ArrayBlob::erase(size_t begin, size_t end)
+{
+    const char* data = nullptr;
+    size_t data_size = 0;
+    replace(begin, end, data, data_size);
+}
+
+inline const char* ArrayBlob::get(const char* header, size_t pos) noexcept
+{
+    const char* data = get_data_from_header(header);
+    return data + pos;
+}
+
+inline void ArrayBlob::create()
+{
+    size_t init_size = 0;
+    MemRef mem = create_array(init_size, get_alloc()); // Throws
+    init_from_mem(mem);
+}
+
+inline MemRef ArrayBlob::create_array(size_t init_size, Allocator& allocator)
+{
+    bool context_flag = false;
+    int_fast64_t value = 0;
+    return Array::create(type_Normal, context_flag, wtype_Ignore, init_size, value, allocator); // Throws
+}
+
+inline size_t ArrayBlob::calc_byte_len(size_t for_size, size_t) const
+{
+    return header_size + for_size;
+}
+
+inline size_t ArrayBlob::calc_item_count(size_t bytes, size_t) const noexcept
+{
+    return bytes - header_size;
+}
+
+
+} // namespace realm
+
+#endif // REALM_ARRAY_BLOB_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_blobs_big.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_blobs_big.hpp
new file mode 100644
index 0000000..cc793fb
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_blobs_big.hpp
@@ -0,0 +1,222 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_BIG_BLOBS_HPP
+#define REALM_ARRAY_BIG_BLOBS_HPP
+
+#include <realm/array_blob.hpp>
+
+namespace realm {
+
+
+class ArrayBigBlobs : public Array {
+public:
+    typedef BinaryData value_type;
+
+    explicit ArrayBigBlobs(Allocator&, bool nullable) noexcept;
+
+    // Disable copying, this is not allowed.
+    ArrayBigBlobs& operator=(const ArrayBigBlobs&) = delete;
+    ArrayBigBlobs(const ArrayBigBlobs&) = delete;
+
+    BinaryData get(size_t ndx) const noexcept;
+    BinaryData get_at(size_t ndx, size_t& pos) const noexcept;
+    void set(size_t ndx, BinaryData value, bool add_zero_term = false);
+    void add(BinaryData value, bool add_zero_term = false);
+    void insert(size_t ndx, BinaryData value, bool add_zero_term = false);
+    void erase(size_t ndx);
+    void truncate(size_t new_size);
+    void clear();
+    void destroy();
+
+    size_t count(BinaryData value, bool is_string = false, size_t begin = 0, size_t end = npos) const noexcept;
+    size_t find_first(BinaryData value, bool is_string = false, size_t begin = 0, size_t end = npos) const noexcept;
+    void find_all(IntegerColumn& result, BinaryData value, bool is_string = false, size_t add_offset = 0,
+                  size_t begin = 0, size_t end = npos);
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static BinaryData get(const char* header, size_t ndx, Allocator&) noexcept;
+
+    ref_type bptree_leaf_insert(size_t ndx, BinaryData, bool add_zero_term, TreeInsertBase& state);
+
+    //@{
+    /// Those that return a string, discard the terminating zero from
+    /// the stored value. Those that accept a string argument, add a
+    /// terminating zero before storing the value.
+    StringData get_string(size_t ndx) const noexcept;
+    void add_string(StringData value);
+    void set_string(size_t ndx, StringData value);
+    void insert_string(size_t ndx, StringData value);
+    static StringData get_string(const char* header, size_t ndx, Allocator&, bool nullable) noexcept;
+    ref_type bptree_leaf_insert_string(size_t ndx, StringData, TreeInsertBase& state);
+    //@}
+
+    /// Create a new empty big blobs array and attach this accessor to
+    /// it. This does not modify the parent reference information of
+    /// this accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated
+    /// underlying node. It is not owned by the accessor.
+    void create();
+
+    /// Construct a copy of the specified slice of this big blobs
+    /// array using the specified target allocator.
+    MemRef slice(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+#ifdef REALM_DEBUG
+    void verify() const;
+    void to_dot(std::ostream&, bool is_strings, StringData title = StringData()) const;
+#endif
+
+private:
+    bool m_nullable;
+};
+
+
+// Implementation:
+
+inline ArrayBigBlobs::ArrayBigBlobs(Allocator& allocator, bool nullable) noexcept
+    : Array(allocator)
+    , m_nullable(nullable)
+{
+}
+
+inline BinaryData ArrayBigBlobs::get(size_t ndx) const noexcept
+{
+    ref_type ref = get_as_ref(ndx);
+    if (ref == 0)
+        return {}; // realm::null();
+
+    const char* blob_header = get_alloc().translate(ref);
+    if (!get_context_flag_from_header(blob_header)) {
+        const char* value = ArrayBlob::get(blob_header, 0);
+        size_t sz = get_size_from_header(blob_header);
+        return BinaryData(value, sz);
+    }
+    return {};
+}
+
+inline BinaryData ArrayBigBlobs::get(const char* header, size_t ndx, Allocator& alloc) noexcept
+{
+    ref_type blob_ref = to_ref(Array::get(header, ndx));
+    if (blob_ref == 0)
+        return {};
+
+    const char* blob_header = alloc.translate(blob_ref);
+    if (!get_context_flag_from_header(blob_header)) {
+        const char* blob_data = Array::get_data_from_header(blob_header);
+        size_t sz = Array::get_size_from_header(blob_header);
+        return BinaryData(blob_data, sz);
+    }
+    return {};
+}
+
+inline void ArrayBigBlobs::erase(size_t ndx)
+{
+    ref_type blob_ref = Array::get_as_ref(ndx);
+    if (blob_ref != 0) {                       // nothing to destroy if null
+        Array::destroy_deep(blob_ref, get_alloc()); // Deep
+    }
+    Array::erase(ndx);
+}
+
+inline void ArrayBigBlobs::truncate(size_t new_size)
+{
+    Array::truncate_and_destroy_children(new_size);
+}
+
+inline void ArrayBigBlobs::clear()
+{
+    Array::clear_and_destroy_children();
+}
+
+inline void ArrayBigBlobs::destroy()
+{
+    Array::destroy_deep();
+}
+
+inline StringData ArrayBigBlobs::get_string(size_t ndx) const noexcept
+{
+    BinaryData bin = get(ndx);
+    if (bin.is_null())
+        return realm::null();
+    else
+        return StringData(bin.data(), bin.size() - 1); // Do not include terminating zero
+}
+
+inline void ArrayBigBlobs::set_string(size_t ndx, StringData value)
+{
+    REALM_ASSERT_DEBUG(!(!m_nullable && value.is_null()));
+    BinaryData bin(value.data(), value.size());
+    bool add_zero_term = true;
+    set(ndx, bin, add_zero_term);
+}
+
+inline void ArrayBigBlobs::add_string(StringData value)
+{
+    REALM_ASSERT_DEBUG(!(!m_nullable && value.is_null()));
+    BinaryData bin(value.data(), value.size());
+    bool add_zero_term = true;
+    add(bin, add_zero_term);
+}
+
+inline void ArrayBigBlobs::insert_string(size_t ndx, StringData value)
+{
+    REALM_ASSERT_DEBUG(!(!m_nullable && value.is_null()));
+    BinaryData bin(value.data(), value.size());
+    bool add_zero_term = true;
+    insert(ndx, bin, add_zero_term);
+}
+
+inline StringData ArrayBigBlobs::get_string(const char* header, size_t ndx, Allocator& alloc, bool nullable) noexcept
+{
+    static_cast<void>(nullable);
+    BinaryData bin = get(header, ndx, alloc);
+    REALM_ASSERT_DEBUG(!(!nullable && bin.is_null()));
+    if (bin.is_null())
+        return realm::null();
+    else
+        return StringData(bin.data(), bin.size() - 1); // Do not include terminating zero
+}
+
+inline ref_type ArrayBigBlobs::bptree_leaf_insert_string(size_t ndx, StringData value, TreeInsertBase& state)
+{
+    REALM_ASSERT_DEBUG(!(!m_nullable && value.is_null()));
+    BinaryData bin(value.data(), value.size());
+    bool add_zero_term = true;
+    return bptree_leaf_insert(ndx, bin, add_zero_term, state);
+}
+
+inline void ArrayBigBlobs::create()
+{
+    bool context_flag = true;
+    Array::create(type_HasRefs, context_flag); // Throws
+}
+
+inline MemRef ArrayBigBlobs::slice(size_t offset, size_t slice_size, Allocator& target_alloc) const
+{
+    return slice_and_clone_children(offset, slice_size, target_alloc);
+}
+
+
+} // namespace realm
+
+#endif // REALM_ARRAY_BIG_BLOBS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_direct.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_direct.hpp
new file mode 100644
index 0000000..e337392
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_direct.hpp
@@ -0,0 +1,372 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_DIRECT_HPP
+#define REALM_ARRAY_DIRECT_HPP
+
+#include <realm/utilities.hpp>
+#include <realm/alloc.hpp>
+
+using namespace realm::util;
+
+// clang-format off
+/* wid == 16/32 likely when accessing offsets in B tree */
+#define REALM_TEMPEX(fun, wid, arg) \
+    if (wid == 16) {fun<16> arg;} \
+    else if (wid == 32) {fun<32> arg;} \
+    else if (wid == 0) {fun<0> arg;} \
+    else if (wid == 1) {fun<1> arg;} \
+    else if (wid == 2) {fun<2> arg;} \
+    else if (wid == 4) {fun<4> arg;} \
+    else if (wid == 8) {fun<8> arg;} \
+    else if (wid == 64) {fun<64> arg;} \
+    else {REALM_ASSERT_DEBUG(false); fun<0> arg;}
+
+#define REALM_TEMPEX2(fun, targ, wid, arg) \
+    if (wid == 16) {fun<targ, 16> arg;} \
+    else if (wid == 32) {fun<targ, 32> arg;} \
+    else if (wid == 0) {fun<targ, 0> arg;} \
+    else if (wid == 1) {fun<targ, 1> arg;} \
+    else if (wid == 2) {fun<targ, 2> arg;} \
+    else if (wid == 4) {fun<targ, 4> arg;} \
+    else if (wid == 8) {fun<targ, 8> arg;} \
+    else if (wid == 64) {fun<targ, 64> arg;} \
+    else {REALM_ASSERT_DEBUG(false); fun<targ, 0> arg;}
+
+#define REALM_TEMPEX3(fun, targ1, targ2, wid, arg) \
+    if (wid == 16) {fun<targ1, targ2, 16> arg;} \
+    else if (wid == 32) {fun<targ1, targ2, 32> arg;} \
+    else if (wid == 0) {fun<targ1, targ2, 0> arg;} \
+    else if (wid == 1) {fun<targ1, targ2, 1> arg;} \
+    else if (wid == 2) {fun<targ1, targ2, 2> arg;} \
+    else if (wid == 4) {fun<targ1, targ2, 4> arg;} \
+    else if (wid == 8) {fun<targ1, targ2, 8> arg;} \
+    else if (wid == 64) {fun<targ1, targ2, 64> arg;} \
+    else {REALM_ASSERT_DEBUG(false); fun<targ1, targ2, 0> arg;}
+
+#define REALM_TEMPEX4(fun, targ1, targ2, wid, targ3, arg) \
+    if (wid == 16) {fun<targ1, targ2, 16, targ3> arg;} \
+    else if (wid == 32) {fun<targ1, targ2, 32, targ3> arg;} \
+    else if (wid == 0) {fun<targ1, targ2, 0, targ3> arg;} \
+    else if (wid == 1) {fun<targ1, targ2, 1, targ3> arg;} \
+    else if (wid == 2) {fun<targ1, targ2, 2, targ3> arg;} \
+    else if (wid == 4) {fun<targ1, targ2, 4, targ3> arg;} \
+    else if (wid == 8) {fun<targ1, targ2, 8, targ3> arg;} \
+    else if (wid == 64) {fun<targ1, targ2, 64, targ3> arg;} \
+    else {REALM_ASSERT_DEBUG(false); fun<targ1, targ2, 0, targ3> arg;}
+
+#define REALM_TEMPEX5(fun, targ1, targ2, targ3, targ4, wid, arg) \
+    if (wid == 16) {fun<targ1, targ2, targ3, targ4, 16> arg;} \
+    else if (wid == 32) {fun<targ1, targ2, targ3, targ4, 32> arg;} \
+    else if (wid == 0) {fun<targ1, targ2, targ3, targ4, 0> arg;} \
+    else if (wid == 1) {fun<targ1, targ2, targ3, targ4, 1> arg;} \
+    else if (wid == 2) {fun<targ1, targ2, targ3, targ4, 2> arg;} \
+    else if (wid == 4) {fun<targ1, targ2, targ3, targ4, 4> arg;} \
+    else if (wid == 8) {fun<targ1, targ2, targ3, targ4, 8> arg;} \
+    else if (wid == 64) {fun<targ1, targ2, targ3, targ4, 64> arg;} \
+    else {REALM_ASSERT_DEBUG(false); fun<targ1, targ2, targ3, targ4, 0> arg;}
+// clang-format on
+
+namespace realm {
+
+// Direct access methods
+
+template <size_t width>
+void set_direct(char* data, size_t ndx, int_fast64_t value) noexcept
+{
+    if (width == 0) {
+        REALM_ASSERT_DEBUG(value == 0);
+        return;
+    }
+    else if (width == 1) {
+        REALM_ASSERT_DEBUG(0 <= value && value <= 0x01);
+        size_t byte_ndx = ndx / 8;
+        size_t bit_ndx = ndx % 8;
+        typedef unsigned char uchar;
+        uchar* p = reinterpret_cast<uchar*>(data) + byte_ndx;
+        *p = uchar((*p & ~(0x01 << bit_ndx)) | (int(value) & 0x01) << bit_ndx);
+    }
+    else if (width == 2) {
+        REALM_ASSERT_DEBUG(0 <= value && value <= 0x03);
+        size_t byte_ndx = ndx / 4;
+        size_t bit_ndx = ndx % 4 * 2;
+        typedef unsigned char uchar;
+        uchar* p = reinterpret_cast<uchar*>(data) + byte_ndx;
+        *p = uchar((*p & ~(0x03 << bit_ndx)) | (int(value) & 0x03) << bit_ndx);
+    }
+    else if (width == 4) {
+        REALM_ASSERT_DEBUG(0 <= value && value <= 0x0F);
+        size_t byte_ndx = ndx / 2;
+        size_t bit_ndx = ndx % 2 * 4;
+        typedef unsigned char uchar;
+        uchar* p = reinterpret_cast<uchar*>(data) + byte_ndx;
+        *p = uchar((*p & ~(0x0F << bit_ndx)) | (int(value) & 0x0F) << bit_ndx);
+    }
+    else if (width == 8) {
+        REALM_ASSERT_DEBUG(std::numeric_limits<int8_t>::min() <= value &&
+                           value <= std::numeric_limits<int8_t>::max());
+        *(reinterpret_cast<int8_t*>(data) + ndx) = int8_t(value);
+    }
+    else if (width == 16) {
+        REALM_ASSERT_DEBUG(std::numeric_limits<int16_t>::min() <= value &&
+                           value <= std::numeric_limits<int16_t>::max());
+        *(reinterpret_cast<int16_t*>(data) + ndx) = int16_t(value);
+    }
+    else if (width == 32) {
+        REALM_ASSERT_DEBUG(std::numeric_limits<int32_t>::min() <= value &&
+                           value <= std::numeric_limits<int32_t>::max());
+        *(reinterpret_cast<int32_t*>(data) + ndx) = int32_t(value);
+    }
+    else if (width == 64) {
+        REALM_ASSERT_DEBUG(std::numeric_limits<int64_t>::min() <= value &&
+                           value <= std::numeric_limits<int64_t>::max());
+        *(reinterpret_cast<int64_t*>(data) + ndx) = int64_t(value);
+    }
+    else {
+        REALM_ASSERT_DEBUG(false);
+    }
+}
+
+template <size_t width>
+void fill_direct(char* data, size_t begin, size_t end, int_fast64_t value) noexcept
+{
+    for (size_t i = begin; i != end; ++i)
+        set_direct<width>(data, i, value);
+}
+
+template <int w>
+int64_t get_direct(const char* data, size_t ndx) noexcept
+{
+    if (w == 0) {
+        return 0;
+    }
+    if (w == 1) {
+        size_t offset = ndx >> 3;
+        return (data[offset] >> (ndx & 7)) & 0x01;
+    }
+    if (w == 2) {
+        size_t offset = ndx >> 2;
+        return (data[offset] >> ((ndx & 3) << 1)) & 0x03;
+    }
+    if (w == 4) {
+        size_t offset = ndx >> 1;
+        return (data[offset] >> ((ndx & 1) << 2)) & 0x0F;
+    }
+    if (w == 8) {
+        return *reinterpret_cast<const signed char*>(data + ndx);
+    }
+    if (w == 16) {
+        size_t offset = ndx * 2;
+        return *reinterpret_cast<const int16_t*>(data + offset);
+    }
+    if (w == 32) {
+        size_t offset = ndx * 4;
+        return *reinterpret_cast<const int32_t*>(data + offset);
+    }
+    if (w == 64) {
+        size_t offset = ndx * 8;
+        return *reinterpret_cast<const int64_t*>(data + offset);
+    }
+    REALM_ASSERT_DEBUG(false);
+    return int64_t(-1);
+}
+
+inline int64_t get_direct(const char* data, size_t width, size_t ndx) noexcept
+{
+    REALM_TEMPEX(return get_direct, width, (data, ndx));
+}
+
+
+template <int width>
+inline std::pair<int64_t, int64_t> get_two(const char* data, size_t ndx) noexcept
+{
+    return std::make_pair(to_size_t(get_direct<width>(data, ndx + 0)), to_size_t(get_direct<width>(data, ndx + 1)));
+}
+
+inline std::pair<int64_t, int64_t> get_two(const char* data, size_t width, size_t ndx) noexcept
+{
+    REALM_TEMPEX(return get_two, width, (data, ndx));
+}
+
+
+template <int width>
+inline void get_three(const char* data, size_t ndx, ref_type& v0, ref_type& v1, ref_type& v2) noexcept
+{
+    v0 = to_ref(get_direct<width>(data, ndx + 0));
+    v1 = to_ref(get_direct<width>(data, ndx + 1));
+    v2 = to_ref(get_direct<width>(data, ndx + 2));
+}
+
+inline void get_three(const char* data, size_t width, size_t ndx, ref_type& v0, ref_type& v1, ref_type& v2) noexcept
+{
+    REALM_TEMPEX(get_three, width, (data, ndx, v0, v1, v2));
+}
+
+
+// Lower/upper bound in sorted sequence
+// ------------------------------------
+//
+//   3 3 3 4 4 4 5 6 7 9 9 9
+//   ^     ^     ^     ^     ^
+//   |     |     |     |     |
+//   |     |     |     |      -- Lower and upper bound of 15
+//   |     |     |     |
+//   |     |     |      -- Lower and upper bound of 8
+//   |     |     |
+//   |     |      -- Upper bound of 4
+//   |     |
+//   |      -- Lower bound of 4
+//   |
+//    -- Lower and upper bound of 1
+//
+// These functions are semantically identical to std::lower_bound() and
+// std::upper_bound().
+//
+// We currently use binary search. See for example
+// http://www.tbray.org/ongoing/When/200x/2003/03/22/Binary.
+template <int width>
+inline size_t lower_bound(const char* data, size_t size, int64_t value) noexcept
+{
+    // The binary search used here is carefully optimized. Key trick is to use a single
+    // loop controlling variable (size) instead of high/low pair, and to keep updates
+    // to size done inside the loop independent of comparisons. Further key to speed
+    // is to avoid branching inside the loop, using conditional moves instead. This
+    // provides robust performance for random searches, though predictable searches
+    // might be slightly faster if we used branches instead. The loop unrolling yields
+    // a final 5-20% speedup depending on circumstances.
+
+    size_t low = 0;
+
+    while (size >= 8) {
+        // The following code (at X, Y and Z) is 3 times manually unrolled instances of (A) below.
+        // These code blocks must be kept in sync. Meassurements indicate 3 times unrolling to give
+        // the best performance. See (A) for comments on the loop body.
+        // (X)
+        size_t half = size / 2;
+        size_t other_half = size - half;
+        size_t probe = low + half;
+        size_t other_low = low + other_half;
+        int64_t v = get_direct<width>(data, probe);
+        size = half;
+        low = (v < value) ? other_low : low;
+
+        // (Y)
+        half = size / 2;
+        other_half = size - half;
+        probe = low + half;
+        other_low = low + other_half;
+        v = get_direct<width>(data, probe);
+        size = half;
+        low = (v < value) ? other_low : low;
+
+        // (Z)
+        half = size / 2;
+        other_half = size - half;
+        probe = low + half;
+        other_low = low + other_half;
+        v = get_direct<width>(data, probe);
+        size = half;
+        low = (v < value) ? other_low : low;
+    }
+    while (size > 0) {
+        // (A)
+        // To understand the idea in this code, please note that
+        // for performance, computation of size for the next iteration
+        // MUST be INDEPENDENT of the conditional. This allows the
+        // processor to unroll the loop as fast as possible, and it
+        // minimizes the length of dependence chains leading up to branches.
+        // Making the unfolding of the loop independent of the data being
+        // searched, also minimizes the delays incurred by branch
+        // mispredictions, because they can be determined earlier
+        // and the speculation corrected earlier.
+
+        // Counterintuitive:
+        // To make size independent of data, we cannot always split the
+        // range at the theoretical optimal point. When we determine that
+        // the key is larger than the probe at some index K, and prepare
+        // to search the upper part of the range, you would normally start
+        // the search at the next index, K+1, to get the shortest range.
+        // We can only do this when splitting a range with odd number of entries.
+        // If there is an even number of entries we search from K instead of K+1.
+        // This potentially leads to redundant comparisons, but in practice we
+        // gain more performance by making the changes to size predictable.
+
+        // if size is even, half and other_half are the same.
+        // if size is odd, half is one less than other_half.
+        size_t half = size / 2;
+        size_t other_half = size - half;
+        size_t probe = low + half;
+        size_t other_low = low + other_half;
+        int64_t v = get_direct<width>(data, probe);
+        size = half;
+        // for max performance, the line below should compile into a conditional
+        // move instruction. Not all compilers do this. To maximize chance
+        // of succes, no computation should be done in the branches of the
+        // conditional.
+        low = (v < value) ? other_low : low;
+    };
+
+    return low;
+}
+
+// See lower_bound()
+template <int width>
+inline size_t upper_bound(const char* data, size_t size, int64_t value) noexcept
+{
+    size_t low = 0;
+    while (size >= 8) {
+        size_t half = size / 2;
+        size_t other_half = size - half;
+        size_t probe = low + half;
+        size_t other_low = low + other_half;
+        int64_t v = get_direct<width>(data, probe);
+        size = half;
+        low = (value >= v) ? other_low : low;
+
+        half = size / 2;
+        other_half = size - half;
+        probe = low + half;
+        other_low = low + other_half;
+        v = get_direct<width>(data, probe);
+        size = half;
+        low = (value >= v) ? other_low : low;
+
+        half = size / 2;
+        other_half = size - half;
+        probe = low + half;
+        other_low = low + other_half;
+        v = get_direct<width>(data, probe);
+        size = half;
+        low = (value >= v) ? other_low : low;
+    }
+
+    while (size > 0) {
+        size_t half = size / 2;
+        size_t other_half = size - half;
+        size_t probe = low + half;
+        size_t other_low = low + other_half;
+        int64_t v = get_direct<width>(data, probe);
+        size = half;
+        low = (value >= v) ? other_low : low;
+    };
+
+    return low;
+}
+}
+
+#endif /* ARRAY_TPL_HPP_ */
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_integer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_integer.hpp
new file mode 100644
index 0000000..e460c53
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_integer.hpp
@@ -0,0 +1,629 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_INTEGER_HPP
+#define REALM_ARRAY_INTEGER_HPP
+
+#include <realm/array.hpp>
+#include <realm/util/safe_int_ops.hpp>
+#include <realm/util/optional.hpp>
+
+namespace realm {
+
+class ArrayInteger : public Array {
+public:
+    typedef int64_t value_type;
+
+    explicit ArrayInteger(Allocator&) noexcept;
+    ~ArrayInteger() noexcept override
+    {
+    }
+
+    // Disable copying, this is not allowed.
+    ArrayInteger& operator=(const ArrayInteger&) = delete;
+    ArrayInteger(const ArrayInteger&) = delete;
+
+    void create(Type type = type_Normal, bool context_flag = false);
+
+    void add(int64_t value);
+    void set(size_t ndx, int64_t value);
+    void set_uint(size_t ndx, uint_fast64_t value) noexcept;
+    int64_t get(size_t ndx) const noexcept;
+    uint64_t get_uint(size_t ndx) const noexcept;
+    static int64_t get(const char* header, size_t ndx) noexcept;
+    bool compare(const ArrayInteger& a) const noexcept;
+
+    /// Add \a diff to the element at the specified index.
+    void adjust(size_t ndx, int_fast64_t diff);
+
+    /// Add \a diff to all the elements in the specified index range.
+    void adjust(size_t begin, size_t end, int_fast64_t diff);
+
+    /// Add signed \a diff to all elements that are greater than, or equal to \a
+    /// limit.
+    void adjust_ge(int_fast64_t limit, int_fast64_t diff);
+
+    int64_t operator[](size_t ndx) const noexcept
+    {
+        return get(ndx);
+    }
+    int64_t front() const noexcept;
+    int64_t back() const noexcept;
+
+    size_t lower_bound(int64_t value) const noexcept;
+    size_t upper_bound(int64_t value) const noexcept;
+
+    std::vector<int64_t> to_vector() const;
+
+private:
+    template <size_t w>
+    bool minmax(size_t from, size_t to, uint64_t maxdiff, int64_t* min, int64_t* max) const;
+};
+
+class ArrayIntNull : public Array {
+public:
+    using value_type = util::Optional<int64_t>;
+
+    explicit ArrayIntNull(Allocator&) noexcept;
+    ~ArrayIntNull() noexcept override;
+
+    /// Construct an array of the specified type and size, and return just the
+    /// reference to the underlying memory. All elements will be initialized to
+    /// the specified value.
+    static MemRef create_array(Type, bool context_flag, size_t size, value_type value, Allocator&);
+    void create(Type = type_Normal, bool context_flag = false);
+
+    void init_from_ref(ref_type) noexcept;
+    void init_from_mem(MemRef) noexcept;
+    void init_from_parent() noexcept;
+
+    size_t size() const noexcept;
+    bool is_empty() const noexcept;
+
+    void insert(size_t ndx, value_type value);
+    void add(value_type value);
+    void set(size_t ndx, value_type value) noexcept;
+    value_type get(size_t ndx) const noexcept;
+    static value_type get(const char* header, size_t ndx) noexcept;
+    void get_chunk(size_t ndx, value_type res[8]) const noexcept;
+    void set_null(size_t ndx) noexcept;
+    bool is_null(size_t ndx) const noexcept;
+    int64_t null_value() const noexcept;
+
+    value_type operator[](size_t ndx) const noexcept;
+    value_type front() const noexcept;
+    value_type back() const noexcept;
+    void erase(size_t ndx);
+    void erase(size_t begin, size_t end);
+    void truncate(size_t size);
+    void clear();
+    void set_all_to_zero();
+
+    void move(size_t begin, size_t end, size_t dest_begin);
+    void move_backward(size_t begin, size_t end, size_t dest_end);
+
+    size_t lower_bound(int64_t value) const noexcept;
+    size_t upper_bound(int64_t value) const noexcept;
+
+    int64_t sum(size_t start = 0, size_t end = npos) const;
+    size_t count(int64_t value) const noexcept;
+    bool maximum(int64_t& result, size_t start = 0, size_t end = npos, size_t* return_ndx = nullptr) const;
+    bool minimum(int64_t& result, size_t start = 0, size_t end = npos, size_t* return_ndx = nullptr) const;
+
+    bool find(int cond, Action action, value_type value, size_t start, size_t end, size_t baseindex,
+              QueryState<int64_t>* state) const;
+
+    template <class cond, Action action, size_t bitwidth, class Callback>
+    bool find(value_type value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+              Callback callback) const;
+
+    // This is the one installed into the m_finder slots.
+    template <class cond, Action action, size_t bitwidth>
+    bool find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state) const;
+
+    template <class cond, Action action, class Callback>
+    bool find(value_type value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+              Callback callback) const;
+
+    // Optimized implementation for release mode
+    template <class cond, Action action, size_t bitwidth, class Callback>
+    bool find_optimized(value_type value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                        Callback callback) const;
+
+    // Called for each search result
+    template <Action action, class Callback>
+    bool find_action(size_t index, value_type value, QueryState<int64_t>* state, Callback callback) const;
+
+    template <Action action, class Callback>
+    bool find_action_pattern(size_t index, uint64_t pattern, QueryState<int64_t>* state, Callback callback) const;
+
+    // Wrappers for backwards compatibility and for simple use without
+    // setting up state initialization etc
+    template <class cond>
+    size_t find_first(value_type value, size_t start = 0, size_t end = npos) const;
+
+    void find_all(IntegerColumn* result, value_type value, size_t col_offset = 0, size_t begin = 0,
+                  size_t end = npos) const;
+
+
+    size_t find_first(value_type value, size_t begin = 0, size_t end = npos) const;
+
+
+    // Overwrite Array::bptree_leaf_insert to correctly split nodes.
+    ref_type bptree_leaf_insert(size_t ndx, value_type value, TreeInsertBase& state);
+
+    MemRef slice(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+    /// Construct a deep copy of the specified slice of this array using the
+    /// specified target allocator. Subarrays will be cloned.
+    MemRef slice_and_clone_children(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+protected:
+    void avoid_null_collision(int64_t value);
+
+private:
+    template <bool find_max>
+    bool minmax_helper(int64_t& result, size_t start = 0, size_t end = npos, size_t* return_ndx = nullptr) const;
+
+    int_fast64_t choose_random_null(int64_t incoming) const;
+    void replace_nulls_with(int64_t new_null);
+    bool can_use_as_null(int64_t value) const;
+};
+
+
+// Implementation:
+
+inline ArrayInteger::ArrayInteger(Allocator& allocator) noexcept
+    : Array(allocator)
+{
+    m_is_inner_bptree_node = false;
+}
+
+inline void ArrayInteger::add(int64_t value)
+{
+    Array::add(value);
+}
+
+inline int64_t ArrayInteger::get(size_t ndx) const noexcept
+{
+    return Array::get(ndx);
+}
+
+inline int64_t ArrayInteger::get(const char* header, size_t ndx) noexcept
+{
+    return Array::get(header, ndx);
+}
+
+inline void ArrayInteger::set(size_t ndx, int64_t value)
+{
+    Array::set(ndx, value);
+}
+
+inline void ArrayInteger::set_uint(size_t ndx, uint_fast64_t value) noexcept
+{
+    // When a value of a signed type is converted to an unsigned type, the C++
+    // standard guarantees that negative values are converted from the native
+    // representation to 2's complement, but the effect of conversions in the
+    // opposite direction is left unspecified by the
+    // standard. `realm::util::from_twos_compl()` is used here to perform the
+    // correct opposite unsigned-to-signed conversion, which reduces to a no-op
+    // when 2's complement is the native representation of negative values.
+    set(ndx, util::from_twos_compl<int_fast64_t>(value));
+}
+
+inline bool ArrayInteger::compare(const ArrayInteger& a) const noexcept
+{
+    if (a.size() != size())
+        return false;
+
+    for (size_t i = 0; i < size(); ++i) {
+        if (get(i) != a.get(i))
+            return false;
+    }
+
+    return true;
+}
+
+inline int64_t ArrayInteger::front() const noexcept
+{
+    return Array::front();
+}
+
+inline int64_t ArrayInteger::back() const noexcept
+{
+    return Array::back();
+}
+
+inline void ArrayInteger::adjust(size_t ndx, int_fast64_t diff)
+{
+    Array::adjust(ndx, diff);
+}
+
+inline void ArrayInteger::adjust(size_t begin, size_t end, int_fast64_t diff)
+{
+    Array::adjust(begin, end, diff);
+}
+
+inline void ArrayInteger::adjust_ge(int_fast64_t limit, int_fast64_t diff)
+{
+    Array::adjust_ge(limit, diff);
+}
+
+inline size_t ArrayInteger::lower_bound(int64_t value) const noexcept
+{
+    return lower_bound_int(value);
+}
+
+inline size_t ArrayInteger::upper_bound(int64_t value) const noexcept
+{
+    return upper_bound_int(value);
+}
+
+
+inline ArrayIntNull::ArrayIntNull(Allocator& allocator) noexcept
+    : Array(allocator)
+{
+}
+
+inline ArrayIntNull::~ArrayIntNull() noexcept
+{
+}
+
+inline void ArrayIntNull::create(Type type, bool context_flag)
+{
+    MemRef r = create_array(type, context_flag, 0, util::none, m_alloc);
+    init_from_mem(r);
+}
+
+
+inline size_t ArrayIntNull::size() const noexcept
+{
+    return Array::size() - 1;
+}
+
+inline bool ArrayIntNull::is_empty() const noexcept
+{
+    return size() == 0;
+}
+
+inline void ArrayIntNull::insert(size_t ndx, value_type value)
+{
+    if (value) {
+        avoid_null_collision(*value);
+        Array::insert(ndx + 1, *value);
+    }
+    else {
+        Array::insert(ndx + 1, null_value());
+    }
+}
+
+inline void ArrayIntNull::add(value_type value)
+{
+    if (value) {
+        avoid_null_collision(*value);
+        Array::add(*value);
+    }
+    else {
+        Array::add(null_value());
+    }
+}
+
+inline void ArrayIntNull::set(size_t ndx, value_type value) noexcept
+{
+    if (value) {
+        avoid_null_collision(*value);
+        Array::set(ndx + 1, *value);
+    }
+    else {
+        Array::set(ndx + 1, null_value());
+    }
+}
+
+inline void ArrayIntNull::set_null(size_t ndx) noexcept
+{
+    Array::set(ndx + 1, null_value());
+}
+
+inline ArrayIntNull::value_type ArrayIntNull::get(size_t ndx) const noexcept
+{
+    int64_t value = Array::get(ndx + 1);
+    if (value == null_value()) {
+        return util::none;
+    }
+    return util::some<int64_t>(value);
+}
+
+inline ArrayIntNull::value_type ArrayIntNull::get(const char* header, size_t ndx) noexcept
+{
+    int64_t null_value = Array::get(header, 0);
+    int64_t value = Array::get(header, ndx + 1);
+    if (value == null_value) {
+        return util::none;
+    }
+    else {
+        return util::some<int64_t>(value);
+    }
+}
+
+inline bool ArrayIntNull::is_null(size_t ndx) const noexcept
+{
+    return !get(ndx);
+}
+
+inline int64_t ArrayIntNull::null_value() const noexcept
+{
+    return Array::get(0);
+}
+
+inline ArrayIntNull::value_type ArrayIntNull::operator[](size_t ndx) const noexcept
+{
+    return get(ndx);
+}
+
+inline ArrayIntNull::value_type ArrayIntNull::front() const noexcept
+{
+    return get(0);
+}
+
+inline ArrayIntNull::value_type ArrayIntNull::back() const noexcept
+{
+    return Array::back();
+}
+
+inline void ArrayIntNull::erase(size_t ndx)
+{
+    Array::erase(ndx + 1);
+}
+
+inline void ArrayIntNull::erase(size_t begin, size_t end)
+{
+    Array::erase(begin + 1, end + 1);
+}
+
+inline void ArrayIntNull::truncate(size_t to_size)
+{
+    Array::truncate(to_size + 1);
+}
+
+inline void ArrayIntNull::clear()
+{
+    truncate(0);
+}
+
+inline void ArrayIntNull::set_all_to_zero()
+{
+    // FIXME: Array::set_all_to_zero does something else
+    for (size_t i = 0; i < size(); ++i) {
+        set(i, 0);
+    }
+}
+
+inline void ArrayIntNull::move(size_t begin, size_t end, size_t dest_begin)
+{
+    Array::move(begin + 1, end + 1, dest_begin + 1);
+}
+
+inline void ArrayIntNull::move_backward(size_t begin, size_t end, size_t dest_end)
+{
+    Array::move_backward(begin + 1, end + 1, dest_end + 1);
+}
+
+inline size_t ArrayIntNull::lower_bound(int64_t value) const noexcept
+{
+    // FIXME: Consider this behaviour with NULLs.
+    // Array::lower_bound_int assumes an already sorted array, but
+    // this array could be sorted with nulls first or last.
+    return Array::lower_bound_int(value);
+}
+
+inline size_t ArrayIntNull::upper_bound(int64_t value) const noexcept
+{
+    // FIXME: see lower_bound
+    return Array::upper_bound_int(value);
+}
+
+inline int64_t ArrayIntNull::sum(size_t start, size_t end) const
+{
+    // FIXME: Optimize
+    int64_t sum_of_range = 0;
+    if (end == npos)
+        end = size();
+    for (size_t i = start; i < end; ++i) {
+        value_type x = get(i);
+        if (x) {
+            sum_of_range += *x;
+        }
+    }
+    return sum_of_range;
+}
+
+inline size_t ArrayIntNull::count(int64_t value) const noexcept
+{
+    size_t count_of_value = Array::count(value);
+    if (value == null_value()) {
+        --count_of_value;
+    }
+    return count_of_value;
+}
+
+// FIXME: Optimize
+template <bool find_max>
+inline bool ArrayIntNull::minmax_helper(int64_t& result, size_t start, size_t end, size_t* return_ndx) const
+{
+    size_t best_index = 1;
+
+    if (end == npos) {
+        end = m_size;
+    }
+
+    ++start;
+
+    REALM_ASSERT(start < m_size && end <= m_size && start < end);
+
+    if (m_size == 1) {
+        // empty array
+        return false;
+    }
+
+    if (m_width == 0) {
+        if (return_ndx)
+            *return_ndx = best_index - 1;
+        result = 0;
+        return true;
+    }
+
+    int64_t m = Array::get(start);
+
+    const int64_t null_val = null_value();
+    for (; start < end; ++start) {
+        const int64_t v = Array::get(start);
+        if (find_max ? v > m : v < m) {
+            if (v == null_val) {
+                continue;
+            }
+            m = v;
+            best_index = start;
+        }
+    }
+
+    result = m;
+    if (return_ndx) {
+        *return_ndx = best_index - 1;
+    }
+    return true;
+}
+
+inline bool ArrayIntNull::maximum(int64_t& result, size_t start, size_t end, size_t* return_ndx) const
+{
+    return minmax_helper<true>(result, start, end, return_ndx);
+}
+
+inline bool ArrayIntNull::minimum(int64_t& result, size_t start, size_t end, size_t* return_ndx) const
+{
+    return minmax_helper<false>(result, start, end, return_ndx);
+}
+
+inline bool ArrayIntNull::find(int cond, Action action, value_type value, size_t start, size_t end, size_t baseindex,
+                               QueryState<int64_t>* state) const
+{
+    if (value) {
+        return Array::find(cond, action, *value, start, end, baseindex, state, true /*treat as nullable array*/,
+                           false /*search parameter given in 'value' argument*/);
+    }
+    else {
+        return Array::find(cond, action, 0 /* unused dummy*/, start, end, baseindex, state,
+                           true /*treat as nullable array*/, true /*search for null, ignore value argument*/);
+    }
+}
+
+template <class cond, Action action, size_t bitwidth, class Callback>
+bool ArrayIntNull::find(value_type value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                        Callback callback) const
+{
+    if (value) {
+        return Array::find<cond, action>(*value, start, end, baseindex, state, std::forward<Callback>(callback),
+                                         true /*treat as nullable array*/,
+                                         false /*search parameter given in 'value' argument*/);
+    }
+    else {
+        return Array::find<cond, action>(0 /*ignored*/, start, end, baseindex, state,
+                                         std::forward<Callback>(callback), true /*treat as nullable array*/,
+                                         true /*search for null, ignore value argument*/);
+    }
+}
+
+
+template <class cond, Action action, size_t bitwidth>
+bool ArrayIntNull::find(int64_t value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state) const
+{
+    return Array::find<cond, action>(value, start, end, baseindex, state, true /*treat as nullable array*/,
+                                     false /*search parameter given in 'value' argument*/);
+}
+
+
+template <class cond, Action action, class Callback>
+bool ArrayIntNull::find(value_type value, size_t start, size_t end, size_t baseindex, QueryState<int64_t>* state,
+                        Callback callback) const
+{
+    if (value) {
+        return Array::find<cond, action>(*value, start, end, baseindex, state, std::forward<Callback>(callback),
+                                         true /*treat as nullable array*/,
+                                         false /*search parameter given in 'value' argument*/);
+    }
+    else {
+        return Array::find<cond, action>(0 /*ignored*/, start, end, baseindex, state,
+                                         std::forward<Callback>(callback), true /*treat as nullable array*/,
+                                         true /*search for null, ignore value argument*/);
+    }
+}
+
+
+template <Action action, class Callback>
+bool ArrayIntNull::find_action(size_t index, value_type value, QueryState<int64_t>* state, Callback callback) const
+{
+    if (value) {
+        return Array::find_action<action, Callback>(index, *value, state, callback, true /*treat as nullable array*/,
+                                                    false /*search parameter given in 'value' argument*/);
+    }
+    else {
+        return Array::find_action<action, Callback>(index, 0 /* ignored */, state, callback,
+                                                    true /*treat as nullable array*/,
+                                                    true /*search for null, ignore value argument*/);
+    }
+}
+
+
+template <Action action, class Callback>
+bool ArrayIntNull::find_action_pattern(size_t index, uint64_t pattern, QueryState<int64_t>* state,
+                                       Callback callback) const
+{
+    return Array::find_action_pattern<action, Callback>(index, pattern, state, callback,
+                                                        true /*treat as nullable array*/,
+                                                        false /*search parameter given in 'value' argument*/);
+}
+
+
+template <class cond>
+size_t ArrayIntNull::find_first(value_type value, size_t start, size_t end) const
+{
+    QueryState<int64_t> state;
+    state.init(act_ReturnFirst, nullptr, 1);
+    if (value) {
+        Array::find<cond, act_ReturnFirst>(*value, start, end, 0, &state, Array::CallbackDummy(),
+                                           true /*treat as nullable array*/,
+                                           false /*search parameter given in 'value' argument*/);
+    }
+    else {
+        Array::find<cond, act_ReturnFirst>(0 /*ignored*/, start, end, 0, &state, Array::CallbackDummy(),
+                                           true /*treat as nullable array*/,
+                                           true /*search for null, ignore value argument*/);
+    }
+
+    if (state.m_match_count > 0)
+        return to_size_t(state.m_state);
+    else
+        return not_found;
+}
+
+inline size_t ArrayIntNull::find_first(value_type value, size_t begin, size_t end) const
+{
+    return find_first<Equal>(value, begin, end);
+}
+}
+
+#endif // REALM_ARRAY_INTEGER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_string.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_string.hpp
new file mode 100644
index 0000000..a533f32
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_string.hpp
@@ -0,0 +1,181 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_STRING_HPP
+#define REALM_ARRAY_STRING_HPP
+
+#include <realm/array.hpp>
+
+namespace realm {
+
+/*
+ArrayString stores strings as a concecutive list of fixed-length blocks of m_width bytes. The
+longest string it can store is (m_width - 1) bytes before it needs to expand.
+
+An example of the format for m_width = 4 is following sequence of bytes, where x is payload:
+
+xxx0 xx01 x002 0003 0004 (strings "xxx",. "xx", "x", "", realm::null())
+
+So each string is 0 terminated, and the last byte in a block tells how many 0s are present, except
+for a realm::null() which has the byte set to m_width (4). The byte is used to compute the length of a string
+in various functions.
+
+New: If m_witdh = 0, then all elements are realm::null(). So to add an empty string we must expand m_width
+New: StringData is null() if-and-only-if StringData::data() == 0.
+*/
+
+class ArrayString : public Array {
+public:
+    static const size_t max_width = 64;
+
+    typedef StringData value_type;
+    // Constructor defaults to non-nullable because we use non-nullable ArrayString so many places internally in core
+    // (data which isn't user payload) where null isn't needed.
+    explicit ArrayString(Allocator&, bool nullable = false) noexcept;
+    ~ArrayString() noexcept override
+    {
+    }
+
+    bool is_null(size_t ndx) const;
+    void set_null(size_t ndx);
+    StringData get(size_t ndx) const noexcept;
+    StringData get_string(size_t ndx) const noexcept { return get(ndx); }
+    void add();
+    void add(StringData value);
+    void set(size_t ndx, StringData value);
+    void insert(size_t ndx, StringData value);
+    void erase(size_t ndx);
+
+    size_t count(StringData value, size_t begin = 0, size_t end = npos) const noexcept;
+    size_t find_first(StringData value, size_t begin = 0, size_t end = npos) const noexcept;
+    void find_all(IntegerColumn& result, StringData value, size_t add_offset = 0, size_t begin = 0,
+                  size_t end = npos);
+
+    /// Compare two string arrays for equality.
+    bool compare_string(const ArrayString&) const noexcept;
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static StringData get(const char* header, size_t ndx, bool nullable) noexcept;
+
+    ref_type bptree_leaf_insert(size_t ndx, StringData, TreeInsertBase& state);
+
+    /// Construct a string array of the specified size and return just
+    /// the reference to the underlying memory. All elements will be
+    /// initialized to the empty string.
+    static MemRef create_array(size_t size, Allocator&);
+
+    /// Create a new empty string array and attach this accessor to
+    /// it. This does not modify the parent reference information of
+    /// this accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated
+    /// underlying node. It is not owned by the accessor.
+    void create();
+
+    /// Construct a copy of the specified slice of this string array
+    /// using the specified target allocator.
+    MemRef slice(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+#ifdef REALM_DEBUG
+    void string_stats() const;
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+#endif
+
+private:
+    size_t calc_byte_len(size_t num_items, size_t width) const override;
+    size_t calc_item_count(size_t bytes, size_t width) const noexcept override;
+
+    bool m_nullable;
+};
+
+
+// Implementation:
+
+// Creates new array (but invalid, call init_from_ref() to init)
+inline ArrayString::ArrayString(Allocator& allocator, bool nullable) noexcept
+    : Array(allocator)
+    , m_nullable(nullable)
+{
+}
+
+inline void ArrayString::create()
+{
+    size_t init_size = 0;
+    MemRef mem = create_array(init_size, get_alloc()); // Throws
+    init_from_mem(mem);
+}
+
+inline MemRef ArrayString::create_array(size_t init_size, Allocator& allocator)
+{
+    bool context_flag = false;
+    int_fast64_t value = 0;
+    return Array::create(type_Normal, context_flag, wtype_Multiply, init_size, value, allocator); // Throws
+}
+
+inline StringData ArrayString::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_size);
+    if (m_width == 0)
+        return m_nullable ? realm::null() : StringData("");
+
+    const char* data = m_data + (ndx * m_width);
+    size_t array_size = (m_width - 1) - data[m_width - 1];
+
+    if (array_size == static_cast<size_t>(-1))
+        return m_nullable ? realm::null() : StringData("");
+
+    REALM_ASSERT_EX(data[array_size] == 0, data[array_size],
+                    array_size); // Realm guarantees 0 terminated return strings
+    return StringData(data, array_size);
+}
+
+inline void ArrayString::add(StringData value)
+{
+    REALM_ASSERT(!(!m_nullable && value.is_null()));
+    insert(m_size, value); // Throws
+}
+
+inline void ArrayString::add()
+{
+    add(m_nullable ? realm::null() : StringData("")); // Throws
+}
+
+inline StringData ArrayString::get(const char* header, size_t ndx, bool nullable) noexcept
+{
+    REALM_ASSERT(ndx < get_size_from_header(header));
+    uint_least8_t width = get_width_from_header(header);
+    const char* data = get_data_from_header(header) + (ndx * width);
+
+    if (width == 0)
+        return nullable ? realm::null() : StringData("");
+
+    size_t size = (width - 1) - data[width - 1];
+
+    if (size == static_cast<size_t>(-1))
+        return nullable ? realm::null() : StringData("");
+
+    return StringData(data, size);
+}
+
+
+} // namespace realm
+
+#endif // REALM_ARRAY_STRING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/array_string_long.hpp b/node_modules/realm/vendor/realm-ios/include/realm/array_string_long.hpp
new file mode 100644
index 0000000..b03d8b4
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/array_string_long.hpp
@@ -0,0 +1,229 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_STRING_LONG_HPP
+#define REALM_ARRAY_STRING_LONG_HPP
+
+#include <realm/array_blob.hpp>
+#include <realm/array_integer.hpp>
+
+namespace realm {
+
+
+class ArrayStringLong : public Array {
+public:
+    typedef StringData value_type;
+
+    explicit ArrayStringLong(Allocator&, bool nullable) noexcept;
+    ~ArrayStringLong() noexcept override
+    {
+    }
+
+    // Disable copying, this is not allowed.
+    ArrayStringLong& operator=(const ArrayStringLong&) = delete;
+    ArrayStringLong(const ArrayStringLong&) = delete;
+
+    /// Create a new empty long string array and attach this accessor to
+    /// it. This does not modify the parent reference information of
+    /// this accessor.
+    ///
+    /// Note that the caller assumes ownership of the allocated
+    /// underlying node. It is not owned by the accessor.
+    void create();
+
+    //@{
+    /// Overriding functions of Array
+    void init_from_ref(ref_type) noexcept;
+    void init_from_mem(MemRef) noexcept;
+    void init_from_parent() noexcept;
+    //@}
+
+    bool is_empty() const noexcept;
+    size_t size() const noexcept;
+
+    StringData get(size_t ndx) const noexcept;
+    StringData get_string(size_t ndx) const noexcept { return get(ndx); }
+
+
+    void add(StringData value);
+    void set(size_t ndx, StringData value);
+    void insert(size_t ndx, StringData value);
+    void erase(size_t ndx);
+    void truncate(size_t size);
+    void clear();
+    void destroy();
+
+    bool is_null(size_t ndx) const;
+    void set_null(size_t ndx);
+
+    size_t count(StringData value, size_t begin = 0, size_t end = npos) const noexcept;
+    size_t find_first(StringData value, size_t begin = 0, size_t end = npos) const noexcept;
+    void find_all(IntegerColumn& result, StringData value, size_t add_offset = 0, size_t begin = 0,
+                  size_t end = npos) const;
+
+    /// Get the specified element without the cost of constructing an
+    /// array instance. If an array instance is already available, or
+    /// you need to get multiple values, then this method will be
+    /// slower.
+    static StringData get(const char* header, size_t ndx, Allocator&, bool nullable) noexcept;
+
+    ref_type bptree_leaf_insert(size_t ndx, StringData, TreeInsertBase&);
+
+    static size_t get_size_from_header(const char*, Allocator&) noexcept;
+
+    /// Construct a long string array of the specified size and return
+    /// just the reference to the underlying memory. All elements will
+    /// be initialized to zero size blobs.
+    static MemRef create_array(size_t size, Allocator&, bool nullable);
+
+    /// Construct a copy of the specified slice of this long string
+    /// array using the specified target allocator.
+    MemRef slice(size_t offset, size_t slice_size, Allocator& target_alloc) const;
+
+#ifdef REALM_DEBUG
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+#endif
+
+    bool update_from_parent(size_t old_baseline) noexcept;
+
+private:
+    ArrayInteger m_offsets;
+    ArrayBlob m_blob;
+    Array m_nulls;
+    bool m_nullable;
+};
+
+
+// Implementation:
+inline ArrayStringLong::ArrayStringLong(Allocator& allocator, bool nullable) noexcept
+    : Array(allocator)
+    , m_offsets(allocator)
+    , m_blob(allocator)
+    , m_nulls(nullable ? allocator : Allocator::get_default())
+    , m_nullable(nullable)
+{
+    m_offsets.set_parent(this, 0);
+    m_blob.set_parent(this, 1);
+    if (nullable)
+        m_nulls.set_parent(this, 2);
+}
+
+inline void ArrayStringLong::create()
+{
+    size_t init_size = 0;
+    MemRef mem = create_array(init_size, get_alloc(), m_nullable); // Throws
+    init_from_mem(mem);
+}
+
+inline void ArrayStringLong::init_from_ref(ref_type ref) noexcept
+{
+    REALM_ASSERT(ref);
+    char* header = get_alloc().translate(ref);
+    init_from_mem(MemRef(header, ref, m_alloc));
+    m_nullable = (Array::size() == 3);
+}
+
+inline void ArrayStringLong::init_from_parent() noexcept
+{
+    ref_type ref = get_ref_from_parent();
+    init_from_ref(ref);
+}
+
+inline bool ArrayStringLong::is_empty() const noexcept
+{
+    return m_offsets.is_empty();
+}
+
+inline size_t ArrayStringLong::size() const noexcept
+{
+    return m_offsets.size();
+}
+
+inline StringData ArrayStringLong::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_offsets.size());
+
+    if (m_nullable && m_nulls.get(ndx) == 0)
+        return realm::null();
+
+    size_t begin, end;
+    if (0 < ndx) {
+        begin = to_size_t(m_offsets.get(ndx - 1));
+        end = to_size_t(m_offsets.get(ndx));
+    }
+    else {
+        begin = 0;
+        end = to_size_t(m_offsets.get(0));
+    }
+    --end; // Discount the terminating zero
+
+    return StringData(m_blob.get(begin), end - begin);
+}
+
+inline void ArrayStringLong::truncate(size_t new_size)
+{
+    REALM_ASSERT_3(new_size, <, m_offsets.size());
+
+    size_t sz = new_size ? to_size_t(m_offsets.get(new_size - 1)) : 0;
+
+    m_offsets.truncate(new_size);
+    m_blob.truncate(sz);
+    if (m_nullable)
+        m_nulls.truncate(new_size);
+}
+
+inline void ArrayStringLong::clear()
+{
+    m_blob.clear();
+    m_offsets.clear();
+    if (m_nullable)
+        m_nulls.clear();
+}
+
+inline void ArrayStringLong::destroy()
+{
+    m_blob.destroy();
+    m_offsets.destroy();
+    if (m_nullable)
+        m_nulls.destroy();
+    Array::destroy();
+}
+
+inline bool ArrayStringLong::update_from_parent(size_t old_baseline) noexcept
+{
+    bool res = Array::update_from_parent(old_baseline);
+    if (res) {
+        m_blob.update_from_parent(old_baseline);
+        m_offsets.update_from_parent(old_baseline);
+        if (m_nullable)
+            m_nulls.update_from_parent(old_baseline);
+    }
+    return res;
+}
+
+inline size_t ArrayStringLong::get_size_from_header(const char* header, Allocator& alloc) noexcept
+{
+    ref_type offsets_ref = to_ref(Array::get(header, 0));
+    const char* offsets_header = alloc.translate(offsets_ref);
+    return Array::get_size_from_header(offsets_header);
+}
+
+
+} // namespace realm
+
+#endif // REALM_ARRAY_STRING_LONG_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/binary_data.hpp b/node_modules/realm/vendor/realm-ios/include/realm/binary_data.hpp
new file mode 100644
index 0000000..a184f0c
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/binary_data.hpp
@@ -0,0 +1,239 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_BINARY_DATA_HPP
+#define REALM_BINARY_DATA_HPP
+
+#include <realm/owned_data.hpp>
+#include <realm/util/features.h>
+#include <realm/utilities.hpp>
+
+#include <algorithm>
+#include <cstddef>
+#include <ostream>
+#include <string>
+
+namespace realm {
+
+/// A reference to a chunk of binary data.
+///
+/// This class does not own the referenced memory, nor does it in any other way
+/// attempt to manage the lifetime of it.
+///
+/// \sa StringData
+class BinaryData {
+public:
+    BinaryData() noexcept
+        : m_data(nullptr)
+        , m_size(0)
+    {
+    }
+    BinaryData(const char* external_data, size_t data_size) noexcept
+        : m_data(external_data)
+        , m_size(data_size)
+    {
+    }
+    template <size_t N>
+    explicit BinaryData(const char (&external_data)[N])
+        : m_data(external_data)
+        , m_size(N)
+    {
+    }
+    template <class T, class A>
+    explicit BinaryData(const std::basic_string<char, T, A>&);
+
+    // BinaryData does not store data, callers must manage their own strings.
+    template <class T, class A>
+    BinaryData(const std::basic_string<char, T, A>&&) = delete;
+
+    template <class T, class A>
+    explicit operator std::basic_string<char, T, A>() const;
+
+    char operator[](size_t i) const noexcept
+    {
+        return m_data[i];
+    }
+
+    const char* data() const noexcept
+    {
+        return m_data;
+    }
+    size_t size() const noexcept
+    {
+        return m_size;
+    }
+
+    /// Is this a null reference?
+    ///
+    /// An instance of BinaryData is a null reference when, and only when the
+    /// stored size is zero (size()) and the stored pointer is the null pointer
+    /// (data()).
+    ///
+    /// In the case of the empty byte sequence, the stored size is still zero,
+    /// but the stored pointer is **not** the null pointer. Note that the actual
+    /// value of the pointer is immaterial in this case (as long as it is not
+    /// zero), because when the size is zero, it is an error to dereference the
+    /// pointer.
+    ///
+    /// Conversion of a BinaryData object to `bool` yields the logical negation
+    /// of the result of calling this function. In other words, a BinaryData
+    /// object is converted to true if it is not the null reference, otherwise
+    /// it is converted to false.
+    ///
+    /// It is important to understand that all of the functions and operators in
+    /// this class, and most of the functions in the Realm API in general
+    /// makes no distinction between a null reference and a reference to the
+    /// empty byte sequence. These functions and operators never look at the
+    /// stored pointer if the stored size is zero.
+    bool is_null() const noexcept;
+
+    friend bool operator==(const BinaryData&, const BinaryData&) noexcept;
+    friend bool operator!=(const BinaryData&, const BinaryData&) noexcept;
+
+    //@{
+    /// Trivial bytewise lexicographical comparison.
+    friend bool operator<(const BinaryData&, const BinaryData&) noexcept;
+    friend bool operator>(const BinaryData&, const BinaryData&) noexcept;
+    friend bool operator<=(const BinaryData&, const BinaryData&) noexcept;
+    friend bool operator>=(const BinaryData&, const BinaryData&) noexcept;
+    //@}
+
+    bool begins_with(BinaryData) const noexcept;
+    bool ends_with(BinaryData) const noexcept;
+    bool contains(BinaryData) const noexcept;
+
+    template <class C, class T>
+    friend std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>&, const BinaryData&);
+
+    explicit operator bool() const noexcept;
+
+private:
+    const char* m_data;
+    size_t m_size;
+};
+
+/// A read-only chunk of binary data.
+class OwnedBinaryData : public OwnedData {
+public:
+    using OwnedData::OwnedData;
+
+    OwnedBinaryData() = default;
+    OwnedBinaryData(const BinaryData& binary_data)
+        : OwnedData(binary_data.data(), binary_data.size())
+    {
+    }
+
+    BinaryData get() const
+    {
+        return {data(), size()};
+    }
+};
+
+
+// Implementation:
+
+template <class T, class A>
+inline BinaryData::BinaryData(const std::basic_string<char, T, A>& s)
+    : m_data(s.data())
+    , m_size(s.size())
+{
+}
+
+template <class T, class A>
+inline BinaryData::operator std::basic_string<char, T, A>() const
+{
+    return std::basic_string<char, T, A>(m_data, m_size);
+}
+
+inline bool BinaryData::is_null() const noexcept
+{
+    return !m_data;
+}
+
+inline bool operator==(const BinaryData& a, const BinaryData& b) noexcept
+{
+    return a.m_size == b.m_size && a.is_null() == b.is_null() && safe_equal(a.m_data, a.m_data + a.m_size, b.m_data);
+}
+
+inline bool operator!=(const BinaryData& a, const BinaryData& b) noexcept
+{
+    return !(a == b);
+}
+
+inline bool operator<(const BinaryData& a, const BinaryData& b) noexcept
+{
+    if (a.is_null() || b.is_null())
+        return !a.is_null() < !b.is_null();
+
+    return std::lexicographical_compare(a.m_data, a.m_data + a.m_size, b.m_data, b.m_data + b.m_size);
+}
+
+inline bool operator>(const BinaryData& a, const BinaryData& b) noexcept
+{
+    return b < a;
+}
+
+inline bool operator<=(const BinaryData& a, const BinaryData& b) noexcept
+{
+    return !(b < a);
+}
+
+inline bool operator>=(const BinaryData& a, const BinaryData& b) noexcept
+{
+    return !(a < b);
+}
+
+inline bool BinaryData::begins_with(BinaryData d) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+
+    return d.m_size <= m_size && safe_equal(m_data, m_data + d.m_size, d.m_data);
+}
+
+inline bool BinaryData::ends_with(BinaryData d) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+
+    return d.m_size <= m_size && safe_equal(m_data + m_size - d.m_size, m_data + m_size, d.m_data);
+}
+
+inline bool BinaryData::contains(BinaryData d) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+
+    return d.m_size == 0 || std::search(m_data, m_data + m_size, d.m_data, d.m_data + d.m_size) != m_data + m_size;
+}
+
+template <class C, class T>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, const BinaryData& d)
+{
+    out << "BinaryData(" << static_cast<const void*>(d.m_data) << ", " << d.m_size << ")";
+    return out;
+}
+
+inline BinaryData::operator bool() const noexcept
+{
+    return !is_null();
+}
+
+} // namespace realm
+
+#endif // REALM_BINARY_DATA_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/bptree.hpp b/node_modules/realm/vendor/realm-ios/include/realm/bptree.hpp
new file mode 100644
index 0000000..aae64de
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/bptree.hpp
@@ -0,0 +1,1271 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_BPTREE_HPP
+#define REALM_BPTREE_HPP
+
+#include <memory> // std::unique_ptr
+#include <realm/array.hpp>
+#include <realm/array_basic.hpp>
+#include <realm/column_type_traits.hpp>
+#include <realm/impl/destroy_guard.hpp>
+#include <realm/impl/output_stream.hpp>
+
+namespace realm {
+
+/// Specialize BpTree to implement column types.
+template <class T>
+class BpTree;
+
+class ArrayInteger;
+class ArrayIntNull;
+
+class BpTreeNode : public Array {
+public:
+    using Array::Array;
+    /// Get the number of elements in the B+-tree rooted at this array
+    /// node. The root must not be a leaf.
+    ///
+    /// Please avoid using this function (consider it deprecated). It
+    /// will have to be removed if we choose to get rid of the last
+    /// element of the main array of an inner B+-tree node that stores
+    /// the total number of elements in the subtree. The motivation
+    /// for removing it, is that it will significantly improve the
+    /// efficiency when inserting after, and erasing the last element.
+    size_t get_bptree_size() const noexcept;
+
+    /// The root must not be a leaf.
+    static size_t get_bptree_size_from_header(const char* root_header) noexcept;
+
+
+    /// Find the leaf node corresponding to the specified element
+    /// index index. The specified element index must refer to an
+    /// element that exists in the tree. This function must be called
+    /// on an inner B+-tree node, never a leaf. Note that according to
+    /// invar:bptree-nonempty-inner and invar:bptree-nonempty-leaf, an
+    /// inner B+-tree node can never be empty.
+    ///
+    /// This function is not obliged to instantiate intermediate array
+    /// accessors. For this reason, this function cannot be used for
+    /// operations that modify the tree, as that requires an unbroken
+    /// chain of parent array accessors between the root and the
+    /// leaf. Thus, despite the fact that the returned MemRef object
+    /// appears to allow modification of the referenced memory, the
+    /// caller must handle the memory reference as if it was
+    /// const-qualified.
+    ///
+    /// \return (`leaf_header`, `ndx_in_leaf`) where `leaf_header`
+    /// points to the the header of the located leaf, and
+    /// `ndx_in_leaf` is the local index within that leaf
+    /// corresponding to the specified element index.
+    std::pair<MemRef, size_t> get_bptree_leaf(size_t elem_ndx) const noexcept;
+
+
+    class NodeInfo;
+    class VisitHandler;
+
+    /// Visit leaves of the B+-tree rooted at this inner node,
+    /// starting with the leaf that contains the element at the
+    /// specified element index start offset, and ending when the
+    /// handler returns false. The specified element index offset must
+    /// refer to an element that exists in the tree. This function
+    /// must be called on an inner B+-tree node, never a leaf. Note
+    /// that according to invar:bptree-nonempty-inner and
+    /// invar:bptree-nonempty-leaf, an inner B+-tree node can never be
+    /// empty.
+    ///
+    /// \param elem_ndx_offset The start position (must be valid).
+    ///
+    /// \param elems_in_tree The total number of elements in the tree.
+    ///
+    /// \param handler The callback which will get called for each leaf.
+    ///
+    /// \return True if, and only if the handler has returned true for
+    /// all visited leafs.
+    bool visit_bptree_leaves(size_t elem_ndx_offset, size_t elems_in_tree, VisitHandler& handler);
+
+
+    class UpdateHandler;
+
+    /// Call the handler for every leaf. This function must be called
+    /// on an inner B+-tree node, never a leaf.
+    void update_bptree_leaves(UpdateHandler&);
+
+    /// Call the handler for the leaf that contains the element at the
+    /// specified index. This function must be called on an inner
+    /// B+-tree node, never a leaf.
+    void update_bptree_elem(size_t elem_ndx, UpdateHandler&);
+
+
+    class EraseHandler;
+
+    /// Erase the element at the specified index in the B+-tree with
+    /// the specified root. When erasing the last element, you must
+    /// pass npos in place of the index. This function must be called
+    /// with a root that is an inner B+-tree node, never a leaf.
+    ///
+    /// This function is guaranteed to succeed (not throw) if the
+    /// specified element was inserted during the current transaction,
+    /// and no other modifying operation has been carried out since
+    /// then (noexcept:bptree-erase-alt).
+    ///
+    /// FIXME: ExceptionSafety: The exception guarantee explained
+    /// above is not as powerfull as we would like it to be. Here is
+    /// what we would like: This function is guaranteed to succeed
+    /// (not throw) if the specified element was inserted during the
+    /// current transaction (noexcept:bptree-erase). This must be true
+    /// even if the element is modified after insertion, and/or if
+    /// other elements are inserted or erased around it. There are two
+    /// aspects of the current design that stand in the way of this
+    /// guarantee: (A) The fact that the node accessor, that is cached
+    /// in the column accessor, has to be reallocated/reinstantiated
+    /// when the root switches between being a leaf and an inner
+    /// node. This problem would go away if we always cached the last
+    /// used leaf accessor in the column accessor instead. (B) The
+    /// fact that replacing one child ref with another can fail,
+    /// because it may require reallocation of memory to expand the
+    /// bit-width. This can be fixed in two ways: Either have the
+    /// inner B+-tree nodes always have a bit-width of 64, or allow
+    /// the root node to be discarded and the column ref to be set to
+    /// zero in Table::m_columns.
+    static void erase_bptree_elem(BpTreeNode* root, size_t elem_ndx, EraseHandler&);
+
+    template <class TreeTraits>
+    struct TreeInsert : TreeInsertBase {
+        typename TreeTraits::value_type m_value;
+        bool m_nullable;
+    };
+
+    /// Same as bptree_insert() but insert after the last element.
+    template <class TreeTraits>
+    ref_type bptree_append(TreeInsert<TreeTraits>& state);
+
+    /// Insert an element into the B+-subtree rooted at this array
+    /// node. The element is inserted before the specified element
+    /// index. This function must be called on an inner B+-tree node,
+    /// never a leaf. If this inner node had to be split, this
+    /// function returns the `ref` of the new sibling.
+    template <class TreeTraits>
+    ref_type bptree_insert(size_t elem_ndx, TreeInsert<TreeTraits>& state);
+
+protected:
+    /// Insert a new child after original. If the parent has to be
+    /// split, this function returns the `ref` of the new parent node.
+    ref_type insert_bptree_child(Array& offsets, size_t orig_child_ndx, ref_type new_sibling_ref,
+                                 TreeInsertBase& state);
+
+    void ensure_bptree_offsets(Array& offsets);
+    void create_bptree_offsets(Array& offsets, int_fast64_t first_value);
+
+    bool do_erase_bptree_elem(size_t elem_ndx, EraseHandler&);
+};
+
+class BpTreeBase {
+public:
+    struct unattached_tag {
+    };
+
+    // Disable copying, this is not allowed.
+    BpTreeBase& operator=(const BpTreeBase&) = delete;
+    BpTreeBase(const BpTreeBase&) = delete;
+
+    // Accessor concept:
+    Allocator& get_alloc() const noexcept;
+    void destroy() noexcept;
+    void detach();
+    bool is_attached() const noexcept;
+    void set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept;
+    size_t get_ndx_in_parent() const noexcept;
+    void set_ndx_in_parent(size_t ndx) noexcept;
+    void update_from_parent(size_t old_baseline) noexcept;
+    MemRef clone_deep(Allocator& alloc) const;
+
+    // BpTree interface:
+    const Array& root() const noexcept;
+    Array& root() noexcept;
+    bool root_is_leaf() const noexcept;
+    BpTreeNode& root_as_node();
+    const BpTreeNode& root_as_node() const;
+    void introduce_new_root(ref_type new_sibling_ref, TreeInsertBase& state, bool is_append);
+    void replace_root(std::unique_ptr<Array> leaf);
+
+protected:
+    explicit BpTreeBase(std::unique_ptr<Array> root);
+    explicit BpTreeBase(BpTreeBase&&) = default;
+    BpTreeBase& operator=(BpTreeBase&&) = default;
+    std::unique_ptr<Array> m_root;
+
+    struct SliceHandler {
+        virtual MemRef slice_leaf(MemRef leaf_mem, size_t offset, size_t size, Allocator& target_alloc) = 0;
+        ~SliceHandler() noexcept
+        {
+        }
+    };
+    static ref_type write_subtree(const BpTreeNode& root, size_t slice_offset, size_t slice_size, size_t table_size,
+                                  SliceHandler&, _impl::OutputStream&);
+    friend class ColumnBase;
+    friend class ColumnBaseSimple;
+
+private:
+    struct WriteSliceHandler;
+
+    // FIXME: Move B+Tree functionality from Array to this class.
+};
+
+
+// Default implementation of BpTree. This should work for all types that have monomorphic
+// leaves (i.e. all leaves are of the same type).
+template <class T>
+class BpTree : public BpTreeBase {
+public:
+    using value_type = T;
+    using LeafType = typename ColumnTypeTraits<T>::leaf_type;
+
+    /// LeafInfo is used by get_leaf() to provide access to a leaf
+    /// without instantiating unnecessary nodes along the way.
+    /// Upon return, out_leaf with hold a pointer to the leaf containing
+    /// the index given to get_leaf(). If the index happens to be
+    /// in the root node (i.e., the root is a leaf), it will point
+    /// to the root node.
+    /// If the index isn't in the root node, fallback will be initialized
+    /// to represent the leaf holding the node, and out_leaf will be set
+    /// to point to fallback.
+    struct LeafInfo {
+        const LeafType** out_leaf;
+        LeafType* fallback;
+    };
+
+    BpTree();
+    explicit BpTree(BpTreeBase::unattached_tag);
+    explicit BpTree(Allocator& alloc);
+    REALM_DEPRECATED("Initialize with MemRef instead")
+    explicit BpTree(std::unique_ptr<Array> init_root)
+        : BpTreeBase(std::move(init_root))
+    {
+    }
+    explicit BpTree(Allocator& alloc, MemRef mem)
+        : BpTreeBase(std::unique_ptr<Array>(new LeafType(alloc)))
+    {
+        init_from_mem(alloc, mem);
+    }
+    BpTree(BpTree&&) = default;
+    BpTree& operator=(BpTree&&) = default;
+
+    // Disable copying, this is not allowed.
+    BpTree& operator=(const BpTree&) = delete;
+    BpTree(const BpTree&) = delete;
+
+    void init_from_ref(Allocator& alloc, ref_type ref);
+    void init_from_mem(Allocator& alloc, MemRef mem);
+    void init_from_parent();
+
+    size_t size() const noexcept;
+    bool is_empty() const noexcept
+    {
+        return size() == 0;
+    }
+
+    T get(size_t ndx) const noexcept;
+    bool is_null(size_t ndx) const noexcept;
+    void set(size_t, T value);
+    void set_null(size_t);
+    void insert(size_t ndx, T value, size_t num_rows = 1);
+    void erase(size_t ndx, bool is_last = false);
+    void move_last_over(size_t ndx, size_t last_row_ndx);
+    void clear();
+    T front() const noexcept;
+    T back() const noexcept;
+
+    size_t find_first(T value, size_t begin = 0, size_t end = npos) const;
+    void find_all(IntegerColumn& out_indices, T value, size_t begin = 0, size_t end = npos) const;
+
+    static MemRef create_leaf(Array::Type leaf_type, size_t size, T value, Allocator&);
+
+    /// See LeafInfo for information about what to put in the inout_leaf
+    /// parameter.
+    ///
+    /// This function cannot be used for modifying operations as it
+    /// does not ensure the presence of an unbroken chain of parent
+    /// accessors. For this reason, the identified leaf should always
+    /// be accessed through the returned const-qualified reference,
+    /// and never directly through the specfied fallback accessor.
+    void get_leaf(size_t ndx, size_t& out_ndx_in_leaf, LeafInfo& inout_leaf) const noexcept;
+
+    void update_each(BpTreeNode::UpdateHandler&);
+    void update_elem(size_t, BpTreeNode::UpdateHandler&);
+
+    void adjust(size_t ndx, T diff);
+    void adjust(T diff);
+    void adjust_ge(T limit, T diff);
+
+    ref_type write(size_t slice_offset, size_t slice_size, size_t table_size, _impl::OutputStream& out) const;
+
+#if defined(REALM_DEBUG)
+    void verify() const;
+    static size_t verify_leaf(MemRef mem, Allocator& alloc);
+#endif
+    static void leaf_to_dot(MemRef mem, ArrayParent* parent, size_t ndx_in_parent, std::ostream& out,
+                            Allocator& alloc);
+
+private:
+    LeafType& root_as_leaf();
+    const LeafType& root_as_leaf() const;
+
+    std::unique_ptr<Array> create_root_from_ref(Allocator& alloc, ref_type ref);
+    std::unique_ptr<Array> create_root_from_mem(Allocator& alloc, MemRef mem);
+
+    struct EraseHandler;
+    struct UpdateHandler;
+    struct SetNullHandler;
+    struct SliceHandler;
+    struct AdjustHandler;
+    struct AdjustGEHandler;
+
+    struct LeafValueInserter;
+    struct LeafNullInserter;
+
+    template <class TreeTraits>
+    void bptree_insert(size_t row_ndx, BpTreeNode::TreeInsert<TreeTraits>& state, size_t num_rows);
+};
+
+
+class BpTreeNode::NodeInfo {
+public:
+    MemRef m_mem;
+    Array* m_parent;
+    size_t m_ndx_in_parent;
+    size_t m_offset, m_size;
+};
+
+class BpTreeNode::VisitHandler {
+public:
+    virtual bool visit(const NodeInfo& leaf_info) = 0;
+    virtual ~VisitHandler() noexcept
+    {
+    }
+};
+
+
+class BpTreeNode::UpdateHandler {
+public:
+    virtual void update(MemRef, ArrayParent*, size_t leaf_ndx_in_parent, size_t elem_ndx_in_leaf) = 0;
+    virtual ~UpdateHandler() noexcept
+    {
+    }
+};
+
+
+class BpTreeNode::EraseHandler {
+public:
+    /// If the specified leaf has more than one element, this function
+    /// must erase the specified element from the leaf and return
+    /// false. Otherwise, when the leaf has a single element, this
+    /// function must return true without modifying the leaf. If \a
+    /// elem_ndx_in_leaf is `npos`, it refers to the last element in
+    /// the leaf. The implementation of this function must be
+    /// exception safe. This function is guaranteed to be called at
+    /// most once during each execution of Array::erase_bptree_elem(),
+    /// and *exactly* once during each *successful* execution of
+    /// Array::erase_bptree_elem().
+    virtual bool erase_leaf_elem(MemRef, ArrayParent*, size_t leaf_ndx_in_parent, size_t elem_ndx_in_leaf) = 0;
+
+    virtual void destroy_leaf(MemRef leaf_mem) noexcept = 0;
+
+    /// Must replace the current root with the specified leaf. The
+    /// implementation of this function must not destroy the
+    /// underlying root node, or any of its children, as that will be
+    /// done by Array::erase_bptree_elem(). The implementation of this
+    /// function must be exception safe.
+    virtual void replace_root_by_leaf(MemRef leaf_mem) = 0;
+
+    /// Same as replace_root_by_leaf(), but must replace the root with
+    /// an empty leaf. Also, if this function is called during an
+    /// execution of Array::erase_bptree_elem(), it is guaranteed that
+    /// it will be preceeded by a call to erase_leaf_elem().
+    virtual void replace_root_by_empty_leaf() = 0;
+
+    virtual ~EraseHandler() noexcept
+    {
+    }
+};
+
+
+/// Implementation:
+
+inline BpTreeBase::BpTreeBase(std::unique_ptr<Array> init_root)
+    : m_root(std::move(init_root))
+{
+}
+
+inline Allocator& BpTreeBase::get_alloc() const noexcept
+{
+    return m_root->get_alloc();
+}
+
+inline void BpTreeBase::destroy() noexcept
+{
+    if (m_root)
+        m_root->destroy_deep();
+}
+
+inline void BpTreeBase::detach()
+{
+    m_root->detach();
+}
+
+inline bool BpTreeBase::is_attached() const noexcept
+{
+    return m_root->is_attached();
+}
+
+inline bool BpTreeBase::root_is_leaf() const noexcept
+{
+    return !m_root->is_inner_bptree_node();
+}
+
+inline BpTreeNode& BpTreeBase::root_as_node()
+{
+    REALM_ASSERT_DEBUG(!root_is_leaf());
+    REALM_ASSERT_DEBUG(dynamic_cast<BpTreeNode*>(m_root.get()) != nullptr);
+    return static_cast<BpTreeNode&>(root());
+}
+
+inline const BpTreeNode& BpTreeBase::root_as_node() const
+{
+    Array* arr = m_root.get();
+    REALM_ASSERT_DEBUG(!root_is_leaf());
+    REALM_ASSERT_DEBUG(dynamic_cast<const BpTreeNode*>(arr) != nullptr);
+    return static_cast<const BpTreeNode&>(*arr);
+}
+
+inline void BpTreeBase::set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept
+{
+    m_root->set_parent(parent, ndx_in_parent);
+}
+
+inline size_t BpTreeBase::get_ndx_in_parent() const noexcept
+{
+    return m_root->get_ndx_in_parent();
+}
+
+inline void BpTreeBase::set_ndx_in_parent(size_t ndx) noexcept
+{
+    m_root->set_ndx_in_parent(ndx);
+}
+
+inline void BpTreeBase::update_from_parent(size_t old_baseline) noexcept
+{
+    m_root->update_from_parent(old_baseline);
+}
+
+inline MemRef BpTreeBase::clone_deep(Allocator& alloc) const
+{
+    return m_root->clone_deep(alloc);
+}
+
+inline const Array& BpTreeBase::root() const noexcept
+{
+    return *m_root;
+}
+
+inline Array& BpTreeBase::root() noexcept
+{
+    return *m_root;
+}
+
+inline size_t BpTreeNode::get_bptree_size() const noexcept
+{
+    REALM_ASSERT_DEBUG(is_inner_bptree_node());
+    int_fast64_t v = back();
+    return size_t(v / 2); // v = 1 + 2*total_elems_in_tree
+}
+
+inline size_t BpTreeNode::get_bptree_size_from_header(const char* root_header) noexcept
+{
+    REALM_ASSERT_DEBUG(get_is_inner_bptree_node_from_header(root_header));
+    size_t root_size = get_size_from_header(root_header);
+    int_fast64_t v = get(root_header, root_size - 1);
+    return size_t(v / 2); // v = 1 + 2*total_elems_in_tree
+}
+
+inline void BpTreeNode::ensure_bptree_offsets(Array& offsets)
+{
+    int_fast64_t first_value = get(0);
+    if (first_value % 2 == 0) {
+        offsets.init_from_ref(to_ref(first_value));
+    }
+    else {
+        create_bptree_offsets(offsets, first_value); // Throws
+    }
+    offsets.set_parent(this, 0);
+}
+
+
+template <class TreeTraits>
+ref_type BpTreeNode::bptree_append(TreeInsert<TreeTraits>& state)
+{
+    // FIXME: Consider exception safety. Especially, how can the split
+    // be carried out in an exception safe manner?
+    //
+    // Can split be done as a separate preparation step, such that if
+    // the actual insert fails, the split will still have occured.
+    //
+    // Unfortunately, it requires a rather significant rearrangement
+    // of the insertion flow. Instead of returning the sibling ref
+    // from insert functions, the leaf-insert functions must instead
+    // call the special bptree_insert() function on the parent, which
+    // will then cascade the split towards the root as required.
+    //
+    // At each level where a split is required (starting at the leaf):
+    //
+    //  1. Create the new sibling.
+    //
+    //  2. Copy relevant entries over such that new sibling is in
+    //     its final state.
+    //
+    //  3. Call Array::bptree_insert() on parent with sibling ref.
+    //
+    //  4. Rearrange entries in original sibling and truncate as
+    //     required (must not throw).
+    //
+    // What about the 'offsets' array? It will always be
+    // present. Consider this carefully.
+
+    REALM_ASSERT_DEBUG(size() >= 1 + 1 + 1); // At least one child
+
+    ArrayParent& childs_parent = *this;
+    size_t child_ref_ndx = size() - 2;
+    ref_type child_ref = get_as_ref(child_ref_ndx), new_sibling_ref;
+    char* child_header = static_cast<char*>(m_alloc.translate(child_ref));
+
+    bool child_is_leaf = !get_is_inner_bptree_node_from_header(child_header);
+    if (child_is_leaf) {
+        size_t elem_ndx_in_child = npos; // Append
+        new_sibling_ref = TreeTraits::leaf_insert(MemRef(child_header, child_ref, m_alloc), childs_parent,
+                                                  child_ref_ndx, m_alloc, elem_ndx_in_child, state); // Throws
+    }
+    else {
+        BpTreeNode child(m_alloc);
+        child.init_from_mem(MemRef(child_header, child_ref, m_alloc));
+        child.set_parent(&childs_parent, child_ref_ndx);
+        new_sibling_ref = child.bptree_append(state); // Throws
+    }
+
+    if (REALM_LIKELY(!new_sibling_ref)) {
+        // +2 because stored value is 1 + 2*total_elems_in_subtree
+        adjust(size() - 1, +2); // Throws
+        return 0;               // Child was not split, so parent was not split either
+    }
+
+    Array offsets(m_alloc);
+    int_fast64_t first_value = get(0);
+    if (first_value % 2 == 0) {
+        // Offsets array is present (general form)
+        offsets.init_from_ref(to_ref(first_value));
+        offsets.set_parent(this, 0);
+    }
+    size_t child_ndx = child_ref_ndx - 1;
+    return insert_bptree_child(offsets, child_ndx, new_sibling_ref, state); // Throws
+}
+
+
+template <class TreeTraits>
+ref_type BpTreeNode::bptree_insert(size_t elem_ndx, TreeInsert<TreeTraits>& state)
+{
+    REALM_ASSERT_3(size(), >=, 1 + 1 + 1); // At least one child
+
+    // Conversion to general form if in compact form. Since this
+    // conversion will occur from root to leaf, it will maintain
+    // invar:bptree-node-form.
+    Array offsets(m_alloc);
+    ensure_bptree_offsets(offsets); // Throws
+
+    size_t child_ndx, elem_ndx_in_child;
+    if (elem_ndx == 0) {
+        // Optimization for prepend
+        child_ndx = 0;
+        elem_ndx_in_child = 0;
+    }
+    else {
+        // There is a choice to be made when the element is to be
+        // inserted between two subtrees. It can either be appended to
+        // the first subtree, or it can be prepended to the second
+        // one. We currently always append to the first subtree. It is
+        // essentially a matter of using the lower vs. the upper bound
+        // when searching through the offsets array.
+        child_ndx = offsets.lower_bound_int(elem_ndx);
+        REALM_ASSERT_3(child_ndx, <, size() - 2);
+        size_t elem_ndx_offset = child_ndx == 0 ? 0 : to_size_t(offsets.get(child_ndx - 1));
+        elem_ndx_in_child = elem_ndx - elem_ndx_offset;
+    }
+
+    ArrayParent& childs_parent = *this;
+    size_t child_ref_ndx = child_ndx + 1;
+    ref_type child_ref = get_as_ref(child_ref_ndx), new_sibling_ref;
+    char* child_header = static_cast<char*>(m_alloc.translate(child_ref));
+    bool child_is_leaf = !get_is_inner_bptree_node_from_header(child_header);
+    if (child_is_leaf) {
+        REALM_ASSERT_3(elem_ndx_in_child, <=, REALM_MAX_BPNODE_SIZE);
+        new_sibling_ref = TreeTraits::leaf_insert(MemRef(child_header, child_ref, m_alloc), childs_parent,
+                                                  child_ref_ndx, m_alloc, elem_ndx_in_child, state); // Throws
+    }
+    else {
+        BpTreeNode child(m_alloc);
+        child.init_from_mem(MemRef(child_header, child_ref, m_alloc));
+        child.set_parent(&childs_parent, child_ref_ndx);
+        new_sibling_ref = child.bptree_insert(elem_ndx_in_child, state); // Throws
+    }
+
+    if (REALM_LIKELY(!new_sibling_ref)) {
+        // +2 because stored value is 1 + 2*total_elems_in_subtree
+        adjust(size() - 1, +2); // Throws
+        offsets.adjust(child_ndx, offsets.size(), +1);
+        return 0; // Child was not split, so parent was not split either
+    }
+
+    return insert_bptree_child(offsets, child_ndx, new_sibling_ref, state); // Throws
+}
+
+template <class T>
+BpTree<T>::BpTree()
+    : BpTree(Allocator::get_default())
+{
+}
+
+template <class T>
+BpTree<T>::BpTree(Allocator& alloc)
+    : BpTreeBase(std::unique_ptr<Array>(new LeafType(alloc)))
+{
+}
+
+template <class T>
+BpTree<T>::BpTree(BpTreeBase::unattached_tag)
+    : BpTreeBase(nullptr)
+{
+}
+
+template <class T>
+std::unique_ptr<Array> BpTree<T>::create_root_from_mem(Allocator& alloc, MemRef mem)
+{
+    const char* header = mem.get_addr();
+    std::unique_ptr<Array> new_root;
+    bool is_inner_bptree_node = Array::get_is_inner_bptree_node_from_header(header);
+
+    bool can_reuse_root_accessor =
+        m_root && &m_root->get_alloc() == &alloc && m_root->is_inner_bptree_node() == is_inner_bptree_node;
+    if (can_reuse_root_accessor) {
+        if (is_inner_bptree_node) {
+            m_root->init_from_mem(mem);
+        }
+        else {
+            static_cast<LeafType&>(*m_root).init_from_mem(mem);
+        }
+        return std::move(m_root); // Same root will be reinstalled.
+    }
+
+    // Not reusing root note, allocating a new one.
+    if (is_inner_bptree_node) {
+        new_root.reset(new BpTreeNode{alloc});
+        new_root->init_from_mem(mem);
+    }
+    else {
+        std::unique_ptr<LeafType> leaf{new LeafType{alloc}};
+        leaf->init_from_mem(mem);
+        new_root = std::move(leaf);
+    }
+    return new_root;
+}
+
+template <class T>
+std::unique_ptr<Array> BpTree<T>::create_root_from_ref(Allocator& alloc, ref_type ref)
+{
+    MemRef mem = MemRef{alloc.translate(ref), ref, alloc};
+    return create_root_from_mem(alloc, mem);
+}
+
+template <class T>
+void BpTree<T>::init_from_ref(Allocator& alloc, ref_type ref)
+{
+    auto new_root = create_root_from_ref(alloc, ref);
+    replace_root(std::move(new_root));
+}
+
+template <class T>
+void BpTree<T>::init_from_mem(Allocator& alloc, MemRef mem)
+{
+    auto new_root = create_root_from_mem(alloc, mem);
+    replace_root(std::move(new_root));
+}
+
+template <class T>
+void BpTree<T>::init_from_parent()
+{
+    ref_type ref = root().get_ref_from_parent();
+    if (ref) {
+        ArrayParent* parent = m_root->get_parent();
+        size_t ndx_in_parent = m_root->get_ndx_in_parent();
+        auto new_root = create_root_from_ref(get_alloc(), ref);
+        new_root->set_parent(parent, ndx_in_parent);
+        m_root = std::move(new_root);
+    }
+    else {
+        m_root->detach();
+    }
+}
+
+template <class T>
+typename BpTree<T>::LeafType& BpTree<T>::root_as_leaf()
+{
+    REALM_ASSERT_DEBUG(root_is_leaf());
+    REALM_ASSERT_DEBUG(dynamic_cast<LeafType*>(m_root.get()) != nullptr);
+    return static_cast<LeafType&>(root());
+}
+
+template <class T>
+const typename BpTree<T>::LeafType& BpTree<T>::root_as_leaf() const
+{
+    REALM_ASSERT_DEBUG(root_is_leaf());
+    REALM_ASSERT_DEBUG(dynamic_cast<const LeafType*>(m_root.get()) != nullptr);
+    return static_cast<const LeafType&>(root());
+}
+
+template <class T>
+size_t BpTree<T>::size() const noexcept
+{
+    if (root_is_leaf()) {
+        return root_as_leaf().size();
+    }
+    return root_as_node().get_bptree_size();
+}
+
+template <class T>
+T BpTree<T>::back() const noexcept
+{
+    // FIXME: slow
+    return get(size() - 1);
+}
+
+namespace _impl {
+
+// NullableOrNothing encapsulates the behavior of nullable and
+// non-nullable leaf types, so that non-nullable leaf types
+// don't have to implement is_null/set_null but BpTree can still
+// support the interface (and return false / assert when null
+// is not supported).
+template <class Leaf>
+struct NullableOrNothing {
+    static bool is_null(const Leaf& leaf, size_t ndx)
+    {
+        return leaf.is_null(ndx);
+    }
+    static void set_null(Leaf& leaf, size_t ndx)
+    {
+        leaf.set_null(ndx);
+    }
+};
+template <>
+struct NullableOrNothing<ArrayInteger> {
+    static bool is_null(const ArrayInteger&, size_t)
+    {
+        return false;
+    }
+    static void set_null(ArrayInteger&, size_t)
+    {
+        REALM_ASSERT_RELEASE(false);
+    }
+};
+}
+
+template <class T>
+bool BpTree<T>::is_null(size_t ndx) const noexcept
+{
+    if (root_is_leaf()) {
+        return _impl::NullableOrNothing<LeafType>::is_null(root_as_leaf(), ndx);
+    }
+    LeafType fallback(get_alloc());
+    const LeafType* leaf;
+    LeafInfo leaf_info{&leaf, &fallback};
+    size_t ndx_in_leaf;
+    get_leaf(ndx, ndx_in_leaf, leaf_info);
+    return _impl::NullableOrNothing<LeafType>::is_null(*leaf, ndx_in_leaf);
+}
+
+template <class T>
+T BpTree<T>::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_DEBUG_EX(ndx < size(), ndx, size());
+    if (root_is_leaf()) {
+        return root_as_leaf().get(ndx);
+    }
+
+    // Use direct getter to avoid initializing leaf array:
+    std::pair<MemRef, size_t> p = root_as_node().get_bptree_leaf(ndx);
+    const char* leaf_header = p.first.get_addr();
+    size_t ndx_in_leaf = p.second;
+    return LeafType::get(leaf_header, ndx_in_leaf);
+}
+
+template <class T>
+template <class TreeTraits>
+void BpTree<T>::bptree_insert(size_t row_ndx, BpTreeNode::TreeInsert<TreeTraits>& state, size_t num_rows)
+{
+    ref_type new_sibling_ref;
+    for (size_t i = 0; i < num_rows; ++i) {
+        size_t row_ndx_2 = row_ndx == realm::npos ? realm::npos : row_ndx + i;
+        if (root_is_leaf()) {
+            REALM_ASSERT_DEBUG(row_ndx_2 == realm::npos || row_ndx_2 < REALM_MAX_BPNODE_SIZE);
+            new_sibling_ref = root_as_leaf().bptree_leaf_insert(row_ndx_2, state.m_value, state);
+        }
+        else {
+            if (row_ndx_2 == realm::npos) {
+                new_sibling_ref = root_as_node().bptree_append(state); // Throws
+            }
+            else {
+                new_sibling_ref = root_as_node().bptree_insert(row_ndx_2, state); // Throws
+            }
+        }
+
+        if (REALM_UNLIKELY(new_sibling_ref)) {
+            bool is_append = row_ndx_2 == realm::npos;
+            introduce_new_root(new_sibling_ref, state, is_append);
+        }
+    }
+}
+
+template <class T>
+struct BpTree<T>::LeafValueInserter {
+    using value_type = T;
+    T m_value;
+    LeafValueInserter(T value)
+        : m_value(std::move(value))
+    {
+    }
+
+    // TreeTraits concept:
+    static ref_type leaf_insert(MemRef leaf_mem, ArrayParent& parent, size_t ndx_in_parent, Allocator& alloc,
+                                size_t ndx_in_leaf, BpTreeNode::TreeInsert<LeafValueInserter>& state)
+    {
+        LeafType leaf{alloc};
+        leaf.init_from_mem(leaf_mem);
+        leaf.set_parent(&parent, ndx_in_parent);
+        // Should not move out of m_value, because the same inserter may be used to perform
+        // multiple insertions (for example, if num_rows > 1).
+        return leaf.bptree_leaf_insert(ndx_in_leaf, state.m_value, state);
+    }
+};
+
+template <class T>
+struct BpTree<T>::LeafNullInserter {
+    using value_type = null;
+    // TreeTraits concept:
+    static ref_type leaf_insert(MemRef leaf_mem, ArrayParent& parent, size_t ndx_in_parent, Allocator& alloc,
+                                size_t ndx_in_leaf, BpTreeNode::TreeInsert<LeafNullInserter>& state)
+    {
+        LeafType leaf{alloc};
+        leaf.init_from_mem(leaf_mem);
+        leaf.set_parent(&parent, ndx_in_parent);
+        return leaf.bptree_leaf_insert(ndx_in_leaf, null{}, state);
+    }
+};
+
+template <class T>
+void BpTree<T>::insert(size_t row_ndx, T value, size_t num_rows)
+{
+    REALM_ASSERT_DEBUG(row_ndx == npos || row_ndx < size());
+    BpTreeNode::TreeInsert<LeafValueInserter> inserter;
+    inserter.m_value = std::move(value);
+    inserter.m_nullable = std::is_same<T, util::Optional<int64_t>>::value; // FIXME
+    bptree_insert(row_ndx, inserter, num_rows);                            // Throws
+}
+
+template <class T>
+struct BpTree<T>::UpdateHandler : BpTreeNode::UpdateHandler {
+    LeafType m_leaf;
+    const T m_value;
+    UpdateHandler(BpTreeBase& tree, T value) noexcept
+        : m_leaf(tree.get_alloc())
+        , m_value(std::move(value))
+    {
+    }
+    void update(MemRef mem, ArrayParent* parent, size_t ndx_in_parent, size_t elem_ndx_in_leaf) override
+    {
+        m_leaf.init_from_mem(mem);
+        m_leaf.set_parent(parent, ndx_in_parent);
+        m_leaf.set(elem_ndx_in_leaf, m_value); // Throws
+    }
+};
+
+template <class T>
+struct BpTree<T>::SetNullHandler : BpTreeNode::UpdateHandler {
+    LeafType m_leaf;
+    SetNullHandler(BpTreeBase& tree) noexcept
+        : m_leaf(tree.get_alloc())
+    {
+    }
+    void update(MemRef mem, ArrayParent* parent, size_t ndx_in_parent, size_t elem_ndx_in_leaf) override
+    {
+        m_leaf.init_from_mem(mem);
+        m_leaf.set_parent(parent, ndx_in_parent);
+        _impl::NullableOrNothing<LeafType>::set_null(m_leaf, elem_ndx_in_leaf); // Throws
+    }
+};
+
+template <class T>
+void BpTree<T>::set(size_t ndx, T value)
+{
+    if (root_is_leaf()) {
+        root_as_leaf().set(ndx, std::move(value));
+    }
+    else {
+        UpdateHandler set_leaf_elem(*this, std::move(value));
+        static_cast<BpTreeNode*>(m_root.get())->update_bptree_elem(ndx, set_leaf_elem); // Throws
+    }
+}
+
+template <class T>
+void BpTree<T>::set_null(size_t ndx)
+{
+    if (root_is_leaf()) {
+        _impl::NullableOrNothing<LeafType>::set_null(root_as_leaf(), ndx);
+    }
+    else {
+        SetNullHandler set_leaf_elem(*this);
+        static_cast<BpTreeNode*>(m_root.get())->update_bptree_elem(ndx, set_leaf_elem); // Throws;
+    }
+}
+
+template <class T>
+struct BpTree<T>::EraseHandler : BpTreeNode::EraseHandler {
+    BpTreeBase& m_tree;
+    LeafType m_leaf;
+    bool m_leaves_have_refs; // FIXME: Should be able to eliminate this.
+    EraseHandler(BpTreeBase& tree) noexcept
+        : m_tree(tree)
+        , m_leaf(tree.get_alloc())
+        , m_leaves_have_refs(false)
+    {
+    }
+    bool erase_leaf_elem(MemRef leaf_mem, ArrayParent* parent, size_t leaf_ndx_in_parent,
+                         size_t elem_ndx_in_leaf) override
+    {
+        m_leaf.init_from_mem(leaf_mem);
+        REALM_ASSERT_3(m_leaf.size(), >=, 1);
+        size_t last_ndx = m_leaf.size() - 1;
+        if (last_ndx == 0) {
+            m_leaves_have_refs = m_leaf.has_refs();
+            return true;
+        }
+        m_leaf.set_parent(parent, leaf_ndx_in_parent);
+        size_t ndx = elem_ndx_in_leaf;
+        if (ndx == npos)
+            ndx = last_ndx;
+        m_leaf.erase(ndx); // Throws
+        return false;
+    }
+    void destroy_leaf(MemRef leaf_mem) noexcept override
+    {
+        // FIXME: Seems like this would cause file space leaks if
+        // m_leaves_have_refs is true, but consider carefully how
+        // m_leaves_have_refs get its value.
+        m_tree.get_alloc().free_(leaf_mem);
+    }
+    void replace_root_by_leaf(MemRef leaf_mem) override
+    {
+        std::unique_ptr<LeafType> leaf{new LeafType(m_tree.get_alloc())}; // Throws
+        leaf->init_from_mem(leaf_mem);
+        m_tree.replace_root(std::move(leaf)); // Throws
+    }
+    void replace_root_by_empty_leaf() override
+    {
+        std::unique_ptr<LeafType> leaf{new LeafType(m_tree.get_alloc())};            // Throws
+        leaf->create(m_leaves_have_refs ? Array::type_HasRefs : Array::type_Normal); // Throws
+        m_tree.replace_root(std::move(leaf));                                        // Throws
+    }
+};
+
+template <class T>
+void BpTree<T>::erase(size_t ndx, bool is_last)
+{
+    REALM_ASSERT_DEBUG_EX(ndx < size(), ndx, size());
+    REALM_ASSERT_DEBUG(is_last == (ndx == size() - 1));
+    if (root_is_leaf()) {
+        root_as_leaf().erase(ndx);
+    }
+    else {
+        size_t ndx_2 = is_last ? npos : ndx;
+        EraseHandler handler(*this);
+        BpTreeNode::erase_bptree_elem(&root_as_node(), ndx_2, handler);
+    }
+}
+
+template <class T>
+void BpTree<T>::move_last_over(size_t row_ndx, size_t last_row_ndx)
+{
+    // Copy value from last row over
+    T value = get(last_row_ndx);
+    set(row_ndx, value);
+    erase(last_row_ndx, true);
+}
+
+template <class T>
+void BpTree<T>::clear()
+{
+    if (root_is_leaf()) {
+        if (std::is_same<T, int64_t>::value && root().get_type() == Array::type_HasRefs) {
+            // FIXME: This is because some column types rely on integer columns
+            // to contain refs.
+            root().clear_and_destroy_children();
+        }
+        else {
+            root_as_leaf().clear();
+        }
+    }
+    else {
+        Allocator& alloc = get_alloc();
+        root().destroy_deep();
+
+        std::unique_ptr<LeafType> new_root(new LeafType(alloc));
+        new_root->create();
+        replace_root(std::move(new_root));
+    }
+}
+
+
+template <class T>
+struct BpTree<T>::AdjustHandler : BpTreeNode::UpdateHandler {
+    LeafType m_leaf;
+    const T m_diff;
+    AdjustHandler(BpTreeBase& tree, T diff)
+        : m_leaf(tree.get_alloc())
+        , m_diff(diff)
+    {
+    }
+
+    void update(MemRef mem, ArrayParent* parent, size_t ndx_in_parent, size_t) final
+    {
+        m_leaf.init_from_mem(mem);
+        m_leaf.set_parent(parent, ndx_in_parent);
+        m_leaf.adjust(0, m_leaf.size(), m_diff);
+    }
+};
+
+template <class T>
+void BpTree<T>::adjust(T diff)
+{
+    if (root_is_leaf()) {
+        root_as_leaf().adjust(0, m_root->size(), std::move(diff)); // Throws
+    }
+    else {
+        AdjustHandler adjust_leaf_elem(*this, std::move(diff));
+        root_as_node().update_bptree_leaves(adjust_leaf_elem); // Throws
+    }
+}
+
+template <class T>
+void BpTree<T>::adjust(size_t ndx, T diff)
+{
+    static_assert(std::is_arithmetic<T>::value, "adjust is undefined for non-arithmetic trees");
+    set(ndx, get(ndx) + diff);
+}
+
+template <class T>
+struct BpTree<T>::AdjustGEHandler : BpTreeNode::UpdateHandler {
+    LeafType m_leaf;
+    const T m_limit, m_diff;
+
+    AdjustGEHandler(BpTreeBase& tree, T limit, T diff)
+        : m_leaf(tree.get_alloc())
+        , m_limit(limit)
+        , m_diff(diff)
+    {
+    }
+
+    void update(MemRef mem, ArrayParent* parent, size_t ndx_in_parent, size_t) final
+    {
+        m_leaf.init_from_mem(mem);
+        m_leaf.set_parent(parent, ndx_in_parent);
+        m_leaf.adjust_ge(m_limit, m_diff);
+    }
+};
+
+template <class T>
+void BpTree<T>::adjust_ge(T limit, T diff)
+{
+    if (root_is_leaf()) {
+        root_as_leaf().adjust_ge(std::move(limit), std::move(diff)); // Throws
+    }
+    else {
+        AdjustGEHandler adjust_leaf_elem(*this, std::move(limit), std::move(diff));
+        root_as_node().update_bptree_leaves(adjust_leaf_elem); // Throws
+    }
+}
+
+template <class T>
+struct BpTree<T>::SliceHandler : public BpTreeBase::SliceHandler {
+public:
+    SliceHandler(Allocator& alloc)
+        : m_leaf(alloc)
+    {
+    }
+    MemRef slice_leaf(MemRef leaf_mem, size_t offset, size_t size, Allocator& target_alloc) override
+    {
+        m_leaf.init_from_mem(leaf_mem);
+        return m_leaf.slice_and_clone_children(offset, size, target_alloc); // Throws
+    }
+
+private:
+    LeafType m_leaf;
+};
+
+template <class T>
+ref_type BpTree<T>::write(size_t slice_offset, size_t slice_size, size_t table_size, _impl::OutputStream& out) const
+{
+    ref_type ref;
+    if (root_is_leaf()) {
+        Allocator& alloc = Allocator::get_default();
+        MemRef mem = root_as_leaf().slice_and_clone_children(slice_offset, slice_size, alloc); // Throws
+        Array slice(alloc);
+        _impl::DeepArrayDestroyGuard dg(&slice);
+        slice.init_from_mem(mem);
+        bool deep = true;
+        bool only_when_modified = false;
+        ref = slice.write(out, deep, only_when_modified); // Throws
+    }
+    else {
+        SliceHandler handler(get_alloc());
+        ref = write_subtree(root_as_node(), slice_offset, slice_size, table_size, handler, out); // Throws
+    }
+    return ref;
+}
+
+template <class T>
+MemRef BpTree<T>::create_leaf(Array::Type leaf_type, size_t size, T value, Allocator& alloc)
+{
+    bool context_flag = false;
+    MemRef mem = LeafType::create_array(leaf_type, context_flag, size, std::move(value), alloc);
+    return mem;
+}
+
+template <class T>
+void BpTree<T>::get_leaf(size_t ndx, size_t& ndx_in_leaf, LeafInfo& inout_leaf_info) const noexcept
+{
+    if (root_is_leaf()) {
+        ndx_in_leaf = ndx;
+        *inout_leaf_info.out_leaf = &root_as_leaf();
+        return;
+    }
+    std::pair<MemRef, size_t> p = root_as_node().get_bptree_leaf(ndx);
+    inout_leaf_info.fallback->init_from_mem(p.first);
+    ndx_in_leaf = p.second;
+    *inout_leaf_info.out_leaf = inout_leaf_info.fallback;
+}
+
+template <class T>
+size_t BpTree<T>::find_first(T value, size_t begin, size_t end) const
+{
+    if (root_is_leaf()) {
+        return root_as_leaf().find_first(value, begin, end);
+    }
+
+    // FIXME: It would be better to always require that 'end' is
+    // specified explicitly, since Table has the size readily
+    // available, and Array::get_bptree_size() is deprecated.
+    if (end == npos)
+        end = size();
+
+    LeafType leaf_cache(get_alloc());
+    size_t ndx_in_tree = begin;
+    while (ndx_in_tree < end) {
+        const LeafType* leaf;
+        LeafInfo leaf_info{&leaf, &leaf_cache};
+        size_t ndx_in_leaf;
+        get_leaf(ndx_in_tree, ndx_in_leaf, leaf_info);
+        size_t leaf_offset = ndx_in_tree - ndx_in_leaf;
+        size_t end_in_leaf = std::min(leaf->size(), end - leaf_offset);
+        size_t ndx = leaf->find_first(value, ndx_in_leaf, end_in_leaf); // Throws (maybe)
+        if (ndx != not_found)
+            return leaf_offset + ndx;
+        ndx_in_tree = leaf_offset + end_in_leaf;
+    }
+
+    return not_found;
+}
+
+template <class T>
+void BpTree<T>::find_all(IntegerColumn& result, T value, size_t begin, size_t end) const
+{
+    if (root_is_leaf()) {
+        root_as_leaf().find_all(&result, value, 0, begin, end); // Throws
+        return;
+    }
+
+    // FIXME: It would be better to always require that 'end' is
+    // specified explicitely, since Table has the size readily
+    // available, and Array::get_bptree_size() is deprecated.
+    if (end == npos)
+        end = size();
+
+    LeafType leaf_cache(get_alloc());
+    size_t ndx_in_tree = begin;
+    while (ndx_in_tree < end) {
+        const LeafType* leaf;
+        LeafInfo leaf_info{&leaf, &leaf_cache};
+        size_t ndx_in_leaf;
+        get_leaf(ndx_in_tree, ndx_in_leaf, leaf_info);
+        size_t leaf_offset = ndx_in_tree - ndx_in_leaf;
+        size_t end_in_leaf = std::min(leaf->size(), end - leaf_offset);
+        leaf->find_all(&result, value, leaf_offset, ndx_in_leaf, end_in_leaf); // Throws
+        ndx_in_tree = leaf_offset + end_in_leaf;
+    }
+}
+
+#if defined(REALM_DEBUG)
+template <class T>
+size_t BpTree<T>::verify_leaf(MemRef mem, Allocator& alloc)
+{
+    LeafType leaf(alloc);
+    leaf.init_from_mem(mem);
+    leaf.verify();
+    return leaf.size();
+}
+
+template <class T>
+void BpTree<T>::verify() const
+{
+    if (root_is_leaf()) {
+        root_as_leaf().verify();
+    }
+    else {
+        root().verify_bptree(&verify_leaf);
+    }
+}
+#endif // REALM_DEBUG
+
+template <class T>
+void BpTree<T>::leaf_to_dot(MemRef leaf_mem, ArrayParent* parent, size_t ndx_in_parent, std::ostream& out,
+                            Allocator& alloc)
+{
+    LeafType leaf(alloc);
+    leaf.init_from_mem(leaf_mem);
+    leaf.set_parent(parent, ndx_in_parent);
+    leaf.to_dot(out);
+}
+
+} // namespace realm
+
+#endif // REALM_BPTREE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/chunked_binary.hpp b/node_modules/realm/vendor/realm-ios/include/realm/chunked_binary.hpp
new file mode 100644
index 0000000..1e76fa8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/chunked_binary.hpp
@@ -0,0 +1,125 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_NOINST_CHUNKED_BINARY_HPP
+#define REALM_NOINST_CHUNKED_BINARY_HPP
+
+#include <realm/binary_data.hpp>
+#include <realm/column_binary.hpp>
+#include <realm/table.hpp>
+
+#include <realm/util/buffer_stream.hpp>
+#include <realm/impl/input_stream.hpp>
+
+
+namespace realm {
+
+/// ChunkedBinaryData manages a vector of BinaryData. It is used to facilitate
+/// extracting large binaries from binary columns and tables.
+class ChunkedBinaryData {
+public:
+
+    ChunkedBinaryData();
+    ChunkedBinaryData(const BinaryData& bd);
+    ChunkedBinaryData(const BinaryIterator& bd);
+    ChunkedBinaryData(const BinaryColumn& col, size_t index);
+
+    /// size() returns the number of bytes in the chunked binary.
+    /// FIXME: This operation is O(n).
+    size_t size() const noexcept;
+
+    /// is_null returns true if the chunked binary has zero chunks or if
+    /// the first chunk points to the nullptr.
+    bool is_null() const;
+
+    /// FIXME: O(n)
+    char operator[](size_t index) const;
+
+    std::string hex_dump(const char* separator = " ", int min_digits = -1) const;
+
+    void write_to(util::ResettableExpandableBufferOutputStream& out) const;
+
+    /// copy_to() copies the chunked binary data to \a buffer of size
+    /// \a buffer_size starting at \a offset in the ChunkedBinary.
+    /// copy_to() copies until the end of \a buffer or the end of
+    /// the ChunkedBinary whichever comes first.
+    /// copy_to() returns the number of copied bytes.
+    size_t copy_to(char* buffer, size_t buffer_size, size_t offset) const;
+
+    /// copy_to() allocates a buffer of size() in \a dest and
+    /// copies the chunked binary data to \a dest.
+    size_t copy_to(std::unique_ptr<char[]>& dest) const;
+
+    /// get_first_chunk() is used in situations
+    /// where it is known that there is exactly one
+    /// chunk. This is the case if the ChunkedBinary
+    /// has been constructed from BinaryData.
+    BinaryData get_first_chunk() const;
+
+private:
+    BinaryIterator m_begin;
+    friend class ChunkedBinaryInputStream;
+};
+
+// FIXME: When ChunkedBinaryData is moved into Core, this should be moved as well.
+class ChunkedBinaryInputStream : public _impl::NoCopyInputStream {
+public:
+    explicit ChunkedBinaryInputStream(const ChunkedBinaryData& chunks)
+        : m_it(chunks.m_begin)
+    {
+    }
+
+    bool next_block(const char*& begin, const char*& end) override
+    {
+        BinaryData block = m_it.get_next();
+        begin = block.data();
+        end = begin + block.size();
+        return begin != end;
+    }
+
+private:
+    BinaryIterator m_it;
+};
+
+
+/// Implementation:
+
+
+inline ChunkedBinaryData::ChunkedBinaryData()
+{
+}
+
+inline ChunkedBinaryData::ChunkedBinaryData(const BinaryData& bd) : m_begin{bd}
+{
+}
+
+inline ChunkedBinaryData::ChunkedBinaryData(const BinaryIterator& bd) : m_begin{bd}
+{
+}
+
+inline ChunkedBinaryData::ChunkedBinaryData(const BinaryColumn& col, size_t index)
+    : m_begin{&col, index}
+{
+}
+
+
+} // namespace realm
+
+#endif // REALM_NOINST_CHUNKED_BINARY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column.hpp
new file mode 100644
index 0000000..bbc6f73
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column.hpp
@@ -0,0 +1,1894 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_HPP
+#define REALM_COLUMN_HPP
+
+#include <cstdint> // unint8_t etc
+#include <cstdlib> // size_t
+#include <cmath>
+#include <vector>
+#include <memory>
+
+#include <realm/array_integer.hpp>
+#include <realm/column_type.hpp>
+#include <realm/column_fwd.hpp>
+#include <realm/spec.hpp>
+#include <realm/impl/output_stream.hpp>
+#include <realm/query_conditions.hpp>
+#include <realm/bptree.hpp>
+#include <realm/index_string.hpp>
+#include <realm/impl/destroy_guard.hpp>
+#include <realm/exceptions.hpp>
+#include <realm/table_ref.hpp>
+
+namespace realm {
+
+
+// Pre-definitions
+struct CascadeState;
+class StringIndex;
+
+template <class T>
+struct ImplicitNull;
+
+template <class T>
+struct ImplicitNull<util::Optional<T>> {
+    static constexpr bool value = true;
+};
+
+template <>
+struct ImplicitNull<int64_t> {
+    static constexpr bool value = false;
+};
+
+template <>
+struct ImplicitNull<float> {
+    static constexpr bool value = true;
+};
+
+template <>
+struct ImplicitNull<double> {
+    static constexpr bool value = true;
+};
+
+// FIXME: Add specialization for ImplicitNull for float, double, StringData, BinaryData.
+
+template <class T, class R, Action action, class Condition, class ColType>
+R aggregate(const ColType& column, T target, size_t start, size_t end, size_t limit, size_t* return_ndx);
+
+
+// Iterator with random access for Columns
+template <typename ColumnDataType>
+class ColumnRandIterator : public std::iterator<std::random_access_iterator_tag, ColumnDataType, ptrdiff_t, size_t> {
+public:
+    ColumnRandIterator(const Column<ColumnDataType>* src_col, size_t ndx = 0);
+    bool operator==(const ColumnRandIterator<ColumnDataType>& rhs) const;
+    bool operator!=(const ColumnRandIterator<ColumnDataType>& rhs) const;
+    bool operator<(const ColumnRandIterator<ColumnDataType>& rhs) const;
+    bool operator>(const ColumnRandIterator<ColumnDataType>& rhs) const;
+    bool operator<=(const ColumnRandIterator<ColumnDataType>& rhs) const;
+    bool operator>=(const ColumnRandIterator<ColumnDataType>& rhs) const;
+    ColumnRandIterator<ColumnDataType>& operator+=(ptrdiff_t movement);
+    ColumnRandIterator<ColumnDataType>& operator-=(ptrdiff_t movement);
+    ColumnRandIterator<ColumnDataType>& operator++();
+    ColumnRandIterator<ColumnDataType>& operator--();
+    ColumnRandIterator<ColumnDataType> operator++(int);
+    ColumnRandIterator<ColumnDataType> operator--(int);
+    ColumnRandIterator<ColumnDataType> operator+(ptrdiff_t movement);
+    ColumnRandIterator<ColumnDataType> operator-(ptrdiff_t movement);
+    ptrdiff_t operator-(const ColumnRandIterator<ColumnDataType>& right) const;
+    const ColumnDataType operator*() const;
+    const ColumnDataType operator->() const;
+    const ColumnDataType operator[](ptrdiff_t offset) const;
+    size_t get_col_ndx() const;
+
+protected:
+    size_t m_col_ndx;
+    const Column<ColumnDataType>* m_col;
+};
+
+/// Base class for all column types.
+class ColumnBase {
+public:
+    /// Get the number of entries in this column. This operation is relatively
+    /// slow.
+    virtual size_t size() const noexcept = 0;
+
+    /// \throw LogicError Thrown if this column is not string valued.
+    virtual void set_string(size_t row_ndx, StringData value);
+
+    /// Whether or not this column is nullable.
+    virtual bool is_nullable() const noexcept;
+
+    /// Whether or not the value at \a row_ndx is NULL. If the column is not
+    /// nullable, always returns false.
+    virtual bool is_null(size_t row_ndx) const noexcept;
+
+    /// Sets the value at \a row_ndx to be NULL.
+    /// \throw LogicError Thrown if this column is not nullable.
+    virtual void set_null(size_t row_ndx);
+
+    /// Inserts the specified number of elements into this column
+    /// starting at the specified row index. The new elements will have the
+    /// default value for the column type.
+    ///
+    /// \param row_ndx The row to start insertion at. If the row_ndx is less
+    /// than prior_num_rows then previous rows from row_ndx onwards will be
+    /// moved ahead by num_rows_to_insert.
+    ///
+    /// \param num_rows_to_insert The number of rows to insert. There is no
+    /// restriction on this value.
+    ///
+    /// \param prior_num_rows The number of elements in this column prior to the
+    /// modification.
+    ///
+    /// \param nullable Specifies whether or not this column is nullable. This
+    /// function may assert if nullable does not agree with \a is_nullable()
+    virtual void insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows, bool nullable) = 0;
+
+    /// Removes the specified number of consecutive elements from
+    /// this column, starting at the specified row index.
+    ///
+    /// \param row_ndx The row to start removal at (inclusive). This must be
+    /// less than prior_num_rows.
+    ///
+    /// \param num_rows_to_erase The number of rows to erase.
+    /// The row_ndx + num_rows_to_erase must be less than prior_num_rows.
+    ///
+    /// \param prior_num_rows The number of elements in this column prior to the
+    /// modification.
+    ///
+    /// \param broken_reciprocal_backlinks If true, link columns must assume
+    /// that reciprocal backlinks have already been removed. Non-link columns
+    /// should ignore this argument.
+    virtual void erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows,
+                            bool broken_reciprocal_backlinks) = 0;
+
+    /// Removes the element at the specified row index by
+    /// moving the element at the last row index over it. This reduces the
+    /// number of elements by one.
+    ///
+    /// \param row_ndx The row to erase. Must be less than prior_num_rows.
+    ///
+    /// \param prior_num_rows The number of elements in this column prior to the
+    /// modification.
+    ///
+    /// \param broken_reciprocal_backlinks If true, link columns must assume
+    /// that reciprocal backlinks have already been removed. Non-link columns
+    /// should ignore this argument.
+    virtual void move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool broken_reciprocal_backlinks) = 0;
+
+    /// Remove all elements from this column.
+    ///
+    /// \param num_rows The total number of rows in this column.
+    ///
+    /// \param broken_reciprocal_backlinks If true, link columns must assume
+    /// that reciprocal backlinks have already been removed. Non-link columns
+    /// should ignore this argument.
+    virtual void clear(size_t num_rows, bool broken_reciprocal_backlinks) = 0;
+
+    /// \brief Swap the elements at the specified indices.
+    ///
+    /// Behaviour is undefined if:
+    /// - \a row_ndx_1 or \a row_ndx_2 point to an invalid element (out-of
+    /// bounds)
+    /// - \a row_ndx_1 and \a row_ndx_2 point to the same value
+    virtual void swap_rows(size_t row_ndx_1, size_t row_ndx_2) = 0;
+
+    virtual void destroy() noexcept = 0;
+    void move_assign(ColumnBase& col) noexcept;
+
+    virtual ~ColumnBase() noexcept
+    {
+    }
+
+    // Disable copying, this is not supported.
+    ColumnBase& operator=(const ColumnBase&) = delete;
+    ColumnBase(const ColumnBase&) = delete;
+
+    // Getter function for index. For integer index, the caller must supply a
+    // buffer that we can store the extracted value in (it may be bitpacked, so
+    // we cannot return a pointer in to the Array as we do with String index).
+    virtual StringData get_index_data(size_t, StringIndex::StringConversionBuffer& buffer) const noexcept = 0;
+
+    // Search index
+    virtual bool supports_search_index() const noexcept;
+    virtual bool has_search_index() const noexcept;
+    virtual StringIndex* create_search_index();
+    virtual void destroy_search_index() noexcept;
+    virtual const StringIndex* get_search_index() const noexcept;
+    virtual StringIndex* get_search_index() noexcept;
+    virtual void set_search_index_ref(ref_type, ArrayParent*, size_t ndx_in_parent);
+
+    virtual Allocator& get_alloc() const noexcept = 0;
+
+    /// Returns the 'ref' of the root array.
+    virtual ref_type get_ref() const noexcept = 0;
+    virtual MemRef get_mem() const noexcept = 0;
+
+    virtual void replace_root_array(std::unique_ptr<Array> leaf) = 0;
+    virtual MemRef clone_deep(Allocator& alloc) const = 0;
+    virtual void detach(void) = 0;
+    virtual bool is_attached(void) const noexcept = 0;
+
+    static size_t get_size_from_type_and_ref(ColumnType, ref_type, Allocator&, bool) noexcept;
+
+    // These assume that the right column compile-time type has been
+    // figured out.
+    static size_t get_size_from_ref(ref_type root_ref, Allocator&);
+    static size_t get_size_from_ref(ref_type spec_ref, ref_type columns_ref, Allocator&);
+
+    /// Write a slice of this column to the specified output stream.
+    virtual ref_type write(size_t slice_offset, size_t slice_size, size_t table_size, _impl::OutputStream&) const = 0;
+
+    /// Get this column's logical index within the containing table, or npos
+    /// for free-standing or non-top-level columns.
+    size_t get_column_index() const noexcept
+    {
+        return m_column_ndx;
+    }
+
+    virtual void set_parent(ArrayParent*, size_t ndx_in_parent) noexcept = 0;
+    virtual size_t get_ndx_in_parent() const noexcept = 0;
+    virtual void set_ndx_in_parent(size_t ndx_in_parent) noexcept = 0;
+
+    /// Called to update refs and memory pointers of this column accessor and
+    /// all its nested accessors, but only in cases where the logical contents
+    /// in strictly unchanged. Group::commit(), and
+    /// SharedGroup::commit_and_continue_as_read()() are examples of such
+    /// cases. In both those cases, the purpose is to keep user visible
+    /// accessors in a valid state across a commit.
+    virtual void update_from_parent(size_t old_baseline) noexcept = 0;
+
+    //@{
+
+    /// cascade_break_backlinks_to() is called iteratively for each column by
+    /// Table::cascade_break_backlinks_to() with the same arguments as are
+    /// passed to Table::cascade_break_backlinks_to(). Link columns must
+    /// override it. The same is true for cascade_break_backlinks_to_all_rows(),
+    /// except that it is called from
+    /// Table::cascade_break_backlinks_to_all_rows(), and that it expects
+    /// Table::cascade_break_backlinks_to_all_rows() to pass the number of rows
+    /// in the table as \a num_rows.
+
+    virtual void cascade_break_backlinks_to(size_t row_ndx, CascadeState&);
+    virtual void cascade_break_backlinks_to_all_rows(size_t num_rows, CascadeState&);
+
+    //@}
+
+    void discard_child_accessors() noexcept;
+
+    /// For columns that are able to contain subtables, this function returns
+    /// the pointer to the subtable accessor at the specified row index if it
+    /// exists, otherwise it returns null. For other column types, this function
+    /// returns null.
+    virtual TableRef get_subtable_accessor(size_t row_ndx) const noexcept;
+
+    /// Detach and remove the subtable accessor at the specified row if it
+    /// exists. For column types that are unable to contain subtable, this
+    /// function does nothing.
+    virtual void discard_subtable_accessor(size_t row_ndx) noexcept;
+
+    virtual void adj_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept;
+    virtual void adj_acc_erase_row(size_t row_ndx) noexcept;
+    /// See Table::adj_acc_move_over()
+    virtual void adj_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+    virtual void adj_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept;
+    virtual void adj_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept;
+    virtual void adj_acc_merge_rows(size_t old_row_ndx, size_t new_row_ndx) noexcept;
+    virtual void adj_acc_clear_root_table() noexcept;
+
+    enum {
+        mark_Recursive = 0x01,
+        mark_LinkTargets = 0x02,
+        mark_LinkOrigins = 0x04,
+    };
+
+    virtual void mark(int type) noexcept;
+
+    virtual void bump_link_origin_table_version() noexcept;
+
+    virtual int compare_values(size_t row1, size_t row2) const noexcept = 0;
+
+    /// Refresh the dirty part of the accessor subtree rooted at this column
+    /// accessor.
+    ///
+    /// The following conditions are necessary and sufficient for the proper
+    /// operation of this function:
+    ///
+    ///  - The parent table accessor (excluding its column accessors) is in a
+    ///    valid state (already refreshed).
+    ///
+    ///  - Every subtable accessor in the subtree is marked dirty if it needs to
+    ///    be refreshed, or if it has a descendant accessor that needs to be
+    ///    refreshed.
+    ///
+    ///  - This column accessor, as well as all its descendant accessors, are in
+    ///    structural correspondence with the underlying node hierarchy whose
+    ///    root ref is stored in the parent (`Table::m_columns`) (see
+    ///    AccessorConsistencyLevels).
+    ///
+    ///  - The 'index in parent' property of the cached root array
+    ///    (`root->m_ndx_in_parent`) is valid.
+    virtual void refresh_accessor_tree(size_t new_col_ndx, const Spec&);
+
+    virtual void verify() const = 0;
+    virtual void verify(const Table&, size_t col_ndx) const;
+    virtual void to_dot(std::ostream&, StringData title = StringData()) const = 0;
+    virtual void do_dump_node_structure(std::ostream&, int level) const = 0;
+
+#ifdef REALM_DEBUG
+    void dump_node_structure() const; // To std::cerr (for GDB)
+    void bptree_to_dot(const Array* root, std::ostream& out) const;
+#endif
+
+protected:
+    using SliceHandler = BpTreeBase::SliceHandler;
+
+    ColumnBase(size_t column_ndx = npos)
+        : m_column_ndx(column_ndx)
+    {
+    }
+    ColumnBase(ColumnBase&&) = default;
+
+    // Must not assume more than minimal consistency (see
+    // AccessorConsistencyLevels).
+    virtual void do_discard_child_accessors() noexcept
+    {
+    }
+
+    //@{
+    /// \tparam L Any type with an appropriate `value_type`, %size(),
+    /// and %get() members.
+    template <class L, class T>
+    size_t lower_bound(const L& list, T value) const noexcept;
+
+    template <class L, class T>
+    size_t upper_bound(const L& list, T value) const noexcept;
+    //@}
+
+    // Node functions
+
+    class CreateHandler {
+    public:
+        virtual ref_type create_leaf(size_t size) = 0;
+        ~CreateHandler() noexcept
+        {
+        }
+    };
+
+    static ref_type create(Allocator&, size_t size, CreateHandler&);
+
+    class LeafToDot;
+    virtual void leaf_to_dot(MemRef, ArrayParent*, size_t ndx_in_parent, std::ostream&) const = 0;
+
+    template <class Column>
+    static int compare_values(const Column* column, size_t row1, size_t row2) noexcept;
+
+private:
+    size_t m_column_ndx = npos;
+
+    static ref_type build(size_t* rest_size_ptr, size_t fixed_height, Allocator&, CreateHandler&);
+};
+
+
+// FIXME: Temporary class until all column types have been migrated to use BpTree interface
+class ColumnBaseSimple : public ColumnBase {
+public:
+    //@{
+    /// Returns the array node at the root of this column, but note
+    /// that there is no guarantee that this node is an inner B+-tree
+    /// node or a leaf. This is the case for a MixedColumn in
+    /// particular.
+    Array* get_root_array() noexcept
+    {
+        return m_array.get();
+    }
+    const Array* get_root_array() const noexcept
+    {
+        return m_array.get();
+    }
+    //@}
+
+    Allocator& get_alloc() const noexcept final
+    {
+        return m_array->get_alloc();
+    }
+    void destroy() noexcept override
+    {
+        if (m_array)
+            m_array->destroy_deep();
+    }
+    ref_type get_ref() const noexcept final
+    {
+        return m_array->get_ref();
+    }
+    MemRef get_mem() const noexcept final
+    {
+        return m_array->get_mem();
+    }
+    void detach() noexcept final
+    {
+        m_array->detach();
+    }
+    bool is_attached() const noexcept final
+    {
+        return m_array->is_attached();
+    }
+    void set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept final
+    {
+        m_array->set_parent(parent, ndx_in_parent);
+    }
+    size_t get_ndx_in_parent() const noexcept final
+    {
+        return m_array->get_ndx_in_parent();
+    }
+    void set_ndx_in_parent(size_t ndx_in_parent) noexcept override
+    {
+        m_array->set_ndx_in_parent(ndx_in_parent);
+    }
+    void update_from_parent(size_t old_baseline) noexcept override
+    {
+        m_array->update_from_parent(old_baseline);
+    }
+    MemRef clone_deep(Allocator& alloc) const override
+    {
+        return m_array->clone_deep(alloc);
+    }
+
+protected:
+    ColumnBaseSimple(size_t column_ndx)
+        : ColumnBase(column_ndx)
+    {
+    }
+    ColumnBaseSimple(Array* root)
+        : m_array(root)
+    {
+    }
+    std::unique_ptr<Array> m_array;
+
+    void replace_root_array(std::unique_ptr<Array> new_root) final;
+    bool root_is_leaf() const noexcept
+    {
+        return !m_array->is_inner_bptree_node();
+    }
+
+    /// Introduce a new root node which increments the height of the
+    /// tree by one.
+    void introduce_new_root(ref_type new_sibling_ref, TreeInsertBase& state, bool is_append);
+
+    static ref_type write(const Array* root, size_t slice_offset, size_t slice_size, size_t table_size, SliceHandler&,
+                          _impl::OutputStream&);
+
+#if defined(REALM_DEBUG)
+    void tree_to_dot(std::ostream&) const;
+#endif
+};
+
+class ColumnBaseWithIndex : public ColumnBase {
+public:
+    ~ColumnBaseWithIndex() noexcept override
+    {
+    }
+    void set_ndx_in_parent(size_t ndx) noexcept override;
+    void update_from_parent(size_t old_baseline) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+    void move_assign(ColumnBaseWithIndex& col) noexcept;
+    void destroy() noexcept override;
+
+    virtual bool supports_search_index() const noexcept override
+    {
+        return true;
+    }
+    bool has_search_index() const noexcept final
+    {
+        return bool(m_search_index);
+    }
+    StringIndex* get_search_index() noexcept final
+    {
+        return m_search_index.get();
+    }
+    const StringIndex* get_search_index() const noexcept final
+    {
+        return m_search_index.get();
+    }
+    void destroy_search_index() noexcept override;
+    void set_search_index_ref(ref_type ref, ArrayParent* parent, size_t ndx_in_parent) final;
+    StringIndex* create_search_index() override = 0;
+
+protected:
+    using ColumnBase::ColumnBase;
+    ColumnBaseWithIndex(ColumnBaseWithIndex&&) = default;
+    std::unique_ptr<StringIndex> m_search_index;
+};
+
+
+/// A column (Column) is a single B+-tree, and the root of
+/// the column is the root of the B+-tree. All leaf nodes are arrays.
+template <class T>
+class Column : public ColumnBaseWithIndex {
+public:
+    using value_type = T;
+    using LeafInfo = typename BpTree<T>::LeafInfo;
+    using LeafType = typename BpTree<T>::LeafType;
+
+    static constexpr bool nullable = ImplicitNull<T>::value;
+
+    struct unattached_root_tag {
+    };
+
+    explicit Column() noexcept
+        : ColumnBaseWithIndex(npos)
+        , m_tree(Allocator::get_default())
+    {
+    }
+    REALM_DEPRECATED("Initialize with ref instead") explicit Column(std::unique_ptr<Array> root) noexcept;
+    Column(Allocator&, ref_type, size_t column_ndx = npos);
+    Column(unattached_root_tag, Allocator&);
+    Column(Column&&) noexcept = default;
+    ~Column() noexcept override;
+
+    void init_from_parent();
+    void init_from_ref(Allocator&, ref_type);
+    void init_from_mem(Allocator&, MemRef);
+    // Accessor concept:
+    void destroy() noexcept override;
+    Allocator& get_alloc() const noexcept final;
+    ref_type get_ref() const noexcept final;
+    MemRef get_mem() const noexcept final;
+    void set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept override;
+    size_t get_ndx_in_parent() const noexcept final;
+    void set_ndx_in_parent(size_t ndx) noexcept final;
+    void update_from_parent(size_t old_baseline) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+    void detach() noexcept final;
+    bool is_attached() const noexcept final;
+    MemRef clone_deep(Allocator&) const override;
+
+    void move_assign(Column&);
+
+    static size_t get_size_from_ref(ref_type root_ref, Allocator& alloc)
+    {
+        return ColumnBase::get_size_from_ref(root_ref, alloc);
+    }
+
+    size_t size() const noexcept override;
+    bool is_empty() const noexcept
+    {
+        return size() == 0;
+    }
+    bool is_nullable() const noexcept override;
+
+    /// Provides access to the leaf that contains the element at the
+    /// specified index. Upon return \a ndx_in_leaf will be set to the
+    /// corresponding index relative to the beginning of the leaf.
+    ///
+    /// LeafInfo is a struct defined by the underlying BpTree<T>
+    /// data structure, that provides a way for the caller to do
+    /// leaf caching without instantiating too many objects along
+    /// the way.
+    ///
+    /// This function cannot be used for modifying operations as it
+    /// does not ensure the presence of an unbroken chain of parent
+    /// accessors. For this reason, the identified leaf should always
+    /// be accessed through the returned const-qualified reference,
+    /// and never directly through the specfied fallback accessor.
+    void get_leaf(size_t ndx, size_t& ndx_in_leaf, LeafInfo& inout_leaf) const noexcept;
+
+    // Getting and setting values
+    T get(size_t ndx) const noexcept;
+    bool is_null(size_t ndx) const noexcept override;
+    T back() const noexcept;
+    void set(size_t, T value);
+    void set_null(size_t) override;
+    void add(T value = T{});
+    void insert(size_t ndx, T value = T{}, size_t num_rows = 1);
+    void erase(size_t row_ndx);
+    void erase(size_t row_ndx, bool is_last);
+    void move_last_over(size_t row_ndx, size_t last_row_ndx);
+    void clear();
+
+    // Index support
+    StringData get_index_data(size_t ndx, StringIndex::StringConversionBuffer& buffer) const noexcept override;
+
+    // FIXME: Remove these
+    uint64_t get_uint(size_t ndx) const noexcept;
+    ref_type get_as_ref(size_t ndx) const noexcept;
+    void set_uint(size_t ndx, uint64_t value);
+    void set_as_ref(size_t ndx, ref_type value);
+
+    template <class U>
+    void adjust(size_t ndx, U diff);
+
+    template <class U>
+    void adjust(U diff);
+
+    template <class U>
+    void adjust_ge(T limit, U diff);
+
+    size_t count(T target) const;
+
+    typename ColumnTypeTraits<T>::sum_type sum(size_t start = 0, size_t end = npos, size_t limit = npos,
+                                               size_t* return_ndx = nullptr) const;
+
+    typename ColumnTypeTraits<T>::minmax_type maximum(size_t start = 0, size_t end = npos, size_t limit = npos,
+                                                      size_t* return_ndx = nullptr) const;
+
+    typename ColumnTypeTraits<T>::minmax_type minimum(size_t start = 0, size_t end = npos, size_t limit = npos,
+                                                      size_t* return_ndx = nullptr) const;
+
+    double average(size_t start = 0, size_t end = npos, size_t limit = npos, size_t* return_ndx = nullptr) const;
+
+    size_t find_first(T value, size_t begin = 0, size_t end = npos) const;
+    void find_all(Column<int64_t>& out_indices, T value, size_t begin = 0, size_t end = npos) const;
+
+    void populate_search_index();
+    StringIndex* create_search_index() override;
+    inline bool supports_search_index() const noexcept override
+    {
+        if (realm::is_any<T, float, double>::value)
+            return false;
+        else
+            return true;
+    }
+
+
+    //@{
+    /// Find the lower/upper bound for the specified value assuming
+    /// that the elements are already sorted in ascending order
+    /// according to ordinary integer comparison.
+    size_t lower_bound(T value) const noexcept;
+    size_t upper_bound(T value) const noexcept;
+    //@}
+
+    using const_iterator = ColumnRandIterator<T>;
+
+    const_iterator cbegin() const
+    {
+        return const_iterator(this, 0); // `this` is const in a const method
+    }
+    const_iterator cend() const
+    {
+        return const_iterator(this, size());
+    }
+
+    size_t find_gte(T target, size_t start) const;
+
+    bool compare(const Column&) const noexcept;
+    int compare_values(size_t row1, size_t row2) const noexcept override;
+
+    static ref_type create(Allocator&, Array::Type leaf_type = Array::type_Normal, size_t size = 0, T value = T{});
+
+    // Overriding method in ColumnBase
+    ref_type write(size_t, size_t, size_t, _impl::OutputStream&) const override;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+
+    /// \brief Swap the elements at the specified indices.
+    ///
+    /// If this \c Column has a search index defined, it will be updated to
+    /// reflect the changes induced by the swap.
+    ///
+    /// Behaviour is undefined if:
+    /// - \a row_ndx_1 or \a row_ndx_2 point to an invalid element (out-of
+    /// bounds)
+    /// - \a row_ndx_1 and \a row_ndx_2 point to the same value
+    void swap_rows(size_t, size_t) override;
+    void clear(size_t, bool) override;
+
+    /// \param row_ndx Must be `realm::npos` if appending.
+    /// \param value The value to store at the specified row.
+    /// \param num_rows The number of rows to insert.
+    void insert_without_updating_index(size_t row_ndx, T value, size_t num_rows);
+
+    void verify() const override;
+    void to_dot(std::ostream&, StringData title) const override;
+    void do_dump_node_structure(std::ostream&, int) const override;
+#ifdef REALM_DEBUG
+    using ColumnBase::verify;
+    void tree_to_dot(std::ostream&) const;
+    MemStats stats() const;
+#endif
+
+    //@{
+    /// Returns the array node at the root of this column, but note
+    /// that there is no guarantee that this node is an inner B+-tree
+    /// node or a leaf. This is the case for a MixedColumn in
+    /// particular.
+    Array* get_root_array() noexcept
+    {
+        return &m_tree.root();
+    }
+    const Array* get_root_array() const noexcept
+    {
+        return &m_tree.root();
+    }
+    //@}
+
+protected:
+    bool root_is_leaf() const noexcept
+    {
+        return m_tree.root_is_leaf();
+    }
+    void replace_root_array(std::unique_ptr<Array> leaf) final
+    {
+        m_tree.replace_root(std::move(leaf));
+    }
+
+    void set_without_updating_index(size_t row_ndx, T value);
+    void erase_without_updating_index(size_t row_ndx, bool is_last);
+    void move_last_over_without_updating_index(size_t row_ndx, size_t last_row_ndx);
+    void swap_rows_without_updating_index(size_t row_ndx_1, size_t row_ndx_2);
+
+    /// If any element points to an array node, this function recursively
+    /// destroys that array node. Note that the same is **not** true for
+    /// IntegerColumn::do_erase() and IntegerColumn::do_move_last_over().
+    ///
+    /// FIXME: Be careful, clear_without_updating_index() currently forgets
+    /// if the leaf type is Array::type_HasRefs.
+    void clear_without_updating_index();
+
+    void leaf_to_dot(MemRef, ArrayParent*, size_t ndx_in_parent, std::ostream&) const override;
+#ifdef REALM_DEBUG
+    static void dump_node_structure(const Array& root, std::ostream&, int level);
+#endif
+    std::pair<ref_type, size_t> get_to_dot_parent(size_t ndx_in_parent) const;
+
+private:
+    class EraseLeafElem;
+    class CreateHandler;
+    class SliceHandler;
+
+    friend class Array;
+    friend class ColumnBase;
+    friend class StringIndex;
+
+    BpTree<T> m_tree;
+
+    void do_erase(size_t row_ndx, size_t num_rows_to_erase, bool is_last);
+};
+
+// Implementation:
+
+
+template <>
+inline size_t IntNullColumn::get_size_from_ref(ref_type root_ref, Allocator& alloc)
+{
+    // FIXME: Speed improvement possible by not creating instance, but tricky! This slow method is OK so far
+    // because it's only invoked by Table::get_size_from_ref() which is only used for subtables which we
+    // currently 2016) do not expose publicly.
+    IntNullColumn inc(alloc, root_ref);
+    return inc.size();
+}
+
+
+inline bool ColumnBase::supports_search_index() const noexcept
+{
+    REALM_ASSERT(!has_search_index());
+    return false;
+}
+
+inline bool ColumnBase::has_search_index() const noexcept
+{
+    return get_search_index() != nullptr;
+}
+
+inline StringIndex* ColumnBase::create_search_index()
+{
+    return nullptr;
+}
+
+inline void ColumnBase::destroy_search_index() noexcept
+{
+}
+
+inline const StringIndex* ColumnBase::get_search_index() const noexcept
+{
+    return nullptr;
+}
+
+inline StringIndex* ColumnBase::get_search_index() noexcept
+{
+    return nullptr;
+}
+
+inline void ColumnBase::set_search_index_ref(ref_type, ArrayParent*, size_t)
+{
+}
+
+inline void ColumnBase::discard_child_accessors() noexcept
+{
+    do_discard_child_accessors();
+}
+
+inline void ColumnBase::discard_subtable_accessor(size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_insert_rows(size_t, size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_erase_row(size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_move_over(size_t, size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_swap_rows(size_t, size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_move_row(size_t, size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_merge_rows(size_t, size_t) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::adj_acc_clear_root_table() noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::mark(int) noexcept
+{
+    // Noop
+}
+
+inline void ColumnBase::bump_link_origin_table_version() noexcept
+{
+    // Noop
+}
+
+template <class Column>
+int ColumnBase::compare_values(const Column* column, size_t row1, size_t row2) noexcept
+{
+    // we negate nullability such that the two ternary statements in this method can look identical to reduce
+    // risk of bugs
+    bool v1 = !column->is_null(row1);
+    bool v2 = !column->is_null(row2);
+
+    if (!v1 || !v2)
+        return v1 == v2 ? 0 : v1 < v2 ? 1 : -1;
+
+    auto a = column->get(row1);
+    auto b = column->get(row2);
+    return a == b ? 0 : a < b ? 1 : -1;
+}
+
+namespace _impl {
+template <int> struct IntTypeForSize;
+template <> struct IntTypeForSize<1> { using type = uint8_t; };
+template <> struct IntTypeForSize<2> { using type = uint16_t; };
+template <> struct IntTypeForSize<4> { using type = uint32_t; };
+template <> struct IntTypeForSize<8> { using type = uint64_t; };
+
+template <typename Float>
+int compare_float(Float a_raw, Float b_raw)
+{
+    // nans (and by extension nulls) are treated as being less than all non-nan values
+    bool a_nan = std::isnan(a_raw);
+    bool b_nan = std::isnan(b_raw);
+    if (a_nan != b_nan) {
+        return a_nan ? 1 : -1;
+    }
+
+    // Compare the values as ints, which gives correct results for IEEE floats
+    // and bypasses the usual behavior of nans not being comparable to each other
+    using IntType = typename _impl::IntTypeForSize<sizeof(Float)>::type;
+    IntType a = 0, b = 0;
+    memcpy(&a, &a_raw, sizeof(Float));
+    memcpy(&b, &b_raw, sizeof(Float));
+    return a == b ? 0 : a < b ? 1 : -1;
+}
+} // namespace _impl
+
+template <>
+inline int ColumnBase::compare_values<Column<float>>(const Column<float>* column, size_t row1, size_t row2) noexcept
+{
+    return _impl::compare_float(column->get(row1), column->get(row2));
+}
+
+template <>
+inline int ColumnBase::compare_values<Column<double>>(const Column<double>* column, size_t row1, size_t row2) noexcept
+{
+    return _impl::compare_float(column->get(row1), column->get(row2));
+}
+
+template <class T>
+void Column<T>::set_without_updating_index(size_t ndx, T value)
+{
+    m_tree.set(ndx, std::move(value));
+}
+
+template <class T>
+void Column<T>::set(size_t ndx, T value)
+{
+    REALM_ASSERT_DEBUG(ndx < size());
+    if (has_search_index()) {
+        m_search_index->set(ndx, value);
+    }
+    set_without_updating_index(ndx, std::move(value));
+}
+
+template <class T>
+void Column<T>::set_null(size_t ndx)
+{
+    REALM_ASSERT_DEBUG(ndx < size());
+    if (!is_nullable()) {
+        throw LogicError{LogicError::column_not_nullable};
+    }
+    if (has_search_index()) {
+        m_search_index->set(ndx, null{});
+    }
+    m_tree.set_null(ndx);
+}
+
+// When a value of a signed type is converted to an unsigned type, the C++ standard guarantees that negative values
+// are converted from the native representation to 2's complement, but the opposite conversion is left as undefined.
+// realm::util::from_twos_compl() is used here to perform the correct opposite unsigned-to-signed conversion,
+// which reduces to a no-op when 2's complement is the native representation of negative values.
+template <class T>
+void Column<T>::set_uint(size_t ndx, uint64_t value)
+{
+    set(ndx, util::from_twos_compl<int_fast64_t>(value));
+}
+
+template <class T>
+void Column<T>::set_as_ref(size_t ndx, ref_type ref)
+{
+    set(ndx, from_ref(ref));
+}
+
+template <class T>
+template <class U>
+void Column<T>::adjust(size_t ndx, U diff)
+{
+    REALM_ASSERT_3(ndx, <, size());
+    m_tree.adjust(ndx, diff);
+}
+
+template <class T>
+template <class U>
+void Column<T>::adjust(U diff)
+{
+    m_tree.adjust(diff);
+}
+
+template <class T>
+template <class U>
+void Column<T>::adjust_ge(T limit, U diff)
+{
+    m_tree.adjust_ge(limit, diff);
+}
+
+template <class T>
+size_t Column<T>::count(T target) const
+{
+    if (has_search_index()) {
+        return m_search_index->count(target);
+    }
+    return to_size_t(aggregate<T, int64_t, act_Count, Equal>(*this, target, 0, size(), npos, nullptr));
+}
+
+template <class T>
+typename ColumnTypeTraits<T>::sum_type Column<T>::sum(size_t start, size_t end, size_t limit,
+                                                      size_t* return_ndx) const
+{
+    using sum_type = typename ColumnTypeTraits<T>::sum_type;
+    if (nullable)
+        return aggregate<T, sum_type, act_Sum, NotNull>(*this, 0, start, end, limit, return_ndx);
+    else
+        return aggregate<T, sum_type, act_Sum, None>(*this, 0, start, end, limit, return_ndx);
+}
+
+template <class T>
+double Column<T>::average(size_t start, size_t end, size_t limit, size_t* return_ndx) const
+{
+    if (end == size_t(-1))
+        end = size();
+
+    auto s = sum(start, end, limit);
+    size_t cnt = to_size_t(aggregate<T, int64_t, act_Count, NotNull>(*this, 0, start, end, limit, nullptr));
+    if (return_ndx)
+        *return_ndx = cnt;
+    double avg = double(s) / (cnt == 0 ? 1 : cnt);
+    return avg;
+}
+
+template <class T>
+typename ColumnTypeTraits<T>::minmax_type Column<T>::minimum(size_t start, size_t end, size_t limit,
+                                                             size_t* return_ndx) const
+{
+    using R = typename ColumnTypeTraits<T>::minmax_type;
+    return aggregate<T, R, act_Min, NotNull>(*this, 0, start, end, limit, return_ndx);
+}
+
+template <class T>
+typename ColumnTypeTraits<T>::minmax_type Column<T>::maximum(size_t start, size_t end, size_t limit,
+                                                             size_t* return_ndx) const
+{
+    using R = typename ColumnTypeTraits<T>::minmax_type;
+    return aggregate<T, R, act_Max, NotNull>(*this, 0, start, end, limit, return_ndx);
+}
+
+template <class T>
+void Column<T>::get_leaf(size_t ndx, size_t& ndx_in_leaf, LeafInfo& inout_leaf_info) const noexcept
+{
+    m_tree.get_leaf(ndx, ndx_in_leaf, inout_leaf_info);
+}
+
+template <class T>
+StringData Column<T>::get_index_data(size_t ndx, StringIndex::StringConversionBuffer& buffer) const noexcept
+{
+    T x = get(ndx);
+    return to_str(x, buffer);
+}
+
+template <class T>
+void Column<T>::populate_search_index()
+{
+    REALM_ASSERT(has_search_index());
+    // Populate the index
+    size_t num_rows = size();
+    for (size_t row_ndx = 0; row_ndx != num_rows; ++row_ndx) {
+        bool is_append = true;
+        if (is_null(row_ndx)) {
+            m_search_index->insert(row_ndx, null{}, 1, is_append); // Throws
+        }
+        else {
+            T value = get(row_ndx);
+            m_search_index->insert(row_ndx, value, 1, is_append); // Throws
+        }
+    }
+}
+
+template <class T>
+StringIndex* Column<T>::create_search_index()
+{
+    if (realm::is_any<T, float, double>::value)
+        return nullptr;
+
+    REALM_ASSERT(!has_search_index());
+    REALM_ASSERT(supports_search_index());
+    m_search_index.reset(new StringIndex(this, get_alloc())); // Throws
+    populate_search_index();
+    return m_search_index.get();
+}
+
+template <class T>
+size_t Column<T>::find_first(T value, size_t begin, size_t end) const
+{
+    REALM_ASSERT_3(begin, <=, size());
+    REALM_ASSERT(end == npos || (begin <= end && end <= size()));
+
+    if (m_search_index && begin == 0 && end == npos)
+        return m_search_index->find_first(value);
+    return m_tree.find_first(value, begin, end);
+}
+
+template <class T>
+void Column<T>::find_all(IntegerColumn& result, T value, size_t begin, size_t end) const
+{
+    REALM_ASSERT_3(begin, <=, size());
+    REALM_ASSERT(end == npos || (begin <= end && end <= size()));
+
+    if (m_search_index && begin == 0 && end == npos)
+        return m_search_index->find_all(result, value);
+    return m_tree.find_all(result, value, begin, end);
+}
+
+inline size_t ColumnBase::get_size_from_ref(ref_type root_ref, Allocator& alloc)
+{
+    const char* root_header = alloc.translate(root_ref);
+    bool root_is_leaf = !Array::get_is_inner_bptree_node_from_header(root_header);
+    if (root_is_leaf)
+        return Array::get_size_from_header(root_header);
+    return BpTreeNode::get_bptree_size_from_header(root_header);
+}
+
+template <class L, class T>
+size_t ColumnBase::lower_bound(const L& list, T value) const noexcept
+{
+    size_t i = 0;
+    size_t list_size = list.size();
+    while (0 < list_size) {
+        size_t half = list_size / 2;
+        size_t mid = i + half;
+        typename L::value_type probe = list.get(mid);
+        if (probe < value) {
+            i = mid + 1;
+            list_size -= half + 1;
+        }
+        else {
+            list_size = half;
+        }
+    }
+    return i;
+}
+
+template <class L, class T>
+size_t ColumnBase::upper_bound(const L& list, T value) const noexcept
+{
+    size_t i = 0;
+    size_t list_size = list.size();
+    while (0 < list_size) {
+        size_t half = list_size / 2;
+        size_t mid = i + half;
+        typename L::value_type probe = list.get(mid);
+        if (!(value < probe)) {
+            i = mid + 1;
+            list_size -= half + 1;
+        }
+        else {
+            list_size = half;
+        }
+    }
+    return i;
+}
+
+
+inline ref_type ColumnBase::create(Allocator& alloc, size_t column_size, CreateHandler& handler)
+{
+    size_t rest_size = column_size;
+    size_t fixed_height = 0; // Not fixed
+    return build(&rest_size, fixed_height, alloc, handler);
+}
+
+template <class T>
+Column<T>::Column(Allocator& alloc, ref_type ref, size_t column_ndx)
+    : ColumnBaseWithIndex(column_ndx)
+    , m_tree(BpTreeBase::unattached_tag{})
+{
+    // fixme, must m_search_index be copied here?
+    m_tree.init_from_ref(alloc, ref);
+}
+
+template <class T>
+Column<T>::Column(unattached_root_tag, Allocator& alloc)
+    : ColumnBaseWithIndex(npos)
+    , m_tree(alloc)
+{
+}
+
+template <class T>
+Column<T>::Column(std::unique_ptr<Array> root) noexcept
+    : m_tree(std::move(root))
+{
+}
+
+template <class T>
+Column<T>::~Column() noexcept
+{
+}
+
+template <class T>
+void Column<T>::init_from_parent()
+{
+    m_tree.init_from_parent();
+}
+
+template <class T>
+void Column<T>::init_from_ref(Allocator& alloc, ref_type ref)
+{
+    m_tree.init_from_ref(alloc, ref);
+}
+
+template <class T>
+void Column<T>::init_from_mem(Allocator& alloc, MemRef mem)
+{
+    m_tree.init_from_mem(alloc, mem);
+}
+
+template <class T>
+void Column<T>::destroy() noexcept
+{
+    ColumnBaseWithIndex::destroy();
+    m_tree.destroy();
+}
+
+template <class T>
+void Column<T>::move_assign(Column<T>& col)
+{
+    ColumnBaseWithIndex::move_assign(col);
+    m_tree = std::move(col.m_tree);
+}
+
+template <class T>
+Allocator& Column<T>::get_alloc() const noexcept
+{
+    return m_tree.get_alloc();
+}
+
+template <class T>
+void Column<T>::set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept
+{
+    m_tree.set_parent(parent, ndx_in_parent);
+}
+
+template <class T>
+size_t Column<T>::get_ndx_in_parent() const noexcept
+{
+    return m_tree.get_ndx_in_parent();
+}
+
+template <class T>
+void Column<T>::set_ndx_in_parent(size_t ndx_in_parent) noexcept
+{
+    ColumnBaseWithIndex::set_ndx_in_parent(ndx_in_parent);
+    m_tree.set_ndx_in_parent(ndx_in_parent);
+}
+
+template <class T>
+void Column<T>::detach() noexcept
+{
+    m_tree.detach();
+}
+
+template <class T>
+bool Column<T>::is_attached() const noexcept
+{
+    return m_tree.is_attached();
+}
+
+template <class T>
+ref_type Column<T>::get_ref() const noexcept
+{
+    return get_root_array()->get_ref();
+}
+
+template <class T>
+MemRef Column<T>::get_mem() const noexcept
+{
+    return get_root_array()->get_mem();
+}
+
+template <class T>
+void Column<T>::update_from_parent(size_t old_baseline) noexcept
+{
+    ColumnBaseWithIndex::update_from_parent(old_baseline);
+    m_tree.update_from_parent(old_baseline);
+}
+
+template <class T>
+MemRef Column<T>::clone_deep(Allocator& alloc) const
+{
+    return m_tree.clone_deep(alloc);
+}
+
+template <class T>
+size_t Column<T>::size() const noexcept
+{
+    return m_tree.size();
+}
+
+template <class T>
+bool Column<T>::is_nullable() const noexcept
+{
+    return nullable;
+}
+
+template <class T>
+T Column<T>::get(size_t ndx) const noexcept
+{
+    return m_tree.get(ndx);
+}
+
+template <class T>
+bool Column<T>::is_null(size_t ndx) const noexcept
+{
+    return nullable && m_tree.is_null(ndx);
+}
+
+template <class T>
+T Column<T>::back() const noexcept
+{
+    return m_tree.back();
+}
+
+template <class T>
+ref_type Column<T>::get_as_ref(size_t ndx) const noexcept
+{
+    return to_ref(get(ndx));
+}
+
+template <class T>
+uint64_t Column<T>::get_uint(size_t ndx) const noexcept
+{
+    static_assert(std::is_convertible<T, uint64_t>::value, "T is not convertible to uint.");
+    return static_cast<uint64_t>(get(ndx));
+}
+
+template <class T>
+void Column<T>::add(T value)
+{
+    insert(npos, std::move(value));
+}
+
+template <class T>
+void Column<T>::insert_without_updating_index(size_t row_ndx, T value, size_t num_rows)
+{
+    size_t column_size = this->size(); // Slow
+    bool is_append = row_ndx == column_size || row_ndx == npos;
+    size_t ndx_or_npos_if_append = is_append ? npos : row_ndx;
+
+    m_tree.insert(ndx_or_npos_if_append, std::move(value), num_rows); // Throws
+}
+
+template <class T>
+void Column<T>::insert(size_t row_ndx, T value, size_t num_rows)
+{
+    size_t column_size = this->size(); // Slow
+    bool is_append = row_ndx == column_size || row_ndx == npos;
+    size_t ndx_or_npos_if_append = is_append ? npos : row_ndx;
+
+    m_tree.insert(ndx_or_npos_if_append, value, num_rows); // Throws
+
+    if (has_search_index()) {
+        row_ndx = is_append ? column_size : row_ndx;
+        m_search_index->insert(row_ndx, value, num_rows, is_append); // Throws
+    }
+}
+
+template <class T>
+void Column<T>::erase_without_updating_index(size_t row_ndx, bool is_last)
+{
+    m_tree.erase(row_ndx, is_last);
+}
+
+template <class T>
+void Column<T>::erase(size_t row_ndx)
+{
+    REALM_ASSERT(size() >= 1);
+    size_t last_row_ndx = size() - 1; // Note that size() is slow
+    bool is_last = (row_ndx == last_row_ndx);
+    erase(row_ndx, is_last); // Throws
+}
+
+template <class T>
+void Column<T>::erase(size_t row_ndx, bool is_last)
+{
+    size_t num_rows_to_erase = 1;
+    do_erase(row_ndx, num_rows_to_erase, is_last); // Throws
+}
+
+template <class T>
+void Column<T>::move_last_over_without_updating_index(size_t row_ndx, size_t last_row_ndx)
+{
+    m_tree.move_last_over(row_ndx, last_row_ndx);
+}
+
+template <class T>
+void Column<T>::move_last_over(size_t row_ndx, size_t last_row_ndx)
+{
+    REALM_ASSERT_3(row_ndx, <=, last_row_ndx);
+    REALM_ASSERT_DEBUG(last_row_ndx + 1 == size());
+
+    if (has_search_index()) {
+        // remove the value to be overwritten from index
+        bool is_last = true; // This tells StringIndex::erase() to not adjust subsequent indexes
+        m_search_index->erase<StringData>(row_ndx, is_last); // Throws
+
+        // update index to point to new location
+        if (row_ndx != last_row_ndx) {
+            T moved_value = get(last_row_ndx);
+            m_search_index->update_ref(moved_value, last_row_ndx, row_ndx); // Throws
+        }
+    }
+
+    move_last_over_without_updating_index(row_ndx, last_row_ndx);
+}
+
+template <class T>
+void Column<T>::swap_rows(size_t row_ndx_1, size_t row_ndx_2)
+{
+    REALM_ASSERT_3(row_ndx_1, <, size());
+    REALM_ASSERT_3(row_ndx_2, <, size());
+    REALM_ASSERT_DEBUG(row_ndx_1 != row_ndx_2);
+
+    if (has_search_index()) {
+        T value_1 = get(row_ndx_1);
+        T value_2 = get(row_ndx_2);
+        size_t column_size = this->size();
+        bool row_ndx_1_is_last = row_ndx_1 == column_size - 1;
+        bool row_ndx_2_is_last = row_ndx_2 == column_size - 1;
+        m_search_index->erase<StringData>(row_ndx_1, row_ndx_1_is_last);
+        m_search_index->insert(row_ndx_1, value_2, 1, row_ndx_1_is_last);
+
+        m_search_index->erase<StringData>(row_ndx_2, row_ndx_2_is_last);
+        m_search_index->insert(row_ndx_2, value_1, 1, row_ndx_2_is_last);
+    }
+
+    swap_rows_without_updating_index(row_ndx_1, row_ndx_2);
+}
+
+template <class T>
+void Column<T>::swap_rows_without_updating_index(size_t row_ndx_1, size_t row_ndx_2)
+{
+    // FIXME: This can be optimized with direct getters and setters.
+    T value_1 = get(row_ndx_1);
+    T value_2 = get(row_ndx_2);
+    m_tree.set(row_ndx_1, value_2);
+    m_tree.set(row_ndx_2, value_1);
+}
+
+template <class T>
+void Column<T>::clear_without_updating_index()
+{
+    m_tree.clear(); // Throws
+}
+
+template <class T>
+void Column<T>::clear()
+{
+    if (has_search_index()) {
+        m_search_index->clear();
+    }
+    clear_without_updating_index();
+}
+
+template <class T, class Enable = void>
+struct NullOrDefaultValue;
+template <class T>
+struct NullOrDefaultValue<T, typename std::enable_if<std::is_floating_point<T>::value>::type> {
+    static T null_or_default_value(bool is_null)
+    {
+        if (is_null) {
+            return null::get_null_float<T>();
+        }
+        else {
+            return T{};
+        }
+    }
+};
+template <class T>
+struct NullOrDefaultValue<util::Optional<T>, void> {
+    static util::Optional<T> null_or_default_value(bool is_null)
+    {
+        if (is_null) {
+            return util::none;
+        }
+        else {
+            return util::some<T>(T{});
+        }
+    }
+};
+template <class T>
+struct NullOrDefaultValue<T, typename std::enable_if<!ImplicitNull<T>::value>::type> {
+    static T null_or_default_value(bool is_null)
+    {
+        REALM_ASSERT(!is_null);
+        return T{};
+    }
+};
+
+// Implementing pure virtual method of ColumnBase.
+template <class T>
+void Column<T>::insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows, bool insert_nulls)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx <= prior_num_rows);
+
+    size_t row_ndx_2 = (row_ndx == prior_num_rows ? realm::npos : row_ndx);
+    T value = NullOrDefaultValue<T>::null_or_default_value(insert_nulls);
+    insert(row_ndx_2, value, num_rows_to_insert); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+template <class T>
+void Column<T>::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(num_rows_to_erase <= prior_num_rows);
+    REALM_ASSERT(row_ndx <= prior_num_rows - num_rows_to_erase);
+
+    bool is_last = (row_ndx + num_rows_to_erase == prior_num_rows);
+    do_erase(row_ndx, num_rows_to_erase, is_last); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+template <class T>
+void Column<T>::move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx < prior_num_rows);
+
+    size_t last_row_ndx = prior_num_rows - 1;
+    move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+template <class T>
+void Column<T>::clear(size_t, bool)
+{
+    clear(); // Throws
+}
+
+
+template <class T>
+size_t Column<T>::lower_bound(T value) const noexcept
+{
+    if (root_is_leaf()) {
+        auto root = static_cast<const LeafType*>(get_root_array());
+        return root->lower_bound(value);
+    }
+    return ColumnBase::lower_bound(*this, value);
+}
+
+template <class T>
+size_t Column<T>::upper_bound(T value) const noexcept
+{
+    if (root_is_leaf()) {
+        auto root = static_cast<const LeafType*>(get_root_array());
+        return root->upper_bound(value);
+    }
+    return ColumnBase::upper_bound(*this, value);
+}
+
+// For a *sorted* Column, return first element E for which E >= target or return -1 if none
+template <class T>
+size_t Column<T>::find_gte(T target, size_t start) const
+{
+    // fixme: slow reference implementation. See Array::find_gte for faster version
+    size_t ref = 0;
+    size_t idx;
+    for (idx = start; idx < size(); ++idx) {
+        if (get(idx) >= target) {
+            ref = idx;
+            break;
+        }
+    }
+    if (idx == size())
+        ref = not_found;
+
+    return ref;
+}
+
+
+template <class T>
+bool Column<T>::compare(const Column<T>& c) const noexcept
+{
+    size_t n = size();
+    if (c.size() != n)
+        return false;
+    for (size_t i = 0; i < n; ++i) {
+        bool left_is_null = is_null(i);
+        bool right_is_null = c.is_null(i);
+        if (left_is_null != right_is_null) {
+            return false;
+        }
+        if (!left_is_null) {
+            if (get(i) != c.get(i))
+                return false;
+        }
+    }
+    return true;
+}
+
+template <class T>
+int Column<T>::compare_values(size_t row1, size_t row2) const noexcept
+{
+    return ColumnBase::compare_values(this, row1, row2);
+}
+
+template <class T>
+class Column<T>::CreateHandler : public ColumnBase::CreateHandler {
+public:
+    CreateHandler(Array::Type leaf_type, T value, Allocator& alloc)
+        : m_value(value)
+        , m_alloc(alloc)
+        , m_leaf_type(leaf_type)
+    {
+    }
+    ref_type create_leaf(size_t size) override
+    {
+        MemRef mem = BpTree<T>::create_leaf(m_leaf_type, size, m_value, m_alloc); // Throws
+        return mem.get_ref();
+    }
+
+private:
+    const T m_value;
+    Allocator& m_alloc;
+    Array::Type m_leaf_type;
+};
+
+template <class T>
+ref_type Column<T>::create(Allocator& alloc, Array::Type leaf_type, size_t size, T value)
+{
+    CreateHandler handler(leaf_type, std::move(value), alloc);
+    return ColumnBase::create(alloc, size, handler);
+}
+
+template <class T>
+ref_type Column<T>::write(size_t slice_offset, size_t slice_size, size_t table_size, _impl::OutputStream& out) const
+{
+    return m_tree.write(slice_offset, slice_size, table_size, out);
+}
+
+template <class T>
+void Column<T>::refresh_accessor_tree(size_t new_col_ndx, const Spec& spec)
+{
+    m_tree.init_from_parent();
+    ColumnBaseWithIndex::refresh_accessor_tree(new_col_ndx, spec);
+}
+
+template <class T>
+void Column<T>::do_erase(size_t row_ndx, size_t num_rows_to_erase, bool is_last)
+{
+    if (has_search_index()) {
+        for (size_t i = num_rows_to_erase; i > 0; --i) {
+            size_t row_ndx_2 = row_ndx + i - 1;
+            m_search_index->erase<T>(row_ndx_2, is_last); // Throws
+        }
+    }
+    for (size_t i = num_rows_to_erase; i > 0; --i) {
+        size_t row_ndx_2 = row_ndx + i - 1;
+        erase_without_updating_index(row_ndx_2, is_last); // Throws
+    }
+}
+
+template <class T>
+void Column<T>::verify() const
+{
+#ifdef REALM_DEBUG
+    m_tree.verify();
+#endif
+}
+
+// LCOV_EXCL_START
+
+template <class T>
+void Column<T>::to_dot(std::ostream& out, StringData title) const
+{
+#ifdef REALM_DEBUG
+    ref_type ref = get_root_array()->get_ref();
+    out << "subgraph cluster_integer_column" << ref << " {" << std::endl;
+    out << " label = \"Integer column";
+    if (title.size() != 0)
+        out << "\\n'" << title << "'";
+    out << "\";" << std::endl;
+    tree_to_dot(out);
+    out << "}" << std::endl;
+#else
+    static_cast<void>(out);
+    static_cast<void>(title);
+#endif
+}
+
+template <class T>
+void Column<T>::leaf_to_dot(MemRef leaf_mem, ArrayParent* parent, size_t ndx_in_parent, std::ostream& out) const
+{
+#ifdef REALM_DEBUG
+    BpTree<T>::leaf_to_dot(leaf_mem, parent, ndx_in_parent, out, get_alloc());
+#else
+    static_cast<void>(leaf_mem);
+    static_cast<void>(parent);
+    static_cast<void>(ndx_in_parent);
+    static_cast<void>(out);
+#endif
+}
+
+template <class T>
+void Column<T>::do_dump_node_structure(std::ostream& out, int level) const
+{
+#ifdef REALM_DEBUG
+    dump_node_structure(*get_root_array(), out, level);
+#else
+    static_cast<void>(out);
+    static_cast<void>(level);
+#endif
+}
+
+#ifdef REALM_DEBUG
+
+template <class T>
+void Column<T>::tree_to_dot(std::ostream& out) const
+{
+    ColumnBase::bptree_to_dot(get_root_array(), out);
+}
+
+
+template <class T>
+MemStats Column<T>::stats() const
+{
+    MemStats mem_stats;
+    get_root_array()->stats(mem_stats);
+    return mem_stats;
+}
+
+namespace _impl {
+void leaf_dumper(MemRef mem, Allocator& alloc, std::ostream& out, int level);
+}
+
+template <class T>
+void Column<T>::dump_node_structure(const Array& root, std::ostream& out, int level)
+{
+    root.dump_bptree_structure(out, level, &_impl::leaf_dumper);
+}
+
+#endif
+
+template <class T>
+std::pair<ref_type, size_t> Column<T>::get_to_dot_parent(size_t ndx_in_parent) const
+{
+    auto root = get_root_array();
+    if (root->is_inner_bptree_node()) {
+        std::pair<MemRef, size_t> p = static_cast<const BpTreeNode*>(root)->get_bptree_leaf(ndx_in_parent);
+        return std::make_pair(p.first.get_ref(), p.second);
+    }
+    else {
+        return std::make_pair(root->get_ref(), ndx_in_parent);
+    }
+}
+
+// LCOV_EXCL_STOP ignore debug functions
+
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType>::ColumnRandIterator(const Column<ColumnDataType>* src_col, size_t ndx)
+    : m_col_ndx(ndx)
+    , m_col(src_col)
+{
+}
+
+template <class ColumnDataType>
+bool ColumnRandIterator<ColumnDataType>::operator==(const ColumnRandIterator<ColumnDataType>& rhs) const
+{
+    return (m_col_ndx == rhs.m_col_ndx);
+}
+
+template <class ColumnDataType>
+bool ColumnRandIterator<ColumnDataType>::operator!=(const ColumnRandIterator<ColumnDataType>& rhs) const
+{
+    return !(*this == rhs);
+}
+
+template <class ColumnDataType>
+bool ColumnRandIterator<ColumnDataType>::operator<(const ColumnRandIterator<ColumnDataType>& rhs) const
+{
+    return m_col_ndx < rhs.m_col_ndx;
+}
+
+template <class ColumnDataType>
+bool ColumnRandIterator<ColumnDataType>::operator>(const ColumnRandIterator<ColumnDataType>& rhs) const
+{
+    return rhs < *this;
+}
+
+template <class ColumnDataType>
+bool ColumnRandIterator<ColumnDataType>::operator<=(const ColumnRandIterator<ColumnDataType>& rhs) const
+{
+    return !(rhs < *this);
+}
+
+template <class ColumnDataType>
+bool ColumnRandIterator<ColumnDataType>::operator>=(const ColumnRandIterator<ColumnDataType>& rhs) const
+{
+    return !(*this < rhs);
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType>& ColumnRandIterator<ColumnDataType>::operator+=(ptrdiff_t movement)
+{
+    m_col_ndx += movement;
+    return (*this);
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType>& ColumnRandIterator<ColumnDataType>::operator-=(ptrdiff_t movement)
+{
+    m_col_ndx -= movement;
+    return (*this);
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType>& ColumnRandIterator<ColumnDataType>::operator++()
+{
+    ++m_col_ndx;
+    return (*this);
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType>& ColumnRandIterator<ColumnDataType>::operator--()
+{
+    --m_col_ndx;
+    return (*this);
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType> ColumnRandIterator<ColumnDataType>::operator++(int)
+{
+    auto temp(*this);
+    ++m_col_ndx;
+    return temp;
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType> ColumnRandIterator<ColumnDataType>::operator--(int)
+{
+    auto temp(*this);
+    --m_col_ndx;
+    return temp;
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType> ColumnRandIterator<ColumnDataType>::operator+(ptrdiff_t movement)
+{
+    return ColumnRandIterator(m_col, m_col_ndx + movement);
+}
+
+template <class ColumnDataType>
+ColumnRandIterator<ColumnDataType> ColumnRandIterator<ColumnDataType>::operator-(ptrdiff_t movement)
+{
+    return ColumnRandIterator(m_col, m_col_ndx - movement);
+}
+
+template <class ColumnDataType>
+ptrdiff_t ColumnRandIterator<ColumnDataType>::operator-(const ColumnRandIterator<ColumnDataType>& right) const
+{
+    return m_col_ndx - right.m_col_ndx;
+}
+
+template <class ColumnDataType>
+const ColumnDataType ColumnRandIterator<ColumnDataType>::operator*() const
+{
+    return m_col->get(m_col_ndx);
+}
+
+template <class ColumnDataType>
+const ColumnDataType ColumnRandIterator<ColumnDataType>::operator->() const
+{
+    return m_col->get(m_col_ndx);
+}
+
+template <class ColumnDataType>
+const ColumnDataType ColumnRandIterator<ColumnDataType>::operator[](ptrdiff_t offset) const
+{
+    return m_col->get(m_col_ndx + offset);
+}
+
+template <class ColumnDataType>
+size_t ColumnRandIterator<ColumnDataType>::get_col_ndx() const
+{
+    return m_col_ndx;
+}
+
+template <class ColumnDataType>
+std::ostream& operator<<(std::ostream& out, const ColumnRandIterator<ColumnDataType>& it)
+{
+    out << "ColumnRandIterator at index: " << it.get_col_ndx();
+    return out;
+}
+
+} // namespace realm
+
+#endif // REALM_COLUMN_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_backlink.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_backlink.hpp
new file mode 100644
index 0000000..cbbe9e6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_backlink.hpp
@@ -0,0 +1,246 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_BACKLINK_HPP
+#define REALM_COLUMN_BACKLINK_HPP
+
+#include <vector>
+
+#include <realm/column.hpp>
+#include <realm/column_linkbase.hpp>
+#include <realm/table.hpp>
+
+namespace realm {
+
+/// A column of backlinks (BacklinkColumn) is a single B+-tree, and the root of
+/// the column is the root of the B+-tree. All leaf nodes are single arrays of
+/// type Array with the hasRefs bit set.
+///
+/// The individual values in the column are either refs to Columns containing
+/// the row indexes in the origin table that links to it, or in the case where
+/// there is a single link, a tagged ref encoding the origin row position.
+class BacklinkColumn : public IntegerColumn, public ArrayParent {
+public:
+    BacklinkColumn(Allocator&, ref_type, size_t col_ndx = npos);
+    ~BacklinkColumn() noexcept override
+    {
+    }
+
+    static ref_type create(Allocator&, size_t size = 0);
+
+    bool has_backlinks(size_t row_ndx) const noexcept;
+    size_t get_backlink_count(size_t row_ndx) const noexcept;
+    size_t get_backlink(size_t row_ndx, size_t backlink_ndx) const noexcept;
+
+    void add_backlink(size_t row_ndx, size_t origin_row_ndx);
+    void remove_one_backlink(size_t row_ndx, size_t origin_row_ndx);
+    void remove_all_backlinks(size_t num_rows);
+    void update_backlink(size_t row_ndx, size_t old_origin_row_ndx, size_t new_origin_row_ndx);
+    void swap_backlinks(size_t row_ndx, size_t origin_row_ndx_1, size_t origin_row_ndx_2);
+
+    void add_row();
+
+    // Link origination info
+    Table& get_origin_table() const noexcept;
+    void set_origin_table(Table&) noexcept;
+    LinkColumnBase& get_origin_column() const noexcept;
+    size_t get_origin_column_index() const noexcept;
+    void set_origin_column(LinkColumnBase& column) noexcept;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void swap_rows(size_t, size_t) override;
+    void clear(size_t, bool) override;
+    void adj_acc_insert_rows(size_t, size_t) noexcept override;
+    void adj_acc_erase_row(size_t) noexcept override;
+    void adj_acc_move_over(size_t, size_t) noexcept override;
+    void adj_acc_swap_rows(size_t, size_t) noexcept override;
+    void adj_acc_move_row(size_t, size_t) noexcept override;
+    void adj_acc_merge_rows(size_t, size_t) noexcept override;
+    void adj_acc_clear_root_table() noexcept override;
+    void mark(int) noexcept override;
+
+    void bump_link_origin_table_version() noexcept override;
+
+    void cascade_break_backlinks_to(size_t row_ndx, CascadeState& state) override;
+    void cascade_break_backlinks_to_all_rows(size_t num_rows, CascadeState&) override;
+
+    int compare_values(size_t, size_t) const noexcept override;
+
+    void verify() const override;
+    void verify(const Table&, size_t) const override;
+#ifdef REALM_DEBUG
+    struct VerifyPair {
+        size_t origin_row_ndx, target_row_ndx;
+        bool operator<(const VerifyPair&) const noexcept;
+    };
+    void get_backlinks(std::vector<VerifyPair>&); // Sorts
+#endif
+
+protected:
+    // ArrayParent overrides
+    void update_child_ref(size_t child_ndx, ref_type new_ref) override;
+    ref_type get_child_ref(size_t child_ndx) const noexcept override;
+
+    std::pair<ref_type, size_t> get_to_dot_parent(size_t) const override;
+
+private:
+    TableRef m_origin_table;
+    LinkColumnBase* m_origin_column = nullptr;
+
+    template <typename Func>
+    size_t for_each_link(size_t row_ndx, bool do_destroy, Func&& f);
+};
+
+
+// Implementation
+
+inline BacklinkColumn::BacklinkColumn(Allocator& alloc, ref_type ref, size_t col_ndx)
+    : IntegerColumn(alloc, ref, col_ndx) // Throws
+{
+}
+
+inline ref_type BacklinkColumn::create(Allocator& alloc, size_t size)
+{
+    return IntegerColumn::create(alloc, Array::type_HasRefs, size); // Throws
+}
+
+inline bool BacklinkColumn::has_backlinks(size_t ndx) const noexcept
+{
+    return IntegerColumn::get(ndx) != 0;
+}
+
+inline Table& BacklinkColumn::get_origin_table() const noexcept
+{
+    return *m_origin_table;
+}
+
+inline void BacklinkColumn::set_origin_table(Table& table) noexcept
+{
+    REALM_ASSERT(!m_origin_table);
+    m_origin_table = table.get_table_ref();
+}
+
+inline LinkColumnBase& BacklinkColumn::get_origin_column() const noexcept
+{
+    return *m_origin_column;
+}
+
+inline size_t BacklinkColumn::get_origin_column_index() const noexcept
+{
+    return m_origin_column ? m_origin_column->get_column_index() : npos;
+}
+
+inline void BacklinkColumn::set_origin_column(LinkColumnBase& column) noexcept
+{
+    m_origin_column = &column;
+}
+
+inline void BacklinkColumn::add_row()
+{
+    IntegerColumn::add(0);
+}
+
+inline void BacklinkColumn::adj_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept
+{
+    IntegerColumn::adj_acc_insert_rows(row_ndx, num_rows);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::adj_acc_erase_row(size_t row_ndx) noexcept
+{
+    IntegerColumn::adj_acc_erase_row(row_ndx);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::adj_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept
+{
+    IntegerColumn::adj_acc_move_over(from_row_ndx, to_row_ndx);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::adj_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept
+{
+    Column::adj_acc_swap_rows(row_ndx_1, row_ndx_2);
+
+    using tf = _impl::TableFriend;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::adj_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept
+{
+    Column::adj_acc_move_row(from_ndx, to_ndx);
+
+    using tf = _impl::TableFriend;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::adj_acc_merge_rows(size_t old_row_ndx, size_t new_row_ndx) noexcept
+{
+    Column::adj_acc_merge_rows(old_row_ndx, new_row_ndx);
+
+    using tf = _impl::TableFriend;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::adj_acc_clear_root_table() noexcept
+{
+    IntegerColumn::adj_acc_clear_root_table();
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_origin_table);
+}
+
+inline void BacklinkColumn::mark(int type) noexcept
+{
+    if (type & mark_LinkOrigins) {
+        typedef _impl::TableFriend tf;
+        tf::mark(*m_origin_table);
+    }
+}
+
+inline void BacklinkColumn::bump_link_origin_table_version() noexcept
+{
+    // It is important to mark connected tables as modified.
+    // Also see LinkColumnBase::bump_link_origin_table_version().
+    typedef _impl::TableFriend tf;
+    if (m_origin_table) {
+        bool bump_global = false;
+        tf::bump_version(*m_origin_table, bump_global);
+    }
+}
+
+#ifdef REALM_DEBUG
+
+inline bool BacklinkColumn::VerifyPair::operator<(const VerifyPair& p) const noexcept
+{
+    return origin_row_ndx < p.origin_row_ndx;
+}
+
+#endif // REALM_DEBUG
+
+} // namespace realm
+
+#endif // REALM_COLUMN_BACKLINK_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_binary.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_binary.hpp
new file mode 100644
index 0000000..48e1d11
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_binary.hpp
@@ -0,0 +1,435 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_BINARY_HPP
+#define REALM_COLUMN_BINARY_HPP
+
+#include <realm/column.hpp>
+#include <realm/array_binary.hpp>
+#include <realm/array_blobs_big.hpp>
+
+namespace realm {
+
+
+/// A binary column (BinaryColumn) is a single B+-tree, and the root
+/// of the column is the root of the B+-tree. Leaf nodes are either of
+/// type ArrayBinary (array of small blobs) or ArrayBigBlobs (array of
+/// big blobs).
+class BinaryColumn : public ColumnBaseSimple {
+public:
+    typedef BinaryData value_type;
+
+    BinaryColumn(Allocator&, ref_type, bool nullable = false, size_t column_ndx = npos);
+
+    size_t size() const noexcept final;
+    bool is_empty() const noexcept
+    {
+        return size() == 0;
+    }
+    bool is_nullable() const noexcept override;
+
+    BinaryData get(size_t ndx) const noexcept;
+
+    /// Return data from position 'pos' and onwards. If the blob is distributed
+    /// across multiple arrays (if bigger than ~ 16M), you will only get data
+    /// from one array. 'pos' will be updated to be an index to next available
+    /// data. It will be 0 if no more data.
+    BinaryData get_at(size_t ndx, size_t& pos) const noexcept;
+
+    bool is_null(size_t ndx) const noexcept override;
+    StringData get_index_data(size_t, StringIndex::StringConversionBuffer&) const noexcept final;
+
+    void add(BinaryData value);
+    void set(size_t ndx, BinaryData value, bool add_zero_term = false);
+    void set_null(size_t ndx) override;
+    void insert(size_t ndx, BinaryData value);
+    void erase(size_t row_ndx);
+    void erase(size_t row_ndx, bool is_last);
+    void move_last_over(size_t row_ndx);
+    void swap_rows(size_t row_ndx_1, size_t row_ndx_2) override;
+    void clear();
+    size_t find_first(BinaryData value) const;
+
+    // Requires that the specified entry was inserted as StringData.
+    StringData get_string(size_t ndx) const noexcept;
+
+    void add_string(StringData value);
+    void set_string(size_t ndx, StringData value) override;
+    void insert_string(size_t ndx, StringData value);
+
+    /// Compare two binary columns for equality.
+    bool compare_binary(const BinaryColumn&) const;
+
+    int compare_values(size_t row1, size_t row2) const noexcept override;
+
+    static ref_type create(Allocator&, size_t size, bool nullable);
+
+    static size_t get_size_from_ref(ref_type root_ref, Allocator&) noexcept;
+
+    // Overrriding method in ColumnBase
+    ref_type write(size_t, size_t, size_t, _impl::OutputStream&) const override;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void clear(size_t, bool) override;
+    void update_from_parent(size_t) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+
+    /// In contrast to update_from_parent(), this function is able to handle
+    /// cases where the accessed payload data has changed. In particular, it
+    /// handles cases where the B+-tree switches from having one level (root is
+    /// a leaf node), to having multiple levels (root is an inner node). Note
+    /// that this is at the expense of loosing the `noexcept` guarantee.
+    void update_from_ref(ref_type ref);
+
+    void verify() const override;
+    void to_dot(std::ostream&, StringData title) const override;
+    void do_dump_node_structure(std::ostream&, int) const override;
+    void find_all(IntegerColumn&, BinaryData, size_t, size_t) const
+    {
+        // Dummy implementation
+        REALM_ASSERT(false);
+    }
+
+
+private:
+    /// \param row_ndx Must be `realm::npos` if appending.
+    void do_insert(size_t row_ndx, BinaryData value, bool add_zero_term, size_t num_rows);
+
+    // Called by Array::bptree_insert().
+    static ref_type leaf_insert(MemRef leaf_mem, ArrayParent&, size_t ndx_in_parent, Allocator&, size_t insert_ndx,
+                                BpTreeNode::TreeInsert<BinaryColumn>& state);
+
+    struct InsertState : BpTreeNode::TreeInsert<BinaryColumn> {
+        bool m_add_zero_term;
+    };
+
+    class EraseLeafElem;
+    class CreateHandler;
+    class SliceHandler;
+
+    void do_move_last_over(size_t row_ndx, size_t last_row_ndx);
+    void do_clear();
+
+    /// Root must be a leaf. Upgrades the root leaf if
+    /// necessary. Returns true if, and only if the root is a 'big
+    /// blobs' leaf upon return.
+    bool upgrade_root_leaf(size_t value_size);
+
+    bool m_nullable = false;
+
+    void leaf_to_dot(MemRef, ArrayParent*, size_t ndx_in_parent, std::ostream&) const override;
+
+    friend class BpTreeNode;
+    friend class ColumnBase;
+};
+
+class BinaryIterator {
+public:
+    BinaryIterator()
+    {
+    }
+    // TODO: When WriteLogCollector is removed, there is no need for this
+    BinaryIterator(BinaryData binary)
+        : m_binary(binary)
+    {
+    }
+
+    BinaryIterator(const BinaryColumn* col, size_t ndx)
+        : m_binary_col(col)
+        , m_ndx(ndx)
+    {
+    }
+
+    BinaryData get_next() noexcept
+    {
+        if (!end_of_data) {
+            if (m_binary_col) {
+                BinaryData ret = m_binary_col->get_at(m_ndx, m_pos);
+                end_of_data = (m_pos == 0);
+                return ret;
+            }
+            else if (!m_binary.is_null()) {
+                end_of_data = true;
+                return m_binary;
+            }
+        }
+        return {};
+    }
+
+private:
+    bool end_of_data = false;
+    const BinaryColumn* m_binary_col = nullptr;
+    size_t m_ndx = 0;
+    size_t m_pos = 0;
+    BinaryData m_binary;
+};
+
+
+// Implementation
+
+// LCOV_EXCL_START
+inline StringData BinaryColumn::get_index_data(size_t, StringIndex::StringConversionBuffer&) const noexcept
+{
+    REALM_ASSERT(false && "Index not implemented for BinaryColumn.");
+    REALM_UNREACHABLE();
+}
+// LCOV_EXCL_STOP
+
+inline size_t BinaryColumn::size() const noexcept
+{
+    if (root_is_leaf()) {
+        bool is_big = m_array->get_context_flag();
+        if (!is_big) {
+            // Small blobs root leaf
+            ArrayBinary* leaf = static_cast<ArrayBinary*>(m_array.get());
+            return leaf->size();
+        }
+        // Big blobs root leaf
+        ArrayBigBlobs* leaf = static_cast<ArrayBigBlobs*>(m_array.get());
+        return leaf->size();
+    }
+    // Non-leaf root
+    return static_cast<BpTreeNode*>(m_array.get())->get_bptree_size();
+}
+
+inline bool BinaryColumn::is_nullable() const noexcept
+{
+    return m_nullable;
+}
+
+inline void BinaryColumn::update_from_parent(size_t old_baseline) noexcept
+{
+    if (root_is_leaf()) {
+        bool is_big = m_array->get_context_flag();
+        if (!is_big) {
+            // Small blobs root leaf
+            REALM_ASSERT(dynamic_cast<ArrayBinary*>(m_array.get()));
+            ArrayBinary* leaf = static_cast<ArrayBinary*>(m_array.get());
+            leaf->update_from_parent(old_baseline);
+            return;
+        }
+        // Big blobs root leaf
+        REALM_ASSERT(dynamic_cast<ArrayBigBlobs*>(m_array.get()));
+        ArrayBigBlobs* leaf = static_cast<ArrayBigBlobs*>(m_array.get());
+        leaf->update_from_parent(old_baseline);
+        return;
+    }
+    // Non-leaf root
+    m_array->update_from_parent(old_baseline);
+}
+
+inline BinaryData BinaryColumn::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_DEBUG(ndx < size());
+    if (root_is_leaf()) {
+        bool is_big = m_array->get_context_flag();
+        BinaryData ret;
+        if (!is_big) {
+            // Small blobs root leaf
+            ArrayBinary* leaf = static_cast<ArrayBinary*>(m_array.get());
+            ret = leaf->get(ndx);
+        }
+        else {
+            // Big blobs root leaf
+            ArrayBigBlobs* leaf = static_cast<ArrayBigBlobs*>(m_array.get());
+            ret = leaf->get(ndx);
+        }
+        if (!m_nullable && ret.is_null())
+            return BinaryData("", 0); // return empty string (non-null)
+        return ret;
+    }
+
+    // Non-leaf root
+    std::pair<MemRef, size_t> p = static_cast<BpTreeNode*>(m_array.get())->get_bptree_leaf(ndx);
+    const char* leaf_header = p.first.get_addr();
+    size_t ndx_in_leaf = p.second;
+    Allocator& alloc = m_array->get_alloc();
+    bool is_big = Array::get_context_flag_from_header(leaf_header);
+    if (!is_big) {
+        // Small blobs
+        return ArrayBinary::get(leaf_header, ndx_in_leaf, alloc);
+    }
+    // Big blobs
+    return ArrayBigBlobs::get(leaf_header, ndx_in_leaf, alloc);
+}
+
+inline bool BinaryColumn::is_null(size_t ndx) const noexcept
+{
+    return m_nullable && get(ndx).is_null();
+}
+
+inline StringData BinaryColumn::get_string(size_t ndx) const noexcept
+{
+    BinaryData bin = get(ndx);
+    REALM_ASSERT_3(0, <, bin.size());
+    return StringData(bin.data(), bin.size() - 1);
+}
+
+inline void BinaryColumn::set_string(size_t ndx, StringData value)
+{
+    if (value.is_null() && !m_nullable)
+        throw LogicError(LogicError::column_not_nullable);
+
+    BinaryData bin(value.data(), value.size());
+    bool add_zero_term = true;
+    set(ndx, bin, add_zero_term);
+}
+
+inline void BinaryColumn::add(BinaryData value)
+{
+    if (value.is_null() && !m_nullable)
+        throw LogicError(LogicError::column_not_nullable);
+
+    size_t row_ndx = realm::npos;
+    bool add_zero_term = false;
+    size_t num_rows = 1;
+    do_insert(row_ndx, value, add_zero_term, num_rows); // Throws
+}
+
+inline void BinaryColumn::insert(size_t row_ndx, BinaryData value)
+{
+    if (value.is_null() && !m_nullable)
+        throw LogicError(LogicError::column_not_nullable);
+
+    size_t column_size = this->size(); // Slow
+    REALM_ASSERT_3(row_ndx, <=, column_size);
+    size_t row_ndx_2 = row_ndx == column_size ? realm::npos : row_ndx;
+    bool add_zero_term = false;
+    size_t num_rows = 1;
+    do_insert(row_ndx_2, value, add_zero_term, num_rows); // Throws
+}
+
+inline void BinaryColumn::set_null(size_t row_ndx)
+{
+    set(row_ndx, BinaryData{});
+}
+
+inline size_t BinaryColumn::find_first(BinaryData value) const
+{
+    for (size_t t = 0; t < size(); t++)
+        if (get(t) == value)
+            return t;
+
+    return not_found;
+}
+
+
+inline void BinaryColumn::erase(size_t row_ndx)
+{
+    size_t last_row_ndx = size() - 1; // Note that size() is slow
+    bool is_last = row_ndx == last_row_ndx;
+    erase(row_ndx, is_last); // Throws
+}
+
+inline void BinaryColumn::move_last_over(size_t row_ndx)
+{
+    size_t last_row_ndx = size() - 1;         // Note that size() is slow
+    do_move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+inline void BinaryColumn::clear()
+{
+    do_clear(); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void BinaryColumn::insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows,
+                                      bool insert_nulls)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx <= prior_num_rows);
+    REALM_ASSERT(!insert_nulls || m_nullable);
+
+    size_t row_ndx_2 = (row_ndx == prior_num_rows ? realm::npos : row_ndx);
+    BinaryData value = m_nullable ? BinaryData() : BinaryData("", 0);
+    bool add_zero_term = false;
+    do_insert(row_ndx_2, value, add_zero_term, num_rows_to_insert); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void BinaryColumn::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(num_rows_to_erase <= prior_num_rows);
+    REALM_ASSERT(row_ndx <= prior_num_rows - num_rows_to_erase);
+
+    bool is_last = (row_ndx + num_rows_to_erase == prior_num_rows);
+    for (size_t i = num_rows_to_erase; i > 0; --i) {
+        size_t row_ndx_2 = row_ndx + i - 1;
+        erase(row_ndx_2, is_last); // Throws
+    }
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void BinaryColumn::move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx < prior_num_rows);
+
+    size_t last_row_ndx = prior_num_rows - 1;
+    do_move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void BinaryColumn::clear(size_t, bool)
+{
+    do_clear(); // Throws
+}
+
+inline void BinaryColumn::add_string(StringData value)
+{
+    size_t row_ndx = realm::npos;
+    BinaryData value_2(value.data(), value.size());
+    bool add_zero_term = true;
+    size_t num_rows = 1;
+    do_insert(row_ndx, value_2, add_zero_term, num_rows); // Throws
+}
+
+inline void BinaryColumn::insert_string(size_t row_ndx, StringData value)
+{
+    size_t column_size = this->size(); // Slow
+    REALM_ASSERT_3(row_ndx, <=, column_size);
+    size_t row_ndx_2 = row_ndx == column_size ? realm::npos : row_ndx;
+    BinaryData value_2(value.data(), value.size());
+    bool add_zero_term = false;
+    size_t num_rows = 1;
+    do_insert(row_ndx_2, value_2, add_zero_term, num_rows); // Throws
+}
+
+inline size_t BinaryColumn::get_size_from_ref(ref_type root_ref, Allocator& alloc) noexcept
+{
+    const char* root_header = alloc.translate(root_ref);
+    bool root_is_leaf = !Array::get_is_inner_bptree_node_from_header(root_header);
+    if (root_is_leaf) {
+        bool is_big = Array::get_context_flag_from_header(root_header);
+        if (!is_big) {
+            // Small blobs leaf
+            return ArrayBinary::get_size_from_header(root_header, alloc);
+        }
+        // Big blobs leaf
+        return ArrayBigBlobs::get_size_from_header(root_header);
+    }
+    return BpTreeNode::get_bptree_size_from_header(root_header);
+}
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_BINARY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_fwd.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_fwd.hpp
new file mode 100644
index 0000000..5b93cdc
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_fwd.hpp
@@ -0,0 +1,58 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_FWD_HPP
+#define REALM_COLUMN_FWD_HPP
+
+#include <cstdint>
+
+namespace realm {
+
+// Regular classes
+class ColumnBase;
+class StringColumn;
+class StringEnumColumn;
+class BinaryColumn;
+class SubtableColumn;
+class MixedColumn;
+class LinkColumn;
+class LinkListColumn;
+class TimestampColumn;
+
+// Templated classes
+template <class T>
+class Column;
+template <class T>
+class BasicColumn;
+template <class T>
+class ColumnRandIterator;
+
+namespace util {
+template <class>
+class Optional;
+}
+
+// Shortcuts, aka typedefs.
+using IntegerColumn = Column<int64_t>;
+using IntNullColumn = Column<util::Optional<int64_t>>;
+using DoubleColumn = Column<double>;
+using FloatColumn = Column<float>;
+using IntegerColumnIterator = ColumnRandIterator<int64_t>;
+} // namespace realm
+
+#endif // REALM_COLUMN_FWD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_link.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_link.hpp
new file mode 100644
index 0000000..185a6c3
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_link.hpp
@@ -0,0 +1,181 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_LINK_HPP
+#define REALM_COLUMN_LINK_HPP
+
+#include <realm/column.hpp>
+#include <realm/column_linkbase.hpp>
+#include <realm/column_backlink.hpp>
+
+namespace realm {
+
+/// A link column is an extension of an integer column (Column) and maintains
+/// its node structure.
+///
+/// The individual values in a link column are indexes of rows in the target
+/// table (offset with one to allow zero to indicate null links.) The target
+/// table is specified by the table descriptor.
+class LinkColumn : public LinkColumnBase {
+public:
+    using LinkColumnBase::LinkColumnBase;
+    ~LinkColumn() noexcept override;
+
+    static ref_type create(Allocator&, size_t size = 0);
+
+    bool is_nullable() const noexcept override;
+
+    //@{
+
+    /// is_null_link() is shorthand for `get_link() == realm::npos`,
+    /// nullify_link() is shorthand foe `set_link(realm::npos)`, and
+    /// insert_null_link() is shorthand for
+    /// `insert_link(realm::npos)`. set_link() returns the original link, with
+    /// `realm::npos` indicating that it was null.
+
+    size_t get_link(size_t row_ndx) const noexcept;
+    bool is_null(size_t row_ndx) const noexcept override;
+    bool is_null_link(size_t row_ndx) const noexcept;
+    size_t set_link(size_t row_ndx, size_t target_row_ndx);
+    void set_null(size_t row_ndx) override;
+    void nullify_link(size_t row_ndx);
+    void insert_link(size_t row_ndx, size_t target_row_ndx);
+    void insert_null_link(size_t row_ndx);
+
+    //@}
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void swap_rows(size_t, size_t) override;
+    void clear(size_t, bool) override;
+    void cascade_break_backlinks_to(size_t, CascadeState&) override;
+    void cascade_break_backlinks_to_all_rows(size_t, CascadeState&) override;
+
+    void verify(const Table&, size_t) const override;
+
+protected:
+    friend class BacklinkColumn;
+    void do_nullify_link(size_t row_ndx, size_t old_target_row_ndx) override;
+    void do_update_link(size_t row_ndx, size_t old_target_row_ndx, size_t new_target_row_ndx) override;
+    void do_swap_link(size_t row_ndx, size_t target_row_ndx_1, size_t target_row_ndx_2) override;
+
+private:
+    void remove_backlinks(size_t row_ndx);
+};
+
+
+// Implementation
+
+inline LinkColumn::~LinkColumn() noexcept
+{
+}
+
+inline bool LinkColumn::is_nullable() const noexcept
+{
+    return true;
+}
+
+inline ref_type LinkColumn::create(Allocator& alloc, size_t size)
+{
+    return IntegerColumn::create(alloc, Array::type_Normal, size); // Throws
+}
+
+inline bool LinkColumn::is_null(size_t row_ndx) const noexcept
+{
+    // Null is represented by zero
+    return LinkColumnBase::get(row_ndx) == 0;
+}
+
+inline size_t LinkColumn::get_link(size_t row_ndx) const noexcept
+{
+    // Map zero to realm::npos, and `n+1` to `n`, where `n` is a target row index.
+    return to_size_t(LinkColumnBase::get(row_ndx)) - size_t(1);
+}
+
+inline bool LinkColumn::is_null_link(size_t row_ndx) const noexcept
+{
+    return is_null(row_ndx);
+}
+
+inline size_t LinkColumn::set_link(size_t row_ndx, size_t target_row_ndx)
+{
+    int_fast64_t old_value = LinkColumnBase::get(row_ndx);
+    size_t old_target_row_ndx = to_size_t(old_value) - size_t(1);
+    if (old_target_row_ndx == target_row_ndx)
+        return old_target_row_ndx; // Nothing to do
+    if (old_value != 0)
+        m_backlink_column->remove_one_backlink(old_target_row_ndx, row_ndx); // Throws
+
+    int_fast64_t new_value = int_fast64_t(size_t(1) + target_row_ndx);
+    LinkColumnBase::set(row_ndx, new_value); // Throws
+
+    if (target_row_ndx != realm::npos)
+        m_backlink_column->add_backlink(target_row_ndx, row_ndx); // Throws
+
+    return old_target_row_ndx;
+}
+
+inline void LinkColumn::set_null(size_t row_ndx)
+{
+    set_link(row_ndx, realm::npos); // Throws
+}
+
+inline void LinkColumn::nullify_link(size_t row_ndx)
+{
+    set_null(row_ndx); // Throws
+}
+
+inline void LinkColumn::insert_link(size_t row_ndx, size_t target_row_ndx)
+{
+    int_fast64_t value = int_fast64_t(size_t(1) + target_row_ndx);
+    LinkColumnBase::insert(row_ndx, value); // Throws
+
+    if (target_row_ndx != realm::npos)
+        m_backlink_column->add_backlink(target_row_ndx, row_ndx); // Throws
+}
+
+inline void LinkColumn::insert_null_link(size_t row_ndx)
+{
+    insert_link(row_ndx, realm::npos); // Throws
+}
+
+inline void LinkColumn::do_update_link(size_t row_ndx, size_t, size_t new_target_row_ndx)
+{
+    // Row pos is offset by one, to allow null refs
+    LinkColumnBase::set(row_ndx, new_target_row_ndx + 1);
+}
+
+inline void LinkColumn::do_swap_link(size_t row_ndx, size_t target_row_ndx_1, size_t target_row_ndx_2)
+{
+    // Row pos is offset by one, to allow null refs
+    ++target_row_ndx_1;
+    ++target_row_ndx_2;
+
+    uint64_t value = LinkColumnBase::get_uint(row_ndx);
+    if (value == target_row_ndx_1) {
+        LinkColumnBase::set_uint(row_ndx, target_row_ndx_2);
+    }
+    else if (value == target_row_ndx_2) {
+        LinkColumnBase::set_uint(row_ndx, target_row_ndx_1);
+    }
+}
+
+} // namespace realm
+
+#endif // REALM_COLUMN_LINK_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_linkbase.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_linkbase.hpp
new file mode 100644
index 0000000..fa67fab
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_linkbase.hpp
@@ -0,0 +1,206 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_LINKBASE_HPP
+#define REALM_COLUMN_LINKBASE_HPP
+
+#include <realm/table.hpp>
+
+namespace realm {
+
+class BacklinkColumn;
+class Table;
+
+// Abstract base class for columns containing links
+class LinkColumnBase : public IntegerColumn {
+public:
+    // Create unattached root array aaccessor.
+    LinkColumnBase(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx);
+    ~LinkColumnBase() noexcept override;
+
+    bool is_nullable() const noexcept override = 0;
+    void set_null(size_t) override = 0;
+    bool is_null(size_t) const noexcept override = 0;
+
+    bool supports_search_index() const noexcept final
+    {
+        return false;
+    }
+    StringIndex* create_search_index() override;
+
+    bool get_weak_links() const noexcept;
+    void set_weak_links(bool) noexcept;
+
+    Table& get_target_table() const noexcept;
+    void set_target_table(Table&) noexcept;
+    BacklinkColumn& get_backlink_column() const noexcept;
+    void set_backlink_column(BacklinkColumn&) noexcept;
+
+    void swap_rows(size_t, size_t) override = 0;
+
+    virtual void do_nullify_link(size_t row_ndx, size_t old_target_row_ndx) = 0;
+    virtual void do_update_link(size_t row_ndx, size_t old_target_row_ndx, size_t new_target_row_ndx) = 0;
+    virtual void do_swap_link(size_t row_ndx, size_t target_row_ndx_1, size_t target_row_ndx_2) = 0;
+
+    void adj_acc_insert_rows(size_t, size_t) noexcept override;
+    void adj_acc_erase_row(size_t) noexcept override;
+    void adj_acc_move_over(size_t, size_t) noexcept override;
+    void adj_acc_swap_rows(size_t, size_t) noexcept override;
+    void adj_acc_move_row(size_t, size_t) noexcept override;
+    void adj_acc_clear_root_table() noexcept override;
+    void mark(int) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+    void bump_link_origin_table_version() noexcept override;
+
+    void verify(const Table&, size_t) const override;
+    using IntegerColumn::verify;
+
+protected:
+    // A pointer to the table that this column is part of.
+    Table* const m_table;
+
+    TableRef m_target_table;
+    BacklinkColumn* m_backlink_column = nullptr;
+    bool m_weak_links = false; // True if these links are weak (not strong)
+
+    /// Call Table::cascade_break_backlinks_to() for the specified target row if
+    /// it is not already in \a state.rows, and the number of strong links to it
+    /// has dropped to zero.
+    void check_cascade_break_backlinks_to(size_t target_table_ndx, size_t target_row_ndx, CascadeState& state);
+};
+
+
+// Implementation
+
+inline LinkColumnBase::LinkColumnBase(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx)
+    : IntegerColumn(alloc, ref, column_ndx) // Throws
+    , m_table(table)
+{
+}
+
+inline LinkColumnBase::~LinkColumnBase() noexcept
+{
+}
+
+inline StringIndex* LinkColumnBase::create_search_index()
+{
+    return nullptr;
+}
+
+inline bool LinkColumnBase::get_weak_links() const noexcept
+{
+    return m_weak_links;
+}
+
+inline void LinkColumnBase::set_weak_links(bool value) noexcept
+{
+    m_weak_links = value;
+}
+
+inline Table& LinkColumnBase::get_target_table() const noexcept
+{
+    return *m_target_table;
+}
+
+inline void LinkColumnBase::set_target_table(Table& table) noexcept
+{
+    REALM_ASSERT(!m_target_table);
+    m_target_table = table.get_table_ref();
+}
+
+inline BacklinkColumn& LinkColumnBase::get_backlink_column() const noexcept
+{
+    return *m_backlink_column;
+}
+
+inline void LinkColumnBase::set_backlink_column(BacklinkColumn& column) noexcept
+{
+    m_backlink_column = &column;
+}
+
+inline void LinkColumnBase::adj_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept
+{
+    IntegerColumn::adj_acc_insert_rows(row_ndx, num_rows);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_target_table);
+}
+
+inline void LinkColumnBase::adj_acc_erase_row(size_t row_ndx) noexcept
+{
+    IntegerColumn::adj_acc_erase_row(row_ndx);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_target_table);
+}
+
+inline void LinkColumnBase::adj_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept
+{
+    IntegerColumn::adj_acc_move_over(from_row_ndx, to_row_ndx);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_target_table);
+}
+
+inline void LinkColumnBase::adj_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept
+{
+    IntegerColumn::adj_acc_swap_rows(row_ndx_1, row_ndx_2);
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_target_table);
+}
+
+inline void LinkColumnBase::adj_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept
+{
+    IntegerColumn::adj_acc_move_row(from_ndx, to_ndx);
+
+    using tf = _impl::TableFriend;
+    tf::mark(*m_target_table);
+}
+
+inline void LinkColumnBase::adj_acc_clear_root_table() noexcept
+{
+    IntegerColumn::adj_acc_clear_root_table();
+
+    typedef _impl::TableFriend tf;
+    tf::mark(*m_target_table);
+}
+
+inline void LinkColumnBase::mark(int type) noexcept
+{
+    if (type & mark_LinkTargets) {
+        typedef _impl::TableFriend tf;
+        tf::mark(*m_target_table);
+    }
+}
+
+inline void LinkColumnBase::bump_link_origin_table_version() noexcept
+{
+    // It is important to mark connected tables as modified.
+    // Also see BacklinkColumn::bump_link_origin_table_version().
+    typedef _impl::TableFriend tf;
+    if (m_target_table) {
+        bool bump_global = false;
+        tf::bump_version(*m_target_table, bump_global);
+    }
+}
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_LINKBASE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_linklist.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_linklist.hpp
new file mode 100644
index 0000000..3dab1b3
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_linklist.hpp
@@ -0,0 +1,248 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_LINKLIST_HPP
+#define REALM_COLUMN_LINKLIST_HPP
+
+#include <algorithm>
+#include <vector>
+
+#include <realm/column.hpp>
+#include <realm/column_linkbase.hpp>
+#include <realm/table.hpp>
+#include <realm/column_backlink.hpp>
+#include <realm/link_view_fwd.hpp>
+
+namespace realm {
+
+namespace _impl {
+class TransactLogConvenientEncoder;
+}
+
+
+/// A column of link lists (LinkListColumn) is a single B+-tree, and the root of
+/// the column is the root of the B+-tree. All leaf nodes are single arrays of
+/// type Array with the hasRefs bit set.
+///
+/// The individual values in the column are either refs to Columns containing the
+/// row positions in the target table, or in the case where they are empty, a zero
+/// ref.
+class LinkListColumn : public LinkColumnBase, public ArrayParent {
+public:
+    using LinkColumnBase::LinkColumnBase;
+    using value_type = ConstLinkViewRef;
+    LinkListColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx);
+    ~LinkListColumn() noexcept override;
+
+    static ref_type create(Allocator&, size_t size = 0);
+
+    bool is_nullable() const noexcept final;
+
+    bool has_links(size_t row_ndx) const noexcept;
+    size_t get_link_count(size_t row_ndx) const noexcept;
+
+    ConstLinkViewRef get(size_t row_ndx) const;
+    LinkViewRef get(size_t row_ndx);
+
+    bool is_null(size_t row_ndx) const noexcept final;
+    void set_null(size_t row_ndx) final;
+
+    /// Compare two columns for equality.
+    bool compare_link_list(const LinkListColumn&) const;
+
+    void to_json_row(size_t row_ndx, std::ostream& out) const;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void swap_rows(size_t, size_t) override;
+    void clear(size_t, bool) override;
+    void cascade_break_backlinks_to(size_t, CascadeState&) override;
+    void cascade_break_backlinks_to_all_rows(size_t, CascadeState&) override;
+    void update_from_parent(size_t) noexcept override;
+    void adj_acc_clear_root_table() noexcept override;
+    void adj_acc_insert_rows(size_t, size_t) noexcept override;
+    void adj_acc_erase_row(size_t) noexcept override;
+    void adj_acc_move_over(size_t, size_t) noexcept override;
+    void adj_acc_swap_rows(size_t, size_t) noexcept override;
+    void adj_acc_move_row(size_t, size_t) noexcept override;
+    void adj_acc_merge_rows(size_t, size_t) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+
+    void verify() const override;
+    void verify(const Table&, size_t) const override;
+
+protected:
+    void do_discard_child_accessors() noexcept override;
+
+private:
+    struct list_entry {
+        size_t m_row_ndx;
+        std::weak_ptr<LinkView> m_list;
+        bool operator<(const list_entry& other) const
+        {
+            return m_row_ndx < other.m_row_ndx;
+        }
+    };
+
+    // The accessors stored in `m_list_accessors` are sorted by their row index.
+    // When a LinkList accessor is destroyed because the last shared_ptr pointing
+    // to it dies, its entry is implicitly replaced by a tombstone (an entry with
+    // an empty `m_list`). These tombstones are pruned at a later time by
+    // `prune_list_accessor_tombstones`. This is done to amortize the O(n) cost
+    // of `std::vector::erase` that would otherwise be incurred each time an
+    // accessor is removed.
+    mutable std::vector<list_entry> m_list_accessors;
+    mutable std::atomic<bool> m_list_accessors_contains_tombstones;
+
+    std::shared_ptr<LinkView> get_ptr(size_t row_ndx) const;
+
+    void do_nullify_link(size_t row_ndx, size_t old_target_row_ndx) override;
+    void do_update_link(size_t row_ndx, size_t old_target_row_ndx, size_t new_target_row_ndx) override;
+    void do_swap_link(size_t row_ndx, size_t target_row_ndx_1, size_t target_row_ndx_2) override;
+
+    void unregister_linkview();
+    ref_type get_row_ref(size_t row_ndx) const noexcept;
+    void set_row_ref(size_t row_ndx, ref_type new_ref);
+    void add_backlink(size_t target_row, size_t source_row);
+    void remove_backlink(size_t target_row, size_t source_row);
+
+    // ArrayParent overrides
+    void update_child_ref(size_t child_ndx, ref_type new_ref) override;
+    ref_type get_child_ref(size_t child_ndx) const noexcept override;
+
+    // These helpers are needed because of the way the B+-tree of links is
+    // traversed in cascade_break_backlinks_to() and
+    // cascade_break_backlinks_to_all_rows().
+    void cascade_break_backlinks_to__leaf(size_t row_ndx, const Array& link_list_leaf, CascadeState&);
+    void cascade_break_backlinks_to_all_rows__leaf(const Array& link_list_leaf, CascadeState&);
+
+    void discard_child_accessors() noexcept;
+
+    template <bool fix_ndx_in_parent>
+    void adj_insert_rows(size_t row_ndx, size_t num_rows_inserted) noexcept;
+
+    template <bool fix_ndx_in_parent>
+    void adj_erase_rows(size_t row_ndx, size_t num_rows_erased) noexcept;
+
+    template <bool fix_ndx_in_parent>
+    void adj_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+
+    template <bool fix_ndx_in_parent>
+    void adj_move(size_t from_ndx, size_t to_ndx) noexcept;
+
+    template <bool fix_ndx_in_parent>
+    void adj_swap(size_t row_ndx_1, size_t row_ndx_2) noexcept;
+
+    void prune_list_accessor_tombstones() noexcept;
+    void validate_list_accessors() const noexcept;
+
+    std::pair<ref_type, size_t> get_to_dot_parent(size_t) const override;
+
+    friend class BacklinkColumn;
+    friend class LinkView;
+    friend class _impl::TransactLogConvenientEncoder;
+};
+
+
+// Implementation
+
+inline LinkListColumn::LinkListColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx)
+    : LinkColumnBase(alloc, ref, table, column_ndx)
+{
+    m_list_accessors_contains_tombstones.store(false);
+}
+
+inline LinkListColumn::~LinkListColumn() noexcept
+{
+    discard_child_accessors();
+}
+
+inline ref_type LinkListColumn::create(Allocator& alloc, size_t size)
+{
+    return IntegerColumn::create(alloc, Array::type_HasRefs, size); // Throws
+}
+
+inline bool LinkListColumn::is_nullable() const noexcept
+{
+    return false;
+}
+
+inline bool LinkListColumn::has_links(size_t row_ndx) const noexcept
+{
+    ref_type ref = LinkColumnBase::get_as_ref(row_ndx);
+    return (ref != 0);
+}
+
+inline size_t LinkListColumn::get_link_count(size_t row_ndx) const noexcept
+{
+    ref_type ref = LinkColumnBase::get_as_ref(row_ndx);
+    if (ref == 0)
+        return 0;
+    return ColumnBase::get_size_from_ref(ref, get_alloc());
+}
+
+inline ConstLinkViewRef LinkListColumn::get(size_t row_ndx) const
+{
+    return get_ptr(row_ndx);
+}
+
+inline LinkViewRef LinkListColumn::get(size_t row_ndx)
+{
+    return get_ptr(row_ndx);
+}
+
+inline bool LinkListColumn::is_null(size_t) const noexcept
+{
+    return false;
+}
+
+inline void LinkListColumn::set_null(size_t)
+{
+    throw LogicError{LogicError::column_not_nullable};
+}
+
+inline void LinkListColumn::do_discard_child_accessors() noexcept
+{
+    discard_child_accessors();
+}
+
+inline ref_type LinkListColumn::get_row_ref(size_t row_ndx) const noexcept
+{
+    return LinkColumnBase::get_as_ref(row_ndx);
+}
+
+inline void LinkListColumn::set_row_ref(size_t row_ndx, ref_type new_ref)
+{
+    LinkColumnBase::set(row_ndx, new_ref); // Throws
+}
+
+inline void LinkListColumn::add_backlink(size_t target_row, size_t source_row)
+{
+    m_backlink_column->add_backlink(target_row, source_row); // Throws
+}
+
+inline void LinkListColumn::remove_backlink(size_t target_row, size_t source_row)
+{
+    m_backlink_column->remove_one_backlink(target_row, source_row); // Throws
+}
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_LINKLIST_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_mixed.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_mixed.hpp
new file mode 100644
index 0000000..5f74c41
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_mixed.hpp
@@ -0,0 +1,265 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_MIXED_HPP
+#define REALM_COLUMN_MIXED_HPP
+
+#include <limits>
+
+#include <realm/column.hpp>
+#include <realm/column_type.hpp>
+#include <realm/column_table.hpp>
+#include <realm/table.hpp>
+#include <realm/utilities.hpp>
+
+
+namespace realm {
+
+
+// Pre-declarations
+class BinaryColumn;
+
+
+/// A mixed column (MixedColumn) is composed of three subcolumns. The first
+/// subcolumn is an integer column (Column) and stores value types. The second
+/// one stores values and is a subtable parent column (SubtableColumnBase),
+/// which is a subclass of an integer column (Column). The last one is a binary
+/// column (BinaryColumn) and stores additional data for values of type string
+/// or binary data. The last subcolumn is optional. The root of a mixed column
+/// is an array node of type Array that stores the root refs of the subcolumns.
+class MixedColumn : public ColumnBaseSimple {
+public:
+    /// Create a mixed column wrapper and attach it to a preexisting
+    /// underlying structure of arrays.
+    ///
+    /// \param alloc The memory allocator to change the underlying
+    /// structure in memory.
+    ///
+    /// \param ref The memory reference of the MixedColumn for which
+    /// this accessor should be creator for.
+    ///
+    /// \param table If this column is used as part of a table you
+    /// must pass a pointer to that table. Otherwise you must pass
+    /// null
+    ///
+    /// \param column_ndx If this column is used as part of a table
+    /// you must pass the logical index of the column within that
+    /// table. Otherwise you should pass zero.
+    MixedColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx);
+
+    ~MixedColumn() noexcept override;
+
+    DataType get_type(size_t ndx) const noexcept;
+    size_t size() const noexcept final
+    {
+        return m_types->size();
+    }
+    bool is_empty() const noexcept
+    {
+        return size() == 0;
+    }
+
+    int64_t get_int(size_t ndx) const noexcept;
+    bool get_bool(size_t ndx) const noexcept;
+    OldDateTime get_olddatetime(size_t ndx) const noexcept;
+    Timestamp get_timestamp(size_t ndx) const noexcept;
+    float get_float(size_t ndx) const noexcept;
+    double get_double(size_t ndx) const noexcept;
+    StringData get_string(size_t ndx) const noexcept;
+    BinaryData get_binary(size_t ndx) const noexcept;
+    StringData get_index_data(size_t ndx, StringIndex::StringConversionBuffer& buffer) const noexcept override;
+
+    /// The returned array ref is zero if the specified row does not
+    /// contain a subtable.
+    ref_type get_subtable_ref(size_t row_ndx) const noexcept;
+
+    /// The returned size is zero if the specified row does not
+    /// contain a subtable.
+    size_t get_subtable_size(size_t row_ndx) const noexcept;
+
+    TableRef get_subtable_accessor(size_t row_ndx) const noexcept override;
+
+    void discard_subtable_accessor(size_t row_ndx) noexcept override;
+
+    /// If the value at the specified index is a subtable, return a
+    /// TableRef to that accessor for that subtable. Otherwise return
+    /// null. The accessor will be created if it does not already
+    /// exist.
+    TableRef get_subtable_tableref(size_t row_ndx);
+
+    ConstTableRef get_subtable_tableref(size_t subtable_ndx) const;
+
+    void set_int(size_t ndx, int64_t value);
+    void set_bool(size_t ndx, bool value);
+    void set_olddatetime(size_t ndx, OldDateTime value);
+    void set_timestamp(size_t ndx, Timestamp value);
+    void set_float(size_t ndx, float value);
+    void set_double(size_t ndx, double value);
+    void set_string(size_t ndx, StringData value) override;
+    void set_binary(size_t ndx, BinaryData value);
+    void set_subtable(size_t ndx, const Table* value);
+
+    void insert_int(size_t ndx, int_fast64_t value);
+    void insert_bool(size_t ndx, bool value);
+    void insert_olddatetime(size_t ndx, OldDateTime value);
+    void insert_timestamp(size_t ndx, Timestamp value);
+    void insert_float(size_t ndx, float value);
+    void insert_double(size_t ndx, double value);
+    void insert_string(size_t ndx, StringData value);
+    void insert_binary(size_t ndx, BinaryData value);
+    void insert_subtable(size_t ndx, const Table* value);
+
+    void erase(size_t row_ndx);
+    void move_last_over(size_t row_ndx);
+    void clear();
+
+    /// Compare two mixed columns for equality.
+    bool compare_mixed(const MixedColumn&) const;
+
+    int compare_values(size_t row1, size_t row2) const noexcept override;
+
+    void discard_child_accessors() noexcept;
+
+    static ref_type create(Allocator&, size_t size = 0);
+
+    static size_t get_size_from_ref(ref_type root_ref, Allocator&) noexcept;
+
+    // Overriding method in ColumnBase
+    ref_type write(size_t, size_t, size_t, _impl::OutputStream&) const override;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void swap_rows(size_t, size_t) override;
+    void clear(size_t, bool) override;
+    void update_from_parent(size_t) noexcept override;
+    void adj_acc_insert_rows(size_t, size_t) noexcept override;
+    void adj_acc_erase_row(size_t) noexcept override;
+    void adj_acc_move_over(size_t, size_t) noexcept override;
+    void adj_acc_swap_rows(size_t, size_t) noexcept override;
+    void adj_acc_move_row(size_t, size_t) noexcept override;
+    void adj_acc_clear_root_table() noexcept override;
+    void mark(int) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+
+    void verify() const override;
+    void verify(const Table&, size_t) const override;
+    void to_dot(std::ostream&, StringData title) const override;
+    void do_dump_node_structure(std::ostream&, int) const override;
+
+private:
+    enum MixedColType {
+        // NOTE: below numbers must be kept in sync with ColumnType
+        // Column types used in Mixed
+        mixcol_Int = 0,
+        mixcol_Bool = 1,
+        mixcol_String = 2,
+        //                    3, used for STRING_ENUM in ColumnType
+        mixcol_Binary = 4,
+        mixcol_Table = 5,
+        mixcol_Mixed = 6,
+        mixcol_OldDateTime = 7,
+        mixcol_Timestamp = 8,
+        mixcol_Float = 9,
+        mixcol_Double = 10,    // Positive Double
+        mixcol_DoubleNeg = 11, // Negative Double
+        mixcol_IntNeg = 12     // Negative Integers
+    };
+
+    class RefsColumn;
+
+    /// Stores the MixedColType of each value at the given index. For
+    /// values that uses all 64 bits, the type also encodes the sign
+    /// bit by having distinct types for positive negative values.
+    std::unique_ptr<IntegerColumn> m_types;
+
+    /// Stores the data for each entry. For a subtable, the stored
+    /// value is the ref of the subtable. For string, binary data,
+    /// the stored value is an index within `m_binary_data`. Likewise,
+    /// for timestamp, an index into `m_timestamp` is stored. For other
+    /// types the stored value is itself. Since we only have 63 bits
+    /// available for a non-ref value, the sign of numeric values is
+    /// encoded as part of the type in `m_types`.
+    std::unique_ptr<RefsColumn> m_data;
+
+    /// For string and binary data types, the bytes are stored here.
+    std::unique_ptr<BinaryColumn> m_binary_data;
+
+    /// Timestamps are stored here.
+    std::unique_ptr<TimestampColumn> m_timestamp_data;
+
+    void do_erase(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows);
+    void do_move_last_over(size_t row_ndx, size_t prior_num_rows);
+    void do_swap_rows(size_t, size_t);
+    void do_clear(size_t num_rows);
+
+    void create(Allocator&, ref_type, Table*, size_t column_ndx);
+    void ensure_binary_data_column();
+    void ensure_timestamp_column();
+
+    MixedColType clear_value(size_t ndx, MixedColType new_type); // Returns old type
+    void clear_value_and_discard_subtab_acc(size_t ndx, MixedColType new_type);
+
+    // Get/set/insert 64-bit values in m_data/m_types
+    int64_t get_value(size_t ndx) const noexcept;
+    void set_value(size_t ndx, int64_t value, MixedColType);
+    void set_int64(size_t ndx, int64_t value, MixedColType pos_type, MixedColType neg_type);
+
+    void insert_value(size_t row_ndx, int_fast64_t types_value, int_fast64_t data_value);
+    void insert_int(size_t ndx, int_fast64_t value, MixedColType type);
+    void insert_pos_neg(size_t ndx, int_fast64_t value, MixedColType pos_type, MixedColType neg_type);
+
+    void do_discard_child_accessors() noexcept override;
+
+#ifdef REALM_DEBUG
+    void do_verify(const Table*, size_t col_ndx) const;
+#endif
+    void leaf_to_dot(MemRef, ArrayParent*, size_t, std::ostream&) const override;
+};
+
+// LCOV_EXCL_START
+inline StringData MixedColumn::get_index_data(size_t, StringIndex::StringConversionBuffer&) const noexcept
+{
+    REALM_ASSERT(false && "Index not supported for MixedColumn yet.");
+    REALM_UNREACHABLE();
+    return {};
+}
+// LCOV_EXCL_STOP
+
+
+class MixedColumn::RefsColumn : public SubtableColumnBase {
+public:
+    RefsColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx);
+    ~RefsColumn() noexcept override;
+
+    using SubtableColumnBase::get_subtable_tableref;
+
+    void refresh_accessor_tree(size_t, const Spec&) override;
+
+    friend class MixedColumn;
+};
+
+
+} // namespace realm
+
+
+// Implementation
+#include <realm/column_mixed_tpl.hpp>
+
+
+#endif // REALM_COLUMN_MIXED_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_mixed_tpl.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_mixed_tpl.hpp
new file mode 100644
index 0000000..5afdddc
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_mixed_tpl.hpp
@@ -0,0 +1,514 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#include <realm/column_binary.hpp>
+#include <realm/column_timestamp.hpp>
+
+namespace realm {
+
+inline MixedColumn::MixedColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx)
+    : ColumnBaseSimple(column_ndx)
+{
+    create(alloc, ref, table, column_ndx);
+}
+
+inline void MixedColumn::adj_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept
+{
+    m_data->adj_acc_insert_rows(row_ndx, num_rows);
+}
+
+inline void MixedColumn::adj_acc_erase_row(size_t row_ndx) noexcept
+{
+    m_data->adj_acc_erase_row(row_ndx);
+}
+
+inline void MixedColumn::adj_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept
+{
+    m_data->adj_acc_swap_rows(row_ndx_1, row_ndx_2);
+}
+
+inline void MixedColumn::adj_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept
+{
+    m_data->adj_acc_move_row(from_ndx, to_ndx);
+}
+
+inline void MixedColumn::adj_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept
+{
+    m_data->adj_acc_move_over(from_row_ndx, to_row_ndx);
+}
+
+inline void MixedColumn::adj_acc_clear_root_table() noexcept
+{
+    m_data->adj_acc_clear_root_table();
+}
+
+inline ref_type MixedColumn::get_subtable_ref(size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_3(row_ndx, <, m_types->size());
+    if (m_types->get(row_ndx) != type_Table)
+        return 0;
+    return m_data->get_as_ref(row_ndx);
+}
+
+inline size_t MixedColumn::get_subtable_size(size_t row_ndx) const noexcept
+{
+    ref_type top_ref = get_subtable_ref(row_ndx);
+    if (top_ref == 0)
+        return 0;
+    return _impl::TableFriend::get_size_from_ref(top_ref, m_data->get_alloc());
+}
+
+inline TableRef MixedColumn::get_subtable_accessor(size_t row_ndx) const noexcept
+{
+    return m_data->get_subtable_accessor(row_ndx);
+}
+
+inline void MixedColumn::discard_subtable_accessor(size_t row_ndx) noexcept
+{
+    m_data->discard_subtable_accessor(row_ndx);
+}
+
+inline TableRef MixedColumn::get_subtable_tableref(size_t row_ndx)
+{
+    REALM_ASSERT_3(row_ndx, <, m_types->size());
+    if (m_types->get(row_ndx) != type_Table)
+        return {};
+    return m_data->get_subtable_tableref(row_ndx); // Throws
+}
+
+inline ConstTableRef MixedColumn::get_subtable_tableref(size_t subtable_ndx) const
+{
+    return const_cast<MixedColumn*>(this)->get_subtable_tableref(subtable_ndx);
+}
+
+inline void MixedColumn::discard_child_accessors() noexcept
+{
+    m_data->discard_child_accessors();
+}
+
+
+//
+// Getters
+//
+
+#define REALM_BIT63 0x8000000000000000ULL
+
+inline int64_t MixedColumn::get_value(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+
+    // Shift the unsigned value right - ensuring 0 gets in from left.
+    // Shifting signed integers right doesn't ensure 0's.
+    uint64_t value = uint64_t(m_data->get(ndx)) >> 1;
+    return int64_t(value);
+}
+
+inline int64_t MixedColumn::get_int(size_t ndx) const noexcept
+{
+    // Get first 63 bits of the integer value
+    int64_t value = get_value(ndx);
+
+    // restore 'sign'-bit from the column-type
+    MixedColType col_type = MixedColType(m_types->get(ndx));
+    if (col_type == mixcol_IntNeg) {
+        // FIXME: Bad cast of result of '|' from unsigned to signed
+        value |= REALM_BIT63; // set sign bit (63)
+    }
+    else {
+        REALM_ASSERT_3(col_type, ==, mixcol_Int);
+    }
+    return value;
+}
+
+inline bool MixedColumn::get_bool(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(m_types->get(ndx), ==, mixcol_Bool);
+
+    return (get_value(ndx) != 0);
+}
+
+inline OldDateTime MixedColumn::get_olddatetime(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(m_types->get(ndx), ==, mixcol_OldDateTime);
+
+    return OldDateTime(get_value(ndx));
+}
+
+inline float MixedColumn::get_float(size_t ndx) const noexcept
+{
+    static_assert(std::numeric_limits<float>::is_iec559, "'float' is not IEEE");
+    static_assert((sizeof(float) * CHAR_BIT == 32), "Assume 32 bit float.");
+    REALM_ASSERT_3(m_types->get(ndx), ==, mixcol_Float);
+
+    return type_punning<float>(get_value(ndx));
+}
+
+inline double MixedColumn::get_double(size_t ndx) const noexcept
+{
+    static_assert(std::numeric_limits<double>::is_iec559, "'double' is not IEEE");
+    static_assert((sizeof(double) * CHAR_BIT == 64), "Assume 64 bit double.");
+
+    int64_t int_val = get_value(ndx);
+
+    // restore 'sign'-bit from the column-type
+    MixedColType col_type = MixedColType(m_types->get(ndx));
+    if (col_type == mixcol_DoubleNeg)
+        int_val |= REALM_BIT63; // set sign bit (63)
+    else {
+        REALM_ASSERT_3(col_type, ==, mixcol_Double);
+    }
+    return type_punning<double>(int_val);
+}
+
+inline StringData MixedColumn::get_string(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+    REALM_ASSERT_3(m_types->get(ndx), ==, mixcol_String);
+    REALM_ASSERT(m_binary_data);
+
+    size_t data_ndx = size_t(int64_t(m_data->get(ndx)) >> 1);
+    return m_binary_data->get_string(data_ndx);
+}
+
+inline BinaryData MixedColumn::get_binary(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+    REALM_ASSERT_3(m_types->get(ndx), ==, mixcol_Binary);
+    REALM_ASSERT(m_binary_data);
+
+    size_t data_ndx = size_t(uint64_t(m_data->get(ndx)) >> 1);
+    return m_binary_data->get(data_ndx);
+}
+
+inline Timestamp MixedColumn::get_timestamp(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+    REALM_ASSERT_3(m_types->get(ndx), ==, mixcol_Timestamp);
+    REALM_ASSERT(m_timestamp_data);
+    size_t data_ndx = size_t(uint64_t(m_data->get(ndx)) >> 1);
+    return m_timestamp_data->get(data_ndx);
+}
+
+//
+// Setters
+//
+
+// Set a int64 value.
+// Store 63 bit of the value in m_data. Store sign bit in m_types.
+
+inline void MixedColumn::set_int64(size_t ndx, int64_t value, MixedColType pos_type, MixedColType neg_type)
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+
+    // If sign-bit is set in value, 'store' it in the column-type
+    MixedColType coltype = ((value & REALM_BIT63) == 0) ? pos_type : neg_type;
+
+    // Remove refs or binary data (sets type to double)
+    clear_value_and_discard_subtab_acc(ndx, coltype); // Throws
+
+    // Shift value one bit and set lowest bit to indicate that this is not a ref
+    value = (value << 1) + 1;
+    m_data->set(ndx, value);
+}
+
+inline void MixedColumn::set_int(size_t ndx, int64_t value)
+{
+    set_int64(ndx, value, mixcol_Int, mixcol_IntNeg); // Throws
+}
+
+inline void MixedColumn::set_double(size_t ndx, double value)
+{
+    int64_t val64 = type_punning<int64_t>(value);
+    set_int64(ndx, val64, mixcol_Double, mixcol_DoubleNeg); // Throws
+}
+
+inline void MixedColumn::set_value(size_t ndx, int64_t value, MixedColType coltype)
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+
+    // Remove refs or binary data (sets type to float)
+    clear_value_and_discard_subtab_acc(ndx, coltype); // Throws
+
+    // Shift value one bit and set lowest bit to indicate that this is not a ref
+    int64_t v = (value << 1) + 1;
+    m_data->set(ndx, v); // Throws
+}
+
+inline void MixedColumn::set_float(size_t ndx, float value)
+{
+    int64_t val64 = type_punning<int64_t>(value);
+    set_value(ndx, val64, mixcol_Float); // Throws
+}
+
+inline void MixedColumn::set_bool(size_t ndx, bool value)
+{
+    set_value(ndx, (value ? 1 : 0), mixcol_Bool); // Throws
+}
+
+inline void MixedColumn::set_olddatetime(size_t ndx, OldDateTime value)
+{
+    set_value(ndx, int64_t(value.get_olddatetime()), mixcol_OldDateTime); // Throws
+}
+
+inline void MixedColumn::set_subtable(size_t ndx, const Table* t)
+{
+    REALM_ASSERT_3(ndx, <, m_types->size());
+    typedef _impl::TableFriend tf;
+    ref_type ref;
+    if (t) {
+        ref = tf::clone(*t, get_alloc()); // Throws
+    }
+    else {
+        ref = tf::create_empty_table(get_alloc()); // Throws
+    }
+    // Remove any previous refs or binary data
+    clear_value_and_discard_subtab_acc(ndx, mixcol_Table); // Throws
+    m_data->set(ndx, ref);                                 // Throws
+}
+
+//
+// Inserts
+//
+
+inline void MixedColumn::insert_value(size_t row_ndx, int_fast64_t types_value, int_fast64_t data_value)
+{
+    size_t types_size = m_types->size(); // Slow
+    bool is_append = row_ndx == types_size;
+    size_t row_ndx_2 = is_append ? realm::npos : row_ndx;
+    size_t num_rows = 1;
+    m_types->insert_without_updating_index(row_ndx_2, types_value, num_rows); // Throws
+    m_data->do_insert(row_ndx_2, data_value, num_rows);                       // Throws
+}
+
+// Insert a int64 value.
+// Store 63 bit of the value in m_data. Store sign bit in m_types.
+
+inline void MixedColumn::insert_int(size_t ndx, int_fast64_t value, MixedColType type)
+{
+    int_fast64_t types_value = type;
+    // Shift value one bit and set lowest bit to indicate that this is not a ref
+    int_fast64_t data_value = 1 + (value << 1);
+    insert_value(ndx, types_value, data_value); // Throws
+}
+
+inline void MixedColumn::insert_pos_neg(size_t ndx, int_fast64_t value, MixedColType pos_type, MixedColType neg_type)
+{
+    // 'store' the sign-bit in the integer-type
+    MixedColType type = (value & REALM_BIT63) == 0 ? pos_type : neg_type;
+    int_fast64_t types_value = type;
+    // Shift value one bit and set lowest bit to indicate that this is not a ref
+    int_fast64_t data_value = 1 + (value << 1);
+    insert_value(ndx, types_value, data_value); // Throws
+}
+
+inline void MixedColumn::insert_int(size_t ndx, int_fast64_t value)
+{
+    insert_pos_neg(ndx, value, mixcol_Int, mixcol_IntNeg); // Throws
+}
+
+inline void MixedColumn::insert_double(size_t ndx, double value)
+{
+    int_fast64_t value_2 = type_punning<int64_t>(value);
+    insert_pos_neg(ndx, value_2, mixcol_Double, mixcol_DoubleNeg); // Throws
+}
+
+inline void MixedColumn::insert_float(size_t ndx, float value)
+{
+    int_fast64_t value_2 = type_punning<int32_t>(value);
+    insert_int(ndx, value_2, mixcol_Float); // Throws
+}
+
+inline void MixedColumn::insert_bool(size_t ndx, bool value)
+{
+    int_fast64_t value_2 = int_fast64_t(value);
+    insert_int(ndx, value_2, mixcol_Bool); // Throws
+}
+
+inline void MixedColumn::insert_olddatetime(size_t ndx, OldDateTime value)
+{
+    int_fast64_t value_2 = int_fast64_t(value.get_olddatetime());
+    insert_int(ndx, value_2, mixcol_OldDateTime); // Throws
+}
+
+inline void MixedColumn::insert_timestamp(size_t ndx, Timestamp value)
+{
+    ensure_timestamp_column();
+    size_t data_ndx = m_timestamp_data->size();
+    m_timestamp_data->add(value); // Throws
+    insert_int(ndx, int_fast64_t(data_ndx), mixcol_Timestamp);
+}
+
+inline void MixedColumn::insert_string(size_t ndx, StringData value)
+{
+    ensure_binary_data_column();
+    size_t blob_ndx = m_binary_data->size();
+    m_binary_data->add_string(value); // Throws
+
+    int_fast64_t value_2 = int_fast64_t(blob_ndx);
+    insert_int(ndx, value_2, mixcol_String); // Throws
+}
+
+inline void MixedColumn::insert_binary(size_t ndx, BinaryData value)
+{
+    ensure_binary_data_column();
+    size_t blob_ndx = m_binary_data->size();
+    m_binary_data->add(value); // Throws
+
+    int_fast64_t value_2 = int_fast64_t(blob_ndx);
+    insert_int(ndx, value_2, mixcol_Binary); // Throws
+}
+
+inline void MixedColumn::insert_subtable(size_t ndx, const Table* t)
+{
+    typedef _impl::TableFriend tf;
+    ref_type ref;
+    if (t) {
+        ref = tf::clone(*t, get_alloc()); // Throws
+    }
+    else {
+        ref = tf::create_empty_table(get_alloc()); // Throws
+    }
+    int_fast64_t types_value = mixcol_Table;
+    int_fast64_t data_value = int_fast64_t(ref);
+    insert_value(ndx, types_value, data_value); // Throws
+}
+
+inline void MixedColumn::erase(size_t row_ndx)
+{
+    size_t num_rows_to_erase = 1;
+    size_t prior_num_rows = size();                       // Note that size() is slow
+    do_erase(row_ndx, num_rows_to_erase, prior_num_rows); // Throws
+}
+
+inline void MixedColumn::move_last_over(size_t row_ndx)
+{
+    size_t prior_num_rows = size();             // Note that size() is slow
+    do_move_last_over(row_ndx, prior_num_rows); // Throws
+}
+
+inline void MixedColumn::swap_rows(size_t row_ndx_1, size_t row_ndx_2)
+{
+    do_swap_rows(row_ndx_1, row_ndx_2);
+}
+
+inline void MixedColumn::clear()
+{
+    size_t num_rows = size(); // Note that size() is slow
+    do_clear(num_rows);       // Throws
+}
+
+inline size_t MixedColumn::get_size_from_ref(ref_type root_ref, Allocator& alloc) noexcept
+{
+    const char* root_header = alloc.translate(root_ref);
+    ref_type types_ref = to_ref(Array::get(root_header, 0));
+    return IntegerColumn::get_size_from_ref(types_ref, alloc);
+}
+
+inline void MixedColumn::clear_value_and_discard_subtab_acc(size_t row_ndx, MixedColType new_type)
+{
+    MixedColType old_type = clear_value(row_ndx, new_type);
+    if (old_type == mixcol_Table)
+        m_data->discard_subtable_accessor(row_ndx);
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void MixedColumn::insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows,
+                                     bool insert_nulls)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx <= prior_num_rows);
+    REALM_ASSERT(!insert_nulls);
+
+    size_t row_ndx_2 = (row_ndx == prior_num_rows ? realm::npos : row_ndx);
+
+    int_fast64_t type_value = mixcol_Int;
+    m_types->insert_without_updating_index(row_ndx_2, type_value, num_rows_to_insert); // Throws
+
+    // The least significant bit indicates that the rest of the bits form an
+    // integer value, so 1 is actually zero.
+    int_fast64_t data_value = 1;
+    m_data->do_insert(row_ndx_2, data_value, num_rows_to_insert); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void MixedColumn::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool)
+{
+    do_erase(row_ndx, num_rows_to_erase, prior_num_rows); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void MixedColumn::move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool)
+{
+    do_move_last_over(row_ndx, prior_num_rows); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void MixedColumn::clear(size_t num_rows, bool)
+{
+    do_clear(num_rows); // Throws
+}
+
+inline void MixedColumn::mark(int type) noexcept
+{
+    m_data->mark(type);
+}
+
+inline void MixedColumn::refresh_accessor_tree(size_t col_ndx, const Spec& spec)
+{
+    ColumnBaseSimple::refresh_accessor_tree(col_ndx, spec);
+
+    get_root_array()->init_from_parent();
+    m_types->refresh_accessor_tree(col_ndx, spec); // Throws
+    m_data->refresh_accessor_tree(col_ndx, spec);  // Throws
+
+    m_binary_data.reset();
+    // See if m_binary_data needs to be created.
+    if (get_root_array()->size() >= 3) {
+        ref_type ref = get_root_array()->get_as_ref(2);
+        m_binary_data.reset(new BinaryColumn(get_alloc(), ref)); // Throws
+        m_binary_data->set_parent(get_root_array(), 2);
+    }
+
+    m_timestamp_data.reset();
+    // See if m_timestamp_data needs to be created.
+    if (get_root_array()->size() >= 4) {
+        ref_type ref = get_root_array()->get_as_ref(3);
+        // When adding/creating a Mixed column the user cannot specify nullability, so the "true" below
+        // makes it implicitly nullable, which may not be wanted. But it's OK since Mixed columns are not
+        // publicly supported
+        m_timestamp_data.reset(new TimestampColumn(true /*fixme*/, get_alloc(), ref)); // Throws
+        m_timestamp_data->set_parent(get_root_array(), 3);
+    }
+
+    if (m_binary_data) {
+        REALM_ASSERT_3(get_root_array()->size(), >=, 3);
+        m_binary_data->refresh_accessor_tree(col_ndx, spec); // Throws
+    }
+    if (m_timestamp_data) {
+        REALM_ASSERT_3(get_root_array()->size(), >=, 4);
+        m_timestamp_data->refresh_accessor_tree(col_ndx, spec); // Throws
+    }
+}
+
+inline void MixedColumn::RefsColumn::refresh_accessor_tree(size_t col_ndx, const Spec& spec)
+{
+    SubtableColumnBase::refresh_accessor_tree(col_ndx, spec); // Throws
+    m_subtable_map.refresh_accessor_tree();                   // Throws
+}
+
+} // namespace realm
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_string.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_string.hpp
new file mode 100644
index 0000000..e7693ee
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_string.hpp
@@ -0,0 +1,377 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_STRING_HPP
+#define REALM_COLUMN_STRING_HPP
+
+#include <memory>
+#include <realm/array_string.hpp>
+#include <realm/array_string_long.hpp>
+#include <realm/array_blobs_big.hpp>
+#include <realm/column.hpp>
+#include <realm/column_tpl.hpp>
+
+namespace realm {
+
+// Pre-declarations
+class StringIndex;
+
+
+/// A string column (StringColumn) is a single B+-tree, and
+/// the root of the column is the root of the B+-tree. Leaf nodes are
+/// either of type ArrayString (array of small strings),
+/// ArrayStringLong (array of medium strings), or ArrayBigBlobs (array
+/// of big strings).
+///
+/// A string column can optionally be equipped with a search index. If
+/// it is, then the root ref of the index is stored in
+/// Table::m_columns immediately after the root ref of the string
+/// column.
+class StringColumn : public ColumnBaseSimple {
+public:
+    typedef StringData value_type;
+
+    StringColumn(Allocator&, ref_type, bool nullable = false, size_t column_ndx = npos);
+    ~StringColumn() noexcept override;
+
+    void destroy() noexcept override;
+
+    size_t size() const noexcept final;
+    bool is_empty() const noexcept
+    {
+        return size() == 0;
+    }
+
+    bool is_null(size_t ndx) const noexcept final;
+    void set_null(size_t ndx) final;
+    StringData get(size_t ndx) const noexcept;
+    void set(size_t ndx, StringData);
+    void add();
+    void add(StringData value);
+    void insert(size_t ndx);
+    void insert(size_t ndx, StringData value);
+    void erase(size_t row_ndx);
+    void move_last_over(size_t row_ndx);
+    void swap_rows(size_t row_ndx_1, size_t row_ndx_2) override;
+    void clear();
+
+    size_t count(StringData value) const;
+    size_t find_first(StringData value, size_t begin = 0, size_t end = npos) const;
+    void find_all(IntegerColumn& result, StringData value, size_t begin = 0, size_t end = npos) const;
+    FindRes find_all_no_copy(StringData value, InternalFindResult& result) const;
+
+    int compare_values(size_t, size_t) const noexcept override;
+
+    //@{
+    /// Find the lower/upper bound for the specified value assuming
+    /// that the elements are already sorted in ascending order
+    /// according to StringData::operator<().
+    size_t lower_bound_string(StringData value) const noexcept;
+    size_t upper_bound_string(StringData value) const noexcept;
+    //@}
+
+    void set_string(size_t, StringData) override;
+
+    bool is_nullable() const noexcept final;
+
+    // Search index
+    StringData get_index_data(size_t ndx, StringIndex::StringConversionBuffer& buffer) const noexcept final;
+    bool has_search_index() const noexcept override;
+    void set_search_index_ref(ref_type, ArrayParent*, size_t) override;
+    StringIndex* get_search_index() noexcept override;
+    const StringIndex* get_search_index() const noexcept override;
+    std::unique_ptr<StringIndex> release_search_index() noexcept;
+    bool supports_search_index() const noexcept final
+    {
+        return true;
+    }
+    StringIndex* create_search_index() override;
+
+    // Simply inserts all column values in the index in a loop
+    void populate_search_index();
+    void destroy_search_index() noexcept override;
+
+    // Optimizing data layout. enforce == true will enforce enumeration;
+    // enforce == false will auto-evaluate if it should be enumerated or not
+    bool auto_enumerate(ref_type& keys, ref_type& values, bool enforce = false) const;
+
+    /// Compare two string columns for equality.
+    bool compare_string(const StringColumn&) const;
+
+    enum LeafType {
+        leaf_type_Small,  ///< ArrayString
+        leaf_type_Medium, ///< ArrayStringLong
+        leaf_type_Big     ///< ArrayBigBlobs
+    };
+
+    std::unique_ptr<const ArrayParent> get_leaf(size_t ndx, size_t& out_ndx_in_parent, LeafType& out_leaf_type) const;
+
+    static ref_type create(Allocator&, size_t size = 0);
+
+    static size_t get_size_from_ref(ref_type root_ref, Allocator&) noexcept;
+
+    // Overrriding method in ColumnBase
+    ref_type write(size_t, size_t, size_t, _impl::OutputStream&) const override;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void clear(size_t, bool) override;
+    void set_ndx_in_parent(size_t ndx_in_parent) noexcept override;
+    void update_from_parent(size_t old_baseline) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+
+    void verify() const override;
+    void verify(const Table&, size_t) const override;
+    void to_dot(std::ostream&, StringData title) const override;
+    void do_dump_node_structure(std::ostream&, int) const override;
+
+private:
+    std::unique_ptr<StringIndex> m_search_index;
+    bool m_nullable;
+
+    LeafType get_block(size_t ndx, ArrayParent**, size_t& off, bool use_retval = false) const;
+
+    /// If you are appending and have the size of the column readily available,
+    /// call the 4 argument version instead. If you are not appending, either
+    /// one is fine.
+    ///
+    /// \param row_ndx Must be `realm::npos` if appending.
+    void do_insert(size_t row_ndx, StringData value, size_t num_rows);
+
+    /// If you are appending and you do not have the size of the column readily
+    /// available, call the 3 argument version instead. If you are not
+    /// appending, either one is fine.
+    ///
+    /// \param is_append Must be true if, and only if `row_ndx` is equal to the
+    /// size of the column (before insertion).
+    void do_insert(size_t row_ndx, StringData value, size_t num_rows, bool is_append);
+
+    /// \param row_ndx Must be `realm::npos` if appending.
+    void bptree_insert(size_t row_ndx, StringData value, size_t num_rows);
+
+    // Called by Array::bptree_insert().
+    static ref_type leaf_insert(MemRef leaf_mem, ArrayParent&, size_t ndx_in_parent, Allocator&, size_t insert_ndx,
+                                BpTreeNode::TreeInsert<StringColumn>& state);
+
+    class EraseLeafElem;
+    class CreateHandler;
+    class SliceHandler;
+
+    void do_erase(size_t row_ndx, bool is_last);
+    void do_move_last_over(size_t row_ndx, size_t last_row_ndx);
+    void do_swap_rows(size_t row_ndx_1, size_t row_ndx_2);
+    void do_clear();
+
+    /// Root must be a leaf. Upgrades the root leaf as
+    /// necessary. Returns the type of the root leaf as it is upon
+    /// return.
+    LeafType upgrade_root_leaf(size_t value_size);
+
+    void refresh_root_accessor();
+
+    void leaf_to_dot(MemRef, ArrayParent*, size_t ndx_in_parent, std::ostream&) const override;
+
+    friend class BpTreeNode;
+    friend class ColumnBase;
+};
+
+
+// Implementation:
+
+inline size_t StringColumn::size() const noexcept
+{
+    if (root_is_leaf()) {
+        bool long_strings = m_array->has_refs();
+        if (!long_strings) {
+            // Small strings root leaf
+            ArrayString* leaf = static_cast<ArrayString*>(m_array.get());
+            return leaf->size();
+        }
+        bool is_big = m_array->get_context_flag();
+        if (!is_big) {
+            // Medium strings root leaf
+            ArrayStringLong* leaf = static_cast<ArrayStringLong*>(m_array.get());
+            return leaf->size();
+        }
+        // Big strings root leaf
+        ArrayBigBlobs* leaf = static_cast<ArrayBigBlobs*>(m_array.get());
+        return leaf->size();
+    }
+    // Non-leaf root
+    BpTreeNode* node = static_cast<BpTreeNode*>(m_array.get());
+    return node->get_bptree_size();
+}
+
+inline void StringColumn::add(StringData value)
+{
+    REALM_ASSERT(!(value.is_null() && !m_nullable));
+    size_t row_ndx = realm::npos;
+    size_t num_rows = 1;
+    do_insert(row_ndx, value, num_rows); // Throws
+}
+
+inline void StringColumn::add()
+{
+    add(m_nullable ? realm::null() : StringData(""));
+}
+
+inline void StringColumn::insert(size_t row_ndx, StringData value)
+{
+    REALM_ASSERT(!(value.is_null() && !m_nullable));
+    size_t column_size = this->size();
+    REALM_ASSERT_3(row_ndx, <=, column_size);
+    size_t num_rows = 1;
+    bool is_append = row_ndx == column_size;
+    do_insert(row_ndx, value, num_rows, is_append); // Throws
+}
+
+inline void StringColumn::insert(size_t row_ndx)
+{
+    insert(row_ndx, m_nullable ? realm::null() : StringData(""));
+}
+
+inline void StringColumn::erase(size_t row_ndx)
+{
+    size_t last_row_ndx = size() - 1; // Note that size() is slow
+    bool is_last = row_ndx == last_row_ndx;
+    do_erase(row_ndx, is_last); // Throws
+}
+
+inline void StringColumn::move_last_over(size_t row_ndx)
+{
+    size_t last_row_ndx = size() - 1;         // Note that size() is slow
+    do_move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+inline void StringColumn::swap_rows(size_t row_ndx_1, size_t row_ndx_2)
+{
+    do_swap_rows(row_ndx_1, row_ndx_2); // Throws
+}
+
+inline void StringColumn::clear()
+{
+    do_clear(); // Throws
+}
+
+inline int StringColumn::compare_values(size_t row1, size_t row2) const noexcept
+{
+    StringData a = get(row1);
+    StringData b = get(row2);
+
+    if (a.is_null() && !b.is_null())
+        return 1;
+    else if (b.is_null() && !a.is_null())
+        return -1;
+    else if (a.is_null() && b.is_null())
+        return 0;
+
+    if (a == b)
+        return 0;
+    return utf8_compare(a, b) ? 1 : -1;
+}
+
+inline void StringColumn::set_string(size_t row_ndx, StringData value)
+{
+    REALM_ASSERT(!(value.is_null() && !m_nullable));
+    set(row_ndx, value); // Throws
+}
+
+inline bool StringColumn::has_search_index() const noexcept
+{
+    return m_search_index != 0;
+}
+
+inline StringIndex* StringColumn::get_search_index() noexcept
+{
+    return m_search_index.get();
+}
+
+inline const StringIndex* StringColumn::get_search_index() const noexcept
+{
+    return m_search_index.get();
+}
+
+inline size_t StringColumn::get_size_from_ref(ref_type root_ref, Allocator& alloc) noexcept
+{
+    const char* root_header = alloc.translate(root_ref);
+    bool root_is_leaf = !Array::get_is_inner_bptree_node_from_header(root_header);
+    if (root_is_leaf) {
+        bool long_strings = Array::get_hasrefs_from_header(root_header);
+        if (!long_strings) {
+            // Small strings leaf
+            return ArrayString::get_size_from_header(root_header);
+        }
+        bool is_big = Array::get_context_flag_from_header(root_header);
+        if (!is_big) {
+            // Medium strings leaf
+            return ArrayStringLong::get_size_from_header(root_header, alloc);
+        }
+        // Big strings leaf
+        return ArrayBigBlobs::get_size_from_header(root_header);
+    }
+
+    return BpTreeNode::get_bptree_size_from_header(root_header);
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void StringColumn::insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows,
+                                      bool insert_nulls)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx <= prior_num_rows);
+    REALM_ASSERT(!insert_nulls || m_nullable);
+
+    StringData value = m_nullable ? realm::null() : StringData("");
+    bool is_append = (row_ndx == prior_num_rows);
+    do_insert(row_ndx, value, num_rows_to_insert, is_append); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void StringColumn::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(num_rows_to_erase <= prior_num_rows);
+    REALM_ASSERT(row_ndx <= prior_num_rows - num_rows_to_erase);
+
+    bool is_last = (row_ndx + num_rows_to_erase == prior_num_rows);
+    for (size_t i = num_rows_to_erase; i > 0; --i) {
+        size_t row_ndx_2 = row_ndx + i - 1;
+        do_erase(row_ndx_2, is_last); // Throws
+    }
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void StringColumn::move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx < prior_num_rows);
+
+    size_t last_row_ndx = prior_num_rows - 1;
+    do_move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+// Implementing pure virtual method of ColumnBase.
+inline void StringColumn::clear(size_t, bool)
+{
+    do_clear(); // Throws
+}
+
+} // namespace realm
+
+#endif // REALM_COLUMN_STRING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_string_enum.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_string_enum.hpp
new file mode 100644
index 0000000..a73fe0c
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_string_enum.hpp
@@ -0,0 +1,311 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_STRING_ENUM_HPP
+#define REALM_COLUMN_STRING_ENUM_HPP
+
+#include <realm/column_string.hpp>
+
+namespace realm {
+
+// Pre-declarations
+class StringIndex;
+
+
+/// From the point of view of the application, an enumerated strings column
+/// (StringEnumColumn) is like a string column (StringColumn), yet it manages
+/// its strings in such a way that each unique string is stored only once. In
+/// fact, an enumerated strings column is a combination of two subcolumns; a
+/// regular string column (StringColumn) that stores the unique strings, and an
+/// integer column that stores one unique string index for each entry in the
+/// enumerated strings column.
+///
+/// In terms of the underlying node structure, the subcolumn containing the
+/// unique strings is not a true part of the enumerated strings column. Instead
+/// it is a part of the spec structure that describes the table of which the
+/// enumerated strings column is a part. This way, the unique strings can be
+/// shared across enumerated strings columns of multiple subtables. This also
+/// means that the root of an enumerated strings column coincides with the root
+/// of the integer subcolumn, and in some sense, an enumerated strings column is
+/// just the integer subcolumn.
+///
+/// An enumerated strings column can optionally be equipped with a
+/// search index. If it is, then the root ref of the index is stored
+/// in Table::m_columns immediately after the root ref of the
+/// enumerated strings column.
+class StringEnumColumn : public IntegerColumn {
+public:
+    typedef StringData value_type;
+
+    StringEnumColumn(Allocator&, ref_type ref, ref_type keys_ref, bool nullable, size_t column_ndx = npos);
+    ~StringEnumColumn() noexcept override;
+    void destroy() noexcept override;
+    MemRef clone_deep(Allocator& alloc) const override;
+
+    int compare_values(size_t row1, size_t row2) const noexcept override
+    {
+        StringData a = get(row1);
+        StringData b = get(row2);
+
+        if (a.is_null() && !b.is_null())
+            return 1;
+        else if (b.is_null() && !a.is_null())
+            return -1;
+        else if (a.is_null() && b.is_null())
+            return 0;
+
+        if (a == b)
+            return 0;
+
+        return utf8_compare(a, b) ? 1 : -1;
+    }
+
+    StringData get(size_t ndx) const noexcept;
+    bool is_null(size_t ndx) const noexcept final;
+    void set(size_t ndx, StringData value);
+    void set_null(size_t ndx) override;
+    void add();
+    void add(StringData value);
+    void insert(size_t ndx);
+    void insert(size_t ndx, StringData value);
+    void erase(size_t row_ndx);
+    void move_last_over(size_t row_ndx);
+    void swap_rows(size_t row_ndx_1, size_t row_ndx_2) override;
+    void clear();
+    bool is_nullable() const noexcept final;
+
+    size_t count(StringData value) const;
+    size_t find_first(StringData value, size_t begin = 0, size_t end = npos) const;
+    void find_all(IntegerColumn& res, StringData value, size_t begin = 0, size_t end = npos) const;
+    FindRes find_all_no_copy(StringData value, InternalFindResult& result) const;
+
+    size_t count(size_t key_index) const;
+    size_t find_first(size_t key_index, size_t begin = 0, size_t end = -1) const;
+    void find_all(IntegerColumn& res, size_t key_index, size_t begin = 0, size_t end = -1) const;
+
+    //@{
+    /// Find the lower/upper bound for the specified value assuming
+    /// that the elements are already sorted in ascending order
+    /// according to StringData::operator<().
+    size_t lower_bound_string(StringData value) const noexcept;
+    size_t upper_bound_string(StringData value) const noexcept;
+    //@}
+
+    void set_string(size_t, StringData) override;
+
+    void adjust_keys_ndx_in_parent(int diff) noexcept;
+
+    // Search index
+    StringData get_index_data(size_t ndx, StringIndex::StringConversionBuffer& buffer) const noexcept final;
+    bool supports_search_index() const noexcept final
+    {
+        return true;
+    }
+    StringIndex* create_search_index() override;
+    void install_search_index(std::unique_ptr<StringIndex>) noexcept;
+    void destroy_search_index() noexcept override;
+
+    // Compare two string columns for equality
+    bool compare_string(const StringColumn&) const;
+    bool compare_string(const StringEnumColumn&) const;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void clear(size_t, bool) override;
+    void update_from_parent(size_t) noexcept override;
+    void refresh_accessor_tree(size_t, const Spec&) override;
+
+    size_t get_key_ndx(StringData value) const;
+    size_t get_key_ndx_or_add(StringData value);
+
+    StringColumn& get_keys();
+    const StringColumn& get_keys() const;
+
+#ifdef REALM_DEBUG
+    void verify() const override;
+    void verify(const Table&, size_t) const override;
+    void do_dump_node_structure(std::ostream&, int) const override;
+    void to_dot(std::ostream&, StringData title) const override;
+#endif
+
+private:
+    // Member variables
+    StringColumn m_keys;
+    bool m_nullable;
+
+    /// If you are appending and have the size of the column readily available,
+    /// call the 4 argument version instead. If you are not appending, either
+    /// one is fine.
+    ///
+    /// \param row_ndx Must be `realm::npos` if appending.
+    void do_insert(size_t row_ndx, StringData value, size_t num_rows);
+
+    /// If you are appending and you do not have the size of the column readily
+    /// available, call the 3 argument version instead. If you are not
+    /// appending, either one is fine.
+    ///
+    /// \param is_append Must be true if, and only if `row_ndx` is equal to the
+    /// size of the column (before insertion).
+    void do_insert(size_t row_ndx, StringData value, size_t num_rows, bool is_append);
+
+    void do_erase(size_t row_ndx, bool is_last);
+    void do_move_last_over(size_t row_ndx, size_t last_row_ndx);
+    void do_clear();
+};
+
+
+// Implementation:
+
+inline StringData StringEnumColumn::get(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, IntegerColumn::size());
+    size_t key_ndx = to_size_t(IntegerColumn::get(ndx));
+    StringData sd = m_keys.get(key_ndx);
+    REALM_ASSERT_DEBUG(!(!m_nullable && sd.is_null()));
+    return sd;
+}
+
+inline bool StringEnumColumn::is_null(size_t ndx) const noexcept
+{
+    return is_nullable() && get(ndx).is_null();
+}
+
+inline void StringEnumColumn::add()
+{
+    add(m_nullable ? realm::null() : StringData(""));
+}
+
+inline void StringEnumColumn::add(StringData value)
+{
+    REALM_ASSERT_DEBUG(!(!m_nullable && value.is_null()));
+    size_t row_ndx = realm::npos;
+    size_t num_rows = 1;
+    do_insert(row_ndx, value, num_rows); // Throws
+}
+
+inline void StringEnumColumn::insert(size_t row_ndx)
+{
+    insert(row_ndx, m_nullable ? realm::null() : StringData(""));
+}
+
+inline void StringEnumColumn::insert(size_t row_ndx, StringData value)
+{
+    REALM_ASSERT_DEBUG(!(!m_nullable && value.is_null()));
+    size_t column_size = this->size();
+    REALM_ASSERT_3(row_ndx, <=, column_size);
+    size_t num_rows = 1;
+    bool is_append = row_ndx == column_size;
+    do_insert(row_ndx, value, num_rows, is_append); // Throws
+}
+
+inline void StringEnumColumn::erase(size_t row_ndx)
+{
+    size_t last_row_ndx = size() - 1; // Note that size() is slow
+    bool is_last = row_ndx == last_row_ndx;
+    do_erase(row_ndx, is_last); // Throws
+}
+
+inline void StringEnumColumn::move_last_over(size_t row_ndx)
+{
+    size_t last_row_ndx = size() - 1;         // Note that size() is slow
+    do_move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+inline void StringEnumColumn::clear()
+{
+    do_clear(); // Throws
+}
+
+// Overriding virtual method of Column.
+inline void StringEnumColumn::insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows,
+                                          bool insert_nulls)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx <= prior_num_rows);
+    REALM_ASSERT(!insert_nulls || m_nullable);
+
+    StringData value = m_nullable ? realm::null() : StringData("");
+    bool is_append = (row_ndx == prior_num_rows);
+    do_insert(row_ndx, value, num_rows_to_insert, is_append); // Throws
+}
+
+// Overriding virtual method of Column.
+inline void StringEnumColumn::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(num_rows_to_erase <= prior_num_rows);
+    REALM_ASSERT(row_ndx <= prior_num_rows - num_rows_to_erase);
+
+    bool is_last = (row_ndx + num_rows_to_erase == prior_num_rows);
+    for (size_t i = num_rows_to_erase; i > 0; --i) {
+        size_t row_ndx_2 = row_ndx + i - 1;
+        do_erase(row_ndx_2, is_last); // Throws
+    }
+}
+
+// Overriding virtual method of Column.
+inline void StringEnumColumn::move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx < prior_num_rows);
+
+    size_t last_row_ndx = prior_num_rows - 1;
+    do_move_last_over(row_ndx, last_row_ndx); // Throws
+}
+
+// Overriding virtual method of Column.
+inline void StringEnumColumn::clear(size_t, bool)
+{
+    do_clear(); // Throws
+}
+
+inline size_t StringEnumColumn::lower_bound_string(StringData value) const noexcept
+{
+    return ColumnBase::lower_bound(*this, value);
+}
+
+inline size_t StringEnumColumn::upper_bound_string(StringData value) const noexcept
+{
+    return ColumnBase::upper_bound(*this, value);
+}
+
+inline void StringEnumColumn::set_string(size_t row_ndx, StringData value)
+{
+    set(row_ndx, value); // Throws
+}
+
+inline void StringEnumColumn::set_null(size_t row_ndx)
+{
+    set(row_ndx, realm::null{});
+}
+
+inline StringColumn& StringEnumColumn::get_keys()
+{
+    return m_keys;
+}
+
+inline const StringColumn& StringEnumColumn::get_keys() const
+{
+    return m_keys;
+}
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_STRING_ENUM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_table.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_table.hpp
new file mode 100644
index 0000000..0d424c2
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_table.hpp
@@ -0,0 +1,693 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_TABLE_HPP
+#define REALM_COLUMN_TABLE_HPP
+
+#include <vector>
+#include <mutex>
+
+#include <realm/util/features.h>
+#include <memory>
+#include <realm/column.hpp>
+#include <realm/table.hpp>
+
+namespace realm {
+
+
+/// Base class for any type of column that can contain subtables.
+// FIXME: Don't derive from IntegerColumn, but define a BpTree<ref_type> specialization.
+class SubtableColumnBase : public IntegerColumn, public Table::Parent {
+public:
+    void discard_child_accessors() noexcept;
+
+    ~SubtableColumnBase() noexcept override;
+
+    static ref_type create(Allocator&, size_t size = 0);
+
+    TableRef get_subtable_accessor(size_t) const noexcept override;
+
+    void insert_rows(size_t, size_t, size_t, bool) override;
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+    void clear(size_t, bool) override;
+    void swap_rows(size_t, size_t) override;
+    void discard_subtable_accessor(size_t) noexcept override;
+    void update_from_parent(size_t) noexcept override;
+    void adj_acc_insert_rows(size_t, size_t) noexcept override;
+    void adj_acc_erase_row(size_t) noexcept override;
+    void adj_acc_move_over(size_t, size_t) noexcept override;
+    void adj_acc_clear_root_table() noexcept override;
+    void adj_acc_swap_rows(size_t, size_t) noexcept override;
+    void adj_acc_move_row(size_t, size_t) noexcept override;
+    void mark(int) noexcept override;
+    bool supports_search_index() const noexcept override
+    {
+        return false;
+    }
+    StringIndex* create_search_index() override
+    {
+        return nullptr;
+    }
+    bool is_null(size_t ndx) const noexcept override
+    {
+        return get_as_ref(ndx) == 0;
+    }
+
+    void verify() const override;
+    void verify(const Table&, size_t) const override;
+
+protected:
+    /// A pointer to the table that this column is part of. For a free-standing
+    /// column, this pointer is null.
+    Table* const m_table;
+
+    struct SubtableMap {
+        bool empty() const noexcept
+        {
+            return m_entries.empty();
+        }
+        Table* find(size_t subtable_ndx) const noexcept;
+        void add(size_t subtable_ndx, Table*);
+        // Returns true if, and only if at least one entry was detached and
+        // removed from the map.
+        bool detach_and_remove_all() noexcept;
+        // Returns true if, and only if the entry was found and removed, and it
+        // was the last entry in the map.
+        bool detach_and_remove(size_t subtable_ndx) noexcept;
+        // Returns true if, and only if the entry was found and removed, and it
+        // was the last entry in the map.
+        bool remove(Table*) noexcept;
+        void update_from_parent(size_t old_baseline) const noexcept;
+        template <bool fix_ndx_in_parent>
+        void adj_insert_rows(size_t row_ndx, size_t num_rows_inserted) noexcept;
+        // Returns true if, and only if an entry was found and removed, and it
+        // was the last entry in the map.
+        template <bool fix_ndx_in_parent>
+        bool adj_erase_rows(size_t row_ndx, size_t num_rows_erased) noexcept;
+        // Returns true if, and only if an entry was found and removed, and it
+        // was the last entry in the map.
+        template <bool fix_ndx_in_parent>
+        bool adj_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+        template <bool fix_ndx_in_parent>
+        void adj_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept;
+        template <bool fix_ndx_in_parent>
+        void adj_move_row(size_t from_ndx, size_t to_ndx) noexcept;
+        void adj_set_null(size_t row_ndx) noexcept;
+
+        void update_accessors(const size_t* col_path_begin, const size_t* col_path_end,
+                              _impl::TableFriend::AccessorUpdater&);
+        void recursive_mark() noexcept;
+        void refresh_accessor_tree();
+        void verify(const SubtableColumn& parent);
+
+    private:
+        struct SubtableEntry {
+            size_t m_subtable_ndx;
+            Table* m_table;
+        };
+        typedef std::vector<SubtableEntry> entries;
+        entries m_entries;
+    };
+
+    /// Contains all existing accessors that are attached to a subtable in this
+    /// column. It can map a row index into a pointer to the corresponding
+    /// accessor when it exists.
+    ///
+    /// There is an invariant in force: Either `m_table` is null, or there is an
+    /// additional referece count on `*m_table` when, and only when the map is
+    /// non-empty.
+    mutable SubtableMap m_subtable_map;
+    mutable std::recursive_mutex m_subtable_map_lock;
+
+    SubtableColumnBase(Allocator&, ref_type, Table*, size_t column_ndx);
+
+    /// Get a TableRef to the accessor of the specified subtable. The
+    /// accessor will be created if it does not already exist.
+    ///
+    /// NOTE: This method must be used only for subtables with
+    /// independent specs, i.e. for elements of a MixedColumn.
+    TableRef get_subtable_tableref(size_t subtable_ndx);
+
+    // Overriding method in ArrayParent
+    void update_child_ref(size_t, ref_type) override;
+
+    // Overriding method in ArrayParent
+    ref_type get_child_ref(size_t) const noexcept override;
+
+    // Overriding method in Table::Parent
+    Table* get_parent_table(size_t*) noexcept override;
+
+    // Overriding method in Table::Parent
+    void child_accessor_destroyed(Table*) noexcept override;
+
+    // Overriding method in Table::Parent
+    std::recursive_mutex* get_accessor_management_lock() noexcept override
+    { return &m_subtable_map_lock; }
+
+    /// Assumes that the two tables have the same spec.
+    static bool compare_subtable_rows(const Table&, const Table&);
+
+    /// Construct a copy of the columns array of the specified table
+    /// and return just the ref to that array.
+    ///
+    /// In the clone, no string column will be of the enumeration
+    /// type.
+    ref_type clone_table_columns(const Table*);
+
+    size_t* record_subtable_path(size_t* begin, size_t* end) noexcept override;
+
+    void update_table_accessors(const size_t* col_path_begin, const size_t* col_path_end,
+                                _impl::TableFriend::AccessorUpdater&);
+
+    /// \param row_ndx Must be `realm::npos` if appending.
+    /// \param value The value to place in any newly created rows.
+    /// \param num_rows The number of rows to insert.
+    void do_insert(size_t row_ndx, int_fast64_t value, size_t num_rows);
+
+    std::pair<ref_type, size_t> get_to_dot_parent(size_t ndx_in_parent) const override;
+
+    friend class Table;
+};
+
+
+class SubtableColumn : public SubtableColumnBase {
+public:
+    using value_type = ConstTableRef;
+    /// Create a subtable column accessor and attach it to a
+    /// preexisting underlying structure of arrays.
+    ///
+    /// \param alloc The allocator to provide new memory.
+    ///
+    /// \param ref The memory reference of the underlying subtable that
+    /// we are creating an accessor for.
+    ///
+    /// \param table If this column is used as part of a table you must
+    /// pass a pointer to that table. Otherwise you must pass null.
+    ///
+    /// \param column_ndx If this column is used as part of a table
+    /// you must pass the logical index of the column within that
+    /// table. Otherwise you should pass zero.
+    SubtableColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx);
+
+    ~SubtableColumn() noexcept override
+    {
+    }
+
+    // Overriding method in Table::Parent
+    Spec* get_subtable_spec() noexcept override;
+
+    size_t get_subtable_size(size_t ndx) const noexcept;
+
+    /// Get a TableRef to the accessor of the specified subtable. The
+    /// accessor will be created if it does not already exist.
+    TableRef get_subtable_tableref(size_t subtable_ndx);
+
+    ConstTableRef get_subtable_tableref(size_t subtable_ndx) const;
+
+    /// This is to be used by the query system that does not need to
+    /// modify the subtable. Will return a ref object containing a
+    /// nullptr if there is no table object yet.
+    ConstTableRef get(size_t subtable_ndx) const
+    {
+        int64_t ref = IntegerColumn::get(subtable_ndx);
+        if (ref)
+            return get_subtable_tableref(subtable_ndx);
+        else
+            return {};
+    }
+
+    // When passing a table to add() or insert() it is assumed that
+    // the table spec is compatible with this column. The number of
+    // columns must be the same, and the corresponding columns must
+    // have the same data type (as returned by
+    // Table::get_column_type()).
+
+    void add(const Table* value = nullptr);
+    void insert(size_t ndx, const Table* value = nullptr);
+    void set(size_t ndx, const Table*);
+    void clear_table(size_t ndx);
+    void set_null(size_t ndx) override;
+
+    using SubtableColumnBase::insert;
+
+    void erase_rows(size_t, size_t, size_t, bool) override;
+    void move_last_row_over(size_t, size_t, bool) override;
+
+    /// Compare two subtable columns for equality.
+    bool compare_table(const SubtableColumn&) const;
+
+    void refresh_accessor_tree(size_t, const Spec&) override;
+    void refresh_subtable_map();
+
+#ifdef REALM_DEBUG
+    void verify(const Table&, size_t) const override;
+    void do_dump_node_structure(std::ostream&, int) const override;
+    void to_dot(std::ostream&, StringData title) const override;
+#endif
+
+private:
+    mutable size_t m_subspec_ndx; // Unknown if equal to `npos`
+
+    size_t get_subspec_ndx() const noexcept;
+
+    void destroy_subtable(size_t ndx) noexcept;
+
+    void do_discard_child_accessors() noexcept override;
+};
+
+
+// Implementation
+
+// Overriding virtual method of Column.
+inline void SubtableColumnBase::insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows, bool)
+{
+    REALM_ASSERT_DEBUG(prior_num_rows == size());
+    REALM_ASSERT(row_ndx <= prior_num_rows);
+
+    size_t row_ndx_2 = (row_ndx == prior_num_rows ? realm::npos : row_ndx);
+    int_fast64_t value = 0;
+    do_insert(row_ndx_2, value, num_rows_to_insert); // Throws
+}
+
+// Overriding virtual method of Column.
+inline void SubtableColumnBase::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows,
+                                           bool broken_reciprocal_backlinks)
+{
+    IntegerColumn::erase_rows(row_ndx, num_rows_to_erase, prior_num_rows, broken_reciprocal_backlinks); // Throws
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = true;
+    bool last_entry_removed = m_subtable_map.adj_erase_rows<fix_ndx_in_parent>(row_ndx, num_rows_to_erase);
+    typedef _impl::TableFriend tf;
+    if (last_entry_removed)
+        tf::unbind_ptr(*m_table);
+}
+
+// Overriding virtual method of Column.
+inline void SubtableColumnBase::move_last_row_over(size_t row_ndx, size_t prior_num_rows,
+                                                   bool broken_reciprocal_backlinks)
+{
+    IntegerColumn::move_last_row_over(row_ndx, prior_num_rows, broken_reciprocal_backlinks); // Throws
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = true;
+    size_t last_row_ndx = prior_num_rows - 1;
+    bool last_entry_removed = m_subtable_map.adj_move_over<fix_ndx_in_parent>(last_row_ndx, row_ndx);
+    typedef _impl::TableFriend tf;
+    if (last_entry_removed)
+        tf::unbind_ptr(*m_table);
+}
+
+inline void SubtableColumnBase::clear(size_t, bool)
+{
+    discard_child_accessors();
+    clear_without_updating_index(); // Throws
+    // FIXME: This one is needed because
+    // IntegerColumn::clear_without_updating_index() forgets about the
+    // leaf type. A better solution should probably be sought after.
+    get_root_array()->set_type(Array::type_HasRefs);
+}
+
+inline void SubtableColumnBase::swap_rows(size_t row_ndx_1, size_t row_ndx_2)
+{
+    IntegerColumn::swap_rows(row_ndx_1, row_ndx_2); // Throws
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = true;
+    m_subtable_map.adj_swap_rows<fix_ndx_in_parent>(row_ndx_1, row_ndx_2);
+}
+
+inline void SubtableColumnBase::mark(int type) noexcept
+{
+    if (type & mark_Recursive) {
+        std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+        m_subtable_map.recursive_mark();
+    }
+}
+
+inline void SubtableColumnBase::adj_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = false;
+    m_subtable_map.adj_insert_rows<fix_ndx_in_parent>(row_ndx, num_rows);
+}
+
+inline void SubtableColumnBase::adj_acc_erase_row(size_t row_ndx) noexcept
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = false;
+    size_t num_rows_erased = 1;
+    bool last_entry_removed = m_subtable_map.adj_erase_rows<fix_ndx_in_parent>(row_ndx, num_rows_erased);
+    typedef _impl::TableFriend tf;
+    if (last_entry_removed)
+        tf::unbind_ptr(*m_table);
+}
+
+inline void SubtableColumnBase::adj_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = false;
+    bool last_entry_removed = m_subtable_map.adj_move_over<fix_ndx_in_parent>(from_row_ndx, to_row_ndx);
+    typedef _impl::TableFriend tf;
+    if (last_entry_removed)
+        tf::unbind_ptr(*m_table);
+}
+
+inline void SubtableColumnBase::adj_acc_clear_root_table() noexcept
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+
+    IntegerColumn::adj_acc_clear_root_table();
+    discard_child_accessors();
+}
+
+inline void SubtableColumnBase::adj_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept
+{
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = false;
+    m_subtable_map.adj_swap_rows<fix_ndx_in_parent>(row_ndx_1, row_ndx_2);
+}
+
+inline void SubtableColumnBase::adj_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept
+{
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    const bool fix_ndx_in_parent = false;
+    m_subtable_map.adj_move_row<fix_ndx_in_parent>(from_ndx, to_ndx);
+}
+
+inline TableRef SubtableColumnBase::get_subtable_accessor(size_t row_ndx) const noexcept
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    TableRef subtable(m_subtable_map.find(row_ndx));
+    return subtable;
+}
+
+inline void SubtableColumnBase::discard_subtable_accessor(size_t row_ndx) noexcept
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    bool last_entry_removed = m_subtable_map.detach_and_remove(row_ndx);
+    typedef _impl::TableFriend tf;
+    if (last_entry_removed)
+        tf::unbind_ptr(*m_table);
+}
+
+inline void SubtableColumnBase::SubtableMap::add(size_t subtable_ndx, Table* table)
+{
+    SubtableEntry e;
+    e.m_subtable_ndx = subtable_ndx;
+    e.m_table = table;
+    m_entries.push_back(e);
+}
+
+template <bool fix_ndx_in_parent>
+void SubtableColumnBase::SubtableMap::adj_insert_rows(size_t row_ndx, size_t num_rows_inserted) noexcept
+{
+    for (auto& entry : m_entries) {
+        if (entry.m_subtable_ndx >= row_ndx) {
+            entry.m_subtable_ndx += num_rows_inserted;
+            typedef _impl::TableFriend tf;
+            if (fix_ndx_in_parent)
+                tf::set_ndx_in_parent(*(entry.m_table), entry.m_subtable_ndx);
+        }
+    }
+}
+
+template <bool fix_ndx_in_parent>
+bool SubtableColumnBase::SubtableMap::adj_erase_rows(size_t row_ndx, size_t num_rows_erased) noexcept
+{
+    if (m_entries.empty())
+        return false;
+    typedef _impl::TableFriend tf;
+    auto end = m_entries.end();
+    auto i = m_entries.begin();
+    do {
+        if (i->m_subtable_ndx >= row_ndx + num_rows_erased) {
+            i->m_subtable_ndx -= num_rows_erased;
+            if (fix_ndx_in_parent)
+                tf::set_ndx_in_parent(*(i->m_table), i->m_subtable_ndx);
+        }
+        else if (i->m_subtable_ndx >= row_ndx) {
+            // Must hold a counted reference while detaching
+            TableRef table(i->m_table);
+            tf::detach(*table);
+            // Move last over
+            *i = *--end;
+            continue;
+        }
+        ++i;
+    } while (i != end);
+    m_entries.erase(end, m_entries.end());
+    return m_entries.empty();
+}
+
+
+template <bool fix_ndx_in_parent>
+bool SubtableColumnBase::SubtableMap::adj_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept
+{
+    typedef _impl::TableFriend tf;
+
+    size_t i = 0, n = m_entries.size();
+    // We return true if, and only if we remove the last entry in the map.  We
+    // need special handling for the case, where the set of entries are already
+    // empty, otherwise the final return statement would return true in this
+    // case, even though we didn't actually remove an entry.
+    if (n == 0)
+        return false;
+
+    while (i < n) {
+        SubtableEntry& e = m_entries[i];
+        if (REALM_UNLIKELY(e.m_subtable_ndx == to_row_ndx)) {
+            // Must hold a counted reference while detaching
+            TableRef table(e.m_table);
+            tf::detach(*table);
+            // Delete entry by moving last over (faster and avoids invalidating
+            // iterators)
+            e = m_entries[--n];
+            m_entries.pop_back();
+        }
+        else {
+            if (REALM_UNLIKELY(e.m_subtable_ndx == from_row_ndx)) {
+                e.m_subtable_ndx = to_row_ndx;
+                if (fix_ndx_in_parent)
+                    tf::set_ndx_in_parent(*(e.m_table), e.m_subtable_ndx);
+            }
+            ++i;
+        }
+    }
+    return m_entries.empty();
+}
+
+template <bool fix_ndx_in_parent>
+void SubtableColumnBase::SubtableMap::adj_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept
+{
+    using tf = _impl::TableFriend;
+    for (auto& entry : m_entries) {
+        if (REALM_UNLIKELY(entry.m_subtable_ndx == row_ndx_1)) {
+            entry.m_subtable_ndx = row_ndx_2;
+            if (fix_ndx_in_parent)
+                tf::set_ndx_in_parent(*(entry.m_table), entry.m_subtable_ndx);
+        }
+        else if (REALM_UNLIKELY(entry.m_subtable_ndx == row_ndx_2)) {
+            entry.m_subtable_ndx = row_ndx_1;
+            if (fix_ndx_in_parent)
+                tf::set_ndx_in_parent(*(entry.m_table), entry.m_subtable_ndx);
+        }
+    }
+}
+
+
+template <bool fix_ndx_in_parent>
+void SubtableColumnBase::SubtableMap::adj_move_row(size_t from_ndx, size_t to_ndx) noexcept
+{
+    using tf = _impl::TableFriend;
+    for (auto& entry : m_entries) {
+        if (entry.m_subtable_ndx == from_ndx) {
+            entry.m_subtable_ndx = to_ndx;
+            if (fix_ndx_in_parent)
+                tf::set_ndx_in_parent(*(entry.m_table), entry.m_subtable_ndx);
+        }
+        else {
+            if (from_ndx < to_ndx) {
+                // shift the range (from, to] down one
+                if (entry.m_subtable_ndx <= to_ndx && entry.m_subtable_ndx > from_ndx) {
+                    entry.m_subtable_ndx--;
+                    if (fix_ndx_in_parent) {
+                        tf::set_ndx_in_parent(*(entry.m_table), entry.m_subtable_ndx);
+                    }
+                }
+            } else if (from_ndx > to_ndx) {
+                // shift the range (from, to] up one
+                if (entry.m_subtable_ndx >= to_ndx && entry.m_subtable_ndx < from_ndx) {
+                    entry.m_subtable_ndx++;
+                    if (fix_ndx_in_parent) {
+                        tf::set_ndx_in_parent(*(entry.m_table), entry.m_subtable_ndx);
+                    }
+                }
+            }
+        }
+    }
+}
+
+inline void SubtableColumnBase::SubtableMap::adj_set_null(size_t row_ndx) noexcept
+{
+    Table* table = find(row_ndx);
+    if (table)
+        _impl::TableFriend::refresh_accessor_tree(*table);
+}
+
+inline SubtableColumnBase::SubtableColumnBase(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx)
+    : IntegerColumn(alloc, ref, column_ndx) // Throws
+    , m_table(table)
+{
+}
+
+inline void SubtableColumnBase::update_child_ref(size_t child_ndx, ref_type new_ref)
+{
+    set_as_ref(child_ndx, new_ref);
+}
+
+inline ref_type SubtableColumnBase::get_child_ref(size_t child_ndx) const noexcept
+{
+    return get_as_ref(child_ndx);
+}
+
+inline void SubtableColumnBase::discard_child_accessors() noexcept
+{
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    bool last_entry_removed = m_subtable_map.detach_and_remove_all();
+    if (last_entry_removed && m_table)
+        _impl::TableFriend::unbind_ptr(*m_table);
+}
+
+inline SubtableColumnBase::~SubtableColumnBase() noexcept
+{
+    discard_child_accessors();
+}
+
+inline bool SubtableColumnBase::compare_subtable_rows(const Table& a, const Table& b)
+{
+    return _impl::TableFriend::compare_rows(a, b);
+}
+
+inline ref_type SubtableColumnBase::clone_table_columns(const Table* t)
+{
+    return _impl::TableFriend::clone_columns(*t, get_root_array()->get_alloc());
+}
+
+inline ref_type SubtableColumnBase::create(Allocator& alloc, size_t size)
+{
+    return IntegerColumn::create(alloc, Array::type_HasRefs, size); // Throws
+}
+
+inline size_t* SubtableColumnBase::record_subtable_path(size_t* begin, size_t* end) noexcept
+{
+    if (end == begin)
+        return 0; // Error, not enough space in buffer
+    *begin++ = get_column_index();
+    if (end == begin)
+        return 0; // Error, not enough space in buffer
+    return _impl::TableFriend::record_subtable_path(*m_table, begin, end);
+}
+
+inline void SubtableColumnBase::update_table_accessors(const size_t* col_path_begin, const size_t* col_path_end,
+                                                       _impl::TableFriend::AccessorUpdater& updater)
+{
+    // This function must assume no more than minimal consistency of the
+    // accessor hierarchy. This means in particular that it cannot access the
+    // underlying node structure. See AccessorConsistencyLevels.
+
+    m_subtable_map.update_accessors(col_path_begin, col_path_end, updater); // Throws
+}
+
+inline void SubtableColumnBase::do_insert(size_t row_ndx, int_fast64_t value, size_t num_rows)
+{
+    IntegerColumn::insert_without_updating_index(row_ndx, value, num_rows); // Throws
+    bool is_append = row_ndx == realm::npos;
+    if (!is_append) {
+        const bool fix_ndx_in_parent = true;
+        m_subtable_map.adj_insert_rows<fix_ndx_in_parent>(row_ndx, num_rows);
+    }
+}
+
+
+inline SubtableColumn::SubtableColumn(Allocator& alloc, ref_type ref, Table* table, size_t column_ndx)
+    : SubtableColumnBase(alloc, ref, table, column_ndx)
+    , m_subspec_ndx(realm::npos)
+{
+}
+
+inline ConstTableRef SubtableColumn::get_subtable_tableref(size_t subtable_ndx) const
+{
+    return const_cast<SubtableColumn*>(this)->get_subtable_tableref(subtable_ndx);
+}
+
+inline void SubtableColumn::refresh_accessor_tree(size_t col_ndx, const Spec& spec)
+{
+    SubtableColumnBase::refresh_accessor_tree(col_ndx, spec); // Throws
+    m_subspec_ndx = spec.get_subspec_ndx(col_ndx);
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    m_subtable_map.refresh_accessor_tree(); // Throws
+}
+
+inline void SubtableColumn::refresh_subtable_map()
+{
+    std::lock_guard<std::recursive_mutex> lg(m_subtable_map_lock);
+    m_subtable_map.refresh_accessor_tree(); // Throws
+}
+
+inline size_t SubtableColumn::get_subspec_ndx() const noexcept
+{
+    if (REALM_UNLIKELY(m_subspec_ndx == realm::npos)) {
+        typedef _impl::TableFriend tf;
+        m_subspec_ndx = tf::get_spec(*m_table).get_subspec_ndx(get_column_index());
+    }
+    return m_subspec_ndx;
+}
+
+inline Spec* SubtableColumn::get_subtable_spec() noexcept
+{
+    typedef _impl::TableFriend tf;
+    return tf::get_spec(*m_table).get_subtable_spec(get_column_index());
+}
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_TABLE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_timestamp.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_timestamp.hpp
new file mode 100644
index 0000000..0cc6d07
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_timestamp.hpp
@@ -0,0 +1,167 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_TIMESTAMP_HPP
+#define REALM_COLUMN_TIMESTAMP_HPP
+
+#include <realm/column.hpp>
+#include <realm/timestamp.hpp>
+
+namespace realm {
+
+// Inherits from ColumnTemplate to get a compare_values() that can be called without knowing the
+// column type
+class TimestampColumn : public ColumnBaseSimple {
+public:
+    TimestampColumn(bool nullable, Allocator& alloc, ref_type ref, size_t col_ndx = npos);
+
+    static ref_type create(Allocator& alloc, size_t size, bool nullable);
+    static size_t get_size_from_ref(ref_type root_ref, Allocator& alloc) noexcept;
+
+    /// Get the number of entries in this column. This operation is relatively
+    /// slow.
+    size_t size() const noexcept override;
+    /// Whether or not this column is nullable.
+    bool is_nullable() const noexcept override;
+    /// Whether or not the value at \a row_ndx is NULL. If the column is not
+    /// nullable, always returns false.
+    bool is_null(size_t row_ndx) const noexcept override;
+    /// Sets the value at \a row_ndx to be NULL.
+    /// \throw LogicError Thrown if this column is not nullable.
+    void set_null(size_t row_ndx) override;
+    void insert_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows, bool nullable) override;
+    void erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows,
+                    bool broken_reciprocal_backlinks) override;
+    void move_last_row_over(size_t row_ndx, size_t prior_num_rows, bool broken_reciprocal_backlinks) override;
+    void clear(size_t num_rows, bool broken_reciprocal_backlinks) override;
+    void swap_rows(size_t row_ndx_1, size_t row_ndx_2) override;
+    void destroy() noexcept override;
+
+    bool has_search_index() const noexcept final
+    {
+        return bool(m_search_index);
+    }
+    StringIndex* get_search_index() noexcept final
+    {
+        return m_search_index.get();
+    }
+    StringIndex* get_search_index() const noexcept final
+    {
+        return m_search_index.get();
+    }
+    void destroy_search_index() noexcept override;
+    void set_search_index_ref(ref_type ref, ArrayParent* parent, size_t ndx_in_parent) final;
+    void populate_search_index();
+    StringIndex* create_search_index() override;
+    bool supports_search_index() const noexcept final
+    {
+        return true;
+    }
+
+    StringData get_index_data(size_t, StringIndex::StringConversionBuffer& buffer) const noexcept override;
+    ref_type write(size_t slice_offset, size_t slice_size, size_t table_size, _impl::OutputStream&) const override;
+    void update_from_parent(size_t old_baseline) noexcept override;
+    void set_ndx_in_parent(size_t ndx) noexcept override;
+    void refresh_accessor_tree(size_t new_col_ndx, const Spec&) override;
+
+    void verify() const override;
+    void to_dot(std::ostream&, StringData title = StringData()) const override;
+    void do_dump_node_structure(std::ostream&, int level) const override;
+    void leaf_to_dot(MemRef, ArrayParent*, size_t ndx_in_parent, std::ostream&) const override;
+    void get_seconds_leaf(size_t ndx, size_t& ndx_in_leaf,
+                          BpTree<util::Optional<int64_t>>::LeafInfo& inout_leaf) const noexcept;
+    void get_nanoseconds_leaf(size_t ndx, size_t& ndx_in_leaf, BpTree<int64_t>::LeafInfo& inout_leaf) const noexcept;
+
+    void add(const Timestamp& ts = Timestamp{});
+    Timestamp get(size_t row_ndx) const noexcept;
+    void set(size_t row_ndx, const Timestamp& ts);
+    bool compare(const TimestampColumn& c) const noexcept;
+    int compare_values(size_t row1, size_t row2) const noexcept override;
+
+    Timestamp maximum(size_t* result_index) const;
+    Timestamp minimum(size_t* result_index) const;
+    size_t count(Timestamp) const;
+    void erase(size_t row_ndx, bool is_last);
+
+    template <class Condition>
+    size_t find(Timestamp value, size_t begin, size_t end) const noexcept
+    {
+        // FIXME: Here we can do all sorts of clever optimizations. Use bithack-search on seconds, then for each match
+        // check nanoseconds, etc. Lots of possibilities. Below code is naive and slow but works.
+
+        Condition cond;
+        for (size_t t = begin; t < end; t++) {
+            Timestamp ts = get(t);
+            if (cond(ts, value, ts.is_null(), value.is_null()))
+                return t;
+        }
+        return npos;
+    }
+
+    void find_all(IntegerColumn& result, Timestamp value, size_t begin, size_t end) const
+    {
+        if (m_search_index && begin == 0 && end == npos) {
+            m_search_index->find_all(result, value); // Throws
+            return;
+        }
+        REALM_ASSERT(false);
+    }
+
+    typedef Timestamp value_type;
+
+private:
+    std::unique_ptr<BpTree<util::Optional<int64_t>>> m_seconds;
+    std::unique_ptr<BpTree<int64_t>> m_nanoseconds;
+
+    std::unique_ptr<StringIndex> m_search_index;
+    bool m_nullable;
+
+    template <class BT>
+    class CreateHandler;
+
+    template <class Condition>
+    Timestamp minmax(size_t* result_index) const noexcept
+    {
+        // Condition is realm::Greater for maximum and realm::Less for minimum. Any non-null value is both larger
+        // and smaller than a null value.
+        if (size() == 0) {
+            if (result_index)
+                *result_index = npos;
+            return Timestamp{};
+        }
+
+        Timestamp best = get(0);
+        size_t best_index = best.is_null() ? npos : 0;
+
+        for (size_t i = 1; i < size(); ++i) {
+            Timestamp candidate = get(i);
+            // Condition() will return false if any of the two values are null.
+            if ((best.is_null() && !candidate.is_null()) || Condition()(candidate, best, candidate.is_null(), best.is_null())) {
+                best = candidate;
+                best_index = i;
+            }
+        }
+        if (result_index)
+            *result_index = best_index;
+        return best;
+    }
+};
+
+} // namespace realm
+
+#endif // REALM_COLUMN_TIMESTAMP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_tpl.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_tpl.hpp
new file mode 100644
index 0000000..2411007
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_tpl.hpp
@@ -0,0 +1,143 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_TPL_HPP
+#define REALM_COLUMN_TPL_HPP
+
+#include <cstdlib>
+
+#include <realm/util/features.h>
+#include <realm/array.hpp>
+#include <realm/array_basic.hpp>
+
+namespace realm {
+
+template <class T, class cond>
+class FloatDoubleNode;
+template <class ColType, class Cond>
+class IntegerNode;
+template <class T>
+class SequentialGetter;
+
+template <class cond, class T>
+struct ColumnTypeTraits2;
+
+template <class cond>
+struct ColumnTypeTraits2<cond, int64_t> {
+    typedef IntegerColumn column_type;
+    typedef ArrayInteger array_type;
+};
+template <class cond>
+struct ColumnTypeTraits2<cond, bool> {
+    typedef IntegerColumn column_type;
+    typedef ArrayInteger array_type;
+};
+template <class cond>
+struct ColumnTypeTraits2<cond, float> {
+    typedef FloatColumn column_type;
+    typedef ArrayFloat array_type;
+};
+template <class cond>
+struct ColumnTypeTraits2<cond, double> {
+    typedef DoubleColumn column_type;
+    typedef ArrayDouble array_type;
+};
+
+
+namespace _impl {
+
+template <class ColType>
+struct FindInLeaf {
+    using LeafType = typename ColType::LeafType;
+
+    template <Action action, class Condition, class T, class R>
+    static bool find(const LeafType& leaf, T target, size_t local_start, size_t local_end, size_t leaf_start,
+                     QueryState<R>& state)
+    {
+        Condition cond;
+        bool cont = true;
+        // todo, make an additional loop with hard coded `false` instead of is_null(v) for non-nullable columns
+        bool null_target = null::is_null_float(target);
+        for (size_t local_index = local_start; cont && local_index < local_end; local_index++) {
+            auto v = leaf.get(local_index);
+            if (cond(v, target, null::is_null_float(v), null_target)) {
+                cont = state.template match<action, false>(leaf_start + local_index, 0, static_cast<R>(v));
+            }
+        }
+        return cont;
+    }
+};
+
+template <>
+struct FindInLeaf<IntegerColumn> {
+    using LeafType = IntegerColumn::LeafType;
+
+    template <Action action, class Condition, class T, class R>
+    static bool find(const LeafType& leaf, T target, size_t local_start, size_t local_end, size_t leaf_start,
+                     QueryState<R>& state)
+    {
+        const int c = Condition::condition;
+        return leaf.find(c, action, target, local_start, local_end, leaf_start, &state);
+    }
+};
+
+template <>
+struct FindInLeaf<IntNullColumn> {
+    using LeafType = IntNullColumn::LeafType;
+
+    template <Action action, class Condition, class T, class R>
+    static bool find(const LeafType& leaf, T target, size_t local_start, size_t local_end, size_t leaf_start,
+                     QueryState<R>& state)
+    {
+        constexpr int cond = Condition::condition;
+        return leaf.find(cond, action, target, local_start, local_end, leaf_start, &state);
+    }
+};
+
+} // namespace _impl
+
+template <class T, class R, Action action, class Condition, class ColType>
+R aggregate(const ColType& column, T target, size_t start, size_t end, size_t limit, size_t* return_ndx)
+{
+    if (end == npos)
+        end = column.size();
+
+    QueryState<R> state;
+    state.init(action, nullptr, limit);
+    SequentialGetter<ColType> sg{&column};
+
+    bool cont = true;
+    for (size_t s = start; cont && s < end;) {
+        sg.cache_next(s);
+        size_t start2 = s - sg.m_leaf_start;
+        size_t end2 = sg.local_end(end);
+        cont = _impl::FindInLeaf<ColType>::template find<action, Condition>(*sg.m_leaf_ptr, target, start2, end2,
+                                                                            sg.m_leaf_start, state);
+        s = sg.m_leaf_start + end2;
+    }
+
+    if (return_ndx)
+        *return_ndx = action == act_Sum ? state.m_match_count : state.m_minmax_index;
+
+    return state.m_state;
+}
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_TPL_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_type.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_type.hpp
new file mode 100644
index 0000000..5a6e21c
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_type.hpp
@@ -0,0 +1,70 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_TYPE_HPP
+#define REALM_COLUMN_TYPE_HPP
+
+namespace realm {
+
+
+// Note: Enumeration value assignments must be kept in sync with
+// <realm/data_type.hpp>.
+enum ColumnType {
+    // Column types
+    col_type_Int = 0,
+    col_type_Bool = 1,
+    col_type_String = 2,
+    col_type_StringEnum = 3, // double refs
+    col_type_Binary = 4,
+    col_type_Table = 5,
+    col_type_Mixed = 6,
+    col_type_OldDateTime = 7,
+    col_type_Timestamp = 8,
+    col_type_Float = 9,
+    col_type_Double = 10,
+    col_type_Reserved4 = 11, // Decimal
+    col_type_Link = 12,
+    col_type_LinkList = 13,
+    col_type_BackLink = 14
+};
+
+
+// Column attributes can be combined using bitwise or.
+enum ColumnAttr {
+    col_attr_None = 0,
+    col_attr_Indexed = 1,
+
+    /// Specifies that this column forms a unique constraint. It requires
+    /// `col_attr_Indexed`.
+    col_attr_Unique = 2,
+
+    /// Reserved for future use.
+    col_attr_Reserved = 4,
+
+    /// Specifies that the links of this column are strong, not weak. Applies
+    /// only to link columns (`type_Link` and `type_LinkList`).
+    col_attr_StrongLinks = 8,
+
+    /// Specifies that elements in the column can be null.
+    col_attr_Nullable = 16
+};
+
+
+} // namespace realm
+
+#endif // REALM_COLUMN_TYPE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/column_type_traits.hpp b/node_modules/realm/vendor/realm-ios/include/realm/column_type_traits.hpp
new file mode 100644
index 0000000..78441de
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/column_type_traits.hpp
@@ -0,0 +1,168 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_COLUMN_TYPE_TRAITS_HPP
+#define REALM_COLUMN_TYPE_TRAITS_HPP
+
+#include <realm/column_fwd.hpp>
+#include <realm/column_type.hpp>
+#include <realm/data_type.hpp>
+#include <realm/array.hpp>
+
+namespace realm {
+
+class OldDateTime;
+class ArrayBinary;
+class ArrayInteger;
+class ArrayIntNull;
+template <class>
+class BasicArray;
+
+template <class T>
+struct ColumnTypeTraits;
+
+template <>
+struct ColumnTypeTraits<int64_t> {
+    using column_type = Column<int64_t>;
+    using leaf_type = ArrayInteger;
+    using sum_type = int64_t;
+    using minmax_type = int64_t;
+    static const DataType id = type_Int;
+    static const ColumnType column_id = col_type_Int;
+    static const ColumnType real_column_type = col_type_Int;
+};
+
+template <>
+struct ColumnTypeTraits<util::Optional<int64_t>> {
+    using column_type = Column<util::Optional<int64_t>>;
+    using leaf_type = ArrayIntNull;
+    using sum_type = int64_t;
+    using minmax_type = int64_t;
+    static const DataType id = type_Int;
+    static const ColumnType column_id = col_type_Int;
+    static const ColumnType real_column_type = col_type_Int;
+};
+
+template <>
+struct ColumnTypeTraits<bool> : ColumnTypeTraits<int64_t> {
+    static const DataType id = type_Bool;
+    static const ColumnType column_id = col_type_Bool;
+};
+
+template <>
+struct ColumnTypeTraits<util::Optional<bool>> : ColumnTypeTraits<util::Optional<int64_t>> {
+    static const DataType id = type_Bool;
+    static const ColumnType column_id = col_type_Bool;
+};
+
+template <>
+struct ColumnTypeTraits<float> {
+    using column_type = FloatColumn;
+    using leaf_type = BasicArray<float>;
+    using sum_type = double;
+    using minmax_type = float;
+    static const DataType id = type_Float;
+    static const ColumnType column_id = col_type_Float;
+    static const ColumnType real_column_type = col_type_Float;
+};
+
+template <>
+struct ColumnTypeTraits<double> {
+    using column_type = DoubleColumn;
+    using leaf_type = BasicArray<double>;
+    using sum_type = double;
+    using minmax_type = double;
+    static const DataType id = type_Double;
+    static const ColumnType column_id = col_type_Double;
+    static const ColumnType real_column_type = col_type_Double;
+};
+
+template <>
+struct ColumnTypeTraits<OldDateTime> : ColumnTypeTraits<int64_t> {
+    static const DataType id = type_OldDateTime;
+    static const ColumnType column_id = col_type_OldDateTime;
+};
+
+template <>
+struct ColumnTypeTraits<Timestamp> {
+    using column_type = TimestampColumn;
+    static const DataType id = type_Timestamp;
+    static const ColumnType column_id = col_type_Timestamp;
+};
+
+template <>
+struct ColumnTypeTraits<util::Optional<OldDateTime>> : ColumnTypeTraits<util::Optional<int64_t>> {
+    static const DataType id = type_OldDateTime;
+    static const ColumnType column_id = col_type_OldDateTime;
+};
+
+template <>
+struct ColumnTypeTraits<StringData> {
+    using column_type = StringColumn;
+    static const DataType id = type_String;
+    static const ColumnType column_id = col_type_String;
+};
+
+template <>
+struct ColumnTypeTraits<BinaryData> {
+    using column_type = BinaryColumn;
+    using leaf_type = ArrayBinary;
+    static const DataType id = type_Binary;
+    static const ColumnType column_id = col_type_Binary;
+    static const ColumnType real_column_type = col_type_Binary;
+};
+
+template <DataType, bool Nullable>
+struct GetColumnType;
+template <>
+struct GetColumnType<type_Int, false> {
+    using type = IntegerColumn;
+};
+template <>
+struct GetColumnType<type_Int, true> {
+    using type = IntNullColumn;
+};
+template <bool N>
+struct GetColumnType<type_Float, N> {
+    // FIXME: Null definition
+    using type = FloatColumn;
+};
+template <bool N>
+struct GetColumnType<type_Double, N> {
+    // FIXME: Null definition
+    using type = DoubleColumn;
+};
+
+// Only purpose is to return 'double' if and only if source column (T) is float and you're doing a sum (A)
+template <class T, Action A>
+struct ColumnTypeTraitsSum {
+    typedef T sum_type;
+};
+
+template <>
+struct ColumnTypeTraitsSum<float, act_Sum> {
+    typedef double sum_type;
+};
+
+template <Action A>
+struct ColumnTypeTraitsSum<util::Optional<int64_t>, A> {
+    using sum_type = int64_t;
+};
+}
+
+#endif // REALM_COLUMN_TYPE_TRAITS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/data_type.hpp b/node_modules/realm/vendor/realm-ios/include/realm/data_type.hpp
new file mode 100644
index 0000000..37e8a1b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/data_type.hpp
@@ -0,0 +1,67 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_DATA_TYPE_HPP
+#define REALM_DATA_TYPE_HPP
+
+#include <stdint.h>
+
+namespace realm {
+
+class StringData;
+class BinaryData;
+class Timestamp;
+
+typedef int64_t Int;
+typedef bool Bool;
+typedef float Float;
+typedef double Double;
+typedef realm::StringData String;
+typedef realm::BinaryData Binary;
+typedef realm::Timestamp Timestamp;
+
+
+// Note: Value assignments must be kept in sync with <realm/column_type.h>
+// Note: Value assignments must be kept in sync with <realm/c/data_type.h>
+// Note: Value assignments must be kept in sync with <realm/objc/type.h>
+// Note: Value assignments must be kept in sync with "com/realm/ColumnType.java"
+// Note: Any change to this enum is a file-format breaking change.
+enum DataType {
+    type_Int = 0,
+    type_Bool = 1,
+    type_Float = 9,
+    type_Double = 10,
+    type_String = 2,
+    type_Binary = 4,
+    type_OldDateTime = 7,
+    type_Timestamp = 8,
+    type_Table = 5,
+    type_Mixed = 6,
+    type_Link = 12,
+    type_LinkList = 13
+};
+
+/// See Descriptor::set_link_type().
+enum LinkType {
+    link_Strong,
+    link_Weak,
+};
+
+} // namespace realm
+
+#endif // REALM_DATA_TYPE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/descriptor.hpp b/node_modules/realm/vendor/realm-ios/include/realm/descriptor.hpp
new file mode 100644
index 0000000..9d37de5
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/descriptor.hpp
@@ -0,0 +1,812 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_DESCRIPTOR_HPP
+#define REALM_DESCRIPTOR_HPP
+
+#include <cstddef>
+
+#include <realm/util/assert.hpp>
+#include <realm/descriptor_fwd.hpp>
+#include <realm/table.hpp>
+
+
+namespace realm {
+
+namespace _impl {
+class DescriptorFriend;
+}
+
+
+/// Accessor for table type descriptors.
+///
+/// A table type descriptor is an entity that specifies the dynamic
+/// type of a Realm table. Objects of this class are accessors
+/// through which the descriptor can be inspected and
+/// changed. Accessors can become detached, see is_attached() for more
+/// on this. The descriptor itself is stored inside the database file,
+/// or elsewhere in case of a free-standing table or a table in a
+/// free-standing group.
+///
+/// The dynamic type consists first, and foremost of an ordered list
+/// of column descriptors. Each column descriptor specifies the name
+/// and type of the column.
+///
+/// When a table has a subtable column, every cell in than column
+/// contains a subtable. All those subtables have the same dynamic
+/// type, and therefore have a shared descriptor. See is_root() for
+/// more on this.
+///
+/// The Table class contains convenience methods, such as
+/// Table::get_column_count() and Table::add_column(), that allow you
+/// to inspect and change the dynamic type of simple tables without
+/// resorting to use of descriptors. For example, the following two
+/// statements have the same effect:
+///
+///     table->add_column(type, name);
+///     table->get_descriptor()->add_column(type, name);
+///
+/// Note, however, that this equivalence holds only as long as no
+/// shared subtable descriptors are involved.
+///
+/// \sa Table::get_descriptor()
+class Descriptor : public std::enable_shared_from_this<Descriptor> {
+public:
+    /// Get the number of columns in the associated tables.
+    size_t get_column_count() const noexcept;
+
+    /// Get the type of the column at the specified index.
+    ///
+    /// The consequences of specifying a column index that is out of
+    /// range, are undefined.
+    DataType get_column_type(size_t column_ndx) const noexcept;
+
+    /// Get the name of the column at the specified index.
+    ///
+    /// The consequences of specifying a column index that is out of
+    /// range, are undefined.
+    StringData get_column_name(size_t column_ndx) const noexcept;
+
+    /// Search for a column with the specified name.
+    ///
+    /// This function finds the first column with the specified name,
+    /// and returns its index. If there are no such columns, it
+    /// returns `not_found`.
+    size_t get_column_index(StringData name) const noexcept;
+
+    /// Get the index of the table to which links in the column at the specified
+    /// index refer.
+    ///
+    /// The consequences of specifying a column index that is out of
+    /// range, are undefined.
+    ///
+    /// The consequences of specifying a column index that does not refer
+    /// to a link column, are undefined.
+    size_t get_column_link_target(size_t column_ndx) const noexcept;
+
+    /// Get whether or not the specified column is nullable.
+    ///
+    /// The consequences of specifying a column index that is out of
+    /// range, are undefined.
+    bool is_nullable(size_t column_ndx) const noexcept;
+
+    /// \defgroup descriptor_column_accessors Accessing Columns Via A Descriptor
+    ///
+    /// add_column() and add_column_link() are a shorthands for calling
+    /// insert_column() and insert_column_link(), respectively, with a column
+    /// index equal to the original number of columns. The returned value is
+    /// that column index.
+    ///
+    /// insert_column() inserts a new column into all the tables associated with
+    /// this descriptor. If any of the tables are not empty, the new column will
+    /// be filled with the default value associated with the specified data
+    /// type. This function cannot be used to insert link-type columns. For
+    /// that, you have to use insert_column_link() instead.
+    ///
+    /// This function modifies the dynamic type of all the tables that
+    /// share this descriptor. It does this by inserting a new column
+    /// with the specified name and type into the descriptor at the
+    /// specified index, and into each of the tables that share this
+    /// descriptor.
+    ///
+    /// insert_column_link() is like insert_column(), but inserts a link-type
+    /// column to a group-level table. It is not possible to add link-type
+    /// columns to tables that are not group-level tables. This functions must
+    /// be used in place of insert_column() when the column type is `type_Link`
+    /// or `type_LinkList`. A link-type column is associated with a particular
+    /// target table. All links in a link-type column refer to rows in the
+    /// target table of that column. The target table must also be a group-level
+    /// table, and it must belong to the same group as the origin table.
+    ///
+    /// \param name Name of new column. All strings are valid column names as
+    /// long as they are valid UTF-8 encodings and the number of bytes does not
+    /// exceed `max_column_name_length`. An attempt to add a column with a name
+    /// that is longer than `max_column_name_length` will cause an exception to
+    /// be thrown.
+    ///
+    /// \param subdesc If a non-null pointer is passed, and the
+    /// specified type is `type_Table`, then this function
+    /// automatically retrieves the descriptor associated with the new
+    /// subtable column, and stores a reference to its accessor in
+    /// `*subdesc`.
+    ///
+    /// \param col_ndx Insert the new column at this index. Preexisting columns
+    /// at indexes equal to, or greater than `col_ndx` will be shifted to the
+    /// next higher index. It is an error to specify an index that is greater
+    /// than the number of columns prior to the insertion.
+    ///
+    /// \param link_type See set_link_type().
+    ///
+    /// \sa Table::add_column()
+    /// \sa Table::insert_column()
+    /// \sa Table::add_column_link()
+    /// \sa Table::insert_column_link()
+    /// \sa is_root()
+    //@{
+
+    static const size_t max_column_name_length = 63;
+
+    size_t add_column(DataType type, StringData name, DescriptorRef* subdesc = nullptr, bool nullable = false);
+
+    void insert_column(size_t col_ndx, DataType type, StringData name, DescriptorRef* subdesc = nullptr,
+                       bool nullable = false);
+
+    size_t add_column_link(DataType type, StringData name, Table& target, LinkType = link_Weak);
+    void insert_column_link(size_t col_ndx, DataType type, StringData name, Table& target, LinkType = link_Weak);
+    //@}
+
+    /// Remove the specified column from each of the associated
+    /// tables. If the removed column is the only column in the
+    /// descriptor, then the table size will drop to zero for all
+    /// tables that were not already empty.
+    ///
+    /// This function modifies the dynamic type of all the tables that
+    /// share this descriptor. It does this by removing the column at
+    /// the specified index from the descriptor, and from each of the
+    /// tables that share this descriptor. The consequences of
+    /// specifying a column index that is out of range, are undefined.
+    ///
+    /// If the removed column was a subtable column, then the
+    /// associated descriptor accessor will be detached, if it
+    /// exists. This function will also detach all accessors of
+    /// subtables of the root table. Only the accessor of the root
+    /// table will remain attached. The root table is the table
+    /// associated with the root descriptor.
+    ///
+    /// \param col_ndx The index of the column to be removed. It is an error to
+    /// specify an index that is greater than, or equal to the number of
+    /// columns.
+    ///
+    /// \sa is_root()
+    /// \sa Table::remove_column()
+    void remove_column(size_t col_ndx);
+
+    /// Rename the specified column.
+    ///
+    /// This function modifies the dynamic type of all the tables that
+    /// share this descriptor. The consequences of specifying a column
+    /// index that is out of range, are undefined.
+    ///
+    /// This function will detach all accessors of subtables of the
+    /// root table. Only the accessor of the root table will remain
+    /// attached. The root table is the table associated with the root
+    /// descriptor.
+    ///
+    /// \param col_ndx The index of the column to be renamed. It is an error to
+    /// specify an index that is greater than, or equal to the number of
+    /// columns.
+    ///
+    /// \param new_name The new name of the column.
+    ///
+    /// \sa is_root()
+    /// \sa Table::rename_column()
+    void rename_column(size_t col_ndx, StringData new_name);
+
+    /// If the descriptor is describing a subtable column, the add_search_index()
+    /// and remove_search_index() will add or remove search indexes of *all*
+    /// subtables of the subtable column. This may take a while if there are many
+    /// subtables with many rows each.
+    bool has_search_index(size_t column_ndx) const noexcept;
+    void add_search_index(size_t column_ndx);
+    void remove_search_index(size_t column_ndx);
+
+    /// There are two kinds of links, 'weak' and 'strong'. A strong link is one
+    /// that implies ownership, i.e., that the origin row (parent) owns the
+    /// target row (child). Simply stated, this means that when the origin row
+    /// (parent) is removed, so is the target row (child). If there are multiple
+    /// strong links to a target row, the origin rows share ownership, and the
+    /// target row is removed when the last owner disappears. Weak links do not
+    /// imply ownership, and will be nullified or removed when the target row
+    /// disappears.
+    ///
+    /// To put this in precise terms; when a strong link is broken, and the
+    /// target row has no other strong links to it, the target row is removed. A
+    /// row that is implicitly removed in this way, is said to be
+    /// *cascade-removed*. When a weak link is broken, nothing is
+    /// cascade-removed.
+    ///
+    /// A link is considered broken if
+    ///
+    ///  - the link is nullified, removed, or replaced by a different link
+    ///    (Row::nullify_link(), Row::set_link(), LinkView::remove_link(),
+    ///    LinkView::set_link(), LinkView::clear()), or if
+    ///
+    ///  - the origin row is explicitly removed (Row::move_last_over(),
+    ///    Table::clear()), or if
+    ///
+    ///  - the origin row is cascade-removed, or if
+    ///
+    ///  - the origin column is removed from the table (Table::remove_column()),
+    ///    or if
+    ///
+    ///  - the origin table is removed from the group.
+    ///
+    /// Note that a link is *not* considered broken when it is replaced by a
+    /// link to the same target row. I.e., no no rows will be cascade-removed
+    /// due to such an operation.
+    ///
+    /// When a row is explicitly removed (such as by Table::move_last_over()),
+    /// all links to it are automatically removed or nullified. For single link
+    /// columns (type_Link), links to the removed row are nullified. For link
+    /// list columns (type_LinkList), links to the removed row are removed from
+    /// the list.
+    ///
+    /// When a row is cascade-removed there can no longer be any strong links to
+    /// it, but if there are any weak links, they will be removed or nullified.
+    ///
+    /// It is important to understand that this cascade-removal scheme is too
+    /// simplistic to enable detection and removal of orphaned link-cycles. In
+    /// this respect, it suffers from the same limitations as a reference
+    /// counting scheme generally does.
+    ///
+    /// It is also important to understand, that the possible presence of a link
+    /// cycle can cause a row to be cascade-removed as a consequence of being
+    /// modified. This happens, for example, if two rows, A and B, have strong
+    /// links to each other, and there are no other strong links to either of
+    /// them. In this case, if A->B is changed to A->C, then both A and B will
+    /// be cascade-removed. This can lead to obscure bugs in some applications,
+    /// such as in the following case:
+    ///
+    ///     table.set_link(col_ndx_1, row_ndx, ...);
+    ///     table.set_int(col_ndx_2, row_ndx, ...); // Oops, `row_ndx` may no longer refer to the same row
+    ///
+    /// To be safe, applications, that may encounter cycles, are advised to
+    /// adopt the following pattern:
+    ///
+    ///     Row row = table[row_ndx];
+    ///     row.set_link(col_ndx_1, ...);
+    ///     if (row)
+    ///         row.set_int(col_ndx_2, ...); // Ok, because we check whether the row has disappeared
+    ///
+    /// \param col_ndx The index of the link column (`type_Link` or
+    /// `type_LinkList`) to be modified. It is an error to specify an index that
+    /// is greater than, or equal to the number of columns, or to specify the
+    /// index of a non-link column.
+    ///
+    /// \param link_type The type of links the column should store.
+    void set_link_type(size_t col_ndx, LinkType link_type);
+
+    //@{
+    /// Get the descriptor for the specified subtable column.
+    ///
+    /// This function provides access to the shared subtable
+    /// descriptor for the subtables in the specified column. The
+    /// specified column must be a column whose type is 'table'. The
+    /// consequences of specifying a column of a different type, or
+    /// specifying an index that is out of range, are undefined.
+    ///
+    /// Note that this function cannot be used with 'mixed' columns,
+    /// since subtables of that kind have independent dynamic types,
+    /// and therefore, have independent descriptors. You can only get
+    /// access to the descriptor of a subtable in a mixed column by
+    /// first getting access to the subtable itself.
+    ///
+    /// \sa is_root()
+    DescriptorRef get_subdescriptor(size_t column_ndx);
+    ConstDescriptorRef get_subdescriptor(size_t column_ndx) const;
+    //@}
+
+    //@{
+    /// Returns the parent table descriptor, if any.
+    ///
+    /// If this descriptor is the *root descriptor*, then this
+    /// function returns null. Otherwise it returns the accessor of
+    /// the parent descriptor.
+    ///
+    /// \sa is_root()
+    DescriptorRef get_parent() noexcept;
+    ConstDescriptorRef get_parent() const noexcept;
+    //@}
+
+    //@{
+    /// Get the table associated with the root descriptor.
+    ///
+    /// \sa get_parent()
+    /// \sa is_root()
+    TableRef get_root_table() noexcept;
+    ConstTableRef get_root_table() const noexcept;
+    //@}
+
+    //@{
+    /// Get the target table associated with the specified link column. This
+    /// descriptor must be a root descriptor (is_root()), and the specified
+    /// column must be a link column (`type_Link` or `type_LinkList`).
+    TableRef get_link_target(size_t col_ndx) noexcept;
+    ConstTableRef get_link_target(size_t col_ndx) const noexcept;
+    //@}
+
+    /// Is this a root descriptor?
+    ///
+    /// Descriptors of tables with independent dynamic type are root
+    /// descriptors. Root descriptors are never shared. Tables that
+    /// are direct members of groups have independent dynamic
+    /// types. The same is true for free-standing tables and subtables
+    /// in columns of type 'mixed'.
+    ///
+    /// When a table has a column of type 'table', the cells in that
+    /// column contain subtables. All those subtables have the same
+    /// dynamic type, and they share a single dynamic type
+    /// descriptor. Such shared descriptors are never root
+    /// descriptors.
+    ///
+    /// A type descriptor can even be shared by subtables with
+    /// different parent tables, but only if the parent tables
+    /// themselves have a shared type descriptor. For example, if a
+    /// table has a column `foo` of type 'table', and each of the
+    /// subtables in `foo` has a column `bar` of type 'table', then
+    /// all the subtables in all the `bar` columns share the same
+    /// dynamic type descriptor.
+    ///
+    /// \sa Table::has_shared_type()
+    bool is_root() const noexcept;
+
+    /// Determine whether this accessor is still attached.
+    ///
+    /// A table descriptor accessor may get detached from the
+    /// underlying descriptor for various reasons (see below). When it
+    /// does, it no longer refers to that descriptor, and can no
+    /// longer be used, except for calling is_attached(). The
+    /// consequences of calling other methods on a detached accessor
+    /// are undefined. Descriptor accessors obtained by calling
+    /// functions in the Realm API are always in the 'attached'
+    /// state immediately upon return from those functions.
+    ///
+    /// A descriptor accessor that is obtained directly from a table
+    /// becomes detached if the table becomes detached. A shared
+    /// subtable descriptor accessor that is obtained by a call to
+    /// get_subdescriptor() becomes detached if the parent descriptor
+    /// accessor becomes detached, or if the corresponding subtable
+    /// column is removed. A descriptor accessor does not get detached
+    /// under any other circumstances.
+    bool is_attached() const noexcept;
+
+    //@{
+    /// \brief Compare two table descriptors.
+    ///
+    /// Two table descriptors are equal if they have the same number of columns,
+    /// and for each column index, the two columns have the same name, data
+    /// type, and set of attributes.
+    ///
+    /// For link columns (`type_Link` and `type_LinkList`), the target table
+    /// (get_link_target()) of the two columns must be the same.
+    ///
+    /// For subtable columns (`type_Table`), the two corresponding
+    /// subdescriptors must themselves be equal, as if by a recursive call to
+    /// operator==().
+    ///
+    /// The consequences of comparing a detached descriptor are
+    /// undefined.
+    bool operator==(const Descriptor&) const noexcept;
+    bool operator!=(const Descriptor&) const noexcept;
+    //@}
+
+    /// If the specified column is optimized to store only unique values, then
+    /// this function returns the number of unique values currently
+    /// stored. Otherwise it returns zero. This function is mainly intended for
+    /// debugging purposes.
+    size_t get_num_unique_values(size_t column_ndx) const;
+
+    ~Descriptor() noexcept;
+
+private:
+    // for initialization through make_shared
+    struct PrivateTag {
+    };
+
+public:
+    Descriptor(const PrivateTag&)
+        : Descriptor()
+    {
+    }
+
+private:
+    // Table associated with root descriptor. Detached iff null.
+    TableRef m_root_table;
+    DescriptorRef m_parent; // Null iff detached or root descriptor.
+    Spec* m_spec;           // Valid if attached. Owned iff valid and `m_parent`.
+
+    // Whenever a subtable descriptor accessor is created, it is
+    // stored in this map. This ensures that when get_subdescriptor()
+    // is called to created multiple DescriptorRef objects that
+    // overlap in time, then they will all refer to the same
+    // descriptor object.
+    //
+    // It also enables the necessary recursive detaching of descriptor
+    // objects.
+    struct subdesc_entry {
+        size_t m_column_ndx;
+        std::weak_ptr<Descriptor> m_subdesc;
+        subdesc_entry(size_t column_ndx, DescriptorRef);
+    };
+    typedef std::vector<subdesc_entry> subdesc_map;
+    mutable subdesc_map m_subdesc_map;
+
+    Descriptor() noexcept;
+
+    // Called by the root table if this becomes the root
+    // descriptor. Otherwise it is called by the descriptor that
+    // becomes its parent.
+    //
+    // Puts this descriptor accessor into the attached state. This
+    // attaches it to the underlying structure of array nodes. It does
+    // not establish the parents reference to this descriptor, that is
+    // the job of the parent. When this function returns,
+    // is_attached() will return true.
+    //
+    // Not idempotent.
+    //
+    // The specified table is not allowed to be a subtable with a
+    // shareable spec. That is, Table::has_shared_spec() must return
+    // false.
+    //
+    // The specified spec must be the spec of the specified table or
+    // of one of its direct or indirect subtable columns.
+    //
+    // When the specified spec is the spec of the root table, the
+    // parent must be specified as null. When the specified spec is
+    // not the root spec, a proper parent must be specified.
+    void attach(Table*, DescriptorRef parent, Spec*) noexcept;
+
+    // Detach accessor from underlying descriptor. Caller must ensure
+    // that a reference count exists upon return, for example by
+    // obtaining an extra reference count before the call.
+    //
+    // This function is called either by the root table if this is the
+    // root descriptor, or by the parent descriptor, if it is not.
+    //
+    // Puts this descriptor accessor into the detached state. This
+    // detaches it from the underlying structure of array nodes. It
+    // also calls detach_subdesc_accessors(). When this function
+    // returns, is_attached() will return false.
+    //
+    // Not idempotent.
+    void detach() noexcept;
+
+    // Recursively detach all subtable descriptor accessors that
+    // exist, that is, all subtable descriptor accessors that have
+    // this descriptor as ancestor.
+    void detach_subdesc_accessors() noexcept;
+
+    // Record the path in terms of subtable column indexes from the
+    // root descriptor to this descriptor. If this descriptor is a
+    // root descriptor, the path is empty. Returns zero if the path is
+    // too long to fit in the specified buffer. Otherwise the path
+    // indexes will be stored between `begin_2`and `end`, where
+    // `begin_2` is the returned pointer.
+    size_t* record_subdesc_path(size_t* begin, size_t* end) const noexcept;
+
+    // Returns a pointer to the accessor of the specified
+    // subdescriptor if that accessor exists, otherwise this function
+    // return null.
+    DescriptorRef get_subdesc_accessor(size_t column_ndx) noexcept;
+
+    void adj_insert_column(size_t col_ndx) noexcept;
+    void adj_erase_column(size_t col_ndx) noexcept;
+
+    friend class util::bind_ptr<Descriptor>;
+    friend class util::bind_ptr<const Descriptor>;
+    friend class _impl::DescriptorFriend;
+};
+
+
+// Implementation:
+
+inline size_t Descriptor::get_column_count() const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_public_column_count();
+}
+
+inline StringData Descriptor::get_column_name(size_t ndx) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_column_name(ndx);
+}
+
+inline DataType Descriptor::get_column_type(size_t ndx) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_public_column_type(ndx);
+}
+
+inline bool Descriptor::is_nullable(size_t ndx) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_column_attr(ndx) & col_attr_Nullable;
+}
+
+inline size_t Descriptor::get_column_index(StringData name) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_column_index(name);
+}
+
+inline size_t Descriptor::get_column_link_target(size_t column_ndx) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_opposite_link_table_ndx(column_ndx);
+}
+
+inline size_t Descriptor::add_column(DataType type, StringData name, DescriptorRef* subdesc, bool nullable)
+{
+    size_t col_ndx = m_spec->get_public_column_count();
+    insert_column(col_ndx, type, name, subdesc, nullable); // Throws
+    return col_ndx;
+}
+
+inline void Descriptor::insert_column(size_t col_ndx, DataType type, StringData name, DescriptorRef* subdesc,
+                                      bool nullable)
+{
+    typedef _impl::TableFriend tf;
+
+    if (REALM_UNLIKELY(!is_attached()))
+        throw LogicError(LogicError::detached_accessor);
+    if (REALM_UNLIKELY(col_ndx > get_column_count()))
+        throw LogicError(LogicError::column_index_out_of_range);
+    if (REALM_UNLIKELY(tf::is_link_type(ColumnType(type))))
+        throw LogicError(LogicError::illegal_type);
+
+    LinkTargetInfo invalid_link;
+    tf::insert_column(*this, col_ndx, type, name, invalid_link, nullable); // Throws
+    adj_insert_column(col_ndx);
+    if (subdesc && type == type_Table)
+        *subdesc = get_subdescriptor(col_ndx);
+}
+
+inline size_t Descriptor::add_column_link(DataType type, StringData name, Table& target, LinkType link_type)
+{
+    size_t col_ndx = m_spec->get_public_column_count();
+    insert_column_link(col_ndx, type, name, target, link_type); // Throws
+    return col_ndx;
+}
+
+inline void Descriptor::insert_column_link(size_t col_ndx, DataType type, StringData name, Table& target,
+                                           LinkType link_type)
+{
+    typedef _impl::TableFriend tf;
+
+    if (REALM_UNLIKELY(!is_attached() || !target.is_attached()))
+        throw LogicError(LogicError::detached_accessor);
+    if (REALM_UNLIKELY(col_ndx > get_column_count()))
+        throw LogicError(LogicError::column_index_out_of_range);
+    if (REALM_UNLIKELY(!tf::is_link_type(ColumnType(type))))
+        throw LogicError(LogicError::illegal_type);
+    if (REALM_UNLIKELY(!is_root()))
+        throw LogicError(LogicError::wrong_kind_of_descriptor);
+    // Both origin and target must be group-level tables, and in the same group.
+    Group* origin_group = tf::get_parent_group(*get_root_table());
+    Group* target_group = tf::get_parent_group(target);
+    if (!origin_group || !target_group)
+        throw LogicError(LogicError::wrong_kind_of_table);
+    if (origin_group != target_group)
+        throw LogicError(LogicError::group_mismatch);
+
+    LinkTargetInfo link(&target);
+    tf::insert_column(*this, col_ndx, type, name, link); // Throws
+    adj_insert_column(col_ndx);
+
+    tf::set_link_type(*get_root_table(), col_ndx, link_type); // Throws
+}
+
+inline void Descriptor::remove_column(size_t col_ndx)
+{
+    typedef _impl::TableFriend tf;
+
+    if (REALM_UNLIKELY(!is_attached()))
+        throw LogicError(LogicError::detached_accessor);
+    if (REALM_UNLIKELY(col_ndx >= get_column_count()))
+        throw LogicError(LogicError::column_index_out_of_range);
+
+    tf::erase_column(*this, col_ndx); // Throws
+    adj_erase_column(col_ndx);
+}
+
+inline void Descriptor::rename_column(size_t col_ndx, StringData name)
+{
+    typedef _impl::TableFriend tf;
+
+    if (REALM_UNLIKELY(!is_attached()))
+        throw LogicError(LogicError::detached_accessor);
+    if (REALM_UNLIKELY(col_ndx >= get_column_count()))
+        throw LogicError(LogicError::column_index_out_of_range);
+
+    tf::rename_column(*this, col_ndx, name); // Throws
+}
+
+inline void Descriptor::set_link_type(size_t col_ndx, LinkType link_type)
+{
+    typedef _impl::TableFriend tf;
+
+    if (REALM_UNLIKELY(!is_attached()))
+        throw LogicError(LogicError::detached_accessor);
+    if (REALM_UNLIKELY(col_ndx >= get_column_count()))
+        throw LogicError(LogicError::column_index_out_of_range);
+    if (REALM_UNLIKELY(!tf::is_link_type(ColumnType(get_column_type(col_ndx)))))
+        throw LogicError(LogicError::illegal_type);
+
+    tf::set_link_type(*get_root_table(), col_ndx, link_type); // Throws
+}
+
+inline ConstDescriptorRef Descriptor::get_subdescriptor(size_t column_ndx) const
+{
+    return const_cast<Descriptor*>(this)->get_subdescriptor(column_ndx);
+}
+
+inline DescriptorRef Descriptor::get_parent() noexcept
+{
+    return m_parent;
+}
+
+inline ConstDescriptorRef Descriptor::get_parent() const noexcept
+{
+    return const_cast<Descriptor*>(this)->get_parent();
+}
+
+inline TableRef Descriptor::get_root_table() noexcept
+{
+    return m_root_table;
+}
+
+inline ConstTableRef Descriptor::get_root_table() const noexcept
+{
+    return const_cast<Descriptor*>(this)->get_root_table();
+}
+
+inline TableRef Descriptor::get_link_target(size_t col_ndx) noexcept
+{
+    REALM_ASSERT(is_attached());
+    REALM_ASSERT(is_root());
+    return get_root_table()->get_link_target(col_ndx);
+}
+
+inline ConstTableRef Descriptor::get_link_target(size_t col_ndx) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    REALM_ASSERT(is_root());
+    return get_root_table()->get_link_target(col_ndx);
+}
+
+inline bool Descriptor::is_root() const noexcept
+{
+    return !m_parent;
+}
+
+inline Descriptor::Descriptor() noexcept
+{
+}
+
+inline void Descriptor::attach(Table* table, DescriptorRef parent, Spec* spec) noexcept
+{
+    REALM_ASSERT(!is_attached());
+    REALM_ASSERT(!table->has_shared_type());
+    m_root_table.reset(table);
+    m_parent = parent;
+    m_spec = spec;
+}
+
+inline bool Descriptor::is_attached() const noexcept
+{
+    return bool(m_root_table);
+}
+
+inline Descriptor::subdesc_entry::subdesc_entry(size_t n, DescriptorRef d)
+    : m_column_ndx(n)
+    , m_subdesc(d)
+{
+}
+
+inline bool Descriptor::operator==(const Descriptor& d) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    REALM_ASSERT(d.is_attached());
+    return *m_spec == *d.m_spec;
+}
+
+inline bool Descriptor::operator!=(const Descriptor& d) const noexcept
+{
+    return !(*this == d);
+}
+
+// The purpose of this class is to give internal access to some, but
+// not all of the non-public parts of the Descriptor class.
+class _impl::DescriptorFriend {
+public:
+    static DescriptorRef create()
+    {
+        return std::make_shared<Descriptor>(Descriptor::PrivateTag()); // Throws
+    }
+
+    static void attach(Descriptor& desc, Table* table, DescriptorRef parent, Spec* spec) noexcept
+    {
+        desc.attach(table, parent, spec);
+    }
+
+    static void detach(Descriptor& desc) noexcept
+    {
+        desc.detach();
+    }
+
+    static void detach_subdesc_accessors(Descriptor& desc) noexcept
+    {
+        desc.detach_subdesc_accessors();
+    }
+
+    static Table& get_root_table(Descriptor& desc) noexcept
+    {
+        return *desc.m_root_table;
+    }
+
+    static const Table& get_root_table(const Descriptor& desc) noexcept
+    {
+        return *desc.m_root_table;
+    }
+
+    static Spec& get_spec(Descriptor& desc) noexcept
+    {
+        return *desc.m_spec;
+    }
+
+    static const Spec& get_spec(const Descriptor& desc) noexcept
+    {
+        return *desc.m_spec;
+    }
+
+    static size_t* record_subdesc_path(const Descriptor& desc, size_t* begin, size_t* end) noexcept
+    {
+        return desc.record_subdesc_path(begin, end);
+    }
+
+    static DescriptorRef get_subdesc_accessor(Descriptor& desc, size_t column_ndx) noexcept
+    {
+        return desc.get_subdesc_accessor(column_ndx);
+    }
+
+    static void adj_insert_column(Descriptor& desc, size_t col_ndx) noexcept
+    {
+        desc.adj_insert_column(col_ndx);
+    }
+
+    static void adj_erase_column(Descriptor& desc, size_t col_ndx) noexcept
+    {
+        desc.adj_erase_column(col_ndx);
+    }
+};
+
+} // namespace realm
+
+#endif // REALM_DESCRIPTOR_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/descriptor_fwd.hpp b/node_modules/realm/vendor/realm-ios/include/realm/descriptor_fwd.hpp
new file mode 100644
index 0000000..2937724
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/descriptor_fwd.hpp
@@ -0,0 +1,33 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_DESCRIPTOR_FWD_HPP
+#define REALM_DESCRIPTOR_FWD_HPP
+
+#include <memory>
+
+
+namespace realm {
+
+class Descriptor;
+typedef std::shared_ptr<Descriptor> DescriptorRef;
+typedef std::shared_ptr<const Descriptor> ConstDescriptorRef;
+
+} // namespace realm
+
+#endif // REALM_DESCRIPTOR_FWD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/disable_sync_to_disk.hpp b/node_modules/realm/vendor/realm-ios/include/realm/disable_sync_to_disk.hpp
new file mode 100644
index 0000000..f642d6f
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/disable_sync_to_disk.hpp
@@ -0,0 +1,37 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_DISABLE_SYNC_TO_DISK_HPP
+#define REALM_DISABLE_SYNC_TO_DISK_HPP
+
+#include <realm/util/features.h>
+
+namespace realm {
+
+/// Completely disable synchronization with storage device to speed up unit
+/// testing. This is an unsafe mode of operation, and should never be used in
+/// production. This function is thread safe.
+void disable_sync_to_disk();
+
+/// Returns true after disable_sync_to_disk() has been called. This function is
+/// thread safe.
+bool get_disable_sync_to_disk() noexcept;
+
+} // namespace realm
+
+#endif // REALM_DISABLE_SYNC_TO_DISK_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/exceptions.hpp b/node_modules/realm/vendor/realm-ios/include/realm/exceptions.hpp
new file mode 100644
index 0000000..7db8d18
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/exceptions.hpp
@@ -0,0 +1,338 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_EXCEPTIONS_HPP
+#define REALM_EXCEPTIONS_HPP
+
+#include <stdexcept>
+
+#include <realm/util/features.h>
+#include <realm/util/backtrace.hpp>
+
+namespace realm {
+
+using util::ExceptionWithBacktrace;
+
+/// Thrown by various functions to indicate that a specified table does not
+/// exist.
+class NoSuchTable : public ExceptionWithBacktrace<std::exception> {
+public:
+    const char* message() const noexcept override;
+};
+
+
+/// Thrown by various functions to indicate that a specified table name is
+/// already in use.
+class TableNameInUse : public ExceptionWithBacktrace<std::exception> {
+public:
+    const char* message() const noexcept override;
+};
+
+
+// Thrown by functions that require a table to **not** be the target of link
+// columns, unless those link columns are part of the table itself.
+class CrossTableLinkTarget : public ExceptionWithBacktrace<std::exception> {
+public:
+    const char* message() const noexcept override;
+};
+
+
+/// Thrown by various functions to indicate that the dynamic type of a table
+/// does not match a particular other table type (dynamic or static).
+class DescriptorMismatch : public ExceptionWithBacktrace<std::exception> {
+public:
+    const char* message() const noexcept override;
+};
+
+
+/// The FileFormatUpgradeRequired exception can be thrown by the SharedGroup
+/// constructor when opening a database that uses a deprecated file format
+/// and/or a deprecated history schema, and the user has indicated he does not
+/// want automatic upgrades to be performed. This exception indicates that until
+/// an upgrade of the file format is performed, the database will be unavailable
+/// for read or write operations.
+class FileFormatUpgradeRequired : public ExceptionWithBacktrace<std::exception> {
+public:
+    const char* message() const noexcept override;
+};
+
+
+/// Thrown when a sync agent attempts to join a session in which there is
+/// already a sync agent. A session may only contain one sync agent at any given
+/// time.
+class MultipleSyncAgents : public ExceptionWithBacktrace<std::exception> {
+public:
+    const char* message() const noexcept override;
+};
+
+
+/// Thrown when memory can no longer be mapped to. When mmap/remap fails.
+class AddressSpaceExhausted : public std::runtime_error {
+public:
+    AddressSpaceExhausted(const std::string& msg);
+    /// runtime_error::what() returns the msg provided in the constructor.
+};
+
+/// Thrown when creating references that are too large to be contained in our ref_type (size_t)
+class MaximumFileSizeExceeded : public std::runtime_error {
+public:
+    MaximumFileSizeExceeded(const std::string& msg);
+    /// runtime_error::what() returns the msg provided in the constructor.
+};
+
+/// Thrown when writing fails because the disk is full.
+class OutOfDiskSpace : public std::runtime_error {
+public:
+    OutOfDiskSpace(const std::string& msg);
+    /// runtime_error::what() returns the msg provided in the constructor.
+};
+
+// SerialisationError intentionally does not inherit ExceptionWithBacktrace
+// because the query-based-sync permissions queries generated on the server
+// use a LinksToNode which is not currently serialisable (this limitation can
+// be lifted in core 6 given stable ids). Coupled with query metrics which
+// serialize all queries, the capturing of the stack for these frequent
+// permission queries shows up in performance profiles.
+class SerialisationError : public std::runtime_error {
+public:
+    SerialisationError(const std::string& msg);
+    /// runtime_error::what() returns the msg provided in the constructor.
+};
+
+// thrown when a user constructed link path is not a valid input
+class InvalidPathError : public std::runtime_error {
+public:
+    InvalidPathError(const std::string& msg);
+    /// runtime_error::what() returns the msg provided in the constructor.
+};
+
+
+/// The \c LogicError exception class is intended to be thrown only when
+/// applications (or bindings) violate rules that are stated (or ought to have
+/// been stated) in the documentation of the public API, and only in cases
+/// where the violation could have been easily and efficiently predicted by the
+/// application. In other words, this exception class is for the cases where
+/// the error is due to incorrect use of the public API.
+///
+/// This class is not supposed to be caught by applications. It is not even
+/// supposed to be considered part of the public API, and therefore the
+/// documentation of the public API should **not** mention the \c LogicError
+/// exception class by name. Note how this contrasts with other exception
+/// classes, such as \c NoSuchTable, which are part of the public API, and are
+/// supposed to be mentioned in the documentation by name. The \c LogicError
+/// exception is part of Realm's private API.
+///
+/// In other words, the \c LogicError class should exclusively be used in
+/// replacement (or in addition to) asserts (debug or not) in order to
+/// guarantee program interruption, while still allowing for complete
+/// test-cases to be written and run.
+///
+/// To this effect, the special `CHECK_LOGIC_ERROR()` macro is provided as a
+/// test framework plugin to allow unit tests to check that the functions in
+/// the public API do throw \c LogicError when rules are violated.
+///
+/// The reason behind hiding this class from the public API is to prevent users
+/// from getting used to the idea that "Undefined Behaviour" equates a specific
+/// exception being thrown. The whole point of properly documenting "Undefined
+/// Behaviour" cases is to help the user know what the limits are, without
+/// constraining the database to handle every and any use-case thrown at it.
+///
+/// FIXME: This exception class should probably be moved to the `_impl`
+/// namespace, in order to avoid some confusion.
+class LogicError : public ExceptionWithBacktrace<std::exception> {
+public:
+    enum ErrorKind {
+        string_too_big,
+        binary_too_big,
+        table_name_too_long,
+        column_name_too_long,
+        table_index_out_of_range,
+        row_index_out_of_range,
+        column_index_out_of_range,
+        string_position_out_of_range,
+        link_index_out_of_range,
+        bad_version,
+        illegal_type,
+
+        /// Indicates that an argument has a value that is illegal in combination
+        /// with another argument, or with the state of an involved object.
+        illegal_combination,
+
+        /// Indicates a data type mismatch, such as when `Table::find_pkey_int()` is
+        /// called and the type of the primary key is not `type_Int`.
+        type_mismatch,
+
+        /// Indicates that two involved tables are not in the same group.
+        group_mismatch,
+
+        /// Indicates that an involved descriptor is of the wrong kind, i.e., if
+        /// it is a subtable descriptor, and the function requires a root table
+        /// descriptor.
+        wrong_kind_of_descriptor,
+
+        /// Indicates that an involved table is of the wrong kind, i.e., if it
+        /// is a subtable, and the function requires a root table, or if it is a
+        /// free-standing table, and the function requires a group-level table.
+        wrong_kind_of_table,
+
+        /// Indicates that an involved accessor is was detached, i.e., was not
+        /// attached to an underlying object.
+        detached_accessor,
+
+        /// Indicates that a specified row index of a target table (a link) is
+        /// out of range. This is used for disambiguation in cases such as
+        /// Table::set_link() where one specifies both a row index of the origin
+        /// table, and a row index of the target table.
+        target_row_index_out_of_range,
+
+        // Indicates that an involved column lacks a search index.
+        no_search_index,
+
+        /// Indicates that a modification was attempted that would have produced a
+        /// duplicate primary value.
+        unique_constraint_violation,
+
+        /// User attempted to insert null in non-nullable column
+        column_not_nullable,
+
+        /// Group::open() is called on a group accessor that is already in the
+        /// attached state. Or Group::open() or Group::commit() is called on a
+        /// group accessor that is managed by a SharedGroup object.
+        wrong_group_state,
+
+        /// No active transaction on a particular SharedGroup object (e.g.,
+        /// SharedGroup::commit()), or the active transaction on the SharedGroup
+        /// object is of the wrong type (read/write), or an attampt was made to
+        /// initiate a new transaction while one is already in progress on the
+        /// same SharedGroup object.
+        wrong_transact_state,
+
+        /// Attempted use of a continuous transaction through a SharedGroup
+        /// object with no history. See Replication::get_history().
+        no_history,
+
+        /// Durability setting (as passed to the SharedGroup constructor) was
+        /// not consistent across the session.
+        mixed_durability,
+
+        /// History type (as specified by the Replication implementation passed
+        /// to the SharedGroup constructor) was not consistent across the
+        /// session.
+        mixed_history_type,
+
+        /// History schema version (as specified by the Replication
+        /// implementation passed to the SharedGroup constructor) was not
+        /// consistent across the session.
+        mixed_history_schema_version,
+
+        /// Adding rows to a table with no columns is not supported.
+        table_has_no_columns,
+
+        /// Referring to a column that has been deleted.
+        column_does_not_exist,
+
+        /// You can not add index on a subtable of a subtable
+        subtable_of_subtable_index
+    };
+
+    LogicError(ErrorKind message);
+
+    const char* message() const noexcept override;
+    ErrorKind kind() const noexcept;
+
+private:
+    ErrorKind m_kind;
+};
+
+
+// Implementation:
+
+// LCOV_EXCL_START (Wording of what() strings are not to be tested)
+
+inline const char* NoSuchTable::message() const noexcept
+{
+    return "No such table exists";
+}
+
+inline const char* TableNameInUse::message() const noexcept
+{
+    return "The specified table name is already in use";
+}
+
+inline const char* CrossTableLinkTarget::message() const noexcept
+{
+    return "Table is target of cross-table link columns";
+}
+
+inline const char* DescriptorMismatch::message() const noexcept
+{
+    return "Table descriptor mismatch";
+}
+
+inline const char* FileFormatUpgradeRequired::message() const noexcept
+{
+    return "Database upgrade required but prohibited";
+}
+
+inline const char* MultipleSyncAgents::message() const noexcept
+{
+    return "Multiple sync agents attempted to join the same session";
+}
+
+// LCOV_EXCL_STOP
+
+inline AddressSpaceExhausted::AddressSpaceExhausted(const std::string& msg)
+    : std::runtime_error(msg)
+{
+}
+
+inline MaximumFileSizeExceeded::MaximumFileSizeExceeded(const std::string& msg)
+    : std::runtime_error(msg)
+{
+}
+
+inline OutOfDiskSpace::OutOfDiskSpace(const std::string& msg)
+: std::runtime_error(msg)
+{
+}
+
+inline SerialisationError::SerialisationError(const std::string& msg)
+    : std::runtime_error(msg)
+{
+}
+
+inline InvalidPathError::InvalidPathError(const std::string& msg)
+    : runtime_error(msg)
+{
+}
+
+inline LogicError::LogicError(LogicError::ErrorKind k)
+    : m_kind(k)
+{
+}
+
+inline LogicError::ErrorKind LogicError::kind() const noexcept
+{
+    return m_kind;
+}
+
+
+} // namespace realm
+
+
+#endif // REALM_EXCEPTIONS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/group.hpp b/node_modules/realm/vendor/realm-ios/include/realm/group.hpp
new file mode 100644
index 0000000..3c0a9e6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/group.hpp
@@ -0,0 +1,1440 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_GROUP_HPP
+#define REALM_GROUP_HPP
+
+#include <functional>
+#include <string>
+#include <vector>
+#include <map>
+#include <stdexcept>
+
+#include <realm/util/features.h>
+#include <realm/exceptions.hpp>
+#include <realm/impl/input_stream.hpp>
+#include <realm/impl/output_stream.hpp>
+#include <realm/impl/cont_transact_hist.hpp>
+#include <realm/metrics/metrics.hpp>
+#include <realm/table.hpp>
+#include <realm/alloc_slab.hpp>
+
+namespace realm {
+
+class SharedGroup;
+namespace _impl {
+class GroupFriend;
+class TransactLogConvenientEncoder;
+class TransactLogParser;
+}
+
+
+/// A group is a collection of named tables.
+///
+/// Tables occur in the group in an unspecified order, but an order that
+/// generally remains fixed. The order is guaranteed to remain fixed between two
+/// points in time if no tables are added to, or removed from the group during
+/// that time. When tables are added to, or removed from the group, the order
+/// may change arbitrarily.
+///
+/// If `table` is a table accessor attached to a group-level table, and `group`
+/// is a group accessor attached to the group, then the following is guaranteed,
+/// even after a change in the table order:
+///
+/// \code{.cpp}
+///
+///     table == group.get_table(table.get_index_in_group())
+///
+/// \endcode
+///
+class Group : private Table::Parent {
+public:
+    /// Construct a free-standing group. This group instance will be
+    /// in the attached state, but neither associated with a file, nor
+    /// with an external memory buffer.
+    Group();
+
+    enum OpenMode {
+        /// Open in read-only mode. Fail if the file does not already exist.
+        mode_ReadOnly,
+        /// Open in read/write mode. Create the file if it doesn't exist.
+        mode_ReadWrite,
+        /// Open in read/write mode. Fail if the file does not already exist.
+        mode_ReadWriteNoCreate
+    };
+
+    /// Equivalent to calling open(const std::string&, const char*, OpenMode)
+    /// on an unattached group accessor.
+    explicit Group(const std::string& file, const char* encryption_key = nullptr, OpenMode = mode_ReadOnly);
+
+    /// Equivalent to calling open(BinaryData, bool) on an unattached
+    /// group accessor. Note that if this constructor throws, the
+    /// ownership of the memory buffer will remain with the caller,
+    /// regardless of whether \a take_ownership is set to `true` or
+    /// `false`.
+    explicit Group(BinaryData, bool take_ownership = true);
+
+    struct unattached_tag {
+    };
+
+    /// Create a Group instance in its unattached state. It may then
+    /// be attached to a database file later by calling one of the
+    /// open() methods. You may test whether this instance is
+    /// currently in its attached state by calling
+    /// is_attached(). Calling any other method (except the
+    /// destructor) while in the unattached state has undefined
+    /// behavior.
+    Group(unattached_tag) noexcept;
+
+    // FIXME: Implement a proper copy constructor (fairly trivial).
+    Group(const Group&) = delete;
+    Group& operator=(const Group&) = delete;
+
+    ~Group() noexcept override;
+
+    /// Attach this Group instance to the specified database file.
+    ///
+    /// By default, the specified file is opened in read-only mode
+    /// (mode_ReadOnly). This allows opening a file even when the
+    /// caller lacks permission to write to that file. The opened
+    /// group may still be modified freely, but the changes cannot be
+    /// written back to the same file using the commit() function. An
+    /// attempt to do that, will cause an exception to be thrown. When
+    /// opening in read-only mode, it is an error if the specified
+    /// file does not already exist in the file system.
+    ///
+    /// Alternatively, the file can be opened in read/write mode
+    /// (mode_ReadWrite). This allows use of the commit() function,
+    /// but, of course, it also requires that the caller has
+    /// permission to write to the specified file. When opening in
+    /// read-write mode, an attempt to create the specified file will
+    /// be made, if it does not already exist in the file system.
+    ///
+    /// In any case, if the file already exists, it must contain a
+    /// valid Realm database. In many cases invalidity will be
+    /// detected and cause the InvalidDatabase exception to be thrown,
+    /// but you should not rely on it.
+    ///
+    /// Note that changes made to the database via a Group instance
+    /// are not automatically committed to the specified file. You
+    /// may, however, at any time, explicitly commit your changes by
+    /// calling the commit() method, provided that the specified
+    /// open-mode is not mode_ReadOnly. Alternatively, you may call
+    /// write() to write the entire database to a new file. Writing
+    /// the database to a new file does not end, or in any other way
+    /// change the association between the Group instance and the file
+    /// that was specified in the call to open().
+    ///
+    /// A Realm file that contains a history (see Replication::HistoryType) may
+    /// be opened via Group::open(), as long as the application can ensure that
+    /// there is no concurrent access to the file (see below for more on
+    /// concurrency), but if the file is modified via Group::commit() the
+    /// history will be discarded. To retain the history, the application must
+    /// instead access the file in shared mode, i.e., via SharedGroup, and
+    /// supply the right kind of replication plugin (see
+    /// Replication::get_history_type()).
+    ///
+    /// A file that is passed to Group::open(), may not be modified by
+    /// a third party until after the Group object is
+    /// destroyed. Behavior is undefined if a file is modified by a
+    /// third party while any Group object is associated with it.
+    ///
+    /// Calling open() on a Group instance that is already in the
+    /// attached state has undefined behavior.
+    ///
+    /// Accessing a Realm database file through manual construction
+    /// of a Group object does not offer any level of thread safety or
+    /// transaction safety. When any of those kinds of safety are a
+    /// concern, consider using a SharedGroup instead. When accessing
+    /// a database file in read/write mode through a manually
+    /// constructed Group object, it is entirely the responsibility of
+    /// the application that the file is not accessed in any way by a
+    /// third party during the life-time of that group object. It is,
+    /// on the other hand, safe to concurrently access a database file
+    /// by multiple manually created Group objects, as long as all of
+    /// them are opened in read-only mode, and there is no other party
+    /// that modifies the file concurrently.
+    ///
+    /// Do not call this function on a group instance that is managed
+    /// by a shared group. Doing so will result in undefined behavior.
+    ///
+    /// Even if this function throws, it may have the side-effect of
+    /// creating the specified file, and the file may get left behind
+    /// in an invalid state. Of course, this can only happen if
+    /// read/write mode (mode_ReadWrite) was requested, and the file
+    /// did not already exist.
+    ///
+    /// \param file File system path to a Realm database file.
+    ///
+    /// \param encryption_key 32-byte key used to encrypt and decrypt
+    /// the database file, or nullptr to disable encryption.
+    ///
+    /// \param mode Specifying a mode that is not mode_ReadOnly
+    /// requires that the specified file can be opened in read/write
+    /// mode. In general there is no reason to open a group in
+    /// read/write mode unless you want to be able to call
+    /// Group::commit().
+    ///
+    /// \throw util::File::AccessError If the file could not be
+    /// opened. If the reason corresponds to one of the exception
+    /// types that are derived from util::File::AccessError, the
+    /// derived exception type is thrown. Note that InvalidDatabase is
+    /// among these derived exception types.
+    void open(const std::string& file, const char* encryption_key = nullptr, OpenMode mode = mode_ReadOnly);
+
+    /// Attach this Group instance to the specified memory buffer.
+    ///
+    /// This is similar to constructing a group from a file except
+    /// that in this case the database is assumed to be stored in the
+    /// specified memory buffer.
+    ///
+    /// If \a take_ownership is `true`, you pass the ownership of the
+    /// specified buffer to the group. In this case the buffer will
+    /// eventually be freed using std::free(), so the buffer you pass,
+    /// must have been allocated using std::malloc().
+    ///
+    /// On the other hand, if \a take_ownership is set to `false`, it
+    /// is your responsibility to keep the memory buffer alive during
+    /// the lifetime of the group, and in case the buffer needs to be
+    /// deallocated afterwards, that is your responsibility too.
+    ///
+    /// If this function throws, the ownership of the memory buffer
+    /// will remain with the caller, regardless of whether \a
+    /// take_ownership is set to `true` or `false`.
+    ///
+    /// Calling open() on a Group instance that is already in the
+    /// attached state has undefined behavior.
+    ///
+    /// Do not call this function on a group instance that is managed
+    /// by a shared group. Doing so will result in undefined behavior.
+    ///
+    /// \throw InvalidDatabase If the specified buffer does not appear
+    /// to contain a valid database.
+    void open(BinaryData, bool take_ownership = true);
+
+    /// A group may be created in the unattached state, and then later
+    /// attached to a file with a call to open(). Calling any method
+    /// other than open(), and is_attached() on an unattached instance
+    /// results in undefined behavior.
+    bool is_attached() const noexcept;
+
+    /// Returns true if, and only if the number of tables in this
+    /// group is zero.
+    bool is_empty() const noexcept;
+
+    /// Returns the number of tables in this group.
+    size_t size() const noexcept;
+
+    /// \defgroup group_table_access Table Accessors
+    ///
+    /// has_table() returns true if, and only if this group contains a table
+    /// with the specified name.
+    ///
+    /// find_table() returns the index of the first table in this group with the
+    /// specified name, or `realm::not_found` if this group does not contain a
+    /// table with the specified name.
+    ///
+    /// get_table_name() returns the name of table at the specified index.
+    ///
+    /// The versions of get_table(), that accepts a \a name argument, return the
+    /// first table with the specified name, or null if no such table exists.
+    ///
+    /// add_table() adds a table with the specified name to this group. It
+    /// throws TableNameInUse if \a require_unique_name is true and \a name
+    /// clashes with the name of an existing table. If \a require_unique_name is
+    /// false, it is possible to add more than one table with the same
+    /// name. Whenever a table is added, the order of the preexisting tables may
+    /// change arbitrarily, and the new table may not end up as the last one
+    /// either. But know that you can always call Table::get_index_in_group() on
+    /// the returned table accessor to find out at which index it ends up.
+    ///
+    /// get_or_add_table() checks if a table exists in this group with the specified
+    /// name. If it doesn't exist, a table is created.
+    ///
+    /// get_or_insert_table() works slightly differently from get_or_add_table(),
+    /// in that it considers the position of the requested table as part of that
+    /// table's identifying "key", in addition to the name.
+    ///
+    /// remove_table() removes the specified table from this group. A table can
+    /// be removed only when it is not the target of a link column of a
+    /// different table. Whenever a table is removed, the order of the remaining
+    /// tables may change arbitrarily.
+    ///
+    /// rename_table() changes the name of a preexisting table. If \a
+    /// require_unique_name is false, it becomes possible to have more than one
+    /// table with a given name in a single group.
+    ///
+    /// The template functions work exactly like their non-template namesakes
+    /// except as follows: The template versions of get_table() and
+    /// get_or_add_table() throw DescriptorMismatch if the dynamic type of the
+    /// specified table does not match the statically specified custom table
+    /// type. The template versions of add_table() and get_or_add_table() set
+    /// the dynamic type (descriptor) to match the statically specified custom
+    /// table type.
+    ///
+    /// \param index Index of table in this group.
+    ///
+    /// \param name Name of table. All strings are valid table names as long as
+    /// they are valid UTF-8 encodings and the number of bytes does not exceed
+    /// `max_table_name_length`. A call to add_table() or get_or_add_table()
+    /// with a name that is longer than `max_table_name_length` will cause an
+    /// exception to be thrown.
+    ///
+    /// \param new_name New name for preexisting table.
+    ///
+    /// \param require_unique_name When set to true (the default), it becomes
+    /// impossible to add a table with a name that is already in use, or to
+    /// rename a table to a name that is already in use.
+    ///
+    /// \param was_added When specified, the boolean variable is set to true if
+    /// the table was added, and to false otherwise. If the function throws, the
+    /// boolean variable retains its original value.
+    ///
+    /// \return get_table(), add_table(), and get_or_add_table() return a table
+    /// accessor attached to the requested (or added) table. get_table() may
+    /// return null.
+    ///
+    /// \throw DescriptorMismatch Thrown by get_table() and get_or_add_table()
+    /// tf the dynamic table type does not match the statically specified custom
+    /// table type (\a T).
+    ///
+    /// \throw NoSuchTable Thrown by remove_table() and rename_table() if there
+    /// is no table with the specified \a name.
+    ///
+    /// \throw TableNameInUse Thrown by add_table() if \a require_unique_name is
+    /// true and \a name clashes with the name of a preexisting table. Thrown by
+    /// rename_table() if \a require_unique_name is true and \a new_name clashes
+    /// with the name of a preexisting table.
+    ///
+    /// \throw CrossTableLinkTarget Thrown by remove_table() if the specified
+    /// table is the target of a link column of a different table.
+    ///
+    //@{
+
+    static const size_t max_table_name_length = 63;
+
+    bool has_table(StringData name) const noexcept;
+    size_t find_table(StringData name) const noexcept;
+    StringData get_table_name(size_t table_ndx) const;
+
+    TableRef get_table(size_t index);
+    ConstTableRef get_table(size_t index) const;
+
+    TableRef get_table(StringData name);
+    ConstTableRef get_table(StringData name) const;
+
+    TableRef add_table(StringData name, bool require_unique_name = true);
+    TableRef insert_table(size_t index, StringData name, bool require_unique_name = true);
+    TableRef get_or_add_table(StringData name, bool* was_added = nullptr);
+    TableRef get_or_insert_table(size_t index, StringData name, bool* was_added = nullptr);
+
+    void remove_table(size_t index);
+    void remove_table(StringData name);
+
+    void rename_table(size_t index, StringData new_name, bool require_unique_name = true);
+    void rename_table(StringData name, StringData new_name, bool require_unique_name = true);
+
+    //@}
+
+    // Serialization
+
+    /// Write this database to the specified output stream.
+    ///
+    /// \param out The destination output stream to write to.
+    ///
+    /// \param pad If true, the file is padded to ensure the footer is aligned
+    /// to the end of a page
+    void write(std::ostream& out, bool pad = false) const;
+
+    /// Write this database to a new file. It is an error to specify a
+    /// file that already exists. This is to protect against
+    /// overwriting a database file that is currently open, which
+    /// would cause undefined behaviour.
+    ///
+    /// \param file A filesystem path.
+    ///
+    /// \param encryption_key 32-byte key used to encrypt the database file,
+    /// or nullptr to disable encryption.
+    ///
+    /// \param version If different from 0, the new file will be a full fledged
+    /// realm file with free list and history info. The version of the commit
+    /// will be set to the value given here.
+    ///
+    /// \throw util::File::AccessError If the file could not be
+    /// opened. If the reason corresponds to one of the exception
+    /// types that are derived from util::File::AccessError, the
+    /// derived exception type is thrown. In particular,
+    /// util::File::Exists will be thrown if the file exists already.
+    void write(const std::string& file, const char* encryption_key = nullptr, uint64_t version = 0,
+               bool write_history = true) const;
+
+    /// Write this database to a memory buffer.
+    ///
+    /// Ownership of the returned buffer is transferred to the
+    /// caller. The memory will have been allocated using
+    /// std::malloc().
+    BinaryData write_to_mem() const;
+
+    /// Commit changes to the attached file. This requires that the
+    /// attached file is opened in read/write mode.
+    ///
+    /// Calling this function on an unattached group, a free-standing
+    /// group, a group whose attached file is opened in read-only
+    /// mode, a group that is attached to a memory buffer, or a group
+    /// that is managed by a shared group, is an error and will result
+    /// in undefined behavior.
+    ///
+    /// Table accesors will remain valid across the commit. Note that
+    /// this is not the case when working with proper transactions.
+    void commit();
+
+    //@{
+    /// Some operations on Tables in a Group can cause indirect changes to other
+    /// fields, including in other Tables in the same Group. Specifically,
+    /// removing a row will set any links to that row to null, and if it had the
+    /// last strong links to other rows, will remove those rows. When this
+    /// happens, The cascade notification handler will be called with a
+    /// CascadeNotification containing information about what indirect changes
+    /// will occur, before any changes are made.
+    ///
+    /// has_cascade_notification_handler() returns true if and only if there is
+    /// currently a non-null notification handler registered.
+    ///
+    /// set_cascade_notification_handler() replaces the current handler (if any)
+    /// with the passed in handler. Pass in nullptr to remove the current handler
+    /// without registering a new one.
+    ///
+    /// CascadeNotification contains a vector of rows which will be removed and
+    /// a vector of links which will be set to null (or removed, for entries in
+    /// LinkLists).
+    struct CascadeNotification {
+        struct row {
+            /// Non-zero iff the removal of this row is ordered
+            /// (Table::remove()), as opposed to ordered
+            /// (Table::move_last_over()). Implicit removals are always
+            /// unordered.
+            ///
+            /// This flag does not take part in comparisons (operator==() and
+            /// operator<()).
+            size_t is_ordered_removal : 1;
+
+            /// Index within group of a group-level table.
+            size_t table_ndx : std::numeric_limits<size_t>::digits - 1;
+
+            /// Row index which will be removed.
+            size_t row_ndx;
+
+            row()
+                : is_ordered_removal(0)
+            {
+            }
+
+            bool operator==(const row&) const noexcept;
+            bool operator!=(const row&) const noexcept;
+
+            /// Trivial lexicographic order
+            bool operator<(const row&) const noexcept;
+        };
+
+        struct link {
+            const Table* origin_table; ///< A group-level table.
+            size_t origin_col_ndx;     ///< Link column being nullified.
+            size_t origin_row_ndx;     ///< Row in column being nullified.
+            /// The target row index which is being removed. Mostly relevant for
+            /// LinkList (to know which entries are being removed), but also
+            /// valid for Link.
+            size_t old_target_row_ndx;
+        };
+
+        /// A sorted list of rows which will be removed by the current operation.
+        std::vector<row> rows;
+
+        /// An unordered list of links which will be nullified by the current
+        /// operation.
+        std::vector<link> links;
+    };
+
+    bool has_cascade_notification_handler() const noexcept;
+    void set_cascade_notification_handler(std::function<void(const CascadeNotification&)> new_handler) noexcept;
+
+    //@}
+
+    //@{
+    /// During sync operation, schema changes may happen at runtime as connected
+    /// clients update their schema as part of an app update. Since this is a
+    /// relatively rare event, no attempt is made at limiting the amount of work
+    /// the handler is required to do to update its information about table and
+    /// column indices (i.e., all table and column indices must be recalculated).
+    ///
+    /// At the time of writing, only additive schema changes may occur in that
+    /// scenario.
+    ///
+    /// has_schema_change_notification_handler() returns true iff there is currently
+    /// a non-null notification handler registered.
+    ///
+    /// set_schema_change_notification_handler() replaces the current handler (if any)
+    /// with the passed in handler. Pass in nullptr to remove the current handler
+    /// without registering a new one.
+
+    bool has_schema_change_notification_handler() const noexcept;
+    void set_schema_change_notification_handler(std::function<void()> new_handler) noexcept;
+
+    //@}
+
+    // Conversion
+    template <class S>
+    void to_json(S& out, size_t link_depth = 0, std::map<std::string, std::string>* renames = nullptr) const;
+    void to_string(std::ostream& out) const;
+
+    /// Compare two groups for equality. Two groups are equal if, and
+    /// only if, they contain the same tables in the same order, that
+    /// is, for each table T at index I in one of the groups, there is
+    /// a table at index I in the other group that is equal to T.
+    /// Tables are equal if they have the same content and the same table name.
+    bool operator==(const Group&) const;
+
+    /// Compare two groups for inequality. See operator==().
+    bool operator!=(const Group& g) const
+    {
+        return !(*this == g);
+    }
+
+    /// Control of what to include when computing memory usage
+    enum SizeAggregateControl {
+        size_of_state = 1, ///< size of tables, indexes, toplevel array
+        size_of_history = 2, ///< size of the in-file history compartment
+        size_of_freelists = 4, ///< size of the freelists
+        size_of_all = 7
+    };
+    /// Compute the sum of the sizes in number of bytes of all the array nodes
+    /// that currently make up this group. When this group represents a snapshot
+    /// in a Realm file (such as during a read transaction via a SharedGroup
+    /// instance), this function computes the footprint of that snapshot within
+    /// the Realm file.
+    ///
+    /// If this group accessor is the detached state, this function returns
+    /// zero.
+    size_t compute_aggregated_byte_size(SizeAggregateControl ctrl = SizeAggregateControl::size_of_all) const noexcept;
+    /// Return the size taken up by the current snapshot. This is in contrast to
+    /// the number returned by SharedGroup::get_stats() which will return the
+    /// size of the last snapshot done in that SharedGroup. If the snapshots are
+    /// identical, the numbers will of course be equal.
+    size_t get_used_space() const noexcept;
+
+    void verify() const;
+#ifdef REALM_DEBUG
+    void print() const;
+    void print_free() const;
+    MemStats get_stats();
+    void enable_mem_diagnostics(bool enable = true)
+    {
+        m_alloc.enable_debug(enable);
+    }
+    void to_dot(std::ostream&) const;
+    void to_dot() const; // To std::cerr (for GDB)
+    void to_dot(const char* file_path) const;
+#endif
+
+private:
+    SlabAlloc m_alloc;
+
+    int m_file_format_version;
+    /// `m_top` is the root node (or top array) of the Realm, and has the
+    /// following layout:
+    ///
+    /// <pre>
+    ///
+    ///                                                     Introduced in file
+    ///   Slot  Value                                       format version
+    ///   ---------------------------------------------------------------------
+    ///    1st   m_table_names
+    ///    2nd   m_tables
+    ///    3rd   Logical file size
+    ///    4th   GroupWriter::m_free_positions (optional)
+    ///    5th   GroupWriter::m_free_lengths   (optional)
+    ///    6th   GroupWriter::m_free_versions  (optional)
+    ///    7th   Transaction number / version  (optional)
+    ///    8th   History type         (optional)             4
+    ///    9th   History ref          (optional)             4
+    ///   10th   History version      (optional)             7
+    ///
+    /// </pre>
+    ///
+    /// The 'History type' slot stores a value of type
+    /// Replication::HistoryType. The 'History version' slot stores a history
+    /// schema version as returned by Replication::get_history_schema_version().
+    ///
+    /// The first three entries are mandatory. In files created by
+    /// Group::write(), none of the optional entries are present and the size of
+    /// `m_top` is 3. In files updated by Group::commit(), the 4th and 5th entry
+    /// are present, and the size of `m_top` is 5. In files updated by way of a
+    /// transaction (SharedGroup::commit()), the 4th, 5th, 6th, and 7th entry
+    /// are present, and the size of `m_top` is 7. In files that contain a
+    /// changeset history, the 8th, 9th, and 10th entry are present, except that
+    /// if the file was opened in nonshared mode (via Group::open()), and the
+    /// file format remains at 6 (not previously upgraded to 7 or later), then
+    /// the 10th entry will be absent.
+    ///
+    /// When a group accessor is attached to a newly created file or an empty
+    /// memory buffer where there is no top array yet, `m_top`, `m_tables`, and
+    /// `m_table_names` will be left in the detached state until the initiation
+    /// of the first write transaction. In particular, they will remain in the
+    /// detached state during read transactions that precede the first write
+    /// transaction.
+    Array m_top;
+    ArrayInteger m_tables;
+    ArrayString m_table_names;
+
+    typedef std::vector<Table*> table_accessors;
+    mutable table_accessors m_table_accessors;
+
+    bool m_attached = false;
+    const bool m_is_shared;
+
+    std::function<void(const CascadeNotification&)> m_notify_handler;
+    std::function<void()> m_schema_change_handler;
+    std::shared_ptr<metrics::Metrics> m_metrics;
+    size_t m_total_rows;
+
+    struct shared_tag {
+    };
+    Group(shared_tag) noexcept;
+
+    void init_array_parents() noexcept;
+
+    void open(ref_type top_ref, const std::string& file_path);
+
+    /// If `top_ref` is not zero, attach this group accessor to the specified
+    /// underlying node structure. If `top_ref` is zero and \a
+    /// create_group_when_missing is true, create a new node structure that
+    /// represents an empty group, and attach this group accessor to it. It is
+    /// an error to call this function on an already attached group accessor.
+    void attach(ref_type top_ref, bool create_group_when_missing);
+
+    /// Detach this group accessor from the underlying node structure. If this
+    /// group accessors is already in the detached state, this function does
+    /// nothing (idempotency).
+    void detach() noexcept;
+
+    /// \param writable Must be set to true when, and only when attaching for a
+    /// write transaction.
+    void attach_shared(ref_type new_top_ref, size_t new_file_size, bool writable);
+
+    void create_empty_group();
+
+    void reset_free_space_tracking();
+
+    void remap(size_t new_file_size);
+    void remap_and_update_refs(ref_type new_top_ref, size_t new_file_size);
+
+    /// Recursively update refs stored in all cached array
+    /// accessors. This includes cached array accessors in any
+    /// currently attached table accessors. This ensures that the
+    /// group instance itself, as well as any attached table accessor
+    /// that exists across Group::commit() will remain valid. This
+    /// function is not appropriate for use in conjunction with
+    /// commits via shared group.
+    void update_refs(ref_type top_ref, size_t old_baseline) noexcept;
+
+    // Overriding method in ArrayParent
+    void update_child_ref(size_t, ref_type) override;
+
+    // Overriding method in ArrayParent
+    ref_type get_child_ref(size_t) const noexcept override;
+
+    // Overriding method in Table::Parent
+    StringData get_child_name(size_t) const noexcept override;
+
+    // Overriding method in Table::Parent
+    void child_accessor_destroyed(Table*) noexcept override;
+
+    // Overriding method in Table::Parent
+    std::recursive_mutex* get_accessor_management_lock() noexcept override
+    { return nullptr; } // we don't need locking for group!
+
+    // Overriding method in Table::Parent
+    Group* get_parent_group() noexcept override;
+
+    class TableWriter;
+    class DefaultTableWriter;
+
+    static void write(std::ostream&, int file_format_version, TableWriter&, bool no_top_array,
+                      bool pad_for_encryption, uint_fast64_t version_number);
+
+    typedef void (*DescSetter)(Table&);
+    typedef bool (*DescMatcher)(const Spec&);
+
+    Table* do_get_table(size_t table_ndx, DescMatcher desc_matcher);
+    const Table* do_get_table(size_t table_ndx, DescMatcher desc_matcher) const;
+    Table* do_get_table(StringData name, DescMatcher desc_matcher);
+    const Table* do_get_table(StringData name, DescMatcher desc_matcher) const;
+    Table* do_insert_table(size_t, StringData name, DescSetter desc_setter, bool require_unique_name);
+    Table* do_insert_table(size_t, StringData name, DescSetter desc_setter);
+    Table* do_get_or_add_table(StringData name, DescMatcher desc_matcher, DescSetter setter, bool* was_added);
+    Table* do_get_or_insert_table(size_t, StringData name, DescMatcher desc_matcher, DescSetter desc_setter,
+                                  bool* was_added);
+
+    void create_and_insert_table(size_t new_table_ndx, StringData name);
+    Table* create_table_accessor(size_t table_ndx);
+
+    void detach_table_accessors() noexcept; // Idempotent
+
+    void mark_all_table_accessors() noexcept;
+
+    void write(util::File& file, const char* encryption_key, uint_fast64_t version_number, bool write_history) const;
+    void write(std::ostream&, bool pad, uint_fast64_t version_numer, bool write_history) const;
+
+    Replication* get_replication() const noexcept;
+    void set_replication(Replication*) noexcept;
+    std::shared_ptr<metrics::Metrics> get_metrics() const noexcept;
+    void set_metrics(std::shared_ptr<metrics::Metrics> other) noexcept;
+    void update_num_objects();
+    class TransactAdvancer;
+    void advance_transact(ref_type new_top_ref, size_t new_file_size, _impl::NoCopyInputStream&);
+    void refresh_dirty_accessors();
+    template <class F>
+    void update_table_indices(F&& map_function);
+
+    /// \brief The version of the format of the node structure (in file or in
+    /// memory) in use by Realm objects associated with this group.
+    ///
+    /// Every group contains a file format version field, which is returned
+    /// by this function. The file format version field is set to the file format
+    /// version specified by the attached file (or attached memory buffer) at the
+    /// time of attachment and the value is used to determine if a file format
+    /// upgrade is required.
+    ///
+    /// A value of zero means that the file format is not yet decided. This is
+    /// only possible for empty Realms where top-ref is zero. (When group is created
+    /// with the unattached_tag). The version number will then be determined in the
+    /// subsequent call to Group::open.
+    ///
+    /// In shared mode (when a Realm file is opened via a SharedGroup instance)
+    /// it can happen that the file format is upgraded asyncronously (via
+    /// another SharedGroup instance), and in that case the file format version
+    /// field can get out of date, but only for a short while. It is always
+    /// guaranteed to be, and remain up to date after the opening process completes
+    /// (when SharedGroup::do_open() returns).
+    ///
+    /// An empty Realm file (one whose top-ref is zero) may specify a file
+    /// format version of zero to indicate that the format is not yet
+    /// decided. In that case the file format version must be changed to a proper
+    /// before the opening process completes (Group::open() or SharedGroup::open()).
+    ///
+    /// File format versions:
+    ///
+    ///   1 Initial file format version
+    ///
+    ///   2 Various changes.
+    ///
+    ///   3 Supporting null on string columns broke the file format in following
+    ///     way: Index appends an 'X' character to all strings except the null
+    ///     string, to be able to distinguish between null and empty
+    ///     string. Bumped to 3 because of null support of String columns and
+    ///     because of new format of index.
+    ///
+    ///   4 Introduction of optional in-Realm history of changes (additional
+    ///     entries in Group::m_top). Since this change is not forward
+    ///     compatible, the file format version had to be bumped. This change is
+    ///     implemented in a way that achieves backwards compatibility with
+    ///     version 3 (and in turn with version 2).
+    ///
+    ///   5 Introduced the new Timestamp column type that replaces DateTime.
+    ///     When opening an older database file, all DateTime columns will be
+    ///     automatically upgraded Timestamp columns.
+    ///
+    ///   6 Introduced a new structure for the StringIndex. Moved the commit
+    ///     logs into the Realm file. Changes to the transaction log format
+    ///     including reshuffling instructions. This is the format used in
+    ///     milestone 2.0.0.
+    ///
+    ///   7 Introduced "history schema version" as 10th entry in top array.
+    ///
+    ///   8 Subtables can now have search index.
+    ///
+    ///   9 Replication instruction values shuffled, instr_MoveRow added.
+    ///
+    /// IMPORTANT: When introducing a new file format version, be sure to review
+    /// the file validity checks in Group::open() and SharedGroup::do_open, the file
+    /// format selection logic in
+    /// Group::get_target_file_format_version_for_session(), and the file format
+    /// upgrade logic in Group::upgrade_file_format().
+
+    int get_file_format_version() const noexcept;
+    void set_file_format_version(int) noexcept;
+    int get_committed_file_format_version() const noexcept;
+
+    /// The specified history type must be a value of Replication::HistoryType.
+    static int get_target_file_format_version_for_session(int current_file_format_version, int history_type) noexcept;
+
+    /// Must be called from within a write transaction
+    void upgrade_file_format(int target_file_format_version);
+
+    std::pair<ref_type, size_t> get_to_dot_parent(size_t ndx_in_parent) const override;
+
+    void send_cascade_notification(const CascadeNotification& notification) const;
+    void send_schema_change_notification() const;
+
+    static void get_version_and_history_info(const Array& top, _impl::History::version_type& version,
+                                             int& history_type, int& history_schema_version) noexcept;
+    static ref_type get_history_ref(const Array& top) noexcept;
+    static int get_history_schema_version(const Array& top) noexcept;
+    void set_history_schema_version(int version);
+    void set_history_parent(Array& history_root) noexcept;
+    void prepare_history_parent(Array& history_root, int history_type, int history_schema_version);
+    static void validate_top_array(const Array& arr, const SlabAlloc& alloc);
+
+    friend class Table;
+    friend class GroupWriter;
+    friend class SharedGroup;
+    friend class _impl::GroupFriend;
+    friend class _impl::TransactLogConvenientEncoder;
+    friend class _impl::TransactLogParser;
+    friend class Replication;
+    friend class TrivialReplication;
+    friend class metrics::QueryInfo;
+    friend class metrics::Metrics;
+};
+
+
+// Implementation
+
+inline Group::Group(const std::string& file, const char* key, OpenMode mode)
+    : m_alloc() // Throws
+    , m_top(m_alloc)
+    , m_tables(m_alloc)
+    , m_table_names(m_alloc)
+    , m_is_shared(false)
+    , m_total_rows(0)
+{
+    init_array_parents();
+
+    open(file, key, mode); // Throws
+}
+
+inline Group::Group(BinaryData buffer, bool take_ownership)
+    : m_alloc() // Throws
+    , m_top(m_alloc)
+    , m_tables(m_alloc)
+    , m_table_names(m_alloc)
+    , m_is_shared(false)
+    , m_total_rows(0)
+{
+    init_array_parents();
+    open(buffer, take_ownership); // Throws
+}
+
+inline Group::Group(unattached_tag) noexcept
+    : m_alloc()
+    , // Throws
+    m_top(m_alloc)
+    , m_tables(m_alloc)
+    , m_table_names(m_alloc)
+    , m_is_shared(false)
+    , m_total_rows(0)
+{
+    init_array_parents();
+}
+
+inline Group* Group::get_parent_group() noexcept
+{
+    return this;
+}
+
+inline Group::Group(shared_tag) noexcept
+    : m_alloc()
+    , // Throws
+    m_top(m_alloc)
+    , m_tables(m_alloc)
+    , m_table_names(m_alloc)
+    , m_is_shared(true)
+    , m_total_rows(0)
+{
+    init_array_parents();
+}
+
+inline bool Group::is_attached() const noexcept
+{
+    return m_attached;
+}
+
+inline bool Group::is_empty() const noexcept
+{
+    if (!is_attached())
+        return false;
+    if (m_table_names.is_attached())
+        return m_table_names.is_empty();
+    return true;
+}
+
+inline size_t Group::size() const noexcept
+{
+    if (!is_attached())
+        return 0;
+    if (m_table_names.is_attached())
+        return m_table_names.size();
+    return 0;
+}
+
+inline StringData Group::get_table_name(size_t table_ndx) const
+{
+    if (table_ndx >= size())
+        throw LogicError(LogicError::table_index_out_of_range);
+    return m_table_names.get(table_ndx);
+}
+
+inline bool Group::has_table(StringData name) const noexcept
+{
+    size_t ndx = find_table(name);
+    return ndx != not_found;
+}
+
+inline size_t Group::find_table(StringData name) const noexcept
+{
+    if (!is_attached())
+        return 0;
+    if (m_table_names.is_attached())
+        return m_table_names.find_first(name);
+    return not_found;
+}
+
+inline TableRef Group::get_table(size_t table_ndx)
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescMatcher desc_matcher = nullptr;                   // Do not check descriptor
+    Table* table = do_get_table(table_ndx, desc_matcher); // Throws
+    return TableRef(table);
+}
+
+inline ConstTableRef Group::get_table(size_t table_ndx) const
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescMatcher desc_matcher = nullptr;                         // Do not check descriptor
+    const Table* table = do_get_table(table_ndx, desc_matcher); // Throws
+    return ConstTableRef(table);
+}
+
+inline TableRef Group::get_table(StringData name)
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescMatcher desc_matcher = nullptr;              // Do not check descriptor
+    Table* table = do_get_table(name, desc_matcher); // Throws
+    return TableRef(table);
+}
+
+inline ConstTableRef Group::get_table(StringData name) const
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescMatcher desc_matcher = nullptr;                    // Do not check descriptor
+    const Table* table = do_get_table(name, desc_matcher); // Throws
+    return ConstTableRef(table);
+}
+
+inline TableRef Group::insert_table(size_t table_ndx, StringData name, bool require_unique_name)
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescSetter desc_setter = nullptr;                                                  // Do not add any columns
+    Table* table = do_insert_table(table_ndx, name, desc_setter, require_unique_name); // Throws
+    return TableRef(table);
+}
+
+inline TableRef Group::add_table(StringData name, bool require_unique_name)
+{
+    return insert_table(size(), name, require_unique_name);
+}
+
+inline TableRef Group::get_or_insert_table(size_t table_ndx, StringData name, bool* was_added)
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescMatcher desc_matcher = nullptr; // Do not check descriptor
+    DescSetter desc_setter = nullptr;   // Do not add any columns
+    Table* table = do_get_or_insert_table(table_ndx, name, desc_matcher, desc_setter, was_added); // Throws
+    return TableRef(table);
+}
+
+inline TableRef Group::get_or_add_table(StringData name, bool* was_added)
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+    DescMatcher desc_matcher = nullptr;                                             // Do not check descriptor
+    DescSetter desc_setter = nullptr;                                               // Do not add any columns
+    Table* table = do_get_or_add_table(name, desc_matcher, desc_setter, was_added); // Throws
+    return TableRef(table);
+}
+
+template <class S>
+void Group::to_json(S& out, size_t link_depth, std::map<std::string, std::string>* renames) const
+{
+    if (!is_attached())
+        throw LogicError(LogicError::detached_accessor);
+
+    std::map<std::string, std::string> renames2;
+    renames = renames ? renames : &renames2;
+
+    out << "{" << std::endl;
+
+    for (size_t i = 0; i < m_tables.size(); ++i) {
+        StringData name = m_table_names.get(i);
+        std::map<std::string, std::string>& m = *renames;
+        if (m[name] != "")
+            name = m[name];
+
+        ConstTableRef table = get_table(i);
+
+        if (i)
+            out << ",";
+        out << "\"" << name << "\"";
+        out << ":";
+        table->to_json(out, link_depth, renames);
+        out << std::endl;
+    }
+
+    out << "}" << std::endl;
+}
+
+inline void Group::init_array_parents() noexcept
+{
+    m_table_names.set_parent(&m_top, 0);
+    m_tables.set_parent(&m_top, 1);
+}
+
+inline void Group::update_child_ref(size_t child_ndx, ref_type new_ref)
+{
+    m_tables.set(child_ndx, new_ref);
+}
+
+inline ref_type Group::get_child_ref(size_t child_ndx) const noexcept
+{
+    return m_tables.get_as_ref(child_ndx);
+}
+
+inline StringData Group::get_child_name(size_t child_ndx) const noexcept
+{
+    return m_table_names.get(child_ndx);
+}
+
+inline void Group::child_accessor_destroyed(Table*) noexcept
+{
+    // Ignore
+}
+
+inline bool Group::has_cascade_notification_handler() const noexcept
+{
+    return !!m_notify_handler;
+}
+
+inline void
+Group::set_cascade_notification_handler(std::function<void(const CascadeNotification&)> new_handler) noexcept
+{
+    m_notify_handler = std::move(new_handler);
+}
+
+inline void Group::send_cascade_notification(const CascadeNotification& notification) const
+{
+    if (m_notify_handler)
+        m_notify_handler(notification);
+}
+
+inline bool Group::has_schema_change_notification_handler() const noexcept
+{
+    return !!m_schema_change_handler;
+}
+
+inline void Group::set_schema_change_notification_handler(std::function<void()> new_handler) noexcept
+{
+    m_schema_change_handler = std::move(new_handler);
+}
+
+inline void Group::send_schema_change_notification() const
+{
+    if (m_schema_change_handler)
+        m_schema_change_handler();
+}
+
+inline void Group::get_version_and_history_info(const Array& top, _impl::History::version_type& version,
+                                                int& history_type, int& history_schema_version) noexcept
+{
+    using version_type = _impl::History::version_type;
+    version_type version_2 = 0;
+    int history_type_2 = 0;
+    int history_schema_version_2 = 0;
+    if (top.is_attached()) {
+        if (top.size() >= 6) {
+            REALM_ASSERT(top.size() >= 7);
+            version_2 = version_type(top.get_as_ref_or_tagged(6).get_as_int());
+        }
+        if (top.size() >= 8) {
+            REALM_ASSERT(top.size() >= 9);
+            history_type_2           = int(top.get_as_ref_or_tagged(7).get_as_int());
+        }
+        if (top.size() >= 10) {
+            history_schema_version_2 = int(top.get_as_ref_or_tagged(9).get_as_int());
+        }
+    }
+    // Version 0 is not a legal initial version, so it has to be set to 1
+    // instead.
+    if (version_2 == 0)
+        version_2 = 1;
+    version = version_2;
+    history_type = history_type_2;
+    history_schema_version = history_schema_version_2;
+}
+
+inline ref_type Group::get_history_ref(const Array& top) noexcept
+{
+    bool has_history = (top.is_attached() && top.size() >= 8);
+    if (has_history) {
+        // This function is only used is shared mode (from SharedGroup)
+        REALM_ASSERT(top.size() >= 10);
+        return top.get_as_ref(8);
+    }
+    return 0;
+}
+
+inline int Group::get_history_schema_version(const Array& top) noexcept
+{
+    bool has_history = (top.is_attached() && top.size() >= 8);
+    if (has_history) {
+        // This function is only used is shared mode (from SharedGroup)
+        REALM_ASSERT(top.size() >= 10);
+        return int(top.get_as_ref_or_tagged(9).get_as_int());
+    }
+    return 0;
+}
+
+inline void Group::set_history_schema_version(int version)
+{
+    // This function is only used is shared mode (from SharedGroup)
+    REALM_ASSERT(m_top.size() >= 10);
+    m_top.set(9, RefOrTagged::make_tagged(unsigned(version))); // Throws
+}
+
+inline void Group::set_history_parent(Array& history_root) noexcept
+{
+    history_root.set_parent(&m_top, 8);
+}
+
+class Group::TableWriter {
+public:
+    struct HistoryInfo {
+        ref_type ref = 0;
+        int type = 0;
+        int version = 0;
+    };
+
+    virtual ref_type write_names(_impl::OutputStream&) = 0;
+    virtual ref_type write_tables(_impl::OutputStream&) = 0;
+    virtual HistoryInfo write_history(_impl::OutputStream&) = 0;
+    virtual ~TableWriter() noexcept
+    {
+    }
+};
+
+inline const Table* Group::do_get_table(size_t table_ndx, DescMatcher desc_matcher) const
+{
+    return const_cast<Group*>(this)->do_get_table(table_ndx, desc_matcher); // Throws
+}
+
+inline const Table* Group::do_get_table(StringData name, DescMatcher desc_matcher) const
+{
+    return const_cast<Group*>(this)->do_get_table(name, desc_matcher); // Throws
+}
+
+inline void Group::reset_free_space_tracking()
+{
+    m_alloc.reset_free_space_tracking(); // Throws
+}
+
+inline Replication* Group::get_replication() const noexcept
+{
+    return m_alloc.get_replication();
+}
+
+inline void Group::set_replication(Replication* repl) noexcept
+{
+    m_alloc.set_replication(repl);
+}
+
+inline std::shared_ptr<metrics::Metrics> Group::get_metrics() const noexcept
+{
+    return m_metrics;
+}
+
+inline void Group::set_metrics(std::shared_ptr<metrics::Metrics> shared) noexcept
+{
+    m_metrics = shared;
+}
+
+// The purpose of this class is to give internal access to some, but
+// not all of the non-public parts of the Group class.
+class _impl::GroupFriend {
+public:
+    static Allocator& get_alloc(Group& group) noexcept
+    {
+        return group.m_alloc;
+    }
+
+    static const Allocator& get_alloc(const Group& group) noexcept
+    {
+        return group.m_alloc;
+    }
+
+    static ref_type get_top_ref(const Group& group) noexcept
+    {
+        return group.m_top.get_ref();
+    }
+
+    static Table& get_table(Group& group, size_t ndx_in_group)
+    {
+        Group::DescMatcher desc_matcher = 0;                           // Do not check descriptor
+        Table* table = group.do_get_table(ndx_in_group, desc_matcher); // Throws
+        return *table;
+    }
+
+    static const Table& get_table(const Group& group, size_t ndx_in_group)
+    {
+        Group::DescMatcher desc_matcher = 0;                                 // Do not check descriptor
+        const Table* table = group.do_get_table(ndx_in_group, desc_matcher); // Throws
+        return *table;
+    }
+
+    static Table* get_table(Group& group, StringData name)
+    {
+        Group::DescMatcher desc_matcher = 0;                   // Do not check descriptor
+        Table* table = group.do_get_table(name, desc_matcher); // Throws
+        return table;
+    }
+
+    static const Table* get_table(const Group& group, StringData name)
+    {
+        Group::DescMatcher desc_matcher = 0;                         // Do not check descriptor
+        const Table* table = group.do_get_table(name, desc_matcher); // Throws
+        return table;
+    }
+
+    static Table& insert_table(Group& group, size_t table_ndx, StringData name, bool require_unique_name)
+    {
+        Group::DescSetter desc_setter = nullptr; // Do not add any columns
+        return *group.do_insert_table(table_ndx, name, desc_setter, require_unique_name);
+    }
+
+    static Table& add_table(Group& group, StringData name, bool require_unique_name)
+    {
+        return insert_table(group, group.size(), name, require_unique_name);
+    }
+
+    static Table& get_or_insert_table(Group& group, size_t table_ndx, StringData name, bool* was_inserted)
+    {
+        Group::DescMatcher desc_matcher = nullptr; // Do not check descriptor
+        Group::DescSetter desc_setter = nullptr;   // Do not add any columns
+        return *group.do_get_or_insert_table(table_ndx, name, desc_matcher, desc_setter, was_inserted);
+    }
+
+    static Table& get_or_add_table(Group& group, StringData name, bool* was_inserted)
+    {
+        Group::DescMatcher desc_matcher = nullptr; // Do not check descriptor
+        Group::DescSetter desc_setter = nullptr;   // Do not add any columns
+        return *group.do_get_or_add_table(name, desc_matcher, desc_setter, was_inserted);
+    }
+
+    static void send_cascade_notification(const Group& group, const Group::CascadeNotification& notification)
+    {
+        group.send_cascade_notification(notification);
+    }
+
+    static Replication* get_replication(const Group& group) noexcept
+    {
+        return group.get_replication();
+    }
+
+    static void set_replication(Group& group, Replication* repl) noexcept
+    {
+        group.set_replication(repl);
+    }
+
+    static void detach(Group& group) noexcept
+    {
+        group.detach();
+    }
+
+    static void attach_shared(Group& group, ref_type new_top_ref, size_t new_file_size, bool writable)
+    {
+        group.attach_shared(new_top_ref, new_file_size, writable); // Throws
+    }
+
+    static void reset_free_space_tracking(Group& group)
+    {
+        group.reset_free_space_tracking(); // Throws
+    }
+
+    static void remap(Group& group, size_t new_file_size)
+    {
+        group.remap(new_file_size); // Throws
+    }
+
+    static void remap_and_update_refs(Group& group, ref_type new_top_ref, size_t new_file_size)
+    {
+        group.remap_and_update_refs(new_top_ref, new_file_size); // Throws
+    }
+
+    static void advance_transact(Group& group, ref_type new_top_ref, size_t new_file_size,
+                                 _impl::NoCopyInputStream& in)
+    {
+        group.advance_transact(new_top_ref, new_file_size, in); // Throws
+    }
+
+    static void create_empty_group_when_missing(Group& group)
+    {
+        if (!group.m_top.is_attached())
+            group.create_empty_group(); // Throws
+    }
+
+    static void get_version_and_history_info(const Allocator& alloc, ref_type top_ref,
+                                             _impl::History::version_type& version,
+                                             int& history_type,
+                                             int& history_schema_version) noexcept
+    {
+        Array top{const_cast<Allocator&>(alloc)};
+        if (top_ref != 0)
+            top.init_from_ref(top_ref);
+        Group::get_version_and_history_info(top, version, history_type, history_schema_version);
+    }
+
+    static ref_type get_history_ref(const Group& group) noexcept
+    {
+        return Group::get_history_ref(group.m_top);
+    }
+
+    static ref_type get_history_ref(Allocator& alloc, ref_type top_ref) noexcept
+    {
+        Array top(alloc);
+        if (top_ref != 0)
+            top.init_from_ref(top_ref);
+        return Group::get_history_ref(top);
+    }
+
+    static int get_history_schema_version(const Group& group) noexcept
+    {
+        return Group::get_history_schema_version(group.m_top);
+    }
+
+    static int get_history_schema_version(Allocator& alloc, ref_type top_ref) noexcept
+    {
+        Array top{alloc};
+        if (top_ref != 0)
+            top.init_from_ref(top_ref);
+        return Group::get_history_schema_version(top);
+    }
+
+    static void set_history_schema_version(Group& group, int version)
+    {
+        group.set_history_schema_version(version); // Throws
+    }
+
+    static void set_history_parent(Group& group, Array& history_root) noexcept
+    {
+        group.set_history_parent(history_root);
+    }
+
+    static void prepare_history_parent(Group& group, Array& history_root, int history_type,
+                                       int history_schema_version)
+    {
+        group.prepare_history_parent(history_root, history_type, history_schema_version); // Throws
+    }
+
+    static int get_file_format_version(const Group& group) noexcept
+    {
+        return group.get_file_format_version();
+    }
+
+    static void set_file_format_version(Group& group, int file_format_version) noexcept
+    {
+        group.set_file_format_version(file_format_version);
+    }
+
+    static int get_committed_file_format_version(const Group& group) noexcept
+    {
+        return group.get_committed_file_format_version();
+    }
+
+    static int get_target_file_format_version_for_session(int current_file_format_version, int history_type) noexcept
+    {
+        return Group::get_target_file_format_version_for_session(current_file_format_version, history_type);
+    }
+
+    static void upgrade_file_format(Group& group, int target_file_format_version)
+    {
+        group.upgrade_file_format(target_file_format_version); // Throws
+    }
+};
+
+
+struct CascadeState : Group::CascadeNotification {
+    /// If non-null, then no recursion will be performed for rows of that
+    /// table. The effect is then exactly as if all the rows of that table were
+    /// added to \a state.rows initially, and then removed again after the
+    /// explicit invocations of Table::cascade_break_backlinks_to() (one for
+    /// each initiating row). This is used by Table::clear() to avoid
+    /// reentrance.
+    ///
+    /// Must never be set concurrently with stop_on_link_list_column.
+    Table* stop_on_table = nullptr;
+
+    /// If non-null, then Table::cascade_break_backlinks_to() will skip the
+    /// removal of reciprocal backlinks for the link list at
+    /// stop_on_link_list_row_ndx in this column, and no recursion will happen
+    /// on its behalf. This is used by LinkView::clear() to avoid reentrance.
+    ///
+    /// Must never be set concurrently with stop_on_table.
+    LinkListColumn* stop_on_link_list_column = nullptr;
+
+    /// Is ignored if stop_on_link_list_column is null.
+    size_t stop_on_link_list_row_ndx = 0;
+
+    /// If false, the links field is not needed, so any work done just for that
+    /// can be skipped.
+    bool track_link_nullifications = false;
+
+    /// If false, weak links are followed too
+    bool only_strong_links = true;
+};
+
+inline bool Group::CascadeNotification::row::operator==(const row& r) const noexcept
+{
+    return table_ndx == r.table_ndx && row_ndx == r.row_ndx;
+}
+
+inline bool Group::CascadeNotification::row::operator!=(const row& r) const noexcept
+{
+    return !(*this == r);
+}
+
+inline bool Group::CascadeNotification::row::operator<(const row& r) const noexcept
+{
+    return table_ndx < r.table_ndx || (table_ndx == r.table_ndx && row_ndx < r.row_ndx);
+}
+
+} // namespace realm
+
+#endif // REALM_GROUP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/group_shared.hpp b/node_modules/realm/vendor/realm-ios/include/realm/group_shared.hpp
new file mode 100644
index 0000000..e607409
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/group_shared.hpp
@@ -0,0 +1,1233 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_GROUP_SHARED_HPP
+#define REALM_GROUP_SHARED_HPP
+
+#include <functional>
+#include <limits>
+#include <realm/util/features.h>
+#include <realm/util/thread.hpp>
+#include <realm/util/interprocess_condvar.hpp>
+#include <realm/util/interprocess_mutex.hpp>
+#include <realm/group.hpp>
+#include <realm/group_shared_options.hpp>
+#include <realm/handover_defs.hpp>
+#include <realm/impl/transact_log.hpp>
+#include <realm/metrics/metrics.hpp>
+#include <realm/replication.hpp>
+#include <realm/version_id.hpp>
+
+namespace realm {
+
+namespace _impl {
+class SharedGroupFriend;
+class WriteLogCollector;
+}
+
+/// Thrown by SharedGroup::open() if the lock file is already open in another
+/// process which can't share mutexes with this process
+struct IncompatibleLockFile : std::runtime_error {
+    IncompatibleLockFile(const std::string& msg)
+        : std::runtime_error("Incompatible lock file. " + msg)
+    {
+    }
+};
+
+/// Thrown by SharedGroup::open() if the type of history
+/// (Replication::HistoryType) in the opened Realm file is incompatible with the
+/// mode in which the Realm file is opened. For example, if there is a mismatch
+/// between the history type in the file, and the history type associated with
+/// the replication plugin passed to SharedGroup::open().
+///
+/// This exception will also be thrown if the history schema version is lower
+/// than required, and no migration is possible
+/// (Replication::is_upgradable_history_schema()).
+struct IncompatibleHistories : util::File::AccessError {
+    IncompatibleHistories(const std::string& msg, const std::string& path)
+        : util::File::AccessError("Incompatible histories. " + msg, path)
+    {
+    }
+};
+
+/// A SharedGroup facilitates transactions.
+///
+/// When multiple threads or processes need to access a database
+/// concurrently, they must do so using transactions. By design,
+/// Realm does not allow for multiple threads (or processes) to
+/// share a single instance of SharedGroup. Instead, each concurrently
+/// executing thread or process must use a separate instance of
+/// SharedGroup.
+///
+/// Each instance of SharedGroup manages a single transaction at a
+/// time. That transaction can be either a read transaction, or a
+/// write transaction.
+///
+/// Utility classes ReadTransaction and WriteTransaction are provided
+/// to make it safe and easy to work with transactions in a scoped
+/// manner (by means of the RAII idiom). However, transactions can
+/// also be explicitly started (begin_read(), begin_write()) and
+/// stopped (end_read(), commit(), rollback()).
+///
+/// If a transaction is active when the SharedGroup is destroyed, that
+/// transaction is implicitly terminated, either by a call to
+/// end_read() or rollback().
+///
+/// Two processes that want to share a database file must reside on
+/// the same host.
+///
+///
+/// Desired exception behavior (not yet fully implemented)
+/// ------------------------------------------------------
+///
+///  - If any data access API function throws an unexpected exception during a
+///    read transaction, the shared group accessor is left in state "error
+///    during read".
+///
+///  - If any data access API function throws an unexpected exception during a
+///    write transaction, the shared group accessor is left in state "error
+///    during write".
+///
+///  - If SharedGroup::begin_write() or SharedGroup::begin_read() throws an
+///    unexpected exception, the shared group accessor is left in state "no
+///    transaction in progress".
+///
+///  - SharedGroup::end_read() and SharedGroup::rollback() do not throw.
+///
+///  - If SharedGroup::commit() throws an unexpected exception, the shared group
+///    accessor is left in state "error during write" and the transaction was
+///    not committed.
+///
+///  - If SharedGroup::advance_read() or SharedGroup::promote_to_write() throws
+///    an unexpected exception, the shared group accessor is left in state
+///    "error during read".
+///
+///  - If SharedGroup::commit_and_continue_as_read() or
+///    SharedGroup::rollback_and_continue_as_read() throws an unexpected
+///    exception, the shared group accessor is left in state "error during
+///    write".
+///
+/// It has not yet been decided exactly what an "unexpected exception" is, but
+/// `std::bad_alloc` is surely one example. On the other hand, an expected
+/// exception is one that is mentioned in the function specific documentation,
+/// and is used to abort an operation due to a special, but expected condition.
+///
+/// States
+/// ------
+///
+///  - A newly created shared group accessor is in state "no transaction in
+///    progress".
+///
+///  - In state "error during read", almost all Realm API functions are
+///    illegal on the connected group of accessors. The only valid operations
+///    are destruction of the shared group, and SharedGroup::end_read(). If
+///    SharedGroup::end_read() is called, the new state becomes "no transaction
+///    in progress".
+///
+///  - In state "error during write", almost all Realm API functions are
+///    illegal on the connected group of accessors. The only valid operations
+///    are destruction of the shared group, and SharedGroup::rollback(). If
+///    SharedGroup::end_write() is called, the new state becomes "no transaction
+///    in progress"
+class SharedGroup {
+public:
+    /// \brief Same as calling the corresponding version of open() on a instance
+    /// constructed in the unattached state. Exception safety note: if the
+    /// `upgrade_callback` throws, then the file will be closed properly and the
+    /// upgrade will be aborted.
+    explicit SharedGroup(const std::string& file, bool no_create = false,
+                         const SharedGroupOptions options = SharedGroupOptions());
+
+    /// \brief Same as calling the corresponding version of open() on a instance
+    /// constructed in the unattached state. Exception safety note: if the
+    /// `upgrade_callback` throws, then the file will be closed properly and
+    /// the upgrade will be aborted.
+    explicit SharedGroup(Replication& repl, const SharedGroupOptions options = SharedGroupOptions());
+
+    struct unattached_tag {
+    };
+
+    /// Create a SharedGroup instance in its unattached state. It may
+    /// then be attached to a database file later by calling
+    /// open(). You may test whether this instance is currently in its
+    /// attached state by calling is_attached(). Calling any other
+    /// function (except the destructor) while in the unattached state
+    /// has undefined behavior.
+    SharedGroup(unattached_tag) noexcept;
+
+    ~SharedGroup() noexcept;
+
+    // Disable copying to prevent accessor errors. If you really want another
+    // instance, open another SharedGroup object on the same file.
+    SharedGroup(const SharedGroup&) = delete;
+    SharedGroup& operator=(const SharedGroup&) = delete;
+
+    /// Attach this SharedGroup instance to the specified database file.
+    ///
+    /// While at least one instance of SharedGroup exists for a specific
+    /// database file, a "lock" file will be present too. The lock file will be
+    /// placed in the same directory as the database file, and its name will be
+    /// derived by appending ".lock" to the name of the database file.
+    ///
+    /// When multiple SharedGroup instances refer to the same file, they must
+    /// specify the same durability level, otherwise an exception will be
+    /// thrown.
+    ///
+    /// \param file Filesystem path to a Realm database file.
+    ///
+    /// \param no_create If the database file does not already exist, it will be
+    /// created (unless this is set to true.) When multiple threads are involved,
+    /// it is safe to let the first thread, that gets to it, create the file.
+    ///
+    /// \param options See SharedGroupOptions for details of each option.
+    /// Sensible defaults are provided if this parameter is left out.
+    ///
+    /// Calling open() on a SharedGroup instance that is already in the attached
+    /// state has undefined behavior.
+    ///
+    /// \throw util::File::AccessError If the file could not be opened. If the
+    /// reason corresponds to one of the exception types that are derived from
+    /// util::File::AccessError, the derived exception type is thrown. Note that
+    /// InvalidDatabase is among these derived exception types.
+    ///
+    /// \throw FileFormatUpgradeRequired only if \a SharedGroupOptions::allow_upgrade
+    /// is `false` and an upgrade is required.
+    void open(const std::string& file, bool no_create = false,
+              const SharedGroupOptions options = SharedGroupOptions());
+
+    /// Open this group in replication mode. The specified Replication instance
+    /// must remain in existence for as long as the SharedGroup.
+    void open(Replication&, const SharedGroupOptions options = SharedGroupOptions());
+
+    /// Close any open database, returning to the unattached state.
+    void close() noexcept;
+
+    /// A SharedGroup may be created in the unattached state, and then
+    /// later attached to a file with a call to open(). Calling any
+    /// function other than open(), is_attached(), and ~SharedGroup()
+    /// on an unattached instance results in undefined behavior.
+    bool is_attached() const noexcept;
+
+#ifdef REALM_DEBUG
+    /// Deprecated method, only called from a unit test
+    ///
+    /// Reserve disk space now to avoid allocation errors at a later
+    /// point in time, and to minimize on-disk fragmentation. In some
+    /// cases, less fragmentation translates into improved
+    /// performance.
+    ///
+    /// When supported by the system, a call to this function will
+    /// make the database file at least as big as the specified size,
+    /// and cause space on the target device to be allocated (note
+    /// that on many systems on-disk allocation is done lazily by
+    /// default). If the file is already bigger than the specified
+    /// size, the size will be unchanged, and on-disk allocation will
+    /// occur only for the initial section that corresponds to the
+    /// specified size.
+    ///
+    /// It is an error to call this function on an unattached shared
+    /// group. Doing so will result in undefined behavior.
+    void reserve(size_t size_in_bytes);
+#endif
+
+    /// Querying for changes:
+    ///
+    /// NOTE:
+    /// "changed" means that one or more commits has been made to the database
+    /// since the SharedGroup (on which wait_for_change() is called) last
+    /// started, committed, promoted or advanced a transaction. If the
+    /// SharedGroup has not yet begun a transaction, "changed" is undefined.
+    ///
+    /// No distinction is made between changes done by another process
+    /// and changes done by another thread in the same process as the caller.
+    ///
+    /// Has db been changed ?
+    bool has_changed();
+
+    /// The calling thread goes to sleep until the database is changed, or
+    /// until wait_for_change_release() is called. After a call to
+    /// wait_for_change_release() further calls to wait_for_change() will return
+    /// immediately. To restore the ability to wait for a change, a call to
+    /// enable_wait_for_change() is required. Return true if the database has
+    /// changed, false if it might have.
+    bool wait_for_change();
+
+    /// release any thread waiting in wait_for_change() on *this* SharedGroup.
+    void wait_for_change_release();
+
+    /// re-enable waiting for change
+    void enable_wait_for_change();
+    // Transactions:
+
+    using version_type = _impl::History::version_type;
+    using VersionID = realm::VersionID;
+
+    /// Thrown by begin_read() if the specified version does not correspond to a
+    /// bound (or tethered) snapshot.
+    struct BadVersion;
+
+    /// \defgroup group_shared_transactions
+    //@{
+
+    /// begin_read() initiates a new read transaction. A read transaction is
+    /// bound to, and provides access to a particular snapshot of the underlying
+    /// Realm (in general the latest snapshot, but see \a version). It cannot be
+    /// used to modify the Realm, and in that sense, a read transaction is not a
+    /// real transaction.
+    ///
+    /// begin_write() initiates a new write transaction. A write transaction
+    /// allows the application to both read and modify the underlying Realm
+    /// file. At most one write transaction can be in progress at any given time
+    /// for a particular underlying Realm file. If another write transaction is
+    /// already in progress, begin_write() will block the caller until the other
+    /// write transaction terminates. No guarantees are made about the order in
+    /// which multiple concurrent requests will be served.
+    ///
+    /// It is an error to call begin_read() or begin_write() on a SharedGroup
+    /// object with an active read or write transaction.
+    ///
+    /// If begin_read() or begin_write() throws, no transaction is initiated,
+    /// and the application may try to initiate a new read or write transaction
+    /// later.
+    ///
+    /// end_read() terminates the active read transaction. If no read
+    /// transaction is active, end_read() does nothing. It is an error to call
+    /// this function on a SharedGroup object with an active write
+    /// transaction. end_read() does not throw.
+    ///
+    /// commit() commits all changes performed in the context of the active
+    /// write transaction, and thereby terminates that transaction. This
+    /// produces a new snapshot in the underlying Realm. commit() returns the
+    /// version associated with the new snapshot. It is an error to call
+    /// commit() when there is no active write transaction. If commit() throws,
+    /// no changes will have been committed, and the transaction will still be
+    /// active, but in a bad state. In that case, the application must either
+    /// call rollback() to terminate the bad transaction (in which case a new
+    /// transaction can be initiated), call close() which also terminates the
+    /// bad transaction, or destroy the SharedGroup object entirely. When the
+    /// transaction is in a bad state, the application is not allowed to call
+    /// any method on the Group accessor or on any of its subordinate accessors
+    /// (Table, Row, Descriptor). Note that the transaction is also left in a
+    /// bad state when a modifying operation on any subordinate accessor throws.
+    ///
+    /// rollback() terminates the active write transaction and discards any
+    /// changes performed in the context of it. If no write transaction is
+    /// active, rollback() does nothing. It is an error to call this function in
+    /// a SharedGroup object with an active read transaction. rollback() does
+    /// not throw.
+    ///
+    /// the Group accessor and all subordinate accessors (Table, Row,
+    /// Descriptor) that are obtained in the context of a particular read or
+    /// write transaction will become detached upon termination of that
+    /// transaction, which means that they can no longer be used to access the
+    /// underlying objects.
+    ///
+    /// Subordinate accessors that were detached at the end of the previous
+    /// read or write transaction will not be automatically reattached when a
+    /// new transaction is initiated. The application must reobtain new
+    /// accessors during a new transaction to regain access to the underlying
+    /// objects.
+    ///
+    /// \param version If specified, this must be the version associated with a
+    /// *bound* snapshot. A snapshot is said to be bound (or tethered) if there
+    /// is at least one active read or write transaction bound to it. A read
+    /// transaction is bound to the snapshot that it provides access to. A write
+    /// transaction is bound to the latest snapshot available at the time of
+    /// initiation of the write transaction. If the specified version is not
+    /// associated with a bound snapshot, this function throws BadVersion.
+    ///
+    /// \throw BadVersion Thrown by begin_read() if the specified version does
+    /// not correspond to a bound (or tethered) snapshot.
+
+    const Group& begin_read(VersionID version = VersionID());
+    void end_read() noexcept;
+    Group& begin_write();
+    // Return true (and take the write lock) if there is no other write
+    // in progress. In case of contention return false immediately.
+    // If the write lock is obtained, also provide the Group associated
+    // with the SharedGroup for further operations.
+    bool try_begin_write(Group*& group);
+    version_type commit();
+    void rollback() noexcept;
+    // report statistics of last commit done on THIS shared group.
+    // The free space reported is what can be expected to be freed
+    // by compact(). This may not correspond to the space which is free
+    // at the point where get_stats() is called, since that will include
+    // memory required to hold older versions of data, which still
+    // needs to be available. The locked space is the amount of memory
+    // that is free in current version, but being used in still live versions.
+    // Notice that we will always have two live versions - the current and the
+    // previous.
+    void get_stats(size_t& free_space, size_t& used_space, util::Optional<size_t&> locked_space = util::none) const;
+    //@}
+
+    enum TransactStage {
+        transact_Ready,
+        transact_Reading,
+        transact_Writing,
+    };
+
+    /// Get the current transaction type
+    TransactStage get_transact_stage() const noexcept;
+
+    /// Get a version id which may be used to request a different SharedGroup
+    /// to start transaction at a specific version.
+    VersionID get_version_of_current_transaction();
+
+    /// Report the number of distinct versions currently stored in the database.
+    /// Note: the database only cleans up versions as part of commit, so ending
+    /// a read transaction will not immediately release any versions.
+    uint_fast64_t get_number_of_versions();
+
+    /// Get the approximate size of the data that would be written to the file if
+    /// a commit were done at this point. The reported size will always be bigger
+    /// than what will eventually be needed as we reserve a bit more memory that
+    /// will be needed.
+    size_t get_commit_size() const;
+
+    /// Get the size of the currently allocated slab area
+    size_t get_allocated_size() const;
+
+    /// Compact the database file.
+    /// - The method will throw if called inside a transaction.
+    /// - The method will throw if called in unattached state.
+    /// - The method will return false if other SharedGroups are accessing the
+    ///    database in which case compaction is not done. This is not
+    ///    necessarily an error.
+    /// It will return true following successful compaction.
+    /// While compaction is in progress, attempts by other
+    /// threads or processes to open the database will wait.
+    /// Be warned that resource requirements for compaction is proportional to
+    /// the amount of live data in the database.
+    /// Compaction works by writing the database contents to a temporary
+    /// database file and then replacing the database with the temporary one.
+    /// The name of the temporary file is formed by appending
+    /// ".tmp_compaction_space" to the name of the database
+    ///
+    /// If the output_encryption_key is `none` then the file's existing key will
+    /// be used (if any). If the output_encryption_key is nullptr, the resulting
+    /// file will be unencrypted. Any other value will change the encryption of
+    /// the file to the new 64 byte key.
+    ///
+    /// FIXME: This function is not yet implemented in an exception-safe manner,
+    /// therefore, if it throws, the application should not attempt to
+    /// continue. If may not even be safe to destroy the SharedGroup object.
+    ///
+    /// WARNING / FIXME: compact() should NOT be exposed publicly on Windows
+    /// because it's not crash safe! It may corrupt your database if something fails
+    bool compact(bool bump_version_number = false, util::Optional<const char*> output_encryption_key = util::none);
+
+#ifdef REALM_DEBUG
+    void test_ringbuf();
+#endif
+
+    /// To handover a table view, query, linkview or row accessor of type T, you
+    /// must wrap it into a Handover<T> for the transfer. Wrapping and
+    /// unwrapping of a handover object is done by the methods
+    /// 'export_for_handover()' and 'import_from_handover()' declared below.
+    /// 'export_for_handover()' returns a Handover object, and
+    /// 'import_for_handover()' consumes that object, producing a new accessor
+    /// which is ready for use in the context of the importing SharedGroup.
+    ///
+    /// The Handover always creates a new accessor object at the importing side.
+    /// For TableViews, there are 3 forms of handover.
+    ///
+    /// - with payload move: the payload is handed over and ends up as a payload
+    ///   held by the accessor at the importing side. The accessor on the
+    ///   exporting side will rerun its query and generate a new payload, if
+    ///   TableView::sync_if_needed() is called. If the original payload was in
+    ///   sync at the exporting side, it will also be in sync at the importing
+    ///   side. This is indicated to handover_export() by the argument
+    ///   MutableSourcePayload::Move
+    ///
+    /// - with payload copy: a copy of the payload is handed over, so both the
+    ///   accessors on the exporting side *and* the accessors created at the
+    ///   importing side has their own payload. This is indicated to
+    ///   handover_export() by the argument ConstSourcePayload::Copy
+    ///
+    /// - without payload: the payload stays with the accessor on the exporting
+    ///   side. On the importing side, the new accessor is created without
+    ///   payload. A call to TableView::sync_if_needed() will trigger generation
+    ///   of a new payload. This form of handover is indicated to
+    ///   handover_export() by the argument ConstSourcePayload::Stay.
+    ///
+    /// For all other (non-TableView) accessors, handover is done with payload
+    /// copy, since the payload is trivial.
+    ///
+    /// Handover *without* payload is useful when you want to ship a tableview
+    /// with its query for execution in a background thread. Handover with
+    /// *payload move* is useful when you want to transfer the result back.
+    ///
+    /// Handover *without* payload or with payload copy is guaranteed *not* to
+    /// change the accessors on the exporting side.
+    ///
+    /// Handover is *not* thread safe and should be carried out
+    /// by the thread that "owns" the involved accessors.
+    ///
+    /// Handover is transitive:
+    /// If the object being handed over depends on other views
+    /// (table- or link- ), those objects will be handed over as well. The mode
+    /// of handover (payload copy, payload move, without payload) is applied
+    /// recursively. Note: If you are handing over a tableview dependent upon
+    /// another tableview and using MutableSourcePayload::Move,
+    /// you are on thin ice!
+    ///
+    /// On the importing side, the top-level accessor being created during
+    /// import takes ownership of all other accessors (if any) being created as
+    /// part of the import.
+
+    /// Type used to support handover of accessors between shared groups.
+    template <typename T>
+    struct Handover;
+
+    /// thread-safe/const export (mode is Stay or Copy)
+    /// during export, the following operations on the shared group is locked:
+    /// - advance_read(), promote_to_write(), commit_and_continue_as_read(),
+    ///   rollback_and_continue_as_read(), close()
+    template <typename T>
+    std::unique_ptr<Handover<T>> export_for_handover(const T& accessor, ConstSourcePayload mode);
+
+    // specialization for handover of Rows
+    template <typename T>
+    std::unique_ptr<Handover<BasicRow<T>>> export_for_handover(const BasicRow<T>& accessor);
+
+    // destructive export (mode is Move)
+    template <typename T>
+    std::unique_ptr<Handover<T>> export_for_handover(T& accessor, MutableSourcePayload mode);
+
+    /// Import an accessor wrapped in a handover object. The import will fail
+    /// if the importing SharedGroup is viewing a version of the database that
+    /// is different from the exporting SharedGroup. The call to
+    /// import_from_handover is not thread-safe.
+    template <typename T>
+    std::unique_ptr<T> import_from_handover(std::unique_ptr<Handover<T>> handover);
+
+    // We need two cases for handling of LinkViews, because they are ref counted.
+    std::unique_ptr<Handover<LinkView>> export_linkview_for_handover(const LinkViewRef& accessor);
+    LinkViewRef import_linkview_from_handover(std::unique_ptr<Handover<LinkView>> handover);
+
+    // likewise for Tables.
+    std::unique_ptr<Handover<Table>> export_table_for_handover(const TableRef& accessor);
+    TableRef import_table_from_handover(std::unique_ptr<Handover<Table>> handover);
+
+    /// When doing handover to background tasks that may be run later, we
+    /// may want to momentarily pin the current version until the other thread
+    /// has retrieved it.
+    ///
+    /// Pinning can be done in both read- and write-transactions, but with different
+    /// semantics. When pinning during a read-transaction, the version pinned is the
+    /// one accessible during the read-transaction. When pinning during a write-transaction,
+    /// the version pinned will be the last version that was succesfully committed to the
+    /// realm file at the point in time, when the write-transaction was started.
+    ///
+    /// The release is not thread-safe, so it has to be done on the SharedGroup
+    /// associated with the thread calling unpin_version(), and the SharedGroup
+    /// must be attached to the realm file at the point of unpinning.
+
+    // Pin version for handover (not thread safe)
+    VersionID pin_version();
+
+    // Release pinned version (not thread safe)
+    void unpin_version(VersionID version);
+
+    std::shared_ptr<metrics::Metrics> get_metrics();
+
+    // Try to grab a exclusive lock of the given realm path's lock file. If the lock
+    // can be acquired, the callback will be executed with the lock and then return true.
+    // Otherwise false will be returned directly.
+    // The lock taken precludes races with other threads or processes accessing the
+    // files through a SharedGroup.
+    // It is safe to delete/replace realm files inside the callback.
+    // WARNING: It is not safe to delete the lock file in the callback.
+    using CallbackWithLock = std::function<void(const std::string& realm_path)>;
+    static bool call_with_lock(const std::string& realm_path, CallbackWithLock callback);
+
+    // Return a list of files/directories core may use of the given realm file path.
+    // The first element of the pair in the returned list is the path string, the
+    // second one is to indicate the path is a directory or not.
+    // The temporary files are not returned by this function.
+    // It is safe to delete those returned files/directories in the call_with_lock's callback.
+    static std::vector<std::pair<std::string, bool>> get_core_files(const std::string& realm_path);
+
+private:
+    struct SharedInfo;
+    struct ReadCount;
+    struct ReadLockInfo {
+        uint_fast64_t m_version = std::numeric_limits<version_type>::max();
+        uint_fast32_t m_reader_idx = 0;
+        ref_type m_top_ref = 0;
+        size_t m_file_size = 0;
+    };
+    class ReadLockUnlockGuard;
+
+    // Member variables
+    size_t m_free_space = 0;
+    size_t m_locked_space = 0;
+    size_t m_used_space = 0;
+    Group m_group;
+    ReadLockInfo m_read_lock;
+    uint_fast32_t m_local_max_entry;
+    util::File m_file;
+    util::File::Map<SharedInfo> m_file_map; // Never remapped
+    util::File::Map<SharedInfo> m_reader_map;
+    bool m_wait_for_change_enabled;
+    std::string m_lockfile_path;
+    std::string m_lockfile_prefix;
+    std::string m_db_path;
+    std::string m_coordination_dir;
+    const char* m_key;
+    TransactStage m_transact_stage;
+    util::InterprocessMutex m_writemutex;
+#ifdef REALM_ASYNC_DAEMON
+    util::InterprocessMutex m_balancemutex;
+#endif
+    util::InterprocessMutex m_controlmutex;
+#ifdef REALM_ASYNC_DAEMON
+    util::InterprocessCondVar m_room_to_write;
+    util::InterprocessCondVar m_work_to_do;
+    util::InterprocessCondVar m_daemon_becomes_ready;
+#endif
+    util::InterprocessCondVar m_new_commit_available;
+    util::InterprocessCondVar m_pick_next_writer;
+    std::function<void(int, int)> m_upgrade_callback;
+
+#if REALM_METRICS
+    std::shared_ptr<metrics::Metrics> m_metrics;
+#endif // REALM_METRICS
+
+    void do_open(const std::string& file, bool no_create, bool is_backend, const SharedGroupOptions options);
+
+    // Ring buffer management
+    bool ringbuf_is_empty() const noexcept;
+    size_t ringbuf_size() const noexcept;
+    size_t ringbuf_capacity() const noexcept;
+    bool ringbuf_is_first(size_t ndx) const noexcept;
+    void ringbuf_remove_first() noexcept;
+    size_t ringbuf_find(uint64_t version) const noexcept;
+    ReadCount& ringbuf_get(size_t ndx) noexcept;
+    ReadCount& ringbuf_get_first() noexcept;
+    ReadCount& ringbuf_get_last() noexcept;
+    void ringbuf_put(const ReadCount& v);
+    void ringbuf_expand();
+
+    /// Grab a read lock on the snapshot associated with the specified
+    /// version. If `version_id == VersionID()`, a read lock will be grabbed on
+    /// the latest available snapshot. Fails if the snapshot is no longer
+    /// available.
+    ///
+    /// As a side effect update memory mapping to ensure that the ringbuffer
+    /// entries referenced in the readlock info is accessible.
+    ///
+    /// FIXME: It needs to be made more clear exactly under which conditions
+    /// this function fails. Also, why is it useful to promise anything about
+    /// detection of bad versions? Can we really promise enough to make such a
+    /// promise useful to the caller?
+    void grab_read_lock(ReadLockInfo&, VersionID);
+
+    // Release a specific read lock. The read lock MUST have been obtained by a
+    // call to grab_read_lock().
+    void release_read_lock(ReadLockInfo&) noexcept;
+
+    void do_begin_read(VersionID, bool writable);
+    void do_end_read() noexcept;
+    /// return true if write transaction can commence, false otherwise.
+    bool do_try_begin_write();
+    void do_begin_write();
+    version_type do_commit();
+    void do_end_write() noexcept;
+    void set_transact_stage(TransactStage stage) noexcept;
+
+    /// Returns the version of the latest snapshot.
+    version_type get_version_of_latest_snapshot();
+
+    /// Returns the version of the snapshot bound in the current read or write
+    /// transaction. It is an error to call this function when no transaction is
+    /// in progress.
+    version_type get_version_of_bound_snapshot() const noexcept;
+
+    // make sure the given index is within the currently mapped area.
+    // if not, expand the mapped area. Returns true if the area is expanded.
+    bool grow_reader_mapping(uint_fast32_t index);
+
+    // Must be called only by someone that has a lock on the write
+    // mutex.
+    void low_level_commit(uint_fast64_t new_version);
+
+    void do_async_commits();
+
+    /// Upgrade file format and/or history schema
+    void upgrade_file_format(bool allow_file_format_upgrade, int target_file_format_version,
+                             int current_hist_schema_version, int target_hist_schema_version);
+
+    //@{
+    /// See LangBindHelper.
+    template <class O>
+    void advance_read(O* observer, VersionID);
+    template <class O>
+    void promote_to_write(O* observer);
+    version_type commit_and_continue_as_read();
+    template <class O>
+    void rollback_and_continue_as_read(O* observer);
+    //@}
+
+    /// Returns true if, and only if _impl::History::update_early_from_top_ref()
+    /// was called during the execution of this function.
+    template <class O>
+    bool do_advance_read(O* observer, VersionID, _impl::History&);
+
+    /// If there is an associated \ref Replication object, then this function
+    /// returns `repl->get_history()` where `repl` is that Replication object,
+    /// otherwise this function returns null.
+    _impl::History* get_history();
+
+    int get_file_format_version() const noexcept;
+
+    /// finish up the process of starting a write transaction. Internal use only.
+    void finish_begin_write();
+
+    void close_internal(std::unique_lock<InterprocessMutex>) noexcept;
+    friend class _impl::SharedGroupFriend;
+};
+
+
+inline void SharedGroup::get_stats(size_t& free_space, size_t& used_space, util::Optional<size_t&> locked_space) const
+{
+    free_space = m_free_space;
+    used_space = m_used_space;
+    if (locked_space) {
+        *locked_space = m_locked_space;
+    }
+}
+
+
+class ReadTransaction {
+public:
+    ReadTransaction(SharedGroup& sg)
+        : m_shared_group(sg)
+    {
+        m_shared_group.begin_read(); // Throws
+    }
+
+    ~ReadTransaction() noexcept
+    {
+        m_shared_group.end_read();
+    }
+
+    bool has_table(StringData name) const noexcept
+    {
+        return get_group().has_table(name);
+    }
+
+    ConstTableRef get_table(size_t table_ndx) const
+    {
+        return get_group().get_table(table_ndx); // Throws
+    }
+
+    ConstTableRef get_table(StringData name) const
+    {
+        return get_group().get_table(name); // Throws
+    }
+
+    const Group& get_group() const noexcept;
+
+    /// Get the version of the snapshot to which this read transaction is bound.
+    SharedGroup::version_type get_version() const noexcept;
+
+private:
+    SharedGroup& m_shared_group;
+};
+
+
+class WriteTransaction {
+public:
+    WriteTransaction(SharedGroup& sg)
+        : m_shared_group(&sg)
+    {
+        m_shared_group->begin_write(); // Throws
+    }
+
+    ~WriteTransaction() noexcept
+    {
+        if (m_shared_group)
+            m_shared_group->rollback();
+    }
+
+    bool has_table(StringData name) const noexcept
+    {
+        return get_group().has_table(name);
+    }
+
+    TableRef get_table(size_t table_ndx) const
+    {
+        return get_group().get_table(table_ndx); // Throws
+    }
+
+    TableRef get_table(StringData name) const
+    {
+        return get_group().get_table(name); // Throws
+    }
+
+    TableRef add_table(StringData name, bool require_unique_name = true) const
+    {
+        return get_group().add_table(name, require_unique_name); // Throws
+    }
+
+    TableRef get_or_add_table(StringData name, bool* was_added = nullptr) const
+    {
+        return get_group().get_or_add_table(name, was_added); // Throws
+    }
+
+    Group& get_group() const noexcept;
+
+    /// Get the version of the snapshot on which this write transaction is
+    /// based.
+    SharedGroup::version_type get_version() const noexcept;
+
+    SharedGroup::version_type commit()
+    {
+        REALM_ASSERT(m_shared_group);
+        SharedGroup::version_type new_version = m_shared_group->commit();
+        m_shared_group = nullptr;
+        return new_version;
+    }
+
+    void rollback() noexcept
+    {
+        REALM_ASSERT(m_shared_group);
+        m_shared_group->rollback();
+        m_shared_group = nullptr;
+    }
+
+private:
+    SharedGroup* m_shared_group;
+};
+
+
+// Implementation:
+
+struct SharedGroup::BadVersion : std::exception {
+};
+
+inline SharedGroup::SharedGroup(const std::string& file, bool no_create, const SharedGroupOptions options)
+    : m_group(Group::shared_tag())
+    , m_upgrade_callback(std::move(options.upgrade_callback))
+{
+    open(file, no_create, options); // Throws
+}
+
+inline SharedGroup::SharedGroup(unattached_tag) noexcept
+    : m_group(Group::shared_tag())
+{
+}
+
+inline SharedGroup::SharedGroup(Replication& repl, const SharedGroupOptions options)
+    : m_group(Group::shared_tag())
+    , m_upgrade_callback(std::move(options.upgrade_callback))
+{
+    open(repl, options); // Throws
+}
+
+inline void SharedGroup::open(const std::string& path, bool no_create_file, const SharedGroupOptions options)
+{
+    // Exception safety: Since open() is called from constructors, if it throws,
+    // it must leave the file closed.
+
+    bool is_backend = false;
+    do_open(path, no_create_file, is_backend, options); // Throws
+}
+
+inline void SharedGroup::open(Replication& repl, const SharedGroupOptions options)
+{
+    // Exception safety: Since open() is called from constructors, if it throws,
+    // it must leave the file closed.
+
+    REALM_ASSERT(!is_attached());
+
+    repl.initialize(*this); // Throws
+
+    typedef _impl::GroupFriend gf;
+    gf::set_replication(m_group, &repl);
+
+    std::string file = repl.get_database_path();
+    bool no_create = false;
+    bool is_backend = false;
+    do_open(file, no_create, is_backend, options); // Throws
+}
+
+inline bool SharedGroup::is_attached() const noexcept
+{
+    return m_file_map.is_attached();
+}
+
+inline SharedGroup::TransactStage SharedGroup::get_transact_stage() const noexcept
+{
+    return m_transact_stage;
+}
+
+inline SharedGroup::version_type SharedGroup::get_version_of_bound_snapshot() const noexcept
+{
+    return m_read_lock.m_version;
+}
+
+class SharedGroup::ReadLockUnlockGuard {
+public:
+    ReadLockUnlockGuard(SharedGroup& shared_group, ReadLockInfo& read_lock) noexcept
+        : m_shared_group(shared_group)
+        , m_read_lock(&read_lock)
+    {
+    }
+    ~ReadLockUnlockGuard() noexcept
+    {
+        if (m_read_lock)
+            m_shared_group.release_read_lock(*m_read_lock);
+    }
+    void release() noexcept
+    {
+        m_read_lock = 0;
+    }
+
+private:
+    SharedGroup& m_shared_group;
+    ReadLockInfo* m_read_lock;
+};
+
+
+template <typename T>
+struct SharedGroup::Handover {
+    std::unique_ptr<typename T::HandoverPatch> patch;
+    std::unique_ptr<T> clone;
+    VersionID version;
+};
+
+template <typename T>
+std::unique_ptr<SharedGroup::Handover<T>> SharedGroup::export_for_handover(const T& accessor, ConstSourcePayload mode)
+{
+    if (m_transact_stage != transact_Reading)
+        throw LogicError(LogicError::wrong_transact_state);
+    std::unique_ptr<Handover<T>> result(new Handover<T>());
+    // Implementation note:
+    // often, the return value from clone will be T*, BUT it may be ptr to some
+    // base of T instead, so we must cast it to T*. This is always safe, because
+    // no matter the type, clone() will clone the actual accessor instance, and
+    // hence return an instance of the same type.
+    result->clone.reset(dynamic_cast<T*>(accessor.clone_for_handover(result->patch, mode).release()));
+    result->version = get_version_of_current_transaction();
+    return move(result);
+}
+
+
+template <typename T>
+std::unique_ptr<SharedGroup::Handover<BasicRow<T>>> SharedGroup::export_for_handover(const BasicRow<T>& accessor)
+{
+    if (m_transact_stage != transact_Reading)
+        throw LogicError(LogicError::wrong_transact_state);
+    std::unique_ptr<Handover<BasicRow<T>>> result(new Handover<BasicRow<T>>());
+    // See implementation note above.
+    result->clone.reset(dynamic_cast<BasicRow<T>*>(accessor.clone_for_handover(result->patch).release()));
+    result->version = get_version_of_current_transaction();
+    return move(result);
+}
+
+
+template <typename T>
+std::unique_ptr<SharedGroup::Handover<T>> SharedGroup::export_for_handover(T& accessor, MutableSourcePayload mode)
+{
+    if (m_transact_stage != transact_Reading)
+        throw LogicError(LogicError::wrong_transact_state);
+    std::unique_ptr<Handover<T>> result(new Handover<T>());
+    // see implementation note above.
+    result->clone.reset(dynamic_cast<T*>(accessor.clone_for_handover(result->patch, mode).release()));
+    result->version = get_version_of_current_transaction();
+    return move(result);
+}
+
+
+template <typename T>
+std::unique_ptr<T> SharedGroup::import_from_handover(std::unique_ptr<SharedGroup::Handover<T>> handover)
+{
+    if (handover->version != get_version_of_current_transaction()) {
+        throw BadVersion();
+    }
+    std::unique_ptr<T> result = move(handover->clone);
+    result->apply_and_consume_patch(handover->patch, m_group);
+    return result;
+}
+
+template <class O>
+inline void SharedGroup::advance_read(O* observer, VersionID version_id)
+{
+    if (m_transact_stage != transact_Reading)
+        throw LogicError(LogicError::wrong_transact_state);
+
+    // It is an error if the new version precedes the currently bound one.
+    if (version_id.version < m_read_lock.m_version)
+        throw LogicError(LogicError::bad_version);
+
+    Replication* repl = m_group.get_replication();
+    _impl::History* hist = repl ? repl->get_history() : nullptr; // Throws
+
+    if (!hist)
+        throw LogicError(LogicError::no_history);
+
+    bool hist_updated = do_advance_read(observer, version_id, *hist); // Throws
+    repl->initiate_transact(Replication::TransactionType::trans_Read, version_id.version, hist_updated);
+}
+
+template <class O>
+inline void SharedGroup::promote_to_write(O* observer)
+{
+    if (m_transact_stage != transact_Reading)
+        throw LogicError(LogicError::wrong_transact_state);
+
+    _impl::History* hist = get_history(); // Throws
+    if (!hist)
+        throw LogicError(LogicError::no_history);
+
+    do_begin_write(); // Throws
+    try {
+        VersionID version = VersionID();                                  // Latest
+        bool history_updated = do_advance_read(observer, version, *hist); // Throws
+
+        Replication* repl = m_group.get_replication();
+        REALM_ASSERT(repl); // Presence of `repl` follows from the presence of `hist`
+        version_type current_version = m_read_lock.m_version;
+        repl->initiate_transact(Replication::TransactionType::trans_Write, current_version,
+                                history_updated); // Throws
+
+        // If the group has no top array (top_ref == 0), create a new node
+        // structure for an empty group now, to be ready for modifications. See
+        // also Group::attach_shared().
+        using gf = _impl::GroupFriend;
+        gf::create_empty_group_when_missing(m_group); // Throws
+    }
+    catch (...) {
+        do_end_write();
+        throw;
+    }
+
+    set_transact_stage(transact_Writing);
+}
+
+template <class O>
+inline void SharedGroup::rollback_and_continue_as_read(O* observer)
+{
+    if (m_transact_stage != transact_Writing)
+        throw LogicError(LogicError::wrong_transact_state);
+
+    _impl::History* hist = get_history(); // Throws
+    if (!hist)
+        throw LogicError(LogicError::no_history);
+
+    BinaryData uncommitted_changes = hist->get_uncommitted_changes();
+
+    // FIXME: We are currently creating two transaction log parsers, one here,
+    // and one in advance_transact(). That is wasteful as the parser creation is
+    // expensive.
+    _impl::SimpleInputStream in(uncommitted_changes.data(), uncommitted_changes.size());
+    _impl::TransactLogParser parser; // Throws
+    _impl::TransactReverser reverser;
+    parser.parse(in, reverser); // Throws
+
+    if (observer && uncommitted_changes.size()) {
+        _impl::ReversedNoCopyInputStream reversed_in(reverser);
+        parser.parse(reversed_in, *observer); // Throws
+        observer->parse_complete();           // Throws
+    }
+
+    // Mark all managed space (beyond the attached file) as free.
+    using gf = _impl::GroupFriend;
+    gf::reset_free_space_tracking(m_group); // Throws
+
+    ref_type top_ref = m_read_lock.m_top_ref;
+    size_t file_size = m_read_lock.m_file_size;
+    _impl::ReversedNoCopyInputStream reversed_in(reverser);
+    gf::advance_transact(m_group, top_ref, file_size, reversed_in); // Throws
+
+    do_end_write();
+
+    Replication* repl = gf::get_replication(m_group);
+    REALM_ASSERT(repl); // Presence of `repl` follows from the presence of `hist`
+    repl->abort_transact();
+
+    set_transact_stage(transact_Reading);
+}
+
+template <class O>
+inline bool SharedGroup::do_advance_read(O* observer, VersionID version_id, _impl::History& hist)
+{
+    ReadLockInfo new_read_lock;
+    grab_read_lock(new_read_lock, version_id); // Throws
+    REALM_ASSERT(new_read_lock.m_version >= m_read_lock.m_version);
+    if (new_read_lock.m_version == m_read_lock.m_version) {
+        release_read_lock(new_read_lock);
+        // _impl::History::update_from_ref() was not called
+        return false;
+    }
+
+    ReadLockUnlockGuard g(*this, new_read_lock);
+    {
+        version_type new_version = new_read_lock.m_version;
+        size_t new_file_size = new_read_lock.m_file_size;
+
+        // Synchronize readers view of the file
+        SlabAlloc& alloc = m_group.m_alloc;
+        alloc.update_reader_view(new_file_size);
+
+        ref_type hist_ref = _impl::GroupFriend::get_history_ref(alloc, new_read_lock.m_top_ref);
+        hist.update_from_ref_and_version(hist_ref, new_version); // Throws
+    }
+
+    if (observer) {
+        // This has to happen in the context of the originally bound snapshot
+        // and while the read transaction is still in a fully functional state.
+        _impl::TransactLogParser parser;
+        version_type old_version = m_read_lock.m_version;
+        version_type new_version = new_read_lock.m_version;
+        _impl::ChangesetInputStream in(hist, old_version, new_version);
+        parser.parse(in, *observer); // Throws
+        observer->parse_complete();  // Throws
+    }
+
+    // The old read lock must be retained for as long as the change history is
+    // accessed (until Group::advance_transact() returns). This ensures that the
+    // oldest needed changeset remains in the history, even when the history is
+    // implemented as a separate unversioned entity outside the Realm (i.e., the
+    // old implementation and ShortCircuitHistory in
+    // test_lang_Bind_helper.cpp). On the other hand, if it had been the case,
+    // that the history was always implemented as a versioned entity, that was
+    // part of the Realm state, then it would not have been necessary to retain
+    // the old read lock beyond this point.
+
+    {
+        version_type old_version = m_read_lock.m_version;
+        version_type new_version = new_read_lock.m_version;
+        ref_type new_top_ref = new_read_lock.m_top_ref;
+        size_t new_file_size = new_read_lock.m_file_size;
+        _impl::ChangesetInputStream in(hist, old_version, new_version);
+        m_group.advance_transact(new_top_ref, new_file_size, in); // Throws
+    }
+
+    g.release();
+    release_read_lock(m_read_lock);
+    m_read_lock = new_read_lock;
+
+    return true; // _impl::History::update_early_from_top_ref() was called
+}
+
+inline _impl::History* SharedGroup::get_history()
+{
+    using gf = _impl::GroupFriend;
+    if (Replication* repl = gf::get_replication(m_group))
+        return repl->get_history();
+    return 0;
+}
+
+inline int SharedGroup::get_file_format_version() const noexcept
+{
+    using gf = _impl::GroupFriend;
+    return gf::get_file_format_version(m_group);
+}
+
+
+// The purpose of this class is to give internal access to some, but
+// not all of the non-public parts of the SharedGroup class.
+class _impl::SharedGroupFriend {
+public:
+    static Group& get_group(SharedGroup& sg) noexcept
+    {
+        return sg.m_group;
+    }
+
+    template <class O>
+    static void advance_read(SharedGroup& sg, O* obs, SharedGroup::VersionID ver)
+    {
+        sg.advance_read(obs, ver); // Throws
+    }
+
+    template <class O>
+    static void promote_to_write(SharedGroup& sg, O* obs)
+    {
+        sg.promote_to_write(obs); // Throws
+    }
+
+    static SharedGroup::version_type commit_and_continue_as_read(SharedGroup& sg)
+    {
+        return sg.commit_and_continue_as_read(); // Throws
+    }
+
+    template <class O>
+    static void rollback_and_continue_as_read(SharedGroup& sg, O* obs)
+    {
+        sg.rollback_and_continue_as_read(obs); // Throws
+    }
+
+    static void async_daemon_open(SharedGroup& sg, const std::string& file)
+    {
+        bool no_create = true;
+        bool is_backend = true;
+        SharedGroupOptions options;
+        options.durability = SharedGroupOptions::Durability::Async;
+        options.encryption_key = nullptr;
+        options.allow_file_format_upgrade = false;
+        sg.do_open(file, no_create, is_backend, options); // Throws
+    }
+
+    static int get_file_format_version(const SharedGroup& sg) noexcept
+    {
+        return sg.get_file_format_version();
+    }
+
+    static SharedGroup::version_type get_version_of_latest_snapshot(SharedGroup& sg)
+    {
+        return sg.get_version_of_latest_snapshot();
+    }
+
+    static SharedGroup::version_type get_version_of_bound_snapshot(const SharedGroup& sg) noexcept
+    {
+        return sg.get_version_of_bound_snapshot();
+    }
+};
+
+inline const Group& ReadTransaction::get_group() const noexcept
+{
+    using sgf = _impl::SharedGroupFriend;
+    return sgf::get_group(m_shared_group);
+}
+
+inline SharedGroup::version_type ReadTransaction::get_version() const noexcept
+{
+    using sgf = _impl::SharedGroupFriend;
+    return sgf::get_version_of_bound_snapshot(m_shared_group);
+}
+
+inline Group& WriteTransaction::get_group() const noexcept
+{
+    REALM_ASSERT(m_shared_group);
+    using sgf = _impl::SharedGroupFriend;
+    return sgf::get_group(*m_shared_group);
+}
+
+inline SharedGroup::version_type WriteTransaction::get_version() const noexcept
+{
+    using sgf = _impl::SharedGroupFriend;
+    return sgf::get_version_of_bound_snapshot(*m_shared_group);
+}
+
+} // namespace realm
+
+#endif // REALM_GROUP_SHARED_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/group_shared_options.hpp b/node_modules/realm/vendor/realm-ios/include/realm/group_shared_options.hpp
new file mode 100644
index 0000000..73f7d3e
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/group_shared_options.hpp
@@ -0,0 +1,118 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_GROUP_SHARED_OPTIONS_HPP
+#define REALM_GROUP_SHARED_OPTIONS_HPP
+
+#include <functional>
+#include <string>
+
+namespace realm {
+
+struct SharedGroupOptions {
+
+    /// The persistence level of the SharedGroup.
+    /// uint16_t is the type of SharedGroup::SharedInfo::durability
+    enum class Durability : uint16_t {
+        Full,
+        MemOnly,
+        Async, ///< Not yet supported on windows.
+        Unsafe  // If you use this, you loose ACID property
+    };
+
+    explicit SharedGroupOptions(Durability level = Durability::Full, const char* key = nullptr,
+                                bool allow_upgrade = true,
+                                std::function<void(int, int)> file_upgrade_callback = std::function<void(int, int)>(),
+                                std::string temp_directory = sys_tmp_dir, bool track_metrics = false,
+                                size_t metrics_history_size = 10000)
+        : durability(level)
+        , encryption_key(key)
+        , allow_file_format_upgrade(allow_upgrade)
+        , upgrade_callback(file_upgrade_callback)
+        , temp_dir(temp_directory)
+        , enable_metrics(track_metrics)
+        , metrics_buffer_size(metrics_history_size)
+
+    {
+    }
+
+    explicit SharedGroupOptions(const char* key)
+        : durability(Durability::Full)
+        , encryption_key(key)
+        , allow_file_format_upgrade(true)
+        , upgrade_callback(std::function<void(int, int)>())
+        , temp_dir(sys_tmp_dir)
+        , enable_metrics(false)
+        , metrics_buffer_size(10000)
+    {
+    }
+
+    /// The persistence level of the Realm file. See Durability.
+    Durability durability;
+
+    /// The key to encrypt and decrypt the Realm file with, or nullptr to
+    /// indicate that encryption should not be used.
+    const char* encryption_key;
+
+    /// If \a allow_file_format_upgrade is set to `true`, this function will
+    /// automatically upgrade the file format used in the specified Realm file
+    /// if necessary (and if it is possible). In order to prevent this, set \a
+    /// allow_upgrade to `false`.
+    ///
+    /// If \a allow_upgrade is set to `false`, only two outcomes are possible:
+    ///
+    /// - the specified Realm file is already using the latest file format, and
+    ///   can be used, or
+    ///
+    /// - the specified Realm file uses a deprecated file format, resulting a
+    ///   the throwing of FileFormatUpgradeRequired.
+    bool allow_file_format_upgrade;
+
+    /// Optionally allows a custom function to be called immediately after the
+    /// Realm file is upgraded. The two parameters in the function are the
+    /// previous version and the version just upgraded to, respectively.
+    /// If the callback function throws, the Realm file will safely abort the
+    /// upgrade (rollback the transaction) but the SharedGroup will not be opened.
+    std::function<void(int, int)> upgrade_callback;
+
+    /// A path to a directory where Realm can write temporary files or pipes to.
+    /// This string should include a trailing slash '/'.
+    std::string temp_dir;
+
+    /// Controls the feature of collecting various metrics to the SharedGroup.
+    /// A prerequisite is compiling with REALM_METRICS=ON.
+    bool enable_metrics;
+
+    /// The maximum number of entries stored by the metrics (if enabled). If this number
+    /// is exceeded without being consumed, only the most recent entries will be stored.
+    size_t metrics_buffer_size;
+
+    /// sys_tmp_dir will be used if the temp_dir is empty when creating SharedGroupOptions.
+    /// It must be writable and allowed to create pipe/fifo file on it.
+    /// set_sys_tmp_dir is not a thread-safe call and it is only supposed to be called once
+    //  when process starts.
+    static void set_sys_tmp_dir(const std::string& dir) noexcept { sys_tmp_dir = dir; }
+    static std::string get_sys_tmp_dir() noexcept { return sys_tmp_dir; }
+
+private:
+    static std::string sys_tmp_dir;
+};
+
+} // end namespace realm
+
+#endif // REALM_GROUP_SHARED_OPTIONS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/group_writer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/group_writer.hpp
new file mode 100644
index 0000000..5721a3e
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/group_writer.hpp
@@ -0,0 +1,202 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_GROUP_WRITER_HPP
+#define REALM_GROUP_WRITER_HPP
+
+#include <cstdint> // unint8_t etc
+#include <utility>
+#include <map>
+
+#include <realm/util/file.hpp>
+#include <realm/alloc.hpp>
+#include <realm/impl/array_writer.hpp>
+#include <realm/array_integer.hpp>
+#include <realm/group_shared_options.hpp>
+
+
+namespace realm {
+
+// Pre-declarations
+class Group;
+class SlabAlloc;
+
+
+/// This class is not supposed to be reused for multiple write sessions. In
+/// particular, do not reuse it in case any of the functions throw.
+///
+/// FIXME: Move this class to namespace realm::_impl and to subdir src/realm/impl.
+class GroupWriter : public _impl::ArrayWriterBase {
+public:
+    // For groups in transactional mode (Group::m_is_shared), this constructor
+    // must be called while a write transaction is in progress.
+    //
+    // The constructor adds free-space tracking information to the specified
+    // group, if it is not already present (4th and 5th entry in
+    // Group::m_top). If the specified group is in transactional mode
+    // (Group::m_is_shared), the constructor also adds version tracking
+    // information to the group, if it is not already present (6th and 7th entry
+    // in Group::m_top).
+    using Durability = SharedGroupOptions::Durability;
+    GroupWriter(Group&, Durability dura = Durability::Full);
+    ~GroupWriter();
+
+    void set_versions(uint64_t current, uint64_t read_lock) noexcept;
+
+    /// Write all changed array nodes into free space.
+    ///
+    /// Returns the new top ref. When in full durability mode, call
+    /// commit() with the returned top ref.
+    ref_type write_group();
+
+    /// Flush changes to physical medium, then write the new top ref
+    /// to the file header, then flush again. Pass the top ref
+    /// returned by write_group().
+    void commit(ref_type new_top_ref);
+
+    size_t get_file_size() const noexcept;
+
+    ref_type write_array(const char*, size_t, uint32_t) override;
+
+#ifdef REALM_DEBUG
+    void dump();
+#endif
+
+    size_t get_free_space_size() const
+    {
+        return m_free_space_size;
+    }
+
+    size_t get_locked_space_size() const
+    {
+        return m_locked_space_size;
+    }
+
+private:
+    class MapWindow;
+    Group& m_group;
+    SlabAlloc& m_alloc;
+    ArrayInteger m_free_positions; // 4th slot in Group::m_top
+    ArrayInteger m_free_lengths;   // 5th slot in Group::m_top
+    ArrayInteger m_free_versions;  // 6th slot in Group::m_top
+    uint64_t m_current_version = 0;
+    uint64_t m_readlock_version;
+    size_t m_window_alignment;
+    size_t m_free_space_size = 0;
+    size_t m_locked_space_size = 0;
+    Durability m_durability;
+
+    struct FreeSpaceEntry {
+        FreeSpaceEntry(size_t r, size_t s, uint64_t v)
+            : ref(r)
+            , size(s)
+            , released_at_version(v)
+        {
+        }
+        size_t ref;
+        size_t size;
+        uint64_t released_at_version;
+    };
+    class FreeList : public std::vector<FreeSpaceEntry> {
+    public:
+        FreeList() = default;
+        // Merge adjacent chunks
+        void merge_adjacent_entries_in_freelist();
+        // Copy free space entries to structure where entries are sorted by size
+        void move_free_in_file_to_size_map(std::multimap<size_t, size_t>& size_map);
+    };
+    //  m_free_in_file;
+    std::vector<FreeSpaceEntry> m_not_free_in_file;
+    std::multimap<size_t, size_t> m_size_map;
+    using FreeListElement = std::multimap<size_t, size_t>::iterator;
+
+    void read_in_freelist();
+    size_t recreate_freelist(size_t reserve_pos);
+    // Currently cached memory mappings. We keep as many as 16 1MB windows
+    // open for writing. The allocator will favor sequential allocation
+    // from a modest number of windows, depending upon fragmentation, so
+    // 16 windows should be more than enough. If more than 16 windows are
+    // needed, the least recently used is sync'ed and closed to make room
+    // for a new one. The windows are kept in MRU (most recently used) order.
+    const static int num_map_windows = 16;
+    std::vector<std::unique_ptr<MapWindow>> m_map_windows;
+
+    // Get a suitable memory mapping for later access:
+    // potentially adding it to the cache, potentially closing
+    // the least recently used and sync'ing it to disk
+    MapWindow* get_window(ref_type start_ref, size_t size);
+
+    // Sync all cached memory mappings
+    void sync_all_mappings();
+
+    /// Allocate a chunk of free space of the specified size. The
+    /// specified size must be 8-byte aligned. Extend the file if
+    /// required. The returned chunk is removed from the amount of
+    /// remaing free space. The returned chunk is guaranteed to be
+    /// within a single contiguous memory mapping.
+    ///
+    /// \return The position within the database file of the allocated
+    /// chunk.
+    size_t get_free_space(size_t size);
+
+    /// Find a block of free space that is at least as big as the
+    /// specified size and which will allow an allocation that is mapped
+    /// inside a contiguous address range. The specified size does not
+    /// need to be 8-byte aligned. Extend the file if required.
+    /// The returned chunk is not removed from the amount of remaing
+    /// free space.
+    ///
+    /// \return A pair (`chunk_ndx`, `chunk_size`) where `chunk_ndx`
+    /// is the index of a chunk whose size is at least the requestd
+    /// size, and `chunk_size` is the size of that chunk.
+    FreeListElement reserve_free_space(size_t size);
+
+    FreeListElement search_free_space_in_free_list_element(FreeListElement element, size_t size);
+
+    /// Search only a range of the free list for a block as big as the
+    /// specified size. Return a pair with index and size of the found chunk.
+    /// \param found indicates whether a suitable block was found.
+    FreeListElement search_free_space_in_part_of_freelist(size_t size);
+
+    /// Extend the file to ensure that a chunk of free space of the
+    /// specified size is available. The specified size does not need
+    /// to be 8-byte aligned. This function guarantees that it will
+    /// add at most one entry to the free-lists.
+    ///
+    /// \return A pair (`chunk_ndx`, `chunk_size`) where `chunk_ndx`
+    /// is the index of a chunk whose size is at least the requestd
+    /// size, and `chunk_size` is the size of that chunk.
+    FreeListElement extend_free_space(size_t requested_size);
+
+    void write_array_at(MapWindow* window, ref_type, const char* data, size_t size);
+    FreeListElement split_freelist_chunk(FreeListElement, size_t alloc_pos);
+};
+
+
+// Implementation:
+
+inline void GroupWriter::set_versions(uint64_t current, uint64_t read_lock) noexcept
+{
+    REALM_ASSERT(read_lock <= current);
+    m_current_version = current;
+    m_readlock_version = read_lock;
+}
+
+} // namespace realm
+
+#endif // REALM_GROUP_WRITER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/handover_defs.hpp b/node_modules/realm/vendor/realm-ios/include/realm/handover_defs.hpp
new file mode 100644
index 0000000..cd8be27
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/handover_defs.hpp
@@ -0,0 +1,105 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_HANDOVER_DEFS
+#define REALM_HANDOVER_DEFS
+
+#include <memory>
+#include <vector>
+
+namespace realm {
+
+enum class ConstSourcePayload { Copy, Stay };
+enum class MutableSourcePayload { Move };
+
+struct RowBaseHandoverPatch;
+struct TableViewHandoverPatch;
+
+struct TableHandoverPatch {
+    bool m_is_sub_table;
+    size_t m_table_num;
+    size_t m_col_ndx;
+    size_t m_row_ndx;
+};
+
+struct LinkViewHandoverPatch {
+    std::unique_ptr<TableHandoverPatch> m_table;
+    size_t m_col_num;
+    size_t m_row_ndx;
+};
+
+// Base class for handover patches for query nodes. Subclasses are declared in query_engine.hpp.
+struct QueryNodeHandoverPatch {
+    virtual ~QueryNodeHandoverPatch() = default;
+};
+
+using QueryNodeHandoverPatches = std::vector<std::unique_ptr<QueryNodeHandoverPatch>>;
+
+struct QueryHandoverPatch {
+    std::unique_ptr<TableHandoverPatch> m_table;
+    std::unique_ptr<TableViewHandoverPatch> table_view_data;
+    std::unique_ptr<LinkViewHandoverPatch> link_view_data;
+    QueryNodeHandoverPatches m_node_data;
+};
+
+enum class DescriptorType { Sort, Distinct, Limit, Include };
+
+struct DescriptorLinkPath {
+    DescriptorLinkPath(size_t column_index, size_t table_index, bool column_is_backlink)
+        : col_ndx(column_index)
+        , table_ndx(table_index)
+        , is_backlink(column_is_backlink)
+    {
+    }
+
+    size_t col_ndx;
+    size_t table_ndx;
+    bool is_backlink = false;
+};
+
+struct DescriptorExport {
+    DescriptorType type;
+    std::vector<std::vector<DescriptorLinkPath>> columns;
+    std::vector<bool> ordering;
+    size_t limit;
+};
+
+struct DescriptorOrderingHandoverPatch {
+    std::vector<DescriptorExport> descriptors;
+};
+
+struct TableViewHandoverPatch {
+    std::unique_ptr<TableHandoverPatch> m_table;
+    std::unique_ptr<RowBaseHandoverPatch> linked_row;
+    size_t linked_col;
+    bool was_in_sync;
+    QueryHandoverPatch query_patch;
+    std::unique_ptr<LinkViewHandoverPatch> linkview_patch;
+    std::unique_ptr<DescriptorOrderingHandoverPatch> descriptors_patch;
+};
+
+
+struct RowBaseHandoverPatch {
+    std::unique_ptr<TableHandoverPatch> m_table;
+    size_t row_ndx;
+};
+
+
+} // end namespace Realm
+
+#endif
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/history.hpp b/node_modules/realm/vendor/realm-ios/include/realm/history.hpp
new file mode 100644
index 0000000..9710d0b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/history.hpp
@@ -0,0 +1,35 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_HISTORY_HPP
+#define REALM_HISTORY_HPP
+
+#include <memory>
+#include <string>
+
+#include <realm/replication.hpp>
+
+
+namespace realm {
+
+std::unique_ptr<Replication> make_in_realm_history(const std::string& realm_path);
+
+} // namespace realm
+
+
+#endif // REALM_HISTORY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/array_writer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/array_writer.hpp
new file mode 100644
index 0000000..f039ad5
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/array_writer.hpp
@@ -0,0 +1,44 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ARRAY_WRITER_HPP
+#define REALM_ARRAY_WRITER_HPP
+
+#include <realm/alloc.hpp>
+
+namespace realm {
+namespace _impl {
+
+class ArrayWriterBase {
+public:
+    virtual ~ArrayWriterBase()
+    {
+    }
+
+    /// Write the specified array data and its checksum into free
+    /// space.
+    ///
+    /// Returns the ref (position in the target stream) of the written copy of
+    /// the specified array data.
+    virtual ref_type write_array(const char* data, size_t size, uint32_t checksum) = 0;
+};
+
+} // namespace impl_
+} // namespace realm
+
+#endif // REALM_ARRAY_WRITER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/clamped_hex_dump.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/clamped_hex_dump.hpp
new file mode 100644
index 0000000..353e546
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/clamped_hex_dump.hpp
@@ -0,0 +1,49 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_CLAMPED_HEX_DUMP_HPP
+#define REALM_IMPL_CLAMPED_HEX_DUMP_HPP
+
+#include <realm/util/hex_dump.hpp>
+#include <realm/binary_data.hpp>
+
+namespace realm {
+namespace _impl {
+
+/// Limit the amount of dumped data to 1024 bytes. For use in connection with
+/// logging.
+inline std::string clamped_hex_dump(BinaryData blob, std::size_t max_size = 1024)
+{
+    bool was_clipped = false;
+    std::size_t size_2 = blob.size();
+    if (size_2 > max_size) {
+        size_2 = max_size;
+        was_clipped = true;
+    }
+    std::string str = util::hex_dump(blob.data(), size_2); // Throws
+    if (was_clipped)
+        str += "..."; // Throws
+    return str;
+}
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_CLAMPED_HEX_DUMP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/clock.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/clock.hpp
new file mode 100644
index 0000000..fdf8aa3
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/clock.hpp
@@ -0,0 +1,54 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_CLOCK_HPP
+#define REALM_IMPL_CLOCK_HPP
+
+#include <cstdint>
+#include <chrono>
+
+#include <realm/sync/protocol.hpp>
+
+namespace realm {
+namespace _impl {
+
+inline sync::milliseconds_type realtime_clock_now() noexcept
+{
+    using clock = std::chrono::system_clock;
+    auto time_since_epoch = clock::now().time_since_epoch();
+    auto millis_since_epoch =
+        std::chrono::duration_cast<std::chrono::milliseconds>(time_since_epoch).count();
+    return sync::milliseconds_type(millis_since_epoch);
+}
+
+
+inline sync::milliseconds_type monotonic_clock_now() noexcept
+{
+    using clock = std::chrono::steady_clock;
+    auto time_since_epoch = clock::now().time_since_epoch();
+    auto millis_since_epoch =
+        std::chrono::duration_cast<std::chrono::milliseconds>(time_since_epoch).count();
+    return sync::milliseconds_type(millis_since_epoch);
+}
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_CLOCK_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/cont_transact_hist.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/cont_transact_hist.hpp
new file mode 100644
index 0000000..deb0f8b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/cont_transact_hist.hpp
@@ -0,0 +1,147 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_CONT_TRANSACT_HIST_HPP
+#define REALM_IMPL_CONT_TRANSACT_HIST_HPP
+
+#include <cstdint>
+#include <memory>
+
+#include <realm/column_binary.hpp>
+#include <realm/version_id.hpp>
+
+namespace realm {
+
+class Group;
+
+namespace _impl {
+
+/// Read-only access to history of changesets as needed to enable continuous
+/// transactions.
+class History {
+public:
+    using version_type = VersionID::version_type;
+
+    virtual ~History() noexcept {}
+
+    /// May be called during any transaction
+    ///
+    /// It is a precondition for calls to this function that the reader view is
+    /// updated - that is, the mapping is updated to provide full visibility to
+    /// the file.
+    ///
+    virtual void update_from_ref_and_version(ref_type ref, version_type version) = 0;
+    virtual void update_from_parent(version_type version) = 0;
+
+    /// Get all changesets between the specified versions. References to those
+    /// changesets will be made available in successive entries of `buffer`. The
+    /// number of retrieved changesets is exactly `end_version -
+    /// begin_version`. If this number is greater than zero, the changeset made
+    /// available in `buffer[0]` is the one that brought the database from
+    /// `begin_version` to `begin_version + 1`.
+    ///
+    /// It is an error to specify a version (for \a begin_version or \a
+    /// end_version) that is outside the range [V,W] where V is the version that
+    /// immediately precedes the first changeset available in the history as the
+    /// history appears in the **latest** available snapshot, and W is the
+    /// version that immediately succeeds the last changeset available in the
+    /// history as the history appears in the snapshot bound to the **current**
+    /// transaction. This restriction is necessary to allow for different kinds
+    /// of implementations of the history (separate standalone history or
+    /// history as part of versioned Realm state).
+    ///
+    /// The callee retains ownership of the memory referenced by those entries,
+    /// i.e., the memory referenced by `buffer[i].changeset` is **not** handed
+    /// over to the caller.
+    ///
+    /// This function may be called only during a transaction (prior to
+    /// initiation of commit operation), and only after a successful invocation
+    /// of update_early_from_top_ref(). In that case, the caller may assume that
+    /// the memory references stay valid for the remainder of the transaction
+    /// (up until initiation of the commit operation).
+    virtual void get_changesets(version_type begin_version, version_type end_version, BinaryIterator* buffer) const
+        noexcept = 0;
+
+    /// \brief Specify the version of the oldest bound snapshot.
+    ///
+    /// This function must be called by the associated SharedGroup object during
+    /// each successfully committed write transaction. It must be called before
+    /// the transaction is finalized (Replication::finalize_commit()) or aborted
+    /// (Replication::abort_transact()), but after the initiation of the commit
+    /// operation (Replication::prepare_commit()). This allows history
+    /// implementations to add new history entries before trimming off old ones,
+    /// and this, in turn, guarantees that the history never becomes empty,
+    /// except in the initial empty Realm state.
+    ///
+    /// The caller must pass the version (\a version) of the oldest snapshot
+    /// that is currently (or was recently) bound via a transaction of the
+    /// current session. This gives the history implementation an opportunity to
+    /// trim off leading (early) history entries.
+    ///
+    /// Since this function must be called during a write transaction, there
+    /// will always be at least one snapshot that is currently bound via a
+    /// transaction.
+    ///
+    /// The caller must guarantee that the passed version (\a version) is less
+    /// than or equal to `begin_version` in all future invocations of
+    /// get_changesets().
+    ///
+    /// The caller is allowed to pass a version that is less than the version
+    /// passed in a preceding invocation.
+    ///
+    /// This function should be called as late as possible, to maximize the
+    /// trimming opportunity, but at a time where the write transaction is still
+    /// open for additional modifications. This is necessary because some types
+    /// of histories are stored inside the Realm file.
+    virtual void set_oldest_bound_version(version_type version) = 0;
+
+    /// Get the list of uncommitted changes accumulated so far in the current
+    /// write transaction.
+    ///
+    /// The callee retains ownership of the referenced memory. The ownership is
+    /// not handed over to the caller.
+    ///
+    /// This function may be called only during a write transaction (prior to
+    /// initiation of commit operation). In that case, the caller may assume that the
+    /// returned memory reference stays valid for the remainder of the transaction (up
+    /// until initiation of the commit operation).
+    virtual BinaryData get_uncommitted_changes() noexcept = 0;
+
+    virtual void verify() const = 0;
+
+    void set_updated(bool updated)
+    {
+        m_updated = updated;
+    }
+
+    void ensure_updated(version_type version) const
+    {
+        if (!m_updated) {
+            const_cast<History*>(this)->update_from_parent(version);
+            m_updated = true;
+        }
+    }
+
+private:
+    mutable bool m_updated = false;
+};
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_CONTINUOUS_TRANSACTIONS_HISTORY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/destroy_guard.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/destroy_guard.hpp
new file mode 100644
index 0000000..f5b5e37
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/destroy_guard.hpp
@@ -0,0 +1,237 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_DESTROY_GUARD_HPP
+#define REALM_IMPL_DESTROY_GUARD_HPP
+
+#include <realm/util/features.h>
+#include <realm/array.hpp>
+
+namespace realm {
+namespace _impl {
+
+
+/// Calls `ptr->destroy()` if the guarded pointer (`ptr`) is not null
+/// when the guard is destroyed. For arrays (`T` = `Array`) this means
+/// that the array is destroyed in a shallow fashion. See
+/// `DeepArrayDestroyGuard` for an alternative.
+template <class T>
+class DestroyGuard {
+public:
+    DestroyGuard() noexcept;
+
+    DestroyGuard(T*) noexcept;
+
+    ~DestroyGuard() noexcept;
+
+    // Default implementations of copy/assign can trigger multiple destructions
+    DestroyGuard(const DestroyGuard&) = delete;
+    DestroyGuard& operator=(const DestroyGuard&) = delete;
+
+    void reset(T*) noexcept;
+
+    T* get() const noexcept;
+
+    T* release() noexcept;
+
+private:
+    T* m_ptr;
+};
+
+using ShallowArrayDestroyGuard = DestroyGuard<Array>;
+
+
+/// Calls `ptr->destroy_deep()` if the guarded Array pointer (`ptr`)
+/// is not null when the guard is destroyed.
+class DeepArrayDestroyGuard {
+public:
+    DeepArrayDestroyGuard() noexcept;
+
+    DeepArrayDestroyGuard(Array*) noexcept;
+
+    ~DeepArrayDestroyGuard() noexcept;
+
+    // Default implementations of copy/assign can trigger multiple destructions
+    DeepArrayDestroyGuard(const DeepArrayDestroyGuard&) = delete;
+    DeepArrayDestroyGuard& operator=(const DeepArrayDestroyGuard&) = delete;
+
+    void reset(Array*) noexcept;
+
+    Array* get() const noexcept;
+
+    Array* release() noexcept;
+
+private:
+    Array* m_ptr;
+};
+
+
+/// Calls `Array::destroy_deep(ref, alloc)` if the guarded 'ref'
+/// (`ref`) is not zero when the guard is destroyed.
+class DeepArrayRefDestroyGuard {
+public:
+    DeepArrayRefDestroyGuard(Allocator&) noexcept;
+
+    DeepArrayRefDestroyGuard(ref_type, Allocator&) noexcept;
+
+    ~DeepArrayRefDestroyGuard() noexcept;
+
+    // Default implementations of copy/assign can trigger multiple destructions
+    DeepArrayRefDestroyGuard(const DeepArrayRefDestroyGuard&) = delete;
+    DeepArrayRefDestroyGuard& operator=(const DeepArrayRefDestroyGuard&) = delete;
+
+    void reset(ref_type) noexcept;
+
+    ref_type get() const noexcept;
+
+    ref_type release() noexcept;
+
+private:
+    ref_type m_ref;
+    Allocator& m_alloc;
+};
+
+
+// Implementation:
+
+// DestroyGuard<T>
+
+template <class T>
+inline DestroyGuard<T>::DestroyGuard() noexcept
+    : m_ptr(nullptr)
+{
+}
+
+template <class T>
+inline DestroyGuard<T>::DestroyGuard(T* ptr) noexcept
+    : m_ptr(ptr)
+{
+}
+
+template <class T>
+inline DestroyGuard<T>::~DestroyGuard() noexcept
+{
+    if (m_ptr)
+        m_ptr->destroy();
+}
+
+template <class T>
+inline void DestroyGuard<T>::reset(T* ptr) noexcept
+{
+    if (m_ptr)
+        m_ptr->destroy();
+    m_ptr = ptr;
+}
+
+template <class T>
+inline T* DestroyGuard<T>::get() const noexcept
+{
+    return m_ptr;
+}
+
+template <class T>
+inline T* DestroyGuard<T>::release() noexcept
+{
+    T* ptr = m_ptr;
+    m_ptr = nullptr;
+    return ptr;
+}
+
+
+// DeepArrayDestroyGuard
+
+inline DeepArrayDestroyGuard::DeepArrayDestroyGuard() noexcept
+    : m_ptr(nullptr)
+{
+}
+
+inline DeepArrayDestroyGuard::DeepArrayDestroyGuard(Array* ptr) noexcept
+    : m_ptr(ptr)
+{
+}
+
+inline DeepArrayDestroyGuard::~DeepArrayDestroyGuard() noexcept
+{
+    if (m_ptr)
+        m_ptr->destroy_deep();
+}
+
+inline void DeepArrayDestroyGuard::reset(Array* ptr) noexcept
+{
+    if (m_ptr)
+        m_ptr->destroy_deep();
+    m_ptr = ptr;
+}
+
+inline Array* DeepArrayDestroyGuard::get() const noexcept
+{
+    return m_ptr;
+}
+
+inline Array* DeepArrayDestroyGuard::release() noexcept
+{
+    Array* ptr = m_ptr;
+    m_ptr = nullptr;
+    return ptr;
+}
+
+
+// DeepArrayRefDestroyGuard
+
+inline DeepArrayRefDestroyGuard::DeepArrayRefDestroyGuard(Allocator& alloc) noexcept
+    : m_ref(0)
+    , m_alloc(alloc)
+{
+}
+
+inline DeepArrayRefDestroyGuard::DeepArrayRefDestroyGuard(ref_type ref, Allocator& alloc) noexcept
+    : m_ref(ref)
+    , m_alloc(alloc)
+{
+}
+
+inline DeepArrayRefDestroyGuard::~DeepArrayRefDestroyGuard() noexcept
+{
+    if (m_ref)
+        Array::destroy_deep(m_ref, m_alloc);
+}
+
+inline void DeepArrayRefDestroyGuard::reset(ref_type ref) noexcept
+{
+    if (m_ref)
+        Array::destroy_deep(m_ref, m_alloc);
+    m_ref = ref;
+}
+
+inline ref_type DeepArrayRefDestroyGuard::get() const noexcept
+{
+    return m_ref;
+}
+
+inline ref_type DeepArrayRefDestroyGuard::release() noexcept
+{
+    ref_type ref = m_ref;
+    m_ref = 0;
+    return ref;
+}
+
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_DESTROY_GUARD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/input_stream.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/input_stream.hpp
new file mode 100644
index 0000000..80db30a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/input_stream.hpp
@@ -0,0 +1,255 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_INPUT_STREAM_HPP
+#define REALM_IMPL_INPUT_STREAM_HPP
+
+#include <algorithm>
+
+#include <realm/binary_data.hpp>
+#include <realm/impl/cont_transact_hist.hpp>
+#include <realm/util/buffer.hpp>
+
+
+namespace realm {
+namespace _impl {
+
+
+class InputStream {
+public:
+    /// Read bytes from this input stream and place them in the specified
+    /// buffer. The returned value is the actual number of bytes that were read,
+    /// and this is some number `n` such that `n <= min(size, m)` where `m` is
+    /// the number of bytes that could have been read from this stream before
+    /// reaching its end. Also, `n` cannot be zero unless `m` or `size` is
+    /// zero. The intention is that `size` should be non-zero, a the return
+    /// value used as the end-of-input indicator.
+    ///
+    /// Implementations are only allowed to block (put the calling thread to
+    /// sleep) up until the point in time where the first byte can be made
+    /// availble.
+    virtual size_t read(char* buffer, size_t size) = 0;
+
+    virtual ~InputStream() noexcept
+    {
+    }
+};
+
+
+class SimpleInputStream : public InputStream {
+public:
+    SimpleInputStream(const char* data, size_t size) noexcept
+        : m_ptr(data)
+        , m_end(data + size)
+    {
+    }
+    size_t read(char* buffer, size_t size) override
+    {
+        size_t n = std::min(size, size_t(m_end - m_ptr));
+        const char* begin = m_ptr;
+        m_ptr += n;
+        realm::safe_copy_n(begin, n, buffer);
+        return n;
+    }
+
+private:
+    const char* m_ptr;
+    const char* const m_end;
+};
+
+
+class NoCopyInputStream {
+public:
+    /// \return if any bytes was read.
+    /// A value of false indicates end-of-input.
+    /// If return value is true, \a begin and \a end are
+    /// updated to reflect the start and limit of a
+    /// contiguous memory chunk.
+    virtual bool next_block(const char*& begin, const char*& end) = 0;
+
+    virtual ~NoCopyInputStream() noexcept
+    {
+    }
+};
+
+
+class NoCopyInputStreamAdaptor : public NoCopyInputStream {
+public:
+    NoCopyInputStreamAdaptor(InputStream& in, char* buffer, size_t buffer_size) noexcept
+        : m_in(in)
+        , m_buffer(buffer)
+        , m_buffer_size(buffer_size)
+    {
+    }
+    bool next_block(const char*& begin, const char*& end) override
+    {
+        size_t n = m_in.read(m_buffer, m_buffer_size);
+        begin = m_buffer;
+        end = m_buffer + n;
+        return n;
+    }
+
+private:
+    InputStream& m_in;
+    char* m_buffer;
+    size_t m_buffer_size;
+};
+
+
+class SimpleNoCopyInputStream : public NoCopyInputStream {
+public:
+    SimpleNoCopyInputStream(const char* data, size_t size)
+        : m_data(data)
+        , m_size(size)
+    {
+    }
+
+    bool next_block(const char*& begin, const char*& end) override
+    {
+        if (m_size == 0)
+            return 0;
+        size_t size = m_size;
+        begin = m_data;
+        end = m_data + size;
+        m_size = 0;
+        return size;
+    }
+
+private:
+    const char* m_data;
+    size_t m_size;
+};
+
+class MultiLogNoCopyInputStream : public NoCopyInputStream {
+public:
+    MultiLogNoCopyInputStream(const BinaryData* logs_begin, const BinaryData* logs_end)
+        : m_logs_begin(logs_begin)
+        , m_logs_end(logs_end)
+    {
+        if (m_logs_begin != m_logs_end)
+            m_curr_buf_remaining_size = m_logs_begin->size();
+    }
+
+    size_t read(char* buffer, size_t size)
+    {
+        if (m_logs_begin == m_logs_end)
+            return 0;
+        for (;;) {
+            if (m_curr_buf_remaining_size > 0) {
+                size_t offset = m_logs_begin->size() - m_curr_buf_remaining_size;
+                const char* data = m_logs_begin->data() + offset;
+                size_t size_2 = std::min(m_curr_buf_remaining_size, size);
+                m_curr_buf_remaining_size -= size_2;
+                // FIXME: Eliminate the need for copying by changing the API of
+                // Replication::InputStream such that blocks can be handed over
+                // without copying. This is a straight forward change, but the
+                // result is going to be more complicated and less conventional.
+                realm::safe_copy_n(data, size_2, buffer);
+                return size_2;
+            }
+
+            ++m_logs_begin;
+            if (m_logs_begin == m_logs_end)
+                return 0;
+            m_curr_buf_remaining_size = m_logs_begin->size();
+        }
+    }
+
+    bool next_block(const char*& begin, const char*& end) override
+    {
+        while (m_logs_begin < m_logs_end) {
+            size_t result = m_logs_begin->size();
+            const char* data = m_logs_begin->data();
+            m_logs_begin++;
+            if (result == 0)
+                continue; // skip empty blocks
+            begin = data;
+            end = data + result;
+            return result;
+        }
+        return 0;
+    }
+
+private:
+    const BinaryData* m_logs_begin;
+    const BinaryData* m_logs_end;
+    size_t m_curr_buf_remaining_size;
+};
+
+
+class ChangesetInputStream : public NoCopyInputStream {
+public:
+    using version_type = History::version_type;
+    static constexpr unsigned NB_BUFFERS = 8;
+
+    ChangesetInputStream(History& hist, version_type begin_version, version_type end_version)
+        : m_history(hist)
+        , m_begin_version(begin_version)
+        , m_end_version(end_version)
+    {
+        get_changeset();
+    }
+
+    bool next_block(const char*& begin, const char*& end) override
+    {
+        while (m_valid) {
+            BinaryData actual = m_changesets_begin->get_next();
+
+            if (actual.size() > 0) {
+                begin = actual.data();
+                end = actual.data() + actual.size();
+                return true;
+            }
+
+            m_changesets_begin++;
+
+            if (REALM_UNLIKELY(m_changesets_begin == m_changesets_end)) {
+                get_changeset();
+            }
+        }
+        return false; // End of input
+    }
+
+private:
+    History& m_history;
+    version_type m_begin_version, m_end_version;
+    BinaryIterator m_changesets[NB_BUFFERS]; // Buffer
+    BinaryIterator* m_changesets_begin = nullptr;
+    BinaryIterator* m_changesets_end = nullptr;
+    bool m_valid;
+
+    void get_changeset()
+    {
+        auto versions_to_get = m_end_version - m_begin_version;
+        m_valid = versions_to_get > 0;
+        if (m_valid) {
+            if (versions_to_get > NB_BUFFERS)
+                versions_to_get = NB_BUFFERS;
+            version_type end_version = m_begin_version + versions_to_get;
+            m_history.get_changesets(m_begin_version, end_version, m_changesets);
+            m_begin_version = end_version;
+            m_changesets_begin = m_changesets;
+            m_changesets_end = m_changesets_begin + versions_to_get;
+        }
+    }
+};
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_INPUT_STREAM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/output_stream.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/output_stream.hpp
new file mode 100644
index 0000000..1d022cd
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/output_stream.hpp
@@ -0,0 +1,75 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_OUTPUT_STREAM_HPP
+#define REALM_IMPL_OUTPUT_STREAM_HPP
+
+#include <cstddef>
+#include <ostream>
+
+#include <cstdint>
+
+#include <realm/util/features.h>
+
+#include <realm/impl/array_writer.hpp>
+
+namespace realm {
+namespace _impl {
+
+
+class OutputStream : public ArrayWriterBase {
+public:
+    OutputStream(std::ostream&);
+    ~OutputStream() noexcept;
+
+    ref_type get_ref_of_next_array() const noexcept;
+
+    void write(const char* data, size_t size);
+
+    ref_type write_array(const char* data, size_t size, uint32_t checksum) override;
+
+private:
+    ref_type m_next_ref;
+    std::ostream& m_out;
+
+    void do_write(const char* data, size_t size);
+};
+
+
+// Implementation:
+
+inline OutputStream::OutputStream(std::ostream& out)
+    : m_next_ref(0)
+    , m_out(out)
+{
+}
+
+inline OutputStream::~OutputStream() noexcept
+{
+}
+
+inline size_t OutputStream::get_ref_of_next_array() const noexcept
+{
+    return m_next_ref;
+}
+
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_OUTPUT_STREAM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/sequential_getter.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/sequential_getter.hpp
new file mode 100644
index 0000000..c7dd866
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/sequential_getter.hpp
@@ -0,0 +1,130 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_SEQUENTIAL_GETTER_HPP
+#define REALM_IMPL_SEQUENTIAL_GETTER_HPP
+
+namespace realm {
+
+class SequentialGetterBase {
+public:
+    virtual ~SequentialGetterBase() noexcept
+    {
+    }
+};
+
+template <class ColType>
+class SequentialGetter : public SequentialGetterBase {
+public:
+    using T = typename ColType::value_type;
+    using ArrayType = typename ColType::LeafType;
+
+    SequentialGetter()
+    {
+    }
+
+    SequentialGetter(const Table& table, size_t column_ndx)
+    {
+        init(static_cast<const ColType*>(&table.get_column_base(column_ndx)));
+    }
+
+    SequentialGetter(const ColType* column)
+    {
+        init(column);
+    }
+
+    ~SequentialGetter() noexcept override
+    {
+    }
+
+    void init(const ColType* column)
+    {
+        REALM_ASSERT(column != nullptr);
+        m_array_ptr.reset(); // Explicitly destroy the old one first, because we're reusing the memory.
+        m_array_ptr.reset(new (&m_leaf_accessor_storage) ArrayType(column->get_alloc()));
+        m_column = column;
+        m_leaf_end = 0;
+    }
+
+    REALM_FORCEINLINE bool cache_next(size_t index)
+    {
+        // Set m_leaf_ptr to point at the leaf that contains the value at column row `index`. Return whether or not
+        // the leaf has changed (could be useful to know for caller).
+
+        // FIXME: Below line has been commented away because array leafs might relocate during the lifetime of the
+        // object that owns this SequentialGetter. Enable again when we have proper support for that.
+        //        if (index >= m_leaf_end || index < m_leaf_start)
+        {
+            typename ColType::LeafInfo leaf{&m_leaf_ptr, m_array_ptr.get()};
+            size_t ndx_in_leaf;
+            m_column->get_leaf(index, ndx_in_leaf, leaf);
+            m_leaf_start = index - ndx_in_leaf;
+            const size_t leaf_size = m_leaf_ptr->size();
+            m_leaf_end = m_leaf_start + leaf_size;
+            return true;
+        }
+        return false;
+    }
+
+
+    REALM_FORCEINLINE T get_next(size_t index)
+    {
+#ifdef _MSC_VER
+#pragma warning(push)
+#pragma warning(disable : 4800) // Disable the Microsoft warning about bool performance issue.
+#endif
+        return m_column->get(index);
+
+        // FIXME: Below optimization is skipped because array leafs might relocate during the lifetime of the
+        // object that owns this SequentialGetter. Enable again when we have proper support for that.
+//
+//      cache_next(index);
+//      T av = m_leaf_ptr->get(index - m_leaf_start);
+//      return av;
+
+#ifdef _MSC_VER
+#pragma warning(pop)
+#endif
+    }
+
+    size_t local_end(size_t global_end)
+    {
+        if (global_end > m_leaf_end)
+            return m_leaf_end - m_leaf_start;
+        else
+            return global_end - m_leaf_start;
+    }
+
+    size_t m_leaf_start = 0;
+    size_t m_leaf_end = 0;
+    const ColType* m_column = nullptr;
+
+    const ArrayType* m_leaf_ptr = nullptr;
+
+private:
+    // Leaf cache for when the root of the column is not a leaf.
+    // This dog and pony show is because Array has a reference to Allocator internally,
+    // but we need to be able to transfer queries between contexts, so init() reinitializes
+    // the leaf cache in the context of the current column.
+    typename std::aligned_storage<sizeof(ArrayType), alignof(ArrayType)>::type m_leaf_accessor_storage;
+    std::unique_ptr<ArrayType, PlacementDelete> m_array_ptr;
+};
+
+} // namespace realm
+
+#endif // REALM_IMPL_SEQUENTIAL_GETTER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/simulated_failure.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/simulated_failure.hpp
new file mode 100644
index 0000000..4958151
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/simulated_failure.hpp
@@ -0,0 +1,228 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_SIMULATED_FAILURE_HPP
+#define REALM_IMPL_SIMULATED_FAILURE_HPP
+
+#include <cstdint>
+#include <system_error>
+
+#include <realm/util/features.h>
+
+#ifdef REALM_DEBUG
+#define REALM_ENABLE_SIMULATED_FAILURE
+#endif
+
+namespace realm {
+namespace _impl {
+
+class SimulatedFailure : public std::system_error {
+public:
+    enum FailureType {
+        generic,
+        slab_alloc__reset_free_space_tracking,
+        slab_alloc__remap,
+        shared_group__grow_reader_mapping,
+        sync_client__read_head,
+        sync_server__read_head,
+        _num_failure_types
+    };
+
+    class OneShotPrimeGuard;
+    class RandomPrimeGuard;
+
+    /// Prime the specified failure type on the calling thread for triggering
+    /// once.
+    static void prime_one_shot(FailureType);
+
+    /// Prime the specified failure type on the calling thread for triggering
+    /// randomly \a n out of \a m times.
+    static void prime_random(FailureType, int n, int m, uint_fast64_t seed = 0);
+
+    /// Unprime the specified failure type on the calling thread.
+    static void unprime(FailureType) noexcept;
+
+    /// Returns true according to the mode of priming of the specified failure
+    /// type on the calling thread, but only if REALM_ENABLE_SIMULATED_FAILURE
+    /// was defined during compilation. If REALM_ENABLE_SIMULATED_FAILURE was
+    /// not defined, this function always return false.
+    static bool check_trigger(FailureType) noexcept;
+
+    /// The specified error code is set to `make_error_code(failure_type)` if
+    /// check_trigger() returns true. Otherwise it is set to
+    /// `std::error_code()`. Returns a copy of the updated error code.
+    static std::error_code trigger(FailureType failure_type, std::error_code&) noexcept;
+
+    /// Throws SimulatedFailure if check_trigger() returns true. The exception
+    /// will be constructed with an error code equal to
+    /// `make_error_code(failure_type)`.
+    static void trigger(FailureType failure_type);
+
+    /// Returns true when, and only when REALM_ENABLE_SIMULATED_FAILURE was
+    /// defined during compilation.
+    static constexpr bool is_enabled();
+
+    SimulatedFailure(std::error_code);
+
+private:
+#ifdef REALM_ENABLE_SIMULATED_FAILURE
+    static void do_prime_one_shot(FailureType);
+    static void do_prime_random(FailureType, int n, int m, uint_fast64_t seed);
+    static void do_unprime(FailureType) noexcept;
+    static bool do_check_trigger(FailureType) noexcept;
+#endif
+};
+
+std::error_code make_error_code(SimulatedFailure::FailureType) noexcept;
+    
+class SimulatedFailure::OneShotPrimeGuard {
+public:
+    OneShotPrimeGuard(FailureType);
+    ~OneShotPrimeGuard() noexcept;
+
+private:
+    const FailureType m_type;
+};
+
+
+class SimulatedFailure::RandomPrimeGuard {
+public:
+    RandomPrimeGuard(FailureType, int n, int m, uint_fast64_t seed = 0);
+    ~RandomPrimeGuard() noexcept;
+
+private:
+    const FailureType m_type;
+};
+
+std::error_code make_error_code(SimulatedFailure::FailureType) noexcept;
+
+} // namespace _impl
+} // namespace realm
+
+namespace std {
+
+template<> struct is_error_code_enum<realm::_impl::SimulatedFailure::FailureType> {
+    static const bool value = true;
+};
+
+} // namespace std
+
+namespace realm {
+namespace _impl {
+
+
+// Implementation
+
+inline void SimulatedFailure::prime_one_shot(FailureType failure_type)
+{
+#ifdef REALM_ENABLE_SIMULATED_FAILURE
+    do_prime_one_shot(failure_type);
+#else
+    static_cast<void>(failure_type);
+#endif
+}
+
+inline void SimulatedFailure::prime_random(FailureType failure_type, int n, int m, uint_fast64_t seed)
+{
+#ifdef REALM_ENABLE_SIMULATED_FAILURE
+    do_prime_random(failure_type, n, m, seed);
+#else
+    static_cast<void>(failure_type);
+    static_cast<void>(n);
+    static_cast<void>(m);
+    static_cast<void>(seed);
+#endif
+}
+
+inline void SimulatedFailure::unprime(FailureType failure_type) noexcept
+{
+#ifdef REALM_ENABLE_SIMULATED_FAILURE
+    do_unprime(failure_type);
+#else
+    static_cast<void>(failure_type);
+#endif
+}
+
+inline bool SimulatedFailure::check_trigger(FailureType failure_type) noexcept
+{
+#ifdef REALM_ENABLE_SIMULATED_FAILURE
+    return do_check_trigger(failure_type);
+#else
+    static_cast<void>(failure_type);
+    return false;
+#endif
+}
+
+inline std::error_code SimulatedFailure::trigger(FailureType failure_type, std::error_code& ec) noexcept
+{
+    if (check_trigger(failure_type)) {
+        ec = make_error_code(failure_type);
+    }
+    else {
+        ec = std::error_code();
+    }
+    return ec;
+}
+
+inline void SimulatedFailure::trigger(FailureType failure_type)
+{
+    if (check_trigger(failure_type))
+        throw SimulatedFailure(make_error_code(failure_type));
+}
+
+inline constexpr bool SimulatedFailure::is_enabled()
+{
+#ifdef REALM_ENABLE_SIMULATED_FAILURE
+    return true;
+#else
+    return false;
+#endif
+}
+
+inline SimulatedFailure::SimulatedFailure(std::error_code ec)
+    : std::system_error(ec)
+{
+}
+
+inline SimulatedFailure::OneShotPrimeGuard::OneShotPrimeGuard(FailureType failure_type)
+    : m_type(failure_type)
+{
+    prime_one_shot(m_type);
+}
+
+inline SimulatedFailure::OneShotPrimeGuard::~OneShotPrimeGuard() noexcept
+{
+    unprime(m_type);
+}
+
+inline SimulatedFailure::RandomPrimeGuard::RandomPrimeGuard(FailureType failure_type, int n, int m,
+                                                            uint_fast64_t seed)
+    : m_type(failure_type)
+{
+    prime_random(m_type, n, m, seed);
+}
+
+inline SimulatedFailure::RandomPrimeGuard::~RandomPrimeGuard() noexcept
+{
+    unprime(m_type);
+}
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_SIMULATED_FAILURE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/impl/transact_log.hpp b/node_modules/realm/vendor/realm-ios/include/realm/impl/transact_log.hpp
new file mode 100644
index 0000000..edace6c
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/impl/transact_log.hpp
@@ -0,0 +1,2808 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_TRANSACT_LOG_HPP
+#define REALM_IMPL_TRANSACT_LOG_HPP
+
+#include <stdexcept>
+
+#include <realm/string_data.hpp>
+#include <realm/data_type.hpp>
+#include <realm/binary_data.hpp>
+#include <realm/olddatetime.hpp>
+#include <realm/mixed.hpp>
+#include <realm/util/buffer.hpp>
+#include <realm/util/string_buffer.hpp>
+#include <realm/impl/input_stream.hpp>
+
+#include <realm/group.hpp>
+#include <realm/descriptor.hpp>
+#include <realm/link_view.hpp>
+
+namespace realm {
+namespace _impl {
+
+/// Transaction log instruction encoding
+/// NOTE: Any change to this enum is a file-format breaking change.
+enum Instruction {
+    instr_InsertGroupLevelTable = 1,
+    instr_EraseGroupLevelTable = 2, // Remove columnless table from group
+    instr_RenameGroupLevelTable = 3,
+    instr_MoveGroupLevelTable = 4, // UNSUPPORTED/UNUSED. FIXME: remove in next breaking change
+    instr_SelectTable = 5,
+    instr_Set = 6,
+    instr_SetUnique = 7,
+    instr_SetDefault = 8,
+    instr_AddInteger = 9,   // Add value to integer field
+    instr_NullifyLink = 10, // Set link to null due to target being erased
+    instr_InsertSubstring = 11,
+    instr_EraseFromString = 12,
+    instr_InsertEmptyRows = 13,
+    instr_EraseRows = 14, // Remove (multiple) rows
+    instr_SwapRows = 15,
+    instr_MoveRow = 16,
+    instr_MergeRows = 17,  // Replace links pointing to row A with links to row B
+    instr_ClearTable = 18, // Remove all rows in selected table
+    instr_OptimizeTable = 19,
+    instr_SelectDescriptor = 20, // Select descriptor from currently selected root table
+    instr_InsertColumn =
+        21, // Insert new non-nullable column into to selected descriptor (nullable is instr_InsertNullableColumn)
+    instr_InsertLinkColumn = 22,     // do, but for a link-type column
+    instr_InsertNullableColumn = 23, // Insert nullable column
+    instr_EraseColumn = 24,          // Remove column from selected descriptor
+    instr_EraseLinkColumn = 25,      // Remove link-type column from selected descriptor
+    instr_RenameColumn = 26,         // Rename column in selected descriptor
+    instr_MoveColumn = 27,           // Move column in selected descriptor (UNSUPPORTED/UNUSED) FIXME: remove
+    instr_AddSearchIndex = 28,       // Add a search index to a column
+    instr_RemoveSearchIndex = 29,    // Remove a search index from a column
+    instr_SetLinkType = 30,          // Strong/weak
+    instr_SelectLinkList = 31,
+    instr_LinkListSet = 32,     // Assign to link list entry
+    instr_LinkListInsert = 33,  // Insert entry into link list
+    instr_LinkListMove = 34,    // Move an entry within a link list
+    instr_LinkListSwap = 35,    // Swap two entries within a link list
+    instr_LinkListErase = 36,   // Remove an entry from a link list
+    instr_LinkListNullify = 37, // Remove an entry from a link list due to linked row being erased
+    instr_LinkListClear = 38,   // Ramove all entries from a link list
+    instr_LinkListSetAll = 39,  // Assign to link list entry
+    instr_AddRowWithKey = 40,   // Insert a row with a given key
+};
+
+class TransactLogStream {
+public:
+    /// Ensure contiguous free space in the transaction log
+    /// buffer. This method must update `out_free_begin`
+    /// and `out_free_end` such that they refer to a chunk
+    /// of free space whose size is at least \a n.
+    ///
+    /// \param n The required amount of contiguous free space. Must be
+    /// small (probably not greater than 1024)
+    /// \param n Must be small (probably not greater than 1024)
+    virtual void transact_log_reserve(size_t size, char** out_free_begin, char** out_free_end) = 0;
+
+    /// Copy the specified data into the transaction log buffer. This
+    /// function should be called only when the specified data does
+    /// not fit inside the chunk of free space currently referred to
+    /// by `out_free_begin` and `out_free_end`.
+    ///
+    /// This method must update `out_begin` and
+    /// `out_end` such that, upon return, they still
+    /// refer to a (possibly empty) chunk of free space.
+    virtual void transact_log_append(const char* data, size_t size, char** out_free_begin, char** out_free_end) = 0;
+};
+
+class TransactLogBufferStream : public TransactLogStream {
+public:
+    void transact_log_reserve(size_t size, char** out_free_begin, char** out_free_end) override;
+    void transact_log_append(const char* data, size_t size, char** out_free_begin, char** out_free_end) override;
+
+    const char* transact_log_data() const;
+
+    util::Buffer<char> m_buffer;
+};
+
+
+// LCOV_EXCL_START (because the NullInstructionObserver is trivial)
+class NullInstructionObserver {
+public:
+    /// The following methods are also those that TransactLogParser expects
+    /// to find on the `InstructionHandler`.
+
+    // No selection needed:
+    bool select_table(size_t, size_t, const size_t*)
+    {
+        return true;
+    }
+    bool select_descriptor(size_t, const size_t*)
+    {
+        return true;
+    }
+    bool select_link_list(size_t, size_t, size_t)
+    {
+        return true;
+    }
+    bool insert_group_level_table(size_t, size_t, StringData)
+    {
+        return true;
+    }
+    bool erase_group_level_table(size_t, size_t)
+    {
+        return true;
+    }
+    bool rename_group_level_table(size_t, StringData)
+    {
+        return true;
+    }
+
+    // Must have table selected:
+    bool insert_empty_rows(size_t, size_t, size_t, bool)
+    {
+        return true;
+    }
+    bool add_row_with_key(size_t, size_t, size_t, int64_t)
+    {
+        return true;
+    }
+    bool erase_rows(size_t, size_t, size_t, bool)
+    {
+        return true;
+    }
+    bool swap_rows(size_t, size_t)
+    {
+        return true;
+    }
+    bool move_row(size_t, size_t)
+    {
+        return true;
+    }
+    bool merge_rows(size_t, size_t)
+    {
+        return true;
+    }
+    bool clear_table(size_t)
+    {
+        return true;
+    }
+    bool set_int(size_t, size_t, int_fast64_t, Instruction, size_t)
+    {
+        return true;
+    }
+    bool add_int(size_t, size_t, int_fast64_t)
+    {
+        return true;
+    }
+    bool set_bool(size_t, size_t, bool, Instruction)
+    {
+        return true;
+    }
+    bool set_float(size_t, size_t, float, Instruction)
+    {
+        return true;
+    }
+    bool set_double(size_t, size_t, double, Instruction)
+    {
+        return true;
+    }
+    bool set_string(size_t, size_t, StringData, Instruction, size_t)
+    {
+        return true;
+    }
+    bool set_binary(size_t, size_t, BinaryData, Instruction)
+    {
+        return true;
+    }
+    bool set_olddatetime(size_t, size_t, OldDateTime, Instruction)
+    {
+        return true;
+    }
+    bool set_timestamp(size_t, size_t, Timestamp, Instruction)
+    {
+        return true;
+    }
+    bool set_table(size_t, size_t, Instruction)
+    {
+        return true;
+    }
+    bool set_mixed(size_t, size_t, const Mixed&, Instruction)
+    {
+        return true;
+    }
+    bool set_link(size_t, size_t, size_t, size_t, Instruction)
+    {
+        return true;
+    }
+    bool set_null(size_t, size_t, Instruction, size_t)
+    {
+        return true;
+    }
+    bool nullify_link(size_t, size_t, size_t)
+    {
+        return true;
+    }
+    bool insert_substring(size_t, size_t, size_t, StringData)
+    {
+        return true;
+    }
+    bool erase_substring(size_t, size_t, size_t, size_t)
+    {
+        return true;
+    }
+    bool optimize_table()
+    {
+        return true;
+    }
+
+    // Must have descriptor selected:
+    bool insert_link_column(size_t, DataType, StringData, size_t, size_t)
+    {
+        return true;
+    }
+    bool insert_column(size_t, DataType, StringData, bool)
+    {
+        return true;
+    }
+    bool erase_link_column(size_t, size_t, size_t)
+    {
+        return true;
+    }
+    bool erase_column(size_t)
+    {
+        return true;
+    }
+    bool rename_column(size_t, StringData)
+    {
+        return true;
+    }
+    bool add_search_index(size_t)
+    {
+        return true;
+    }
+    bool remove_search_index(size_t)
+    {
+        return true;
+    }
+    bool set_link_type(size_t, LinkType)
+    {
+        return true;
+    }
+
+    // Must have linklist selected:
+    bool link_list_set(size_t, size_t, size_t)
+    {
+        return true;
+    }
+    bool link_list_insert(size_t, size_t, size_t)
+    {
+        return true;
+    }
+    bool link_list_move(size_t, size_t)
+    {
+        return true;
+    }
+    bool link_list_swap(size_t, size_t)
+    {
+        return true;
+    }
+    bool link_list_erase(size_t, size_t)
+    {
+        return true;
+    }
+    bool link_list_nullify(size_t, size_t)
+    {
+        return true;
+    }
+    bool link_list_clear(size_t)
+    {
+        return true;
+    }
+
+    void parse_complete()
+    {
+    }
+};
+// LCOV_EXCL_STOP (NullInstructionObserver)
+
+
+/// See TransactLogConvenientEncoder for information about the meaning of the
+/// arguments of each of the functions in this class.
+class TransactLogEncoder {
+public:
+    /// The following methods are also those that TransactLogParser expects
+    /// to find on the `InstructionHandler`.
+
+    // No selection needed:
+    bool select_table(size_t group_level_ndx, size_t levels, const size_t* path);
+    bool select_descriptor(size_t levels, const size_t* path);
+    bool select_link_list(size_t col_ndx, size_t row_ndx, size_t link_target_group_level_ndx);
+    bool insert_group_level_table(size_t table_ndx, size_t num_tables, StringData name);
+    bool erase_group_level_table(size_t table_ndx, size_t num_tables);
+    bool rename_group_level_table(size_t table_ndx, StringData new_name);
+
+    /// Must have table selected.
+    bool insert_empty_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows, bool unordered);
+    bool add_row_with_key(size_t row_ndx, size_t prior_num_rows, size_t key_col_ndx, int64_t key);
+    bool erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool unordered);
+    bool swap_rows(size_t row_ndx_1, size_t row_ndx_2);
+    bool move_row(size_t from_ndx, size_t to_ndx);
+    bool merge_rows(size_t row_ndx, size_t new_row_ndx);
+    bool clear_table(size_t old_table_size);
+
+    bool set_int(size_t col_ndx, size_t row_ndx, int_fast64_t, Instruction = instr_Set, size_t = 0);
+    bool add_int(size_t col_ndx, size_t row_ndx, int_fast64_t);
+    bool set_bool(size_t col_ndx, size_t row_ndx, bool, Instruction = instr_Set);
+    bool set_float(size_t col_ndx, size_t row_ndx, float, Instruction = instr_Set);
+    bool set_double(size_t col_ndx, size_t row_ndx, double, Instruction = instr_Set);
+    bool set_string(size_t col_ndx, size_t row_ndx, StringData, Instruction = instr_Set, size_t = 0);
+    bool set_binary(size_t col_ndx, size_t row_ndx, BinaryData, Instruction = instr_Set);
+    bool set_olddatetime(size_t col_ndx, size_t row_ndx, OldDateTime, Instruction = instr_Set);
+    bool set_timestamp(size_t col_ndx, size_t row_ndx, Timestamp, Instruction = instr_Set);
+    bool set_table(size_t col_ndx, size_t row_ndx, Instruction = instr_Set);
+    bool set_mixed(size_t col_ndx, size_t row_ndx, const Mixed&, Instruction = instr_Set);
+    bool set_link(size_t col_ndx, size_t row_ndx, size_t, size_t target_group_level_ndx, Instruction = instr_Set);
+    bool set_null(size_t col_ndx, size_t row_ndx, Instruction = instr_Set, size_t = 0);
+    bool nullify_link(size_t col_ndx, size_t row_ndx, size_t target_group_level_ndx);
+    bool insert_substring(size_t col_ndx, size_t row_ndx, size_t pos, StringData);
+    bool erase_substring(size_t col_ndx, size_t row_ndx, size_t pos, size_t size);
+    bool optimize_table();
+
+    // Must have descriptor selected:
+    bool insert_link_column(size_t col_ndx, DataType, StringData name, size_t link_target_table_ndx,
+                            size_t backlink_col_ndx);
+    bool insert_column(size_t col_ndx, DataType, StringData name, bool nullable = false);
+    bool erase_link_column(size_t col_ndx, size_t link_target_table_ndx, size_t backlink_col_ndx);
+    bool erase_column(size_t col_ndx);
+    bool rename_column(size_t col_ndx, StringData new_name);
+    bool add_search_index(size_t col_ndx);
+    bool remove_search_index(size_t col_ndx);
+    bool set_link_type(size_t col_ndx, LinkType);
+
+    // Must have linklist selected:
+    bool link_list_set(size_t link_ndx, size_t value, size_t prior_size);
+    bool link_list_set_all(const IntegerColumn& values);
+    bool link_list_insert(size_t link_ndx, size_t value, size_t prior_size);
+    bool link_list_move(size_t from_link_ndx, size_t to_link_ndx);
+    bool link_list_swap(size_t link1_ndx, size_t link2_ndx);
+    bool link_list_erase(size_t link_ndx, size_t prior_size);
+    bool link_list_nullify(size_t link_ndx, size_t prior_size);
+    bool link_list_clear(size_t old_list_size);
+
+    /// End of methods expected by parser.
+
+
+    TransactLogEncoder(TransactLogStream& out_stream);
+    void set_buffer(char* new_free_begin, char* new_free_end);
+    char* write_position() const
+    {
+        return m_transact_log_free_begin;
+    }
+
+private:
+    using IntegerList = std::tuple<IntegerColumnIterator, IntegerColumnIterator>;
+    using UnsignedList = std::tuple<const size_t*, const size_t*>;
+
+    // Make sure this is in agreement with the actual integer encoding
+    // scheme (see encode_int()).
+    static constexpr int max_enc_bytes_per_int = 10;
+    static constexpr int max_enc_bytes_per_double = sizeof(double);
+    static constexpr int max_enc_bytes_per_num =
+        max_enc_bytes_per_int < max_enc_bytes_per_double ? max_enc_bytes_per_double : max_enc_bytes_per_int;
+// Space is reserved in chunks to avoid excessive over allocation.
+#ifdef REALM_DEBUG
+    static constexpr int max_numbers_per_chunk = 2; // Increase the chance of chunking in debug mode
+#else
+    static constexpr int max_numbers_per_chunk = 8;
+#endif
+
+    // This value is used in Set* instructions in place of the 'type' field in
+    // the stream to indicate that the value of the Set* instruction is NULL,
+    // which doesn't have a type.
+    static constexpr int set_null_sentinel()
+    {
+        return -1;
+    }
+
+    TransactLogStream& m_stream;
+
+    // These two delimit a contiguous region of free space in a
+    // transaction log buffer following the last written data. It may
+    // be empty.
+    char* m_transact_log_free_begin = nullptr;
+    char* m_transact_log_free_end = nullptr;
+
+    char* reserve(size_t size);
+    /// \param ptr Must be in the range [m_transact_log_free_begin, m_transact_log_free_end]
+    void advance(char* ptr) noexcept;
+
+    template <class T>
+    size_t max_size(T);
+
+    size_t max_size_list()
+    {
+        return 0;
+    }
+
+    template <class T, class... Args>
+    size_t max_size_list(T val, Args... args)
+    {
+        return max_size(val) + max_size_list(args...);
+    }
+
+    template <class T>
+    char* encode(char* ptr, T value);
+
+    char* encode_list(char* ptr)
+    {
+        advance(ptr);
+        return ptr;
+    }
+
+    template <class T, class... Args>
+    char* encode_list(char* ptr, T value, Args... args)
+    {
+        return encode_list(encode(ptr, value), args...);
+    }
+
+    template <class... L>
+    void append_simple_instr(L... numbers);
+
+    template <class... L>
+    void append_mixed_instr(Instruction instr, const Mixed& value, L... numbers);
+
+    template <class T>
+    static char* encode_int(char*, T value);
+    friend class TransactLogParser;
+};
+
+class TransactLogConvenientEncoder {
+public:
+    virtual void insert_group_level_table(size_t table_ndx, size_t num_tables, StringData name);
+    virtual void erase_group_level_table(size_t table_ndx, size_t num_tables);
+    virtual void rename_group_level_table(size_t table_ndx, StringData new_name);
+    virtual void insert_column(const Descriptor&, size_t col_ndx, DataType type, StringData name, LinkTargetInfo& link,
+                               bool nullable = false);
+    virtual void erase_column(const Descriptor&, size_t col_ndx);
+    virtual void rename_column(const Descriptor&, size_t col_ndx, StringData name);
+
+    virtual void set_int(const Table*, size_t col_ndx, size_t ndx, int_fast64_t value, Instruction variant = instr_Set);
+    virtual void add_int(const Table*, size_t col_ndx, size_t ndx, int_fast64_t value);
+    virtual void set_bool(const Table*, size_t col_ndx, size_t ndx, bool value, Instruction variant = instr_Set);
+    virtual void set_float(const Table*, size_t col_ndx, size_t ndx, float value, Instruction variant = instr_Set);
+    virtual void set_double(const Table*, size_t col_ndx, size_t ndx, double value, Instruction variant = instr_Set);
+    virtual void set_string(const Table*, size_t col_ndx, size_t ndx, StringData value, Instruction variant = instr_Set);
+    virtual void set_binary(const Table*, size_t col_ndx, size_t ndx, BinaryData value, Instruction variant = instr_Set);
+    virtual void set_olddatetime(const Table*, size_t col_ndx, size_t ndx, OldDateTime value,
+                                 Instruction variant = instr_Set);
+    virtual void set_timestamp(const Table*, size_t col_ndx, size_t ndx, Timestamp value, Instruction variant = instr_Set);
+    virtual void set_table(const Table*, size_t col_ndx, size_t ndx, Instruction variant = instr_Set);
+    virtual void set_mixed(const Table*, size_t col_ndx, size_t ndx, const Mixed& value, Instruction variant = instr_Set);
+    virtual void set_link(const Table*, size_t col_ndx, size_t ndx, size_t value, Instruction variant = instr_Set);
+    virtual void set_null(const Table*, size_t col_ndx, size_t ndx, Instruction variant = instr_Set);
+    virtual void set_link_list(const LinkView&, const IntegerColumn& values);
+    virtual void insert_substring(const Table*, size_t col_ndx, size_t row_ndx, size_t pos, StringData);
+    virtual void erase_substring(const Table*, size_t col_ndx, size_t row_ndx, size_t pos, size_t size);
+
+    /// \param prior_num_rows The number of rows in the table prior to the
+    /// modification.
+    virtual void insert_empty_rows(const Table*, size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows);
+    virtual void add_row_with_key(const Table* t, size_t row_ndx, size_t prior_num_rows, size_t key_col_ndx,
+                                  int64_t key);
+
+    /// \param prior_num_rows The number of rows in the table prior to the
+    /// modification.
+    virtual void erase_rows(const Table*, size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows,
+                            bool is_move_last_over);
+
+    virtual void swap_rows(const Table*, size_t row_ndx_1, size_t row_ndx_2);
+    virtual void move_row(const Table*, size_t from_ndx, size_t to_ndx);
+    virtual void merge_rows(const Table*, size_t row_ndx, size_t new_row_ndx);
+    virtual void add_search_index(const Descriptor&, size_t col_ndx);
+    virtual void remove_search_index(const Descriptor&, size_t col_ndx);
+    virtual void set_link_type(const Table*, size_t col_ndx, LinkType);
+    virtual void clear_table(const Table*, size_t prior_num_rows);
+    virtual void optimize_table(const Table*);
+
+    virtual void link_list_set(const LinkView&, size_t link_ndx, size_t value);
+    virtual void link_list_insert(const LinkView&, size_t link_ndx, size_t value);
+    virtual void link_list_move(const LinkView&, size_t from_link_ndx, size_t to_link_ndx);
+    virtual void link_list_swap(const LinkView&, size_t link_ndx_1, size_t link_ndx_2);
+    virtual void link_list_erase(const LinkView&, size_t link_ndx);
+    virtual void link_list_clear(const LinkView&);
+
+    //@{
+
+    /// Implicit nullifications due to removal of target row. This is redundant
+    /// information from the point of view of replication, as the removal of the
+    /// target row will reproduce the implicit nullifications in the target
+    /// Realm anyway. The purpose of this instruction is to allow observers
+    /// (reactor pattern) to be explicitly notified about the implicit
+    /// nullifications.
+
+    virtual void nullify_link(const Table*, size_t col_ndx, size_t ndx);
+    virtual void link_list_nullify(const LinkView&, size_t link_ndx);
+
+    //@}
+
+    void on_table_destroyed(const Table*) noexcept;
+    void on_spec_destroyed(const Spec*) noexcept;
+    void on_link_list_destroyed(const LinkView&) noexcept;
+
+protected:
+    TransactLogConvenientEncoder(TransactLogStream& encoder);
+
+    void reset_selection_caches() noexcept;
+    void set_buffer(char* new_free_begin, char* new_free_end)
+    {
+        m_encoder.set_buffer(new_free_begin, new_free_end);
+    }
+    char* write_position() const
+    {
+        return m_encoder.write_position();
+    }
+
+private:
+    TransactLogEncoder m_encoder;
+    // These are mutable because they are caches.
+    mutable util::Buffer<size_t> m_subtab_path_buf;
+    mutable const Table* m_selected_table;
+    mutable const Spec* m_selected_spec;
+    // Has to be atomic to support concurrent reset when a linklist
+    // is unselected. This can happen on a different thread. In case
+    // of races, setting of a new value must win.
+    mutable std::atomic<const LinkView*> m_selected_link_list;
+
+    void unselect_all() noexcept;
+    void select_table(const Table*);        // unselects descriptor and link list
+    void select_desc(const Descriptor&);    // unselects link list
+    void select_link_list(const LinkView&); // unselects descriptor
+
+    void record_subtable_path(const Table&, size_t*& out_begin, size_t*& out_end);
+    void do_select_table(const Table*);
+    void do_select_desc(const Descriptor&);
+    void do_select_link_list(const LinkView&);
+
+    friend class TransactReverser;
+};
+
+
+class TransactLogParser {
+public:
+    class BadTransactLog; // Exception
+
+    TransactLogParser();
+    ~TransactLogParser() noexcept;
+
+    /// See `TransactLogEncoder` for a list of methods that the `InstructionHandler` must define.
+    /// parse() promises that the path passed by reference to
+    /// InstructionHandler::select_descriptor() will remain valid
+    /// during subsequent calls to all descriptor modifying functions.
+    template <class InstructionHandler>
+    void parse(InputStream&, InstructionHandler&);
+
+    template <class InstructionHandler>
+    void parse(NoCopyInputStream&, InstructionHandler&);
+
+private:
+    util::Buffer<char> m_input_buffer;
+
+    // The input stream is assumed to consist of chunks of memory organised such that
+    // every instruction resides in a single chunk only.
+    NoCopyInputStream* m_input;
+    // pointer into transaction log, each instruction is parsed from m_input_begin and onwards.
+    // Each instruction are assumed to be contiguous in memory.
+    const char* m_input_begin;
+    // pointer to one past current instruction log chunk. If m_input_begin reaches m_input_end,
+    // a call to next_input_buffer will move m_input_begin and m_input_end to a new chunk of
+    // memory. Setting m_input_end to 0 disables this check, and is used if it is already known
+    // that all of the instructions are in memory.
+    const char* m_input_end;
+    util::StringBuffer m_string_buffer;
+    static const int m_max_levels = 1024;
+    util::Buffer<size_t> m_path;
+
+    REALM_NORETURN void parser_error() const;
+
+    template <class InstructionHandler>
+    void parse_one(InstructionHandler&);
+    bool has_next() noexcept;
+
+    template <class T>
+    T read_int();
+
+    void read_bytes(char* data, size_t size);
+    BinaryData read_buffer(util::StringBuffer&, size_t size);
+
+    bool read_bool();
+    float read_float();
+    double read_double();
+
+    StringData read_string(util::StringBuffer&);
+    BinaryData read_binary(util::StringBuffer&);
+    Timestamp read_timestamp();
+    void read_mixed(Mixed*);
+
+    // Advance m_input_begin and m_input_end to reflect the next block of instructions
+    // Returns false if no more input was available
+    bool next_input_buffer();
+
+    // return true if input was available
+    bool read_char(char&); // throws
+
+    bool is_valid_data_type(int type);
+    bool is_valid_link_type(int type);
+};
+
+
+class TransactLogParser::BadTransactLog : public std::exception {
+public:
+    const char* what() const noexcept override
+    {
+        return "Bad transaction log";
+    }
+};
+
+
+/// Implementation:
+
+inline void TransactLogBufferStream::transact_log_reserve(size_t n, char** inout_new_begin, char** out_new_end)
+{
+    char* data = m_buffer.data();
+    REALM_ASSERT(*inout_new_begin >= data);
+    REALM_ASSERT(*inout_new_begin <= (data + m_buffer.size()));
+    size_t size = *inout_new_begin - data;
+    m_buffer.reserve_extra(size, n);
+    data = m_buffer.data(); // May have changed
+    *inout_new_begin = data + size;
+    *out_new_end = data + m_buffer.size();
+}
+
+inline void TransactLogBufferStream::transact_log_append(const char* data, size_t size, char** out_new_begin,
+                                                         char** out_new_end)
+{
+    transact_log_reserve(size, out_new_begin, out_new_end);
+    *out_new_begin = realm::safe_copy_n(data, size, *out_new_begin);
+}
+
+inline const char* TransactLogBufferStream::transact_log_data() const
+{
+    return m_buffer.data();
+}
+
+inline TransactLogEncoder::TransactLogEncoder(TransactLogStream& stream)
+    : m_stream(stream)
+{
+}
+
+inline void TransactLogEncoder::set_buffer(char* free_begin, char* free_end)
+{
+    REALM_ASSERT(free_begin <= free_end);
+    m_transact_log_free_begin = free_begin;
+    m_transact_log_free_end = free_end;
+}
+
+inline void TransactLogConvenientEncoder::reset_selection_caches() noexcept
+{
+    unselect_all();
+}
+
+inline char* TransactLogEncoder::reserve(size_t n)
+{
+    if (size_t(m_transact_log_free_end - m_transact_log_free_begin) < n) {
+        m_stream.transact_log_reserve(n, &m_transact_log_free_begin, &m_transact_log_free_end);
+    }
+    return m_transact_log_free_begin;
+}
+
+inline void TransactLogEncoder::advance(char* ptr) noexcept
+{
+    REALM_ASSERT_DEBUG(m_transact_log_free_begin <= ptr);
+    REALM_ASSERT_DEBUG(ptr <= m_transact_log_free_end);
+    m_transact_log_free_begin = ptr;
+}
+
+
+// The integer encoding is platform independent. Also, it does not
+// depend on the type of the specified integer. Integers of any type
+// can be encoded as long as the specified buffer is large enough (see
+// below). The decoding does not have to use the same type. Decoding
+// will fail if, and only if the encoded value falls outside the range
+// of the requested destination type.
+//
+// The encoding uses one or more bytes. It never uses more than 8 bits
+// per byte. The last byte in the sequence is the first one that has
+// its 8th bit set to zero.
+//
+// Consider a particular non-negative value V. Let W be the number of
+// bits needed to encode V using the trivial binary encoding of
+// integers. The total number of bytes produced is then
+// ceil((W+1)/7). The first byte holds the 7 least significant bits of
+// V. The last byte holds at most 6 bits of V including the most
+// significant one. The value of the first bit of the last byte is
+// always 2**((N-1)*7) where N is the total number of bytes.
+//
+// A negative value W is encoded by setting the sign bit to one and
+// then encoding the positive result of -(W+1) as described above. The
+// advantage of this representation is that it converts small negative
+// values to small positive values which require a small number of
+// bytes. This would not have been true for 2's complements
+// representation, for example. The sign bit is always stored as the
+// 7th bit of the last byte.
+//
+//               value bits    value + sign    max bytes
+//     --------------------------------------------------
+//     int8_t         7              8              2
+//     uint8_t        8              9              2
+//     int16_t       15             16              3
+//     uint16_t      16             17              3
+//     int32_t       31             32              5
+//     uint32_t      32             33              5
+//     int64_t       63             64             10
+//     uint64_t      64             65             10
+//
+template <class T>
+char* TransactLogEncoder::encode_int(char* ptr, T value)
+{
+    static_assert(std::numeric_limits<T>::is_integer, "Integer required");
+    bool negative = util::is_negative(value);
+    if (negative) {
+        // The following conversion is guaranteed by C++11 to never
+        // overflow (contrast this with "-value" which indeed could
+        // overflow). See C99+TC3 section 6.2.6.2 paragraph 2.
+        REALM_DIAG_PUSH();
+        REALM_DIAG_IGNORE_UNSIGNED_MINUS();
+        value = -(value + 1);
+        REALM_DIAG_POP();
+    }
+    // At this point 'value' is always a positive number. Also, small
+    // negative numbers have been converted to small positive numbers.
+    REALM_ASSERT(!util::is_negative(value));
+    // One sign bit plus number of value bits
+    const int num_bits = 1 + std::numeric_limits<T>::digits;
+    // Only the first 7 bits are available per byte. Had it not been
+    // for the fact that maximum guaranteed bit width of a char is 8,
+    // this value could have been increased to 15 (one less than the
+    // number of value bits in 'unsigned').
+    const int bits_per_byte = 7;
+    const int max_bytes = (num_bits + (bits_per_byte - 1)) / bits_per_byte;
+    static_assert(max_bytes <= max_enc_bytes_per_int, "Bad max_enc_bytes_per_int");
+    // An explicit constant maximum number of iterations is specified
+    // in the hope that it will help the optimizer (to do loop
+    // unrolling, for example).
+    typedef unsigned char uchar;
+    for (int i = 0; i < max_bytes; ++i) {
+        if (value >> (bits_per_byte - 1) == 0)
+            break;
+        *reinterpret_cast<uchar*>(ptr) = uchar((1U << bits_per_byte) | unsigned(value & ((1U << bits_per_byte) - 1)));
+        ++ptr;
+        value >>= bits_per_byte;
+    }
+    *reinterpret_cast<uchar*>(ptr) = uchar(negative ? (1U << (bits_per_byte - 1)) | unsigned(value) : value);
+    return ++ptr;
+}
+
+template <class T>
+char* TransactLogEncoder::encode(char* ptr, T value)
+{
+    auto value_2 = value + 0; // Perform integral promotion
+    return encode_int(ptr, value_2);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<char>(char* ptr, char value)
+{
+    // Write the char as-is without encoding.
+    *ptr++ = value;
+    return ptr;
+}
+
+template <>
+inline char* TransactLogEncoder::encode<Instruction>(char* ptr, Instruction inst)
+{
+    return encode<char>(ptr, inst);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<bool>(char* ptr, bool value)
+{
+    return encode<char>(ptr, value);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<float>(char* ptr, float value)
+{
+    static_assert(std::numeric_limits<float>::is_iec559 &&
+                      sizeof(float) * std::numeric_limits<unsigned char>::digits == 32,
+                  "Unsupported 'float' representation");
+    const char* val_ptr = reinterpret_cast<char*>(&value);
+    return realm::safe_copy_n(val_ptr, sizeof value, ptr);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<double>(char* ptr, double value)
+{
+    static_assert(std::numeric_limits<double>::is_iec559 &&
+                      sizeof(double) * std::numeric_limits<unsigned char>::digits == 64,
+                  "Unsupported 'double' representation");
+    const char* val_ptr = reinterpret_cast<char*>(&value);
+    return realm::safe_copy_n(val_ptr, sizeof value, ptr);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<DataType>(char* ptr, DataType type)
+{
+    return encode<char>(ptr, type);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<StringData>(char* ptr, StringData s)
+{
+    ptr = encode_int(ptr, s.size());
+    return std::copy_n(s.data(), s.size(), ptr);
+}
+
+template <>
+inline char* TransactLogEncoder::encode<TransactLogEncoder::IntegerList>(char* ptr,
+                                                                         TransactLogEncoder::IntegerList list)
+{
+    IntegerColumnIterator i = std::get<0>(list);
+    IntegerColumnIterator end = std::get<1>(list);
+
+    while (end - i > max_numbers_per_chunk) {
+        for (int j = 0; j < max_numbers_per_chunk; ++j)
+            ptr = encode_int(ptr, *i++);
+        advance(ptr);
+        size_t max_required_bytes_2 = max_enc_bytes_per_num * max_numbers_per_chunk;
+        ptr = reserve(max_required_bytes_2); // Throws
+    }
+
+    while (i != end)
+        ptr = encode_int(ptr, *i++);
+
+    return ptr;
+}
+
+template <>
+inline char* TransactLogEncoder::encode<TransactLogEncoder::UnsignedList>(char* ptr,
+                                                                          TransactLogEncoder::UnsignedList list)
+{
+    const size_t* i = std::get<0>(list);
+    const size_t* end = std::get<1>(list);
+
+    while (i != end)
+        ptr = encode_int(ptr, *i++);
+
+    return ptr;
+}
+
+template <class T>
+size_t TransactLogEncoder::max_size(T)
+{
+    return max_enc_bytes_per_num;
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size(char)
+{
+    return 1;
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size(bool)
+{
+    return 1;
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size(Instruction)
+{
+    return 1;
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size(DataType)
+{
+    return 1;
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size(StringData s)
+{
+    return max_enc_bytes_per_num + s.size();
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size<TransactLogEncoder::IntegerList>(IntegerList)
+{
+    // We only allocate space for 'max_numbers_per_chunk' at a time
+    return max_enc_bytes_per_num * max_numbers_per_chunk;
+}
+
+template <>
+inline size_t TransactLogEncoder::max_size<TransactLogEncoder::UnsignedList>(UnsignedList list)
+{
+    const size_t* begin = std::get<0>(list);
+    const size_t* end = std::get<1>(list);
+    // list contains (end - begin) elements
+    return max_enc_bytes_per_num * (end - begin);
+}
+
+template <class... L>
+void TransactLogEncoder::append_simple_instr(L... numbers)
+{
+    size_t max_required_bytes = max_size_list(numbers...);
+    char* ptr = reserve(max_required_bytes); // Throws
+    encode_list(ptr, numbers...);
+}
+
+template <class... L>
+void TransactLogEncoder::append_mixed_instr(Instruction instr, const Mixed& value, L... numbers)
+{
+    DataType type = value.get_type();
+    switch (type) {
+        case type_Int:
+            append_simple_instr(instr, numbers..., type, value.get_int()); // Throws
+            return;
+        case type_Bool:
+            append_simple_instr(instr, numbers..., type, value.get_bool()); // Throws
+            return;
+        case type_Float:
+            append_simple_instr(instr, numbers..., type, value.get_float()); // Throws
+            return;
+        case type_Double:
+            append_simple_instr(instr, numbers..., type, value.get_double()); // Throws
+            return;
+        case type_OldDateTime: {
+            auto value_2 = value.get_olddatetime().get_olddatetime();
+            append_simple_instr(instr, numbers..., type, value_2); // Throws
+            return;
+        }
+        case type_String: {
+            append_simple_instr(instr, numbers..., type, value.get_string()); // Throws
+            return;
+        }
+        case type_Binary: {
+            BinaryData value_2 = value.get_binary();
+            StringData value_3(value_2.data(), value_2.size());
+            append_simple_instr(instr, numbers..., type, value_3); // Throws
+            return;
+        }
+        case type_Timestamp: {
+            Timestamp ts = value.get_timestamp();
+            int64_t seconds = ts.get_seconds();
+            int32_t nano_seconds = ts.get_nanoseconds();
+            append_simple_instr(instr, numbers..., type, seconds, nano_seconds); // Throws
+            return;
+        }
+        case type_Table:
+            append_simple_instr(instr, numbers..., type); // Throws
+            return;
+        case type_Mixed:
+            // Mixed in mixed is not possible
+            REALM_TERMINATE("Mixed in Mixed not possible");
+        case type_Link:
+        case type_LinkList:
+            // FIXME: Need to handle new link types here.
+            REALM_TERMINATE("Link types in Mixed not supported.");
+    }
+    REALM_TERMINATE("Invalid Mixed.");
+}
+
+inline void TransactLogConvenientEncoder::unselect_all() noexcept
+{
+    m_selected_table = nullptr;
+    m_selected_spec = nullptr;
+    // no race with on_link_list_destroyed since both are setting to nullptr
+    m_selected_link_list = nullptr;
+}
+
+inline void TransactLogConvenientEncoder::select_table(const Table* table)
+{
+    if (table != m_selected_table)
+        do_select_table(table); // Throws
+    m_selected_spec = nullptr;
+    // no race with on_link_list_destroyed since both are setting to nullptr
+    m_selected_link_list = nullptr;
+}
+
+inline void TransactLogConvenientEncoder::select_desc(const Descriptor& desc)
+{
+    typedef _impl::DescriptorFriend df;
+    if (&df::get_spec(desc) != m_selected_spec)
+        do_select_desc(desc); // Throws
+    // no race with on_link_list_destroyed since both are setting to nullptr
+    m_selected_link_list = nullptr;
+}
+
+inline void TransactLogConvenientEncoder::select_link_list(const LinkView& list)
+{
+    // A race between this and a call to on_link_list_destroyed() must
+    // end up with m_selected_link_list pointing to the list argument given
+    // here. We assume that the list given to on_link_list_destroyed() can
+    // *never* be the same as the list argument given here. We resolve the
+    // race by a) always updating m_selected_link_list in do_select_link_list()
+    // and b) only atomically and conditionally updating it in
+    // on_link_list_destroyed().
+    if (&list != m_selected_link_list) {
+        do_select_link_list(list); // Throws
+    }
+    m_selected_spec = nullptr;
+}
+
+
+inline bool TransactLogEncoder::insert_group_level_table(size_t table_ndx, size_t prior_num_tables, StringData name)
+{
+    append_simple_instr(instr_InsertGroupLevelTable, table_ndx, prior_num_tables, name); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::insert_group_level_table(size_t table_ndx, size_t prior_num_tables,
+                                                                   StringData name)
+{
+    unselect_all();
+    m_encoder.insert_group_level_table(table_ndx, prior_num_tables, name); // Throws
+}
+
+inline bool TransactLogEncoder::erase_group_level_table(size_t table_ndx, size_t prior_num_tables)
+{
+    append_simple_instr(instr_EraseGroupLevelTable, table_ndx, prior_num_tables); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::erase_group_level_table(size_t table_ndx, size_t prior_num_tables)
+{
+    unselect_all();
+    m_encoder.erase_group_level_table(table_ndx, prior_num_tables); // Throws
+}
+
+inline bool TransactLogEncoder::rename_group_level_table(size_t table_ndx, StringData new_name)
+{
+    append_simple_instr(instr_RenameGroupLevelTable, table_ndx, new_name); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::rename_group_level_table(size_t table_ndx, StringData new_name)
+{
+    unselect_all();
+    m_encoder.rename_group_level_table(table_ndx, new_name); // Throws
+}
+
+inline bool TransactLogEncoder::insert_column(size_t col_ndx, DataType type, StringData name, bool nullable)
+{
+    Instruction instr = (nullable ? instr_InsertNullableColumn : instr_InsertColumn);
+    append_simple_instr(instr, col_ndx, type, name); // Throws
+    return true;
+}
+
+inline bool TransactLogEncoder::insert_link_column(size_t col_ndx, DataType type, StringData name,
+                                                   size_t link_target_table_ndx, size_t backlink_col_ndx)
+{
+    REALM_ASSERT(_impl::TableFriend::is_link_type(ColumnType(type)));
+    append_simple_instr(instr_InsertLinkColumn, col_ndx, type, link_target_table_ndx, backlink_col_ndx,
+                        name); // Throws
+    return true;
+}
+
+
+inline void TransactLogConvenientEncoder::insert_column(const Descriptor& desc, size_t col_ndx, DataType type,
+                                                        StringData name, LinkTargetInfo& link, bool nullable)
+{
+    select_desc(desc); // Throws
+    if (link.is_valid()) {
+        typedef _impl::TableFriend tf;
+        typedef _impl::DescriptorFriend df;
+        size_t target_table_ndx = link.m_target_table->get_index_in_group();
+        const Table& origin_table = df::get_root_table(desc);
+        REALM_ASSERT(origin_table.is_group_level());
+        const Spec& target_spec = tf::get_spec(*(link.m_target_table));
+        size_t origin_table_ndx = origin_table.get_index_in_group();
+        size_t backlink_col_ndx = target_spec.find_backlink_column(origin_table_ndx, col_ndx);
+        REALM_ASSERT_3(backlink_col_ndx, ==, link.m_backlink_col_ndx);
+        m_encoder.insert_link_column(col_ndx, type, name, target_table_ndx, backlink_col_ndx); // Throws
+    }
+    else {
+        m_encoder.insert_column(col_ndx, type, name, nullable); // Throws
+    }
+}
+
+inline bool TransactLogEncoder::erase_column(size_t col_ndx)
+{
+    append_simple_instr(instr_EraseColumn, col_ndx); // Throws
+    return true;
+}
+
+inline bool TransactLogEncoder::erase_link_column(size_t col_ndx, size_t link_target_table_ndx,
+                                                  size_t backlink_col_ndx)
+{
+    append_simple_instr(instr_EraseLinkColumn, col_ndx, link_target_table_ndx, backlink_col_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::erase_column(const Descriptor& desc, size_t col_ndx)
+{
+    select_desc(desc); // Throws
+
+    DataType type = desc.get_column_type(col_ndx);
+    typedef _impl::TableFriend tf;
+    if (!tf::is_link_type(ColumnType(type))) {
+        m_encoder.erase_column(col_ndx); // Throws
+    }
+    else { // it's a link column:
+        REALM_ASSERT(desc.is_root());
+        typedef _impl::DescriptorFriend df;
+        const Table& origin_table = df::get_root_table(desc);
+        REALM_ASSERT(origin_table.is_group_level());
+        const Table& target_table = *tf::get_link_target_table_accessor(origin_table, col_ndx);
+        size_t target_table_ndx = target_table.get_index_in_group();
+        const Spec& target_spec = tf::get_spec(target_table);
+        size_t origin_table_ndx = origin_table.get_index_in_group();
+        size_t backlink_col_ndx = target_spec.find_backlink_column(origin_table_ndx, col_ndx);
+        m_encoder.erase_link_column(col_ndx, target_table_ndx, backlink_col_ndx); // Throws
+    }
+}
+
+inline bool TransactLogEncoder::rename_column(size_t col_ndx, StringData new_name)
+{
+    append_simple_instr(instr_RenameColumn, col_ndx, new_name); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::rename_column(const Descriptor& desc, size_t col_ndx, StringData name)
+{
+    select_desc(desc);                      // Throws
+    m_encoder.rename_column(col_ndx, name); // Throws
+}
+
+
+inline bool TransactLogEncoder::set_int(size_t col_ndx, size_t ndx, int_fast64_t value, Instruction variant,
+                                        size_t prior_num_rows)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault || variant == instr_SetUnique, variant);
+    if (REALM_UNLIKELY(variant == instr_SetUnique))
+        append_simple_instr(variant, type_Int, col_ndx, ndx, prior_num_rows, value); // Throws
+    else
+        append_simple_instr(variant, type_Int, col_ndx, ndx, value); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_int(const Table* t, size_t col_ndx, size_t ndx, int_fast64_t value,
+                                                  Instruction variant)
+{
+    select_table(t); // Throws
+    size_t prior_num_rows = (variant == instr_SetUnique ? t->size() : 0);
+    m_encoder.set_int(col_ndx, ndx, value, variant, prior_num_rows); // Throws
+}
+
+
+inline bool TransactLogEncoder::add_int(size_t col_ndx, size_t ndx, int_fast64_t value)
+{
+    append_simple_instr(instr_AddInteger, col_ndx, ndx, value); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::add_int(const Table* t, size_t col_ndx, size_t ndx, int_fast64_t value)
+{
+    select_table(t); // Throws
+    m_encoder.add_int(col_ndx, ndx, value);
+}
+
+inline bool TransactLogEncoder::set_bool(size_t col_ndx, size_t ndx, bool value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_simple_instr(variant, type_Bool, col_ndx, ndx, value); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_bool(const Table* t, size_t col_ndx, size_t ndx, bool value,
+                                                   Instruction variant)
+{
+    select_table(t);                                  // Throws
+    m_encoder.set_bool(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_float(size_t col_ndx, size_t ndx, float value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_simple_instr(variant, type_Float, col_ndx, ndx, value); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_float(const Table* t, size_t col_ndx, size_t ndx, float value,
+                                                    Instruction variant)
+{
+    select_table(t);                                   // Throws
+    m_encoder.set_float(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_double(size_t col_ndx, size_t ndx, double value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_simple_instr(instr_Set, type_Double, col_ndx, ndx, value); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_double(const Table* t, size_t col_ndx, size_t ndx, double value,
+                                                     Instruction variant)
+{
+    select_table(t);                                    // Throws
+    m_encoder.set_double(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_string(size_t col_ndx, size_t ndx, StringData value, Instruction variant,
+                                           size_t prior_num_rows)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault || variant == instr_SetUnique, variant);
+    if (value.is_null()) {
+        set_null(col_ndx, ndx, variant, prior_num_rows); // Throws
+    }
+    else {
+        if (REALM_UNLIKELY(variant == instr_SetUnique))
+            append_simple_instr(variant, type_String, col_ndx, ndx, prior_num_rows, value); // Throws
+        else
+            append_simple_instr(variant, type_String, col_ndx, ndx, value); // Throws
+    }
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_string(const Table* t, size_t col_ndx, size_t ndx, StringData value,
+                                                     Instruction variant)
+{
+    select_table(t); // Throws
+    size_t prior_num_rows = (variant == instr_SetUnique ? t->size() : 0);
+    m_encoder.set_string(col_ndx, ndx, value, variant, prior_num_rows); // Throws
+}
+
+inline bool TransactLogEncoder::set_binary(size_t col_ndx, size_t row_ndx, BinaryData value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    if (value.is_null()) {
+        set_null(col_ndx, row_ndx, variant); // Throws
+    }
+    else {
+        StringData value_2(value.data(), value.size());
+        append_simple_instr(variant, type_Binary, col_ndx, row_ndx, value_2); // Throws
+    }
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_binary(const Table* t, size_t col_ndx, size_t ndx, BinaryData value,
+                                                     Instruction variant)
+{
+    select_table(t);                                    // Throws
+    m_encoder.set_binary(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_olddatetime(size_t col_ndx, size_t ndx, OldDateTime value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_simple_instr(variant, type_OldDateTime, col_ndx, ndx, value.get_olddatetime()); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_olddatetime(const Table* t, size_t col_ndx, size_t ndx,
+                                                          OldDateTime value, Instruction variant)
+{
+    select_table(t);                                         // Throws
+    m_encoder.set_olddatetime(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_timestamp(size_t col_ndx, size_t ndx, Timestamp value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_simple_instr(variant, type_Timestamp, col_ndx, ndx, value.get_seconds(),
+                        value.get_nanoseconds()); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_timestamp(const Table* t, size_t col_ndx, size_t ndx, Timestamp value,
+                                                        Instruction variant)
+{
+    select_table(t);                                       // Throws
+    m_encoder.set_timestamp(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_table(size_t col_ndx, size_t ndx, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_simple_instr(variant, type_Table, col_ndx, ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_table(const Table* t, size_t col_ndx, size_t ndx, Instruction variant)
+{
+    select_table(t);                            // Throws
+    m_encoder.set_table(col_ndx, ndx, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_mixed(size_t col_ndx, size_t ndx, const Mixed& value, Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    append_mixed_instr(variant, value, type_Mixed, col_ndx, ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_mixed(const Table* t, size_t col_ndx, size_t ndx, const Mixed& value,
+                                                    Instruction variant)
+{
+    select_table(t);                                   // Throws
+    m_encoder.set_mixed(col_ndx, ndx, value, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_link(size_t col_ndx, size_t ndx, size_t value, size_t target_group_level_ndx,
+                                         Instruction variant)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault, variant);
+    // Map `realm::npos` to zero, and `n` to `n+1`, where `n` is a target row
+    // index.
+    size_t value_2 = size_t(1) + value;
+    append_simple_instr(variant, type_Link, col_ndx, ndx, value_2, target_group_level_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_link(const Table* t, size_t col_ndx, size_t ndx, size_t value,
+                                                   Instruction variant)
+{
+    select_table(t); // Throws
+    size_t target_group_level_ndx = t->get_descriptor()->get_column_link_target(col_ndx);
+    m_encoder.set_link(col_ndx, ndx, value, target_group_level_ndx, variant); // Throws
+}
+
+inline bool TransactLogEncoder::set_null(size_t col_ndx, size_t ndx, Instruction variant, size_t prior_num_rows)
+{
+    REALM_ASSERT_EX(variant == instr_Set || variant == instr_SetDefault || variant == instr_SetUnique, variant);
+    if (REALM_UNLIKELY(variant == instr_SetUnique)) {
+        append_simple_instr(variant, set_null_sentinel(), col_ndx, ndx, prior_num_rows); // Throws
+    }
+    else {
+        append_simple_instr(variant, set_null_sentinel(), col_ndx, ndx); // Throws
+    }
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_null(const Table* t, size_t col_ndx, size_t row_ndx,
+                                                   Instruction variant)
+{
+    select_table(t); // Throws
+    size_t prior_num_rows = (variant == instr_SetUnique ? t->size() : 0);
+    m_encoder.set_null(col_ndx, row_ndx, variant, prior_num_rows); // Throws
+}
+
+inline bool TransactLogEncoder::nullify_link(size_t col_ndx, size_t ndx, size_t target_group_level_ndx)
+{
+    append_simple_instr(instr_NullifyLink, col_ndx, ndx, target_group_level_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::nullify_link(const Table* t, size_t col_ndx, size_t ndx)
+{
+    select_table(t); // Throws
+    size_t target_group_level_ndx = t->get_descriptor()->get_column_link_target(col_ndx);
+    m_encoder.nullify_link(col_ndx, ndx, target_group_level_ndx); // Throws
+}
+
+inline bool TransactLogEncoder::insert_substring(size_t col_ndx, size_t row_ndx, size_t pos, StringData value)
+{
+    append_simple_instr(instr_InsertSubstring, col_ndx, row_ndx, pos, value); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::insert_substring(const Table* t, size_t col_ndx, size_t row_ndx, size_t pos,
+                                                           StringData value)
+{
+    if (value.size() > 0) {
+        select_table(t);                                          // Throws
+        m_encoder.insert_substring(col_ndx, row_ndx, pos, value); // Throws
+    }
+}
+
+inline bool TransactLogEncoder::erase_substring(size_t col_ndx, size_t row_ndx, size_t pos, size_t size)
+{
+    append_simple_instr(instr_EraseFromString, col_ndx, row_ndx, pos, size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::erase_substring(const Table* t, size_t col_ndx, size_t row_ndx, size_t pos,
+                                                          size_t size)
+{
+    if (size > 0) {
+        select_table(t);                                        // Throws
+        m_encoder.erase_substring(col_ndx, row_ndx, pos, size); // Throws
+    }
+}
+
+inline bool TransactLogEncoder::insert_empty_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows,
+                                                  bool unordered)
+{
+    append_simple_instr(instr_InsertEmptyRows, row_ndx, num_rows_to_insert, prior_num_rows, unordered); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::insert_empty_rows(const Table* t, size_t row_ndx, size_t num_rows_to_insert,
+                                                            size_t prior_num_rows)
+{
+    select_table(t); // Throws
+    bool unordered = false;
+    m_encoder.insert_empty_rows(row_ndx, num_rows_to_insert, prior_num_rows, unordered); // Throws
+}
+
+inline bool TransactLogEncoder::add_row_with_key(size_t row_ndx, size_t prior_num_rows, size_t key_col_ndx,
+                                                 int64_t key)
+{
+    append_simple_instr(instr_AddRowWithKey, row_ndx, prior_num_rows, key_col_ndx, key); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::add_row_with_key(const Table* t, size_t row_ndx, size_t prior_num_rows,
+                                                           size_t key_col_ndx, int64_t key)
+{
+    select_table(t);                                          // Throws
+    m_encoder.add_row_with_key(row_ndx, prior_num_rows, key_col_ndx, key); // Throws
+}
+
+inline bool TransactLogEncoder::erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows,
+                                           bool unordered)
+{
+    append_simple_instr(instr_EraseRows, row_ndx, num_rows_to_erase, prior_num_rows, unordered); // Throws
+    return true;
+}
+
+
+inline void TransactLogConvenientEncoder::erase_rows(const Table* t, size_t row_ndx, size_t num_rows_to_erase,
+                                                     size_t prior_num_rows, bool is_move_last_over)
+{
+    select_table(t); // Throws
+    bool unordered = is_move_last_over;
+    m_encoder.erase_rows(row_ndx, num_rows_to_erase, prior_num_rows, unordered); // Throws
+}
+
+inline bool TransactLogEncoder::swap_rows(size_t row_ndx_1, size_t row_ndx_2)
+{
+    append_simple_instr(instr_SwapRows, row_ndx_1, row_ndx_2); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::swap_rows(const Table* t, size_t row_ndx_1, size_t row_ndx_2)
+{
+    REALM_ASSERT(row_ndx_1 < row_ndx_2);
+    select_table(t); // Throws
+    m_encoder.swap_rows(row_ndx_1, row_ndx_2);
+}
+
+inline bool TransactLogEncoder::move_row(size_t from_ndx, size_t to_ndx)
+{
+    append_simple_instr(instr_MoveRow, from_ndx, to_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::move_row(const Table* t, size_t from_ndx, size_t to_ndx)
+{
+    REALM_ASSERT(from_ndx != to_ndx);
+    select_table(t); // Throws
+    m_encoder.move_row(from_ndx, to_ndx);
+}
+
+inline bool TransactLogEncoder::merge_rows(size_t row_ndx, size_t new_row_ndx)
+{
+    append_simple_instr(instr_MergeRows, row_ndx, new_row_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::merge_rows(const Table* t, size_t row_ndx, size_t new_row_ndx)
+{
+    select_table(t); // Throws
+    m_encoder.merge_rows(row_ndx, new_row_ndx);
+}
+
+inline bool TransactLogEncoder::add_search_index(size_t col_ndx)
+{
+    append_simple_instr(instr_AddSearchIndex, col_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::add_search_index(const Descriptor& desc, size_t col_ndx)
+{
+    select_desc(desc);                   // Throws
+    m_encoder.add_search_index(col_ndx); // Throws
+}
+
+
+inline bool TransactLogEncoder::remove_search_index(size_t col_ndx)
+{
+    append_simple_instr(instr_RemoveSearchIndex, col_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::remove_search_index(const Descriptor& desc, size_t col_ndx)
+{
+    select_desc(desc);                      // Throws
+    m_encoder.remove_search_index(col_ndx); // Throws
+}
+
+inline bool TransactLogEncoder::set_link_type(size_t col_ndx, LinkType link_type)
+{
+    append_simple_instr(instr_SetLinkType, col_ndx, int(link_type)); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_link_type(const Table* t, size_t col_ndx, LinkType link_type)
+{
+    select_table(t);                             // Throws
+    m_encoder.set_link_type(col_ndx, link_type); // Throws
+}
+
+
+inline bool TransactLogEncoder::clear_table(size_t old_size)
+{
+    append_simple_instr(instr_ClearTable, old_size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::clear_table(const Table* t, size_t prior_num_rows)
+{
+    select_table(t);         // Throws
+    m_encoder.clear_table(prior_num_rows); // Throws
+}
+
+inline bool TransactLogEncoder::optimize_table()
+{
+    append_simple_instr(instr_OptimizeTable); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::optimize_table(const Table* t)
+{
+    select_table(t);            // Throws
+    m_encoder.optimize_table(); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_set(size_t link_ndx, size_t value, size_t prior_size)
+{
+    append_simple_instr(instr_LinkListSet, link_ndx, value, prior_size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::link_list_set(const LinkView& list, size_t link_ndx, size_t value)
+{
+    select_link_list(list);                                // Throws
+    m_encoder.link_list_set(link_ndx, value, list.size()); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_nullify(size_t link_ndx, size_t prior_size)
+{
+    append_simple_instr(instr_LinkListNullify, link_ndx, prior_size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::link_list_nullify(const LinkView& list, size_t link_ndx)
+{
+    select_link_list(list);                            // Throws
+    size_t prior_size = list.size();                   // Instruction is emitted before the fact.
+    m_encoder.link_list_nullify(link_ndx, prior_size); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_set_all(const IntegerColumn& values)
+{
+    size_t num_values = values.size();
+    append_simple_instr(
+        instr_LinkListSetAll, num_values,
+        std::make_tuple(IntegerColumnIterator(&values, 0), IntegerColumnIterator(&values, num_values))); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::set_link_list(const LinkView& list, const IntegerColumn& values)
+{
+    select_link_list(list);              // Throws
+    m_encoder.link_list_set_all(values); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_insert(size_t link_ndx, size_t value, size_t prior_size)
+{
+    append_simple_instr(instr_LinkListInsert, link_ndx, value, prior_size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::link_list_insert(const LinkView& list, size_t link_ndx, size_t value)
+{
+    select_link_list(list);                                  // Throws
+    size_t prior_size = list.size() - 1;                     // The instruction is emitted after the fact.
+    m_encoder.link_list_insert(link_ndx, value, prior_size); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_move(size_t from_link_ndx, size_t to_link_ndx)
+{
+    REALM_ASSERT(from_link_ndx != to_link_ndx);
+    append_simple_instr(instr_LinkListMove, from_link_ndx, to_link_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::link_list_move(const LinkView& list, size_t from_link_ndx,
+                                                         size_t to_link_ndx)
+{
+    select_link_list(list);                               // Throws
+    m_encoder.link_list_move(from_link_ndx, to_link_ndx); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_swap(size_t link1_ndx, size_t link2_ndx)
+{
+    append_simple_instr(instr_LinkListSwap, link1_ndx, link2_ndx); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::link_list_swap(const LinkView& list, size_t link1_ndx, size_t link2_ndx)
+{
+    select_link_list(list);                         // Throws
+    m_encoder.link_list_swap(link1_ndx, link2_ndx); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_erase(size_t link_ndx, size_t prior_size)
+{
+    append_simple_instr(instr_LinkListErase, link_ndx, prior_size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::link_list_erase(const LinkView& list, size_t link_ndx)
+{
+    select_link_list(list);                          // Throws
+    size_t prior_size = list.size();                 // The instruction is emitted before the fact.
+    m_encoder.link_list_erase(link_ndx, prior_size); // Throws
+}
+
+inline bool TransactLogEncoder::link_list_clear(size_t old_list_size)
+{
+    append_simple_instr(instr_LinkListClear, old_list_size); // Throws
+    return true;
+}
+
+inline void TransactLogConvenientEncoder::on_table_destroyed(const Table* t) noexcept
+{
+    if (m_selected_table == t)
+        m_selected_table = nullptr;
+}
+
+inline void TransactLogConvenientEncoder::on_spec_destroyed(const Spec* s) noexcept
+{
+    if (m_selected_spec == s)
+        m_selected_spec = nullptr;
+}
+
+
+inline void TransactLogConvenientEncoder::on_link_list_destroyed(const LinkView& list) noexcept
+{
+    const LinkView* lw_ptr = &list;
+    // atomically clear m_selected_link_list iff it already points to 'list':
+    // (lw_ptr will be modified if the swap fails, but we ignore that)
+    m_selected_link_list.compare_exchange_strong(lw_ptr, nullptr, std::memory_order_relaxed,
+                                                 std::memory_order_relaxed);
+}
+
+
+inline TransactLogParser::TransactLogParser()
+    : m_input_buffer(1024) // Throws
+{
+}
+
+
+inline TransactLogParser::~TransactLogParser() noexcept
+{
+}
+
+
+template <class InstructionHandler>
+void TransactLogParser::parse(NoCopyInputStream& in, InstructionHandler& handler)
+{
+    m_input = &in;
+    m_input_begin = m_input_end = nullptr;
+
+    while (has_next())
+        parse_one(handler); // Throws
+}
+
+template <class InstructionHandler>
+void TransactLogParser::parse(InputStream& in, InstructionHandler& handler)
+{
+    NoCopyInputStreamAdaptor in_2(in, m_input_buffer.data(), m_input_buffer.size());
+    parse(in_2, handler); // Throws
+}
+
+inline bool TransactLogParser::has_next() noexcept
+{
+    return m_input_begin != m_input_end || next_input_buffer();
+}
+
+template <class InstructionHandler>
+void TransactLogParser::parse_one(InstructionHandler& handler)
+{
+    char instr_ch = 0;
+    if (!read_char(instr_ch))
+        parser_error(); // Throws
+    //    std::cerr << "parsing " << util::promote(instr) << " @ " << std::hex << long(m_input_begin) << std::dec <<
+    //    "\n";
+    Instruction instr = Instruction(instr_ch);
+    switch (instr) {
+        case instr_SetDefault:
+        case instr_SetUnique:
+        case instr_Set: {
+            int type = read_int<int>();          // Throws
+            size_t col_ndx = read_int<size_t>(); // Throws
+            size_t row_ndx = read_int<size_t>(); // Throws
+            size_t prior_num_rows = 0;
+            if (REALM_UNLIKELY(instr == instr_SetUnique))
+                prior_num_rows = read_int<size_t>(); // Throws
+
+            if (type == TransactLogEncoder::set_null_sentinel()) {
+                // Special case for set_null
+                if (!handler.set_null(col_ndx, row_ndx, instr, prior_num_rows)) // Throws
+                    parser_error();
+                return;
+            }
+
+            switch (DataType(type)) {
+                case type_Int: {
+                    int_fast64_t value = read_int<int64_t>();                             // Throws
+                    if (!handler.set_int(col_ndx, row_ndx, value, instr, prior_num_rows)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Bool: {
+                    bool value = read_bool();                              // Throws
+                    if (!handler.set_bool(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Float: {
+                    float value = read_float();                             // Throws
+                    if (!handler.set_float(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Double: {
+                    double value = read_double();                            // Throws
+                    if (!handler.set_double(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_String: {
+                    StringData value = read_string(m_string_buffer);                         // Throws
+                    if (!handler.set_string(col_ndx, row_ndx, value, instr, prior_num_rows)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Binary: {
+                    BinaryData value = read_binary(m_string_buffer);         // Throws
+                    if (!handler.set_binary(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_OldDateTime: {
+                    int_fast64_t value = read_int<int_fast64_t>();                // Throws
+                    if (!handler.set_olddatetime(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Timestamp: {
+                    int64_t seconds = read_int<int64_t>();     // Throws
+                    int32_t nanoseconds = read_int<int32_t>(); // Throws
+                    Timestamp value = Timestamp(seconds, nanoseconds);
+                    if (!handler.set_timestamp(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Table: {
+                    if (!handler.set_table(col_ndx, row_ndx, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Mixed: {
+                    Mixed value;
+                    read_mixed(&value);                                     // Throws
+                    if (!handler.set_mixed(col_ndx, row_ndx, value, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_Link: {
+                    size_t value = read_int<size_t>(); // Throws
+                    // Map zero to realm::npos, and `n+1` to `n`, where `n` is a target row index.
+                    size_t target_row_ndx = size_t(value - 1);
+                    size_t target_group_level_ndx = read_int<size_t>();                                     // Throws
+                    if (!handler.set_link(col_ndx, row_ndx, target_row_ndx, target_group_level_ndx, instr)) // Throws
+                        parser_error();
+                    return;
+                }
+                case type_LinkList: {
+                    // Unsupported column type for Set.
+                    parser_error();
+                    return;
+                }
+            }
+            parser_error();
+            return;
+        }
+        case instr_AddInteger: {
+            size_t col_ndx = read_int<size_t>();           // Throws
+            size_t row_ndx = read_int<size_t>();           // Throws
+            int_fast64_t value = read_int<int64_t>();      // Throws
+            if (!handler.add_int(col_ndx, row_ndx, value)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_NullifyLink: {
+            size_t col_ndx = read_int<size_t>();                                 // Throws
+            size_t row_ndx = read_int<size_t>();                                 // Throws
+            size_t target_group_level_ndx = read_int<size_t>();                  // Throws
+            if (!handler.nullify_link(col_ndx, row_ndx, target_group_level_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_InsertSubstring: {
+            size_t col_ndx = read_int<size_t>();                         // Throws
+            size_t row_ndx = read_int<size_t>();                         // Throws
+            size_t pos = read_int<size_t>();                             // Throws
+            StringData value = read_string(m_string_buffer);             // Throws
+            if (!handler.insert_substring(col_ndx, row_ndx, pos, value)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_EraseFromString: {
+            size_t col_ndx = read_int<size_t>();                       // Throws
+            size_t row_ndx = read_int<size_t>();                       // Throws
+            size_t pos = read_int<size_t>();                           // Throws
+            size_t size = read_int<size_t>();                          // Throws
+            if (!handler.erase_substring(col_ndx, row_ndx, pos, size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_InsertEmptyRows: {
+            size_t row_ndx = read_int<size_t>();                                                    // Throws
+            size_t num_rows_to_insert = read_int<size_t>();                                         // Throws
+            size_t prior_num_rows = read_int<size_t>();                                             // Throws
+            bool unordered = read_bool();                                                           // Throws
+            if (!handler.insert_empty_rows(row_ndx, num_rows_to_insert, prior_num_rows, unordered)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_AddRowWithKey: {
+            size_t row_ndx = read_int<size_t>();                         // Throws
+            size_t prior_num_rows = read_int<size_t>();                  // Throws
+            size_t key_col_ndx = read_int<size_t>();                     // Throws
+            int64_t key = read_int<int64_t>();                           // Throws
+            if (!handler.add_row_with_key(row_ndx, prior_num_rows, key_col_ndx, key)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_EraseRows: {
+            size_t row_ndx = read_int<size_t>();                                            // Throws
+            size_t num_rows_to_erase = read_int<size_t>();                                  // Throws
+            size_t prior_num_rows = read_int<size_t>();                                     // Throws
+            bool unordered = read_bool();                                                   // Throws
+            if (!handler.erase_rows(row_ndx, num_rows_to_erase, prior_num_rows, unordered)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_SwapRows: {
+            size_t row_ndx_1 = read_int<size_t>();        // Throws
+            size_t row_ndx_2 = read_int<size_t>();        // Throws
+            if (!handler.swap_rows(row_ndx_1, row_ndx_2)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_MoveRow: {
+            size_t from_ndx = read_int<size_t>();    // Throws
+            size_t to_ndx = read_int<size_t>();      // Throws
+            if (!handler.move_row(from_ndx, to_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_MergeRows: {
+            size_t row_ndx = read_int<size_t>();           // Throws
+            size_t new_row_ndx = read_int<size_t>();       // Throws
+            if (!handler.merge_rows(row_ndx, new_row_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_SelectTable: {
+            int levels = read_int<int>(); // Throws
+            if (levels < 0 || levels > m_max_levels)
+                parser_error();
+            m_path.reserve(0, 2 * levels); // Throws
+            size_t* path = m_path.data();
+            size_t group_level_ndx = read_int<size_t>(); // Throws
+            for (int i = 0; i != levels; ++i) {
+                size_t col_ndx = read_int<size_t>(); // Throws
+                size_t row_ndx = read_int<size_t>(); // Throws
+                path[2 * i + 0] = col_ndx;
+                path[2 * i + 1] = row_ndx;
+            }
+            if (!handler.select_table(group_level_ndx, levels, path)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_ClearTable: {
+            size_t old_size = read_int<size_t>();   // Throws
+            if (!handler.clear_table(old_size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListSet: {
+            size_t link_ndx = read_int<size_t>();                    // Throws
+            size_t value = read_int<size_t>();                       // Throws
+            size_t prior_size = read_int<size_t>();                  // Throws
+            if (!handler.link_list_set(link_ndx, value, prior_size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListSetAll: {
+            // todo, log that it's a SetAll we're doing
+            size_t size = read_int<size_t>(); // Throws
+            for (size_t i = 0; i < size; i++) {
+                size_t link = read_int<size_t>();          // Throws
+                if (!handler.link_list_set(i, link, size)) // Throws
+                    parser_error();
+            }
+            return;
+        }
+        case instr_LinkListInsert: {
+            size_t link_ndx = read_int<size_t>();                       // Throws
+            size_t value = read_int<size_t>();                          // Throws
+            size_t prior_size = read_int<size_t>();                     // Throws
+            if (!handler.link_list_insert(link_ndx, value, prior_size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListMove: {
+            size_t from_link_ndx = read_int<size_t>();               // Throws
+            size_t to_link_ndx = read_int<size_t>();                 // Throws
+            if (!handler.link_list_move(from_link_ndx, to_link_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListSwap: {
+            size_t link1_ndx = read_int<size_t>();             // Throws
+            size_t link2_ndx = read_int<size_t>();             // Throws
+            if (!handler.link_list_swap(link1_ndx, link2_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListErase: {
+            size_t link_ndx = read_int<size_t>();               // Throws
+            size_t prior_size = read_int<size_t>();             // Throws
+            if (!handler.link_list_erase(link_ndx, prior_size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListNullify: {
+            size_t link_ndx = read_int<size_t>();                 // Throws
+            size_t prior_size = read_int<size_t>();               // Throws
+            if (!handler.link_list_nullify(link_ndx, prior_size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_LinkListClear: {
+            size_t old_list_size = read_int<size_t>();   // Throws
+            if (!handler.link_list_clear(old_list_size)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_SelectLinkList: {
+            size_t col_ndx = read_int<size_t>();                                     // Throws
+            size_t row_ndx = read_int<size_t>();                                     // Throws
+            size_t target_group_level_ndx = read_int<size_t>();                      // Throws
+            if (!handler.select_link_list(col_ndx, row_ndx, target_group_level_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_MoveColumn: {
+            // FIXME: remove this in the next breaking change.
+            // This instruction is no longer supported and not used by either
+            // bindings or sync, so if we see it here, there was a problem parsing.
+            parser_error();
+            return;
+        }
+        case instr_AddSearchIndex: {
+            size_t col_ndx = read_int<size_t>();    // Throws
+            if (!handler.add_search_index(col_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_RemoveSearchIndex: {
+            size_t col_ndx = read_int<size_t>();       // Throws
+            if (!handler.remove_search_index(col_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_SetLinkType: {
+            size_t col_ndx = read_int<size_t>(); // Throws
+            int link_type = read_int<int>();     // Throws
+            if (!is_valid_link_type(link_type))
+                parser_error();
+            if (!handler.set_link_type(col_ndx, LinkType(link_type))) // Throws
+                parser_error();
+            return;
+        }
+        case instr_InsertColumn:
+        case instr_InsertNullableColumn: {
+            size_t col_ndx = read_int<size_t>(); // Throws
+            int type = read_int<int>();          // Throws
+            if (!is_valid_data_type(type))
+                parser_error();
+            if (REALM_UNLIKELY(type == type_Link || type == type_LinkList))
+                parser_error();
+            StringData name = read_string(m_string_buffer); // Throws
+            bool nullable = (Instruction(instr) == instr_InsertNullableColumn);
+            if (REALM_UNLIKELY(nullable && (type == type_Mixed))) {
+                // Nullability not supported for Mixed columns.
+                parser_error();
+            }
+            if (!handler.insert_column(col_ndx, DataType(type), name, nullable)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_InsertLinkColumn: {
+            size_t col_ndx = read_int<size_t>(); // Throws
+            int type = read_int<int>();          // Throws
+            if (!is_valid_data_type(type))
+                parser_error();
+            if (REALM_UNLIKELY(type != type_Link && type != type_LinkList))
+                parser_error();
+            size_t link_target_table_ndx = read_int<size_t>(); // Throws
+            size_t backlink_col_ndx = read_int<size_t>();      // Throws
+            StringData name = read_string(m_string_buffer);    // Throws
+            if (!handler.insert_link_column(col_ndx, DataType(type), name, link_target_table_ndx,
+                                            backlink_col_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_EraseColumn: {
+            size_t col_ndx = read_int<size_t>(); // Throws
+            if (!handler.erase_column(col_ndx))  // Throws
+                parser_error();
+            return;
+        }
+        case instr_EraseLinkColumn: {
+            size_t col_ndx = read_int<size_t>();                                              // Throws
+            size_t link_target_table_ndx = read_int<size_t>();                                // Throws
+            size_t backlink_col_ndx = read_int<size_t>();                                     // Throws
+            if (!handler.erase_link_column(col_ndx, link_target_table_ndx, backlink_col_ndx)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_RenameColumn: {
+            size_t col_ndx = read_int<size_t>();            // Throws
+            StringData name = read_string(m_string_buffer); // Throws
+            if (!handler.rename_column(col_ndx, name))      // Throws
+                parser_error();
+            return;
+        }
+        case instr_SelectDescriptor: {
+            int levels = read_int<int>(); // Throws
+            if (levels < 0 || levels > m_max_levels)
+                parser_error();
+            m_path.reserve(0, levels); // Throws
+            size_t* path = m_path.data();
+            for (int i = 0; i != levels; ++i) {
+                size_t col_ndx = read_int<size_t>(); // Throws
+                path[i] = col_ndx;
+            }
+            if (!handler.select_descriptor(levels, path)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_InsertGroupLevelTable: {
+            size_t table_ndx = read_int<size_t>();                              // Throws
+            size_t num_tables = read_int<size_t>();                             // Throws
+            StringData name = read_string(m_string_buffer);                     // Throws
+            if (!handler.insert_group_level_table(table_ndx, num_tables, name)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_EraseGroupLevelTable: {
+            size_t table_ndx = read_int<size_t>();                             // Throws
+            size_t prior_num_tables = read_int<size_t>();                      // Throws
+            if (!handler.erase_group_level_table(table_ndx, prior_num_tables)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_RenameGroupLevelTable: {
+            size_t table_ndx = read_int<size_t>();                      // Throws
+            StringData new_name = read_string(m_string_buffer);         // Throws
+            if (!handler.rename_group_level_table(table_ndx, new_name)) // Throws
+                parser_error();
+            return;
+        }
+        case instr_MoveGroupLevelTable: {
+            // This instruction is no longer supported and not used by either
+            // bindings or sync, so if we see it here, there was a problem parsing.
+            // FIXME: remove this in the next breaking change.
+            parser_error();
+            return;
+        }
+        case instr_OptimizeTable: {
+            if (!handler.optimize_table()) // Throws
+                parser_error();
+            return;
+        }
+    }
+
+    throw BadTransactLog();
+}
+
+
+template <class T>
+T TransactLogParser::read_int()
+{
+    T value = 0;
+    int part = 0;
+    const int max_bytes = (std::numeric_limits<T>::digits + 1 + 6) / 7;
+    for (int i = 0; i != max_bytes; ++i) {
+        char c;
+        if (!read_char(c))
+            goto bad_transact_log;
+        part = static_cast<unsigned char>(c);
+        if (0xFF < part)
+            goto bad_transact_log; // Only the first 8 bits may be used in each byte
+        if ((part & 0x80) == 0) {
+            T p = part & 0x3F;
+            if (util::int_shift_left_with_overflow_detect(p, i * 7))
+                goto bad_transact_log;
+            value |= p;
+            break;
+        }
+        if (i == max_bytes - 1)
+            goto bad_transact_log; // Too many bytes
+        value |= T(part & 0x7F) << (i * 7);
+    }
+    if (part & 0x40) {
+        // The real value is negative. Because 'value' is positive at
+        // this point, the following negation is guaranteed by C++11
+        // to never overflow. See C99+TC3 section 6.2.6.2 paragraph 2.
+        REALM_DIAG_PUSH();
+        REALM_DIAG_IGNORE_UNSIGNED_MINUS();
+        value = -value;
+        REALM_DIAG_POP();
+        if (util::int_subtract_with_overflow_detect(value, 1))
+            goto bad_transact_log;
+    }
+    return value;
+
+bad_transact_log:
+    throw BadTransactLog();
+}
+
+
+inline void TransactLogParser::read_bytes(char* data, size_t size)
+{
+    for (;;) {
+        const size_t avail = m_input_end - m_input_begin;
+        if (size <= avail)
+            break;
+        realm::safe_copy_n(m_input_begin, avail, data);
+        if (!next_input_buffer())
+            throw BadTransactLog();
+        data += avail;
+        size -= avail;
+    }
+    const char* to = m_input_begin + size;
+    realm::safe_copy_n(m_input_begin, size, data);
+    m_input_begin = to;
+}
+
+
+inline BinaryData TransactLogParser::read_buffer(util::StringBuffer& buf, size_t size)
+{
+    const size_t avail = m_input_end - m_input_begin;
+    if (avail >= size) {
+        m_input_begin += size;
+        return BinaryData(m_input_begin - size, size);
+    }
+
+    buf.clear();
+    buf.resize(size); // Throws
+    read_bytes(buf.data(), size);
+    return BinaryData(buf.data(), size);
+}
+
+
+inline bool TransactLogParser::read_bool()
+{
+    return read_int<char>();
+}
+
+
+inline float TransactLogParser::read_float()
+{
+    static_assert(std::numeric_limits<float>::is_iec559 &&
+                      sizeof(float) * std::numeric_limits<unsigned char>::digits == 32,
+                  "Unsupported 'float' representation");
+    float value;
+    read_bytes(reinterpret_cast<char*>(&value), sizeof value); // Throws
+    return value;
+}
+
+
+inline double TransactLogParser::read_double()
+{
+    static_assert(std::numeric_limits<double>::is_iec559 &&
+                      sizeof(double) * std::numeric_limits<unsigned char>::digits == 64,
+                  "Unsupported 'double' representation");
+    double value;
+    read_bytes(reinterpret_cast<char*>(&value), sizeof value); // Throws
+    return value;
+}
+
+
+inline StringData TransactLogParser::read_string(util::StringBuffer& buf)
+{
+    size_t size = read_int<size_t>(); // Throws
+
+    if (size > Table::max_string_size)
+        parser_error();
+
+    BinaryData buffer = read_buffer(buf, size);
+    return StringData{buffer.data(), size};
+}
+
+inline Timestamp TransactLogParser::read_timestamp()
+{
+    int64_t seconds = read_int<int64_t>();     // Throws
+    int32_t nanoseconds = read_int<int32_t>(); // Throws
+    return Timestamp(seconds, nanoseconds);
+}
+
+
+inline BinaryData TransactLogParser::read_binary(util::StringBuffer& buf)
+{
+    size_t size = read_int<size_t>(); // Throws
+
+    return read_buffer(buf, size);
+}
+
+
+inline void TransactLogParser::read_mixed(Mixed* mixed)
+{
+    DataType type = DataType(read_int<int>()); // Throws
+    switch (type) {
+        case type_Int: {
+            int_fast64_t value = read_int<int64_t>(); // Throws
+            mixed->set_int(value);
+            return;
+        }
+        case type_Bool: {
+            bool value = read_bool(); // Throws
+            mixed->set_bool(value);
+            return;
+        }
+        case type_Float: {
+            float value = read_float(); // Throws
+            mixed->set_float(value);
+            return;
+        }
+        case type_Double: {
+            double value = read_double(); // Throws
+            mixed->set_double(value);
+            return;
+        }
+        case type_OldDateTime: {
+            int_fast64_t value = read_int<int_fast64_t>(); // Throws
+            mixed->set_olddatetime(value);
+            return;
+        }
+        case type_Timestamp: {
+            Timestamp value = read_timestamp(); // Throws
+            mixed->set_timestamp(value);
+            return;
+        }
+        case type_String: {
+            StringData value = read_string(m_string_buffer); // Throws
+            mixed->set_string(value);
+            return;
+        }
+        case type_Binary: {
+            BinaryData value = read_binary(m_string_buffer); // Throws
+            mixed->set_binary(value);
+            return;
+        }
+        case type_Table: {
+            *mixed = Mixed::subtable_tag();
+            return;
+        }
+        case type_Mixed:
+            break;
+        case type_Link:
+        case type_LinkList:
+            // FIXME: Need to handle new link types here
+            break;
+    }
+    throw BadTransactLog();
+}
+
+
+inline bool TransactLogParser::next_input_buffer()
+{
+    return m_input->next_block(m_input_begin, m_input_end);
+}
+
+
+inline bool TransactLogParser::read_char(char& c)
+{
+    if (m_input_begin == m_input_end && !next_input_buffer())
+        return false;
+    c = *m_input_begin++;
+    return true;
+}
+
+
+inline bool TransactLogParser::is_valid_data_type(int type)
+{
+    switch (DataType(type)) {
+        case type_Int:
+        case type_Bool:
+        case type_Float:
+        case type_Double:
+        case type_String:
+        case type_Binary:
+        case type_OldDateTime:
+        case type_Timestamp:
+        case type_Table:
+        case type_Mixed:
+        case type_Link:
+        case type_LinkList:
+            return true;
+    }
+    return false;
+}
+
+
+inline bool TransactLogParser::is_valid_link_type(int type)
+{
+    switch (LinkType(type)) {
+        case link_Strong:
+        case link_Weak:
+            return true;
+    }
+    return false;
+}
+
+
+class TransactReverser {
+public:
+    bool select_table(size_t group_level_ndx, size_t levels, const size_t* path)
+    {
+        sync_table();
+        m_encoder.select_table(group_level_ndx, levels, path);
+        m_pending_ts_instr = get_inst();
+        return true;
+    }
+
+    bool select_descriptor(size_t levels, const size_t* path)
+    {
+        sync_descriptor();
+        m_encoder.select_descriptor(levels, path);
+        m_pending_ds_instr = get_inst();
+        return true;
+    }
+
+    bool insert_group_level_table(size_t table_ndx, size_t num_tables, StringData)
+    {
+        sync_table();
+        m_encoder.erase_group_level_table(table_ndx, num_tables + 1);
+        append_instruction();
+        return true;
+    }
+
+    bool erase_group_level_table(size_t table_ndx, size_t num_tables)
+    {
+        sync_table();
+        m_encoder.insert_group_level_table(table_ndx, num_tables - 1, "");
+        append_instruction();
+        return true;
+    }
+
+    bool rename_group_level_table(size_t, StringData)
+    {
+        sync_table();
+        return true;
+    }
+
+    bool optimize_table()
+    {
+        return true; // No-op
+    }
+
+    bool insert_empty_rows(size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows, bool unordered)
+    {
+        size_t num_rows_to_erase = num_rows_to_insert;
+        size_t prior_num_rows_2 = prior_num_rows + num_rows_to_insert;
+        m_encoder.erase_rows(row_ndx, num_rows_to_erase, prior_num_rows_2, unordered); // Throws
+        append_instruction();
+        return true;
+    }
+
+    bool add_row_with_key(size_t row_ndx, size_t prior_num_rows, size_t, int64_t)
+    {
+        bool unordered = true;
+        m_encoder.erase_rows(row_ndx, 1, prior_num_rows + 1, unordered); // Throws
+        append_instruction();
+        return true;
+    }
+
+    bool erase_rows(size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rows, bool unordered)
+    {
+        size_t num_rows_to_insert = num_rows_to_erase;
+        // Number of rows in table after removal, but before inverse insertion
+        size_t prior_num_rows_2 = prior_num_rows - num_rows_to_erase;
+        m_encoder.insert_empty_rows(row_ndx, num_rows_to_insert, prior_num_rows_2, unordered); // Throws
+        append_instruction();
+        return true;
+    }
+
+    bool swap_rows(size_t row_ndx_1, size_t row_ndx_2)
+    {
+        m_encoder.swap_rows(row_ndx_1, row_ndx_2);
+        append_instruction();
+        return true;
+    }
+
+    bool move_row(size_t from_ndx, size_t to_ndx)
+    {
+        m_encoder.move_row(to_ndx, from_ndx);
+        append_instruction();
+        return true;
+    }
+
+    bool merge_rows(size_t row_ndx, size_t new_row_ndx)
+    {
+        // There is no instruction we can generate here to change back.
+        // However, we do need to refresh accessors for any tables
+        // connected through backlinks, so we generate updates on each
+        // affected row by merging to itself.
+        m_encoder.merge_rows(row_ndx, row_ndx);
+        append_instruction();
+        m_encoder.merge_rows(new_row_ndx, new_row_ndx);
+        append_instruction();
+        return true;
+    }
+
+    bool set_int(size_t col_ndx, size_t row_ndx, int_fast64_t value, Instruction variant, size_t prior_num_rows)
+    {
+        m_encoder.set_int(col_ndx, row_ndx, value, variant, prior_num_rows);
+        append_instruction();
+        return true;
+    }
+
+    bool add_int(size_t col_ndx, size_t row_ndx, int_fast64_t value)
+    {
+        m_encoder.add_int(col_ndx, row_ndx, -value);
+        append_instruction();
+        return true;
+    }
+
+    bool set_bool(size_t col_ndx, size_t row_ndx, bool value, Instruction variant)
+    {
+        m_encoder.set_bool(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_float(size_t col_ndx, size_t row_ndx, float value, Instruction variant)
+    {
+        m_encoder.set_float(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_double(size_t col_ndx, size_t row_ndx, double value, Instruction variant)
+    {
+        m_encoder.set_double(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_string(size_t col_ndx, size_t row_ndx, StringData value, Instruction variant, size_t prior_num_rows)
+    {
+        m_encoder.set_string(col_ndx, row_ndx, value, variant, prior_num_rows);
+        append_instruction();
+        return true;
+    }
+
+    bool set_binary(size_t col_ndx, size_t row_ndx, BinaryData value, Instruction variant)
+    {
+        m_encoder.set_binary(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_olddatetime(size_t col_ndx, size_t row_ndx, OldDateTime value, Instruction variant)
+    {
+        m_encoder.set_olddatetime(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_timestamp(size_t col_ndx, size_t row_ndx, Timestamp value, Instruction variant)
+    {
+        m_encoder.set_timestamp(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_table(size_t col_ndx, size_t row_ndx, Instruction variant)
+    {
+        m_encoder.set_table(col_ndx, row_ndx, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_mixed(size_t col_ndx, size_t row_ndx, const Mixed& value, Instruction variant)
+    {
+        m_encoder.set_mixed(col_ndx, row_ndx, value, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool set_null(size_t col_ndx, size_t row_ndx, Instruction variant, size_t prior_num_rows)
+    {
+        m_encoder.set_null(col_ndx, row_ndx, variant, prior_num_rows);
+        append_instruction();
+        return true;
+    }
+
+    bool set_link(size_t col_ndx, size_t row_ndx, size_t value, size_t target_group_level_ndx, Instruction variant)
+    {
+        m_encoder.set_link(col_ndx, row_ndx, value, target_group_level_ndx, variant);
+        append_instruction();
+        return true;
+    }
+
+    bool insert_substring(size_t, size_t, size_t, StringData)
+    {
+        return true; // No-op
+    }
+
+    bool erase_substring(size_t, size_t, size_t, size_t)
+    {
+        return true; // No-op
+    }
+
+    bool clear_table(size_t old_size)
+    {
+        bool unordered = false;
+        m_encoder.insert_empty_rows(0, old_size, 0, unordered);
+        append_instruction();
+        return true;
+    }
+
+    bool add_search_index(size_t)
+    {
+        return true; // No-op
+    }
+
+    bool remove_search_index(size_t)
+    {
+        return true; // No-op
+    }
+
+    bool set_link_type(size_t, LinkType)
+    {
+        return true; // No-op
+    }
+
+    bool insert_link_column(size_t col_idx, DataType, StringData, size_t target_table_idx, size_t backlink_col_ndx)
+    {
+        m_encoder.erase_link_column(col_idx, target_table_idx, backlink_col_ndx);
+        append_instruction();
+        return true;
+    }
+
+    bool erase_link_column(size_t col_idx, size_t target_table_idx, size_t backlink_col_idx)
+    {
+        DataType type = type_Link; // The real type of the column doesn't matter here,
+        // but the encoder asserts that it's actually a link type.
+        m_encoder.insert_link_column(col_idx, type, "", target_table_idx, backlink_col_idx);
+        append_instruction();
+        return true;
+    }
+
+    bool insert_column(size_t col_idx, DataType, StringData, bool)
+    {
+        m_encoder.erase_column(col_idx);
+        append_instruction();
+        return true;
+    }
+
+    bool erase_column(size_t col_idx)
+    {
+        m_encoder.insert_column(col_idx, DataType(), "");
+        append_instruction();
+        return true;
+    }
+
+    bool rename_column(size_t, StringData)
+    {
+        return true; // No-op
+    }
+
+    bool select_link_list(size_t col_ndx, size_t row_ndx, size_t link_target_group_level_ndx)
+    {
+        sync_linkview();
+        m_encoder.select_link_list(col_ndx, row_ndx, link_target_group_level_ndx);
+        m_pending_lv_instr = get_inst();
+        return true;
+    }
+
+    bool link_list_set(size_t row, size_t value, size_t prior_size)
+    {
+        m_encoder.link_list_set(row, value, prior_size);
+        append_instruction();
+        return true;
+    }
+
+    bool link_list_insert(size_t link_ndx, size_t, size_t prior_size)
+    {
+        m_encoder.link_list_erase(link_ndx, prior_size + 1);
+        append_instruction();
+        return true;
+    }
+
+    bool link_list_move(size_t from_link_ndx, size_t to_link_ndx)
+    {
+        m_encoder.link_list_move(from_link_ndx, to_link_ndx);
+        append_instruction();
+        return true;
+    }
+
+    bool link_list_swap(size_t link1_ndx, size_t link2_ndx)
+    {
+        m_encoder.link_list_swap(link1_ndx, link2_ndx);
+        append_instruction();
+        return true;
+    }
+
+    bool link_list_erase(size_t link_ndx, size_t prior_size)
+    {
+        m_encoder.link_list_insert(link_ndx, 0, prior_size - 1);
+        append_instruction();
+        return true;
+    }
+
+    bool link_list_clear(size_t old_list_size)
+    {
+        // Append in reverse order because the reversed log is itself applied
+        // in reverse, and this way it generates all back-insertions rather than
+        // all front-insertions
+        for (size_t i = old_list_size; i > 0; --i) {
+            m_encoder.link_list_insert(i - 1, 0, old_list_size - i);
+            append_instruction();
+        }
+        return true;
+    }
+
+    bool nullify_link(size_t col_ndx, size_t row_ndx, size_t target_group_level_ndx)
+    {
+        size_t value = 0;
+        // FIXME: Is zero this right value to pass here, or should
+        // TransactReverser::nullify_link() also have taken a
+        // `target_group_level_ndx` argument.
+        m_encoder.set_link(col_ndx, row_ndx, value, target_group_level_ndx);
+        append_instruction();
+        return true;
+    }
+
+    bool link_list_nullify(size_t link_ndx, size_t prior_size)
+    {
+        m_encoder.link_list_insert(link_ndx, 0, prior_size - 1);
+        append_instruction();
+        return true;
+    }
+
+private:
+    _impl::TransactLogBufferStream m_buffer;
+    _impl::TransactLogEncoder m_encoder{m_buffer};
+    struct Instr {
+        size_t begin;
+        size_t end;
+    };
+    std::vector<Instr> m_instructions;
+    size_t current_instr_start = 0;
+    Instr m_pending_ts_instr{0, 0};
+    Instr m_pending_ds_instr{0, 0};
+    Instr m_pending_lv_instr{0, 0};
+
+    Instr get_inst()
+    {
+        Instr instr;
+        instr.begin = current_instr_start;
+        current_instr_start = transact_log_size();
+        instr.end = current_instr_start;
+        return instr;
+    }
+
+    size_t transact_log_size() const
+    {
+        REALM_ASSERT_3(m_encoder.write_position(), >=, m_buffer.transact_log_data());
+        return m_encoder.write_position() - m_buffer.transact_log_data();
+    }
+
+    void append_instruction()
+    {
+        m_instructions.push_back(get_inst());
+    }
+
+    void append_instruction(Instr instr)
+    {
+        m_instructions.push_back(instr);
+    }
+
+    void sync_select(Instr& pending_instr)
+    {
+        if (pending_instr.begin != pending_instr.end) {
+            append_instruction(pending_instr);
+            pending_instr = {0, 0};
+        }
+    }
+
+    void sync_linkview()
+    {
+        sync_select(m_pending_lv_instr);
+    }
+
+    void sync_descriptor()
+    {
+        sync_linkview();
+        sync_select(m_pending_ds_instr);
+    }
+
+    void sync_table()
+    {
+        sync_descriptor();
+        sync_select(m_pending_ts_instr);
+    }
+
+    friend class ReversedNoCopyInputStream;
+};
+
+
+class ReversedNoCopyInputStream : public NoCopyInputStream {
+public:
+    ReversedNoCopyInputStream(TransactReverser& reverser)
+        : m_instr_order(reverser.m_instructions)
+    {
+        // push any pending select_table or select_descriptor into the buffer
+        reverser.sync_table();
+
+        m_buffer = reverser.m_buffer.transact_log_data();
+        m_current = m_instr_order.size();
+    }
+
+    bool next_block(const char*& begin, const char*& end) override
+    {
+        if (m_current != 0) {
+            m_current--;
+            begin = m_buffer + m_instr_order[m_current].begin;
+            end = m_buffer + m_instr_order[m_current].end;
+            return (end > begin);
+        }
+        return false;
+    }
+
+private:
+    const char* m_buffer;
+    std::vector<TransactReverser::Instr>& m_instr_order;
+    size_t m_current;
+};
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_TRANSACT_LOG_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/index_string.hpp b/node_modules/realm/vendor/realm-ios/include/realm/index_string.hpp
new file mode 100644
index 0000000..1c27039
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/index_string.hpp
@@ -0,0 +1,606 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_INDEX_STRING_HPP
+#define REALM_INDEX_STRING_HPP
+
+#include <cstring>
+#include <memory>
+#include <array>
+
+#include <realm/array.hpp>
+#include <realm/column_fwd.hpp>
+
+/*
+The StringIndex class is used for both type_String and all integral types, such as type_Bool, type_OldDateTime and
+type_Int. When used for integral types, the 64-bit integer is simply casted to a string of 8 bytes through a
+pretty simple "wrapper layer" in all public methods.
+
+The StringIndex data structure is like an "inversed" B+ tree where the leafs contain row indexes and the non-leafs
+contain 4-byte chunks of payload. Imagine a table with following strings:
+
+       hello, kitty, kitten, foobar, kitty, foobar
+
+The topmost level of the index tree contains prefixes of the payload strings of length <= 4. The next level contains
+prefixes of the remaining parts of the strings. Unnecessary levels of the tree are optimized away; the prefix "foob"
+is shared only by rows that are identical ("foobar"), so "ar" is not needed to be stored in the tree.
+
+       hell   kitt      foob
+        |      /\        |
+        0     en  y    {3, 5}
+              |    \
+           {1, 4}   2
+
+Each non-leafs consists of two integer arrays of the same length, one containing payload and the other containing
+references to the sublevel nodes.
+
+The leafs can be either a single value or a Column. If the reference in its parent node has its least significant
+bit set, then the remaining upper bits specify the row index at which the string is stored. If the bit is clear,
+it must be interpreted as a reference to a Column that stores the row indexes at which the string is stored.
+
+If a Column is used, then all row indexes are guaranteed to be sorted increasingly, which means you an search in it
+using our binary search functions such as upper_bound() and lower_bound(). Each duplicate value will be stored in
+the same Column, but Columns may contain more than just duplicates if the depth of the tree exceeds the value
+`s_max_offset` This is to avoid stack overflow problems with many of our recursive functions if we have two very
+long strings that have a long common prefix but differ in the last couple bytes. If a Column stores more than just
+duplicates, then the list is kept sorted in ascending order by string value and within the groups of common
+strings, the rows are sorted in ascending order.
+*/
+
+namespace realm {
+
+class Spec;
+class Timestamp;
+
+class IndexArray : public Array {
+public:
+    IndexArray(Allocator& allocator)
+        : Array(allocator)
+    {
+    }
+
+    size_t index_string_find_first(StringData value, ColumnBase* column) const;
+    void index_string_find_all(IntegerColumn& result, StringData value, ColumnBase* column, bool case_insensitive = false) const;
+    FindRes index_string_find_all_no_copy(StringData value, ColumnBase* column, InternalFindResult& result) const;
+    size_t index_string_count(StringData value, ColumnBase* column) const;
+
+private:
+    template <IndexMethod>
+    size_t from_list(StringData value, InternalFindResult& result_ref, const IntegerColumn& rows,
+                     ColumnBase* column) const;
+
+    void from_list_all(StringData value, IntegerColumn& result, const IntegerColumn& rows, ColumnBase* column) const;
+
+    void from_list_all_ins(StringData value, std::vector<size_t>& result, const IntegerColumn& rows,
+                           ColumnBase* column) const;
+
+    template <IndexMethod method>
+    size_t index_string(StringData value, InternalFindResult& result_ref, ColumnBase* column) const;
+
+    void index_string_all(StringData value, IntegerColumn& result, ColumnBase* column) const;
+
+    void index_string_all_ins(StringData value, IntegerColumn& result, ColumnBase* column) const;
+};
+
+
+class StringIndex {
+public:
+    StringIndex(ColumnBase* target_column, Allocator&);
+    StringIndex(ref_type, ArrayParent*, size_t ndx_in_parent, ColumnBase* target_column, Allocator&);
+    ~StringIndex() noexcept
+    {
+    }
+
+    static ref_type create_empty(Allocator& alloc);
+
+    void set_target(ColumnBase* target_column) noexcept;
+
+    // Accessor concept:
+    Allocator& get_alloc() const noexcept;
+    void destroy() noexcept;
+    void detach();
+    bool is_attached() const noexcept;
+    void set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept;
+    size_t get_ndx_in_parent() const noexcept;
+    void set_ndx_in_parent(size_t ndx_in_parent) noexcept;
+    void update_from_parent(size_t old_baseline) noexcept;
+    void refresh_accessor_tree(size_t, const Spec&);
+    ref_type get_ref() const noexcept;
+
+    // StringIndex interface:
+
+    // 12 is the biggest element size of any non-string/binary Realm type
+    static const size_t string_conversion_buffer_size = 12;
+    using StringConversionBuffer = std::array<char, string_conversion_buffer_size>;
+
+    bool is_empty() const;
+
+    template <class T>
+    void insert(size_t row_ndx, T value, size_t num_rows, bool is_append);
+    template <class T>
+    void insert(size_t row_ndx, util::Optional<T> value, size_t num_rows, bool is_append);
+
+    template <class T>
+    void set(size_t row_ndx, T new_value);
+    template <class T>
+    void set(size_t row_ndx, util::Optional<T> new_value);
+
+    template <class T>
+    void erase(size_t row_ndx, bool is_last);
+
+    template <class T>
+    size_t find_first(T value) const;
+    template <class T>
+    void find_all(IntegerColumn& result, T value, bool case_insensitive = false) const;
+    template <class T>
+    FindRes find_all_no_copy(T value, InternalFindResult& result) const;
+    template <class T>
+    size_t count(T value) const;
+    template <class T>
+    void update_ref(T value, size_t old_row_ndx, size_t new_row_ndx);
+
+    void clear();
+
+    void distinct(IntegerColumn& result) const;
+    bool has_duplicate_values() const noexcept;
+
+    void verify() const;
+#ifdef REALM_DEBUG
+    template <typename T>
+    void verify_entries(const T& column) const;
+    void do_dump_node_structure(std::ostream&, int) const;
+    void to_dot() const;
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+    void to_dot_2(std::ostream&, StringData title = StringData()) const;
+#endif
+
+    typedef int32_t key_type;
+
+    // s_max_offset specifies the number of levels of recursive string indexes
+    // allowed before storing everything in lists. This is to avoid nesting
+    // to too deep of a level. Since every SubStringIndex stores 4 bytes, this
+    // means that a StringIndex is helpful for strings of a common prefix up to
+    // 4 times this limit (200 bytes shared). Lists are stored in sorted order,
+    // so strings sharing a common prefix of more than this limit will use a
+    // binary search of approximate complexity log2(n) from `std::lower_bound`.
+    static const size_t s_max_offset = 200; // max depth * s_index_key_length
+    static const size_t s_index_key_length = 4;
+    static key_type create_key(StringData) noexcept;
+    static key_type create_key(StringData, size_t) noexcept;
+
+private:
+    // m_array is a compact representation for storing the children of this StringIndex.
+    // Children can be:
+    // 1) a row number
+    // 2) a reference to a list which stores row numbers (for duplicate strings).
+    // 3) a reference to a sub-index
+    // m_array[0] is always a reference to a values array which stores the 4 byte chunk
+    // of payload data for quick string chunk comparisons. The array stored
+    // at m_array[0] lines up with the indices of values in m_array[1] so for example
+    // starting with an empty StringIndex:
+    // StringColumn::insert(target_row_ndx=42, value="test_string") would result with
+    // get_array_from_ref(m_array[0])[0] == create_key("test") and
+    // m_array[1] == 42
+    // In this way, m_array which stores one child has a size of two.
+    // Children are type 1 (row number) if the LSB of the value is set.
+    // To get the actual row value, shift value down by one.
+    // If the LSB of the value is 0 then the value is a reference and can be either
+    // type 2, or type 3 (no shifting in either case).
+    // References point to a list if the context header flag is NOT set.
+    // If the header flag is set, references point to a sub-StringIndex (nesting).
+    std::unique_ptr<IndexArray> m_array;
+    ColumnBase* m_target_column;
+
+    struct inner_node_tag {
+    };
+    StringIndex(inner_node_tag, Allocator&);
+
+    static IndexArray* create_node(Allocator&, bool is_leaf);
+
+    void insert_with_offset(size_t row_ndx, StringData value, size_t offset);
+    void insert_row_list(size_t ref, size_t offset, StringData value);
+    void insert_to_existing_list(size_t row, StringData value, IntegerColumn& list);
+    void insert_to_existing_list_at_lower(size_t row, StringData value, IntegerColumn& list,
+                                          const IntegerColumnIterator& lower);
+    key_type get_last_key() const;
+
+    /// Add small signed \a diff to all elements that are greater than, or equal
+    /// to \a min_row_ndx.
+    void adjust_row_indexes(size_t min_row_ndx, int diff);
+
+    struct NodeChange {
+        size_t ref1;
+        size_t ref2;
+        enum ChangeType { change_None, change_InsertBefore, change_InsertAfter, change_Split } type;
+        NodeChange(ChangeType t, size_t r1 = 0, size_t r2 = 0)
+            : ref1(r1)
+            , ref2(r2)
+            , type(t)
+        {
+        }
+        NodeChange()
+            : ref1(0)
+            , ref2(0)
+            , type(change_None)
+        {
+        }
+    };
+
+    // B-Tree functions
+    void TreeInsert(size_t row_ndx, key_type, size_t offset, StringData value);
+    NodeChange do_insert(size_t ndx, key_type, size_t offset, StringData value);
+    /// Returns true if there is room or it can join existing entries
+    bool leaf_insert(size_t row_ndx, key_type, size_t offset, StringData value, bool noextend = false);
+    void node_insert_split(size_t ndx, size_t new_ref);
+    void node_insert(size_t ndx, size_t ref);
+    void do_delete(size_t ndx, StringData, size_t offset);
+    void do_update_ref(StringData value, size_t row_ndx, size_t new_row_ndx, size_t offset);
+
+    StringData get(size_t ndx, StringConversionBuffer& buffer) const;
+
+    void node_add_key(ref_type ref);
+
+#ifdef REALM_DEBUG
+    static void dump_node_structure(const Array& node, std::ostream&, int level);
+    static void array_to_dot(std::ostream&, const Array&);
+    static void keys_to_dot(std::ostream&, const Array&, StringData title = StringData());
+#endif
+};
+
+
+class SortedListComparator {
+public:
+    SortedListComparator(ColumnBase& column_values);
+    bool operator()(int64_t ndx, StringData needle);
+    bool operator()(StringData needle, int64_t ndx);
+
+private:
+    ColumnBase& values;
+};
+
+
+// Implementation:
+
+template <class T>
+struct GetIndexData;
+
+template <>
+struct GetIndexData<int64_t> {
+    static StringData get_index_data(const int64_t& value, StringIndex::StringConversionBuffer& buffer)
+    {
+        const char* c = reinterpret_cast<const char*>(&value);
+        realm::safe_copy_n(c, sizeof(int64_t), buffer.data());
+        return StringData{buffer.data(), sizeof(int64_t)};
+    }
+};
+
+template <>
+struct GetIndexData<StringData> {
+    static StringData get_index_data(StringData data, StringIndex::StringConversionBuffer&)
+    {
+        return data;
+    }
+};
+
+template <>
+struct GetIndexData<null> {
+    static StringData get_index_data(null, StringIndex::StringConversionBuffer&)
+    {
+        return null{};
+    }
+};
+
+template <>
+struct GetIndexData<Timestamp> {
+    static StringData get_index_data(const Timestamp&, StringIndex::StringConversionBuffer&);
+};
+
+template <class T>
+struct GetIndexData<util::Optional<T>> {
+    static StringData get_index_data(const util::Optional<T>& value, StringIndex::StringConversionBuffer& buffer)
+    {
+        if (value)
+            return GetIndexData<T>::get_index_data(*value, buffer);
+        return null{};
+    }
+};
+
+template <>
+struct GetIndexData<float> {
+    static StringData get_index_data(float, StringIndex::StringConversionBuffer&)
+    {
+        REALM_ASSERT_RELEASE(false); // LCOV_EXCL_LINE; Index on float not supported
+    }
+};
+
+template <>
+struct GetIndexData<double> {
+    static StringData get_index_data(double, StringIndex::StringConversionBuffer&)
+    {
+        REALM_ASSERT_RELEASE(false); // LCOV_EXCL_LINE; Index on float not supported
+    }
+};
+
+template <>
+struct GetIndexData<const char*> : GetIndexData<StringData> {
+};
+
+// to_str() is used by the integer index. The existing StringIndex is re-used for this
+// by making IntegerColumn convert its integers to strings by calling to_str().
+
+template <class T>
+inline StringData to_str(T&& value, StringIndex::StringConversionBuffer& buffer)
+{
+    return GetIndexData<typename std::remove_reference<T>::type>::get_index_data(value, buffer);
+}
+
+
+inline StringIndex::StringIndex(ColumnBase* target_column, Allocator& alloc)
+    : m_array(create_node(alloc, true)) // Throws
+    , m_target_column(target_column)
+{
+}
+
+inline StringIndex::StringIndex(ref_type ref, ArrayParent* parent, size_t ndx_in_parent, ColumnBase* target_column,
+                                Allocator& alloc)
+    : m_array(new IndexArray(alloc))
+    , m_target_column(target_column)
+{
+    REALM_ASSERT_EX(Array::get_context_flag_from_header(alloc.translate(ref)), ref, size_t(alloc.translate(ref)));
+    m_array->init_from_ref(ref);
+    set_parent(parent, ndx_in_parent);
+}
+
+inline StringIndex::StringIndex(inner_node_tag, Allocator& alloc)
+    : m_array(create_node(alloc, false)) // Throws
+    , m_target_column(nullptr)
+{
+}
+
+// Byte order of the key is *reversed*, so that for the integer index, the least significant
+// byte comes first, so that it fits little-endian machines. That way we can perform fast
+// range-lookups and iterate in order, etc, as future features. This, however, makes the same
+// features slower for string indexes. Todo, we should reverse the order conditionally, depending
+// on the column type.
+inline StringIndex::key_type StringIndex::create_key(StringData str) noexcept
+{
+    key_type key = 0;
+
+    if (str.size() >= 4)
+        goto four;
+    if (str.size() < 2) {
+        if (str.size() == 0)
+            goto none;
+        goto one;
+    }
+    if (str.size() == 2)
+        goto two;
+    goto three;
+
+// Create 4 byte index key
+// (encoded like this to allow literal comparisons
+// independently of endianness)
+four:
+    key |= (key_type(static_cast<unsigned char>(str[3])) << 0);
+three:
+    key |= (key_type(static_cast<unsigned char>(str[2])) << 8);
+two:
+    key |= (key_type(static_cast<unsigned char>(str[1])) << 16);
+one:
+    key |= (key_type(static_cast<unsigned char>(str[0])) << 24);
+none:
+    return key;
+}
+
+// Index works as follows: All non-NULL values are stored as if they had appended an 'X' character at the end. So
+// "foo" is stored as if it was "fooX", and "" (empty string) is stored as "X". And NULLs are stored as empty strings.
+inline StringIndex::key_type StringIndex::create_key(StringData str, size_t offset) noexcept
+{
+    if (str.is_null())
+        return 0;
+
+    if (offset > str.size())
+        return 0;
+
+    // for very short strings
+    size_t tail = str.size() - offset;
+    if (tail <= sizeof(key_type) - 1) {
+        char buf[sizeof(key_type)];
+        memset(buf, 0, sizeof(key_type));
+        buf[tail] = 'X';
+        memcpy(buf, str.data() + offset, tail);
+        return create_key(StringData(buf, tail + 1));
+    }
+    // else fallback
+    return create_key(str.substr(offset));
+}
+
+template <class T>
+void StringIndex::insert(size_t row_ndx, T value, size_t num_rows, bool is_append)
+{
+    REALM_ASSERT_3(row_ndx, !=, npos);
+
+    // If the new row is inserted after the last row in the table, we don't need
+    // to adjust any row indexes.
+    if (!is_append) {
+        for (size_t i = 0; i < num_rows; ++i) {
+            size_t row_ndx_2 = row_ndx + i;
+            adjust_row_indexes(row_ndx_2, 1); // Throws
+        }
+    }
+
+    StringConversionBuffer buffer;
+
+    for (size_t i = 0; i < num_rows; ++i) {
+        size_t row_ndx_2 = row_ndx + i;
+        size_t offset = 0;                                            // First key from beginning of string
+        insert_with_offset(row_ndx_2, to_str(value, buffer), offset); // Throws
+    }
+}
+
+template <class T>
+void StringIndex::insert(size_t row_ndx, util::Optional<T> value, size_t num_rows, bool is_append)
+{
+    if (value) {
+        insert(row_ndx, *value, num_rows, is_append);
+    }
+    else {
+        insert(row_ndx, null{}, num_rows, is_append);
+    }
+}
+
+template <class T>
+void StringIndex::set(size_t row_ndx, T new_value)
+{
+    StringConversionBuffer buffer;
+    StringConversionBuffer buffer2;
+    StringData old_value = get(row_ndx, buffer);
+    StringData new_value2 = to_str(new_value, buffer2);
+
+    // Note that insert_with_offset() throws UniqueConstraintViolation.
+
+    if (REALM_LIKELY(new_value2 != old_value)) {
+        // We must erase this row first because erase uses find_first which
+        // might find the duplicate if we insert before erasing.
+        bool is_last = true;        // To avoid updating refs
+        erase<T>(row_ndx, is_last); // Throws
+
+        size_t offset = 0;                               // First key from beginning of string
+        insert_with_offset(row_ndx, new_value2, offset); // Throws
+    }
+}
+
+template <class T>
+void StringIndex::set(size_t row_ndx, util::Optional<T> new_value)
+{
+    if (new_value) {
+        set(row_ndx, *new_value);
+    }
+    else {
+        set(row_ndx, null{});
+    }
+}
+
+template <class T>
+void StringIndex::erase(size_t row_ndx, bool is_last)
+{
+    StringConversionBuffer buffer;
+    StringData value = get(row_ndx, buffer);
+
+    do_delete(row_ndx, value, 0);
+
+    // Collapse top nodes with single item
+    while (m_array->is_inner_bptree_node()) {
+        REALM_ASSERT(m_array->size() > 1); // node cannot be empty
+        if (m_array->size() > 2)
+            break;
+
+        ref_type ref = m_array->get_as_ref(1);
+        m_array->set(1, 1); // avoid destruction of the extracted ref
+        m_array->destroy_deep();
+        m_array->init_from_ref(ref);
+        m_array->update_parent();
+    }
+
+    // If it is last item in column, we don't have to update refs
+    if (!is_last)
+        adjust_row_indexes(row_ndx, -1);
+}
+
+template <class T>
+size_t StringIndex::find_first(T value) const
+{
+    // Use direct access method
+    StringConversionBuffer buffer;
+    return m_array->index_string_find_first(to_str(value, buffer), m_target_column);
+}
+
+template <class T>
+void StringIndex::find_all(IntegerColumn& result, T value, bool case_insensitive) const
+{
+    // Use direct access method
+    StringConversionBuffer buffer;
+    return m_array->index_string_find_all(result, to_str(value, buffer), m_target_column, case_insensitive);
+}
+
+template <class T>
+FindRes StringIndex::find_all_no_copy(T value, InternalFindResult& result) const
+{
+    // Use direct access method
+    StringConversionBuffer buffer;
+    return m_array->index_string_find_all_no_copy(to_str(value, buffer), m_target_column, result);
+}
+
+template <class T>
+size_t StringIndex::count(T value) const
+{
+    // Use direct access method
+    StringConversionBuffer buffer;
+    return m_array->index_string_count(to_str(value, buffer), m_target_column);
+}
+
+template <class T>
+void StringIndex::update_ref(T value, size_t old_row_ndx, size_t new_row_ndx)
+{
+    StringConversionBuffer buffer;
+    do_update_ref(to_str(value, buffer), old_row_ndx, new_row_ndx, 0);
+}
+
+inline void StringIndex::destroy() noexcept
+{
+    return m_array->destroy_deep();
+}
+
+inline bool StringIndex::is_attached() const noexcept
+{
+    return m_array->is_attached();
+}
+
+inline void StringIndex::refresh_accessor_tree(size_t, const Spec&)
+{
+    m_array->init_from_parent();
+}
+
+inline ref_type StringIndex::get_ref() const noexcept
+{
+    return m_array->get_ref();
+}
+
+inline void StringIndex::set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept
+{
+    m_array->set_parent(parent, ndx_in_parent);
+}
+
+inline size_t StringIndex::get_ndx_in_parent() const noexcept
+{
+    return m_array->get_ndx_in_parent();
+}
+
+inline void StringIndex::set_ndx_in_parent(size_t ndx_in_parent) noexcept
+{
+    m_array->set_ndx_in_parent(ndx_in_parent);
+}
+
+inline void StringIndex::update_from_parent(size_t old_baseline) noexcept
+{
+    m_array->update_from_parent(old_baseline);
+}
+
+} // namespace realm
+
+#endif // REALM_INDEX_STRING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/lang_bind_helper.hpp b/node_modules/realm/vendor/realm-ios/include/realm/lang_bind_helper.hpp
new file mode 100644
index 0000000..de287bf
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/lang_bind_helper.hpp
@@ -0,0 +1,378 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_LANG_BIND_HELPER_HPP
+#define REALM_LANG_BIND_HELPER_HPP
+
+#include <cstddef>
+
+#include <realm/table.hpp>
+#include <realm/table_view.hpp>
+#include <realm/link_view.hpp>
+#include <realm/group.hpp>
+#include <realm/group_shared.hpp>
+
+#include <realm/replication.hpp>
+
+namespace realm {
+
+
+/// These functions are only to be used by language bindings to gain
+/// access to certain memebers that are othewise private.
+///
+/// \note Applications are not supposed to call any of these functions
+/// directly.
+///
+/// All of the get_subtable_ptr() functions bind the table accessor pointer
+/// before it is returned (bind_table_ptr()). The caller is then responsible for
+/// making the corresponding call to unbind_table_ptr().
+class LangBindHelper {
+public:
+    /// Increment the reference counter of the specified table accessor. This is
+    /// done automatically by all of the functions in this class that return
+    /// table accessor pointers, but if the binding/application makes a copy of
+    /// such a pointer, and the copy needs to have an "independent life", then
+    /// the binding/application must bind that copy using this function.
+    static void bind_table_ptr(const Table*) noexcept;
+
+    /// Decrement the reference counter of the specified table accessor. The
+    /// binding/application must call this function for every bound table
+    /// accessor pointer object, when that pointer object ends its life.
+    static void unbind_table_ptr(const Table*) noexcept;
+
+    /// Construct a new freestanding table. The table accessor pointer is bound
+    /// by the callee before it is returned (bind_table_ptr()).
+    static Table* new_table();
+
+    /// Construct a new freestanding table as a copy of the specified one. The
+    /// table accessor pointer is bound by the callee before it is returned
+    /// (bind_table_ptr()).
+    static Table* copy_table(const Table&);
+
+    //@{
+
+    /// These functions are like their namesakes in Group, but these bypass the
+    /// construction of a smart-pointer object (TableRef). The table accessor
+    /// pointer is bound by the callee before it is returned (bind_table_ptr()).
+
+    static Table* get_table(Group&, size_t index_in_group);
+    static const Table* get_table(const Group&, size_t index_in_group);
+
+    static Table* get_table(Group&, StringData name);
+    static const Table* get_table(const Group&, StringData name);
+
+    static Table* add_table(Group&, StringData name, bool require_unique_name = true);
+    static Table* get_or_add_table(Group&, StringData name, bool* was_added = nullptr);
+
+    //@}
+
+    static Table* get_subtable_ptr(Table*, size_t column_ndx, size_t row_ndx);
+    static const Table* get_subtable_ptr(const Table*, size_t column_ndx, size_t row_ndx);
+
+    // FIXME: This is an 'oddball', do we really need it? If we do,
+    // please provide a comment that explains why it is needed!
+    static Table* get_subtable_ptr_during_insert(Table*, size_t col_ndx, size_t row_ndx);
+
+    static Table* get_subtable_ptr(TableView*, size_t column_ndx, size_t row_ndx);
+    static const Table* get_subtable_ptr(const TableView*, size_t column_ndx, size_t row_ndx);
+    static const Table* get_subtable_ptr(const ConstTableView*, size_t column_ndx, size_t row_ndx);
+
+    /// Calls parent.set_mixed_subtable(col_ndx, row_ndx, &source). Note
+    /// that the source table must have a descriptor that is
+    /// compatible with the target subtable column.
+    static void set_mixed_subtable(Table& parent, size_t col_ndx, size_t row_ndx, const Table& source);
+
+    static const LinkViewRef& get_linklist_ptr(Row&, size_t col_ndx);
+    static void unbind_linklist_ptr(const LinkViewRef&);
+
+    using VersionID = SharedGroup::VersionID;
+
+    /// \defgroup lang_bind_helper_transactions Continuous Transactions
+    ///
+    /// advance_read() is equivalent to terminating the current read transaction
+    /// (SharedGroup::end_read()), and initiating a new one
+    /// (SharedGroup::begin_read()), except that all subordinate accessors
+    /// (Table, Row, Descriptor) will remain attached to the underlying objects,
+    /// unless those objects were removed in the target snapshot. By default,
+    /// the read transaction is advanced to the latest available snapshot, but
+    /// see SharedGroup::begin_read() for information about \a version.
+    ///
+    /// promote_to_write() is equivalent to terminating the current read
+    /// transaction (SharedGroup::end_read()), and initiating a new write
+    /// transaction (SharedGroup::begin_write()), except that all subordinate
+    /// accessors (Table, Row, Descriptor) will remain attached to the
+    /// underlying objects, unless those objects were removed in the target
+    /// snapshot.
+    ///
+    /// commit_and_continue_as_read() is equivalent to committing the current
+    /// write transaction (SharedGroup::commit()) and initiating a new read
+    /// transaction, which is bound to the snapshot produced by the write
+    /// transaction (SharedGroup::begin_read()), except that all subordinate
+    /// accessors (Table, Row, Descriptor) will remain attached to the
+    /// underlying objects. commit_and_continue_as_read() returns the version
+    /// produced by the committed transaction.
+    ///
+    /// rollback_and_continue_as_read() is equivalent to rolling back the
+    /// current write transaction (SharedGroup::rollback()) and initiating a new
+    /// read transaction, which is bound to the snapshot, that the write
+    /// transaction was based on (SharedGroup::begin_read()), except that all
+    /// subordinate accessors (Table, Row, Descriptor) will remain attached to
+    /// the underlying objects, unless they were attached to object that were
+    /// added during the rolled back transaction.
+    ///
+    /// If advance_read(), promote_to_write(), commit_and_continue_as_read(), or
+    /// rollback_and_continue_as_read() throws, the associated group accessor
+    /// and all of its subordinate accessors are left in a state that may not be
+    /// fully consistent. Only minimal consistency is guaranteed (see
+    /// AccessorConsistencyLevels). In this case, the application is required to
+    /// either destroy the SharedGroup object, forcing all associated accessors
+    /// to become detached, or take some other equivalent action that involves a
+    /// complete accessor detachment, such as terminating the transaction in
+    /// progress. Until then it is an error, and unsafe if the application
+    /// attempts to access any of those accessors.
+    ///
+    /// The application must use SharedGroup::end_read() if it wants to
+    /// terminate the transaction after advance_read() or promote_to_write() has
+    /// thrown an exception. Likewise, it must use SharedGroup::rollback() if it
+    /// wants to terminate the transaction after commit_and_continue_as_read()
+    /// or rollback_and_continue_as_read() has thrown an exception.
+    ///
+    /// \param observer An optional custom replication instruction handler. The
+    /// application may pass such a handler to observe the sequence of
+    /// modifications that advances (or rolls back) the state of the Realm.
+    ///
+    /// \throw SharedGroup::BadVersion Thrown by advance_read() if the specified
+    /// version does not correspond to a bound (or tethered) snapshot.
+    ///
+    //@{
+
+    static void advance_read(SharedGroup&, VersionID = VersionID());
+    template <class O>
+    static void advance_read(SharedGroup&, O&& observer, VersionID = VersionID());
+    static void promote_to_write(SharedGroup&);
+    template <class O>
+    static void promote_to_write(SharedGroup&, O&& observer);
+    static SharedGroup::version_type commit_and_continue_as_read(SharedGroup&);
+    static void rollback_and_continue_as_read(SharedGroup&);
+    template <class O>
+    static void rollback_and_continue_as_read(SharedGroup&, O&& observer);
+
+    //@}
+
+    /// Returns the name of the specified data type. Examples:
+    ///
+    /// <pre>
+    ///
+    ///   type_Int          ->  "int"
+    ///   type_Bool         ->  "bool"
+    ///   type_Float        ->  "float"
+    ///   ...
+    ///
+    /// </pre>
+    static const char* get_data_type_name(DataType) noexcept;
+
+    static SharedGroup::version_type get_version_of_latest_snapshot(SharedGroup&);
+};
+
+
+// Implementation:
+
+inline Table* LangBindHelper::new_table()
+{
+    typedef _impl::TableFriend tf;
+    Allocator& alloc = Allocator::get_default();
+    size_t ref = tf::create_empty_table(alloc); // Throws
+    Table::Parent* parent = nullptr;
+    size_t ndx_in_parent = 0;
+    Table* table = tf::create_accessor(alloc, ref, parent, ndx_in_parent); // Throws
+    bind_table_ptr(table);
+    return table;
+}
+
+inline Table* LangBindHelper::copy_table(const Table& table)
+{
+    typedef _impl::TableFriend tf;
+    Allocator& alloc = Allocator::get_default();
+    size_t ref = tf::clone(table, alloc); // Throws
+    Table::Parent* parent = nullptr;
+    size_t ndx_in_parent = 0;
+    Table* copy_of_table = tf::create_accessor(alloc, ref, parent, ndx_in_parent); // Throws
+    bind_table_ptr(copy_of_table);
+    return copy_of_table;
+}
+
+inline Table* LangBindHelper::get_subtable_ptr(Table* t, size_t column_ndx, size_t row_ndx)
+{
+    TableRef subtab = t->get_subtable_tableref(column_ndx, row_ndx); // Throws
+    return subtab.release();
+}
+
+inline const Table* LangBindHelper::get_subtable_ptr(const Table* t, size_t column_ndx, size_t row_ndx)
+{
+    ConstTableRef subtab = t->get_subtable_tableref(column_ndx, row_ndx); // Throws
+    return subtab.release();
+}
+
+inline Table* LangBindHelper::get_subtable_ptr(TableView* tv, size_t column_ndx, size_t row_ndx)
+{
+    return get_subtable_ptr(&tv->get_parent(), column_ndx, tv->get_source_ndx(row_ndx));
+}
+
+inline const Table* LangBindHelper::get_subtable_ptr(const TableView* tv, size_t column_ndx, size_t row_ndx)
+{
+    return get_subtable_ptr(&tv->get_parent(), column_ndx, tv->get_source_ndx(row_ndx));
+}
+
+inline const Table* LangBindHelper::get_subtable_ptr(const ConstTableView* tv, size_t column_ndx, size_t row_ndx)
+{
+    return get_subtable_ptr(&tv->get_parent(), column_ndx, tv->get_source_ndx(row_ndx));
+}
+
+inline Table* LangBindHelper::get_table(Group& group, size_t index_in_group)
+{
+    typedef _impl::GroupFriend gf;
+    Table* table = &gf::get_table(group, index_in_group); // Throws
+    table->bind_ptr();
+    return table;
+}
+
+inline const Table* LangBindHelper::get_table(const Group& group, size_t index_in_group)
+{
+    typedef _impl::GroupFriend gf;
+    const Table* table = &gf::get_table(group, index_in_group); // Throws
+    table->bind_ptr();
+    return table;
+}
+
+inline Table* LangBindHelper::get_table(Group& group, StringData name)
+{
+    typedef _impl::GroupFriend gf;
+    Table* table = gf::get_table(group, name); // Throws
+    if (table)
+        table->bind_ptr();
+    return table;
+}
+
+inline const Table* LangBindHelper::get_table(const Group& group, StringData name)
+{
+    typedef _impl::GroupFriend gf;
+    const Table* table = gf::get_table(group, name); // Throws
+    if (table)
+        table->bind_ptr();
+    return table;
+}
+
+inline Table* LangBindHelper::add_table(Group& group, StringData name, bool require_unique_name)
+{
+    typedef _impl::GroupFriend gf;
+    Table* table = &gf::add_table(group, name, require_unique_name); // Throws
+    table->bind_ptr();
+    return table;
+}
+
+inline Table* LangBindHelper::get_or_add_table(Group& group, StringData name, bool* was_added)
+{
+    typedef _impl::GroupFriend gf;
+    Table* table = &gf::get_or_add_table(group, name, was_added); // Throws
+    table->bind_ptr();
+    return table;
+}
+
+inline void LangBindHelper::unbind_table_ptr(const Table* t) noexcept
+{
+    t->unbind_ptr();
+}
+
+inline void LangBindHelper::bind_table_ptr(const Table* t) noexcept
+{
+    t->bind_ptr();
+}
+
+inline void LangBindHelper::set_mixed_subtable(Table& parent, size_t col_ndx, size_t row_ndx, const Table& source)
+{
+    parent.set_mixed_subtable(col_ndx, row_ndx, &source);
+}
+
+inline const LinkViewRef& LangBindHelper::get_linklist_ptr(Row& row, size_t col_ndx)
+{
+    LinkViewRef* link_view = new LinkViewRef(row.get_linklist(col_ndx));
+    return *link_view;
+}
+
+inline void LangBindHelper::unbind_linklist_ptr(const LinkViewRef& link_view)
+{
+    delete (&link_view);
+}
+
+inline void LangBindHelper::advance_read(SharedGroup& sg, VersionID version)
+{
+    using sgf = _impl::SharedGroupFriend;
+    _impl::NullInstructionObserver* observer = nullptr;
+    sgf::advance_read(sg, observer, version); // Throws
+}
+
+template <class O>
+inline void LangBindHelper::advance_read(SharedGroup& sg, O&& observer, VersionID version)
+{
+    using sgf = _impl::SharedGroupFriend;
+    sgf::advance_read(sg, &observer, version); // Throws
+}
+
+inline void LangBindHelper::promote_to_write(SharedGroup& sg)
+{
+    using sgf = _impl::SharedGroupFriend;
+    _impl::NullInstructionObserver* observer = nullptr;
+    sgf::promote_to_write(sg, observer); // Throws
+}
+
+template <class O>
+inline void LangBindHelper::promote_to_write(SharedGroup& sg, O&& observer)
+{
+    using sgf = _impl::SharedGroupFriend;
+    sgf::promote_to_write(sg, &observer); // Throws
+}
+
+inline SharedGroup::version_type LangBindHelper::commit_and_continue_as_read(SharedGroup& sg)
+{
+    using sgf = _impl::SharedGroupFriend;
+    return sgf::commit_and_continue_as_read(sg); // Throws
+}
+
+inline void LangBindHelper::rollback_and_continue_as_read(SharedGroup& sg)
+{
+    using sgf = _impl::SharedGroupFriend;
+    _impl::NullInstructionObserver* observer = nullptr;
+    sgf::rollback_and_continue_as_read(sg, observer); // Throws
+}
+
+template <class O>
+inline void LangBindHelper::rollback_and_continue_as_read(SharedGroup& sg, O&& observer)
+{
+    using sgf = _impl::SharedGroupFriend;
+    sgf::rollback_and_continue_as_read(sg, &observer); // Throws
+}
+
+inline SharedGroup::version_type LangBindHelper::get_version_of_latest_snapshot(SharedGroup& sg)
+{
+    using sgf = _impl::SharedGroupFriend;
+    return sgf::get_version_of_latest_snapshot(sg); // Throws
+}
+
+} // namespace realm
+
+#endif // REALM_LANG_BIND_HELPER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/link_view.hpp b/node_modules/realm/vendor/realm-ios/include/realm/link_view.hpp
new file mode 100644
index 0000000..14be525
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/link_view.hpp
@@ -0,0 +1,397 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_LINK_VIEW_HPP
+#define REALM_LINK_VIEW_HPP
+
+#include <realm/column.hpp>
+#include <realm/column_linklist.hpp>
+#include <realm/link_view_fwd.hpp>
+#include <realm/table.hpp>
+
+namespace realm {
+
+class LinkListColumn;
+
+namespace _impl {
+class LinkListFriend;
+class TransactLogConvenientEncoder;
+}
+
+
+/// The effect of calling most of the link list functions on a detached accessor
+/// is unspecified and may lead to general corruption, or even a crash. The
+/// exceptions are is_attached() and the destructor.
+///
+/// FIXME: Rename this class to `LinkList`.
+class LinkView : public RowIndexes, public std::enable_shared_from_this<LinkView> {
+public:
+    ~LinkView() noexcept;
+    bool is_attached() const noexcept;
+
+    /// This method will return true if the LinkView is detached (no assert).
+    bool is_empty() const noexcept;
+
+    /// This method will return 0 if the LinkView is detached (no assert).
+    size_t size() const noexcept override;
+
+    bool operator==(const LinkView&) const noexcept;
+    bool operator!=(const LinkView&) const noexcept;
+
+    // Getting links
+    Table::ConstRowExpr operator[](size_t link_ndx) const noexcept;
+    Table::RowExpr operator[](size_t link_ndx) noexcept;
+    Table::ConstRowExpr get(size_t link_ndx) const noexcept;
+    Table::RowExpr get(size_t link_ndx) noexcept;
+
+    // Modifiers
+    void add(size_t target_row_ndx);
+    void insert(size_t link_ndx, size_t target_row_ndx);
+    void set(size_t link_ndx, size_t target_row_ndx);
+    /// Move the link at \a from_ndx such that it ends up at \a to_ndx. Other
+    /// links are shifted as necessary in such a way that their order is
+    /// preserved.
+    ///
+    /// Note that \a to_ndx is the desired final index of the moved link,
+    /// therefore, `move(1,1)` is a no-op, while `move(1,2)` moves the link at
+    /// index 1 by one position, such that it ends up at index 2. A side-effect
+    /// of that, is that the link, that was originally at index 2, is moved to
+    /// index 1.
+    void move(size_t from_ndx, size_t to_ndx);
+    void swap(size_t link1_ndx, size_t link2_ndx);
+    void remove(size_t link_ndx);
+    void clear();
+
+    void sort(size_t column, bool ascending = true);
+    void sort(SortDescriptor&& order);
+
+    TableView get_sorted_view(size_t column_index, bool ascending = true) const;
+    TableView get_sorted_view(SortDescriptor order) const;
+
+    /// Remove the target row of the specified link from the target table. This
+    /// also removes the specified link from this link list, and any other link
+    /// pointing to that row. This is merely a shorthand for
+    /// `get_target_table.move_last_over(get(link_ndx))`.
+    void remove_target_row(size_t link_ndx);
+
+    /// Remove all target rows pointed to by links in this link list, and clear
+    /// this link list.
+    void remove_all_target_rows();
+
+    /// Search this list for a link to the specified target table row (specified
+    /// by its index in the target table). If found, the index of the link to
+    /// that row within this list is returned, otherwise `realm::not_found` is
+    /// returned.
+    size_t find(size_t target_row_ndx, size_t start = 0) const noexcept;
+
+    const ColumnBase& get_column_base(size_t index)
+        const override; // FIXME: `ColumnBase` is not part of the public API, so this function must be made private.
+    const Table& get_origin_table() const noexcept;
+    Table& get_origin_table() noexcept;
+
+    size_t get_origin_row_index() const noexcept;
+
+    const Table& get_target_table() const noexcept;
+    Table& get_target_table() noexcept;
+
+    // No-op because LinkViews are always kept in sync.
+    uint_fast64_t sync_if_needed() const override;
+    bool is_in_sync() const override
+    {
+        return true;
+    }
+
+private:
+    struct ctor_cookie {
+    };
+
+    TableRef m_origin_table;
+    LinkListColumn* m_origin_column;
+
+    using HandoverPatch = LinkViewHandoverPatch;
+    static void generate_patch(const ConstLinkViewRef& ref, std::unique_ptr<HandoverPatch>& patch);
+    static LinkViewRef create_from_and_consume_patch(std::unique_ptr<HandoverPatch>& patch, Group& group);
+
+    void detach();
+    void set_origin_row_index(size_t row_ndx) noexcept;
+
+    void do_insert(size_t link_ndx, size_t target_row_ndx);
+    size_t do_set(size_t link_ndx, size_t target_row_ndx);
+    size_t do_remove(size_t link_ndx);
+    void do_clear(bool broken_reciprocal_backlinks);
+
+    void do_nullify_link(size_t old_target_row_ndx);
+    void do_update_link(size_t old_target_row_ndx, size_t new_target_row_ndx);
+    void do_swap_link(size_t target_row_ndx_1, size_t target_row_ndx_2);
+
+    void refresh_accessor_tree(size_t new_row_ndx) noexcept;
+
+    void update_from_parent(size_t old_baseline) noexcept;
+
+    Replication* get_repl() noexcept;
+    void repl_unselect() noexcept;
+    friend class _impl::TransactLogConvenientEncoder;
+
+#ifdef REALM_DEBUG
+    void verify(size_t row_ndx) const;
+#endif
+    // allocate using make_shared:
+    static std::shared_ptr<LinkView> create(Table* origin_table, LinkListColumn&, size_t row_ndx);
+    static std::shared_ptr<LinkView> create_detached();
+
+    friend class _impl::LinkListFriend;
+    friend class LinkListColumn;
+    friend class LangBindHelper;
+    friend class SharedGroup;
+    friend class Query;
+    friend class TableViewBase;
+
+    // must be public for use by make_shared, but cannot be called from outside,
+    // because ctor_cookie is private
+public:
+    LinkView(const ctor_cookie&, Table* origin_table, LinkListColumn&, size_t row_ndx);
+    LinkView(const ctor_cookie&);
+};
+
+
+// Implementation
+
+inline LinkView::LinkView(const ctor_cookie&, Table* origin_table, LinkListColumn& column, size_t row_ndx)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), column.get_alloc()) // Throws
+    , m_origin_table(origin_table->get_table_ref())
+    , m_origin_column(&column)
+{
+    m_row_indexes.set_parent(m_origin_column, row_ndx);
+    m_row_indexes.init_from_parent();
+}
+
+// create a detached LinkView. Only partially initialized, as it will never be used for
+// anything, but indicating that it is detached.
+inline LinkView::LinkView(const ctor_cookie&)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default()) // Throws
+    , m_origin_table(TableRef())
+    , m_origin_column(nullptr)
+{
+}
+
+inline std::shared_ptr<LinkView> LinkView::create(Table* origin_table, LinkListColumn& column, size_t row_ndx)
+{
+    return std::make_shared<LinkView>(ctor_cookie(), origin_table, column, row_ndx);
+}
+
+inline std::shared_ptr<LinkView> LinkView::create_detached()
+{
+    return std::make_shared<LinkView>(ctor_cookie());
+}
+
+inline LinkView::~LinkView() noexcept
+{
+    if (is_attached()) {
+        repl_unselect();
+        m_origin_column->unregister_linkview();
+    }
+}
+
+inline void LinkView::detach()
+{
+    REALM_ASSERT(is_attached());
+    repl_unselect();
+    m_origin_table.reset();
+    m_row_indexes.detach();
+}
+
+inline bool LinkView::is_attached() const noexcept
+{
+    return static_cast<bool>(m_origin_table);
+}
+
+inline bool LinkView::is_empty() const noexcept
+{
+    if (!is_attached())
+        return true;
+
+    if (!m_row_indexes.is_attached())
+        return true;
+
+    return m_row_indexes.is_empty();
+}
+
+inline size_t LinkView::size() const noexcept
+{
+    if (!is_attached())
+        return 0;
+
+    if (!m_row_indexes.is_attached())
+        return 0;
+
+    return m_row_indexes.size();
+}
+
+inline bool LinkView::operator==(const LinkView& link_list) const noexcept
+{
+    Table& target_table_1 = m_origin_column->get_target_table();
+    Table& target_table_2 = link_list.m_origin_column->get_target_table();
+    if (target_table_1.get_index_in_group() != target_table_2.get_index_in_group())
+        return false;
+    if (!m_row_indexes.is_attached() || m_row_indexes.is_empty()) {
+        return !link_list.m_row_indexes.is_attached() || link_list.m_row_indexes.is_empty();
+    }
+    return link_list.m_row_indexes.is_attached() && m_row_indexes.compare(link_list.m_row_indexes);
+}
+
+inline bool LinkView::operator!=(const LinkView& link_list) const noexcept
+{
+    return !(*this == link_list);
+}
+
+inline Table::ConstRowExpr LinkView::get(size_t link_ndx) const noexcept
+{
+    return const_cast<LinkView*>(this)->get(link_ndx);
+}
+
+inline Table::RowExpr LinkView::get(size_t link_ndx) noexcept
+{
+    REALM_ASSERT(is_attached());
+    REALM_ASSERT(m_row_indexes.is_attached());
+    REALM_ASSERT_3(link_ndx, <, m_row_indexes.size());
+
+    Table& target_table = m_origin_column->get_target_table();
+    size_t target_row_ndx = to_size_t(m_row_indexes.get(link_ndx));
+    return target_table[target_row_ndx];
+}
+
+inline Table::ConstRowExpr LinkView::operator[](size_t link_ndx) const noexcept
+{
+    return get(link_ndx);
+}
+
+inline Table::RowExpr LinkView::operator[](size_t link_ndx) noexcept
+{
+    return get(link_ndx);
+}
+
+inline void LinkView::add(size_t target_row_ndx)
+{
+    REALM_ASSERT(is_attached());
+    size_t ins_pos = (m_row_indexes.is_attached()) ? m_row_indexes.size() : 0;
+    insert(ins_pos, target_row_ndx);
+}
+
+inline size_t LinkView::find(size_t target_row_ndx, size_t start) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    REALM_ASSERT_3(target_row_ndx, <, m_origin_column->get_target_table().size());
+    REALM_ASSERT_3(start, <=, size());
+
+    if (!m_row_indexes.is_attached())
+        return not_found;
+
+    return m_row_indexes.find_first(target_row_ndx, start);
+}
+
+inline const ColumnBase& LinkView::get_column_base(size_t index) const
+{
+    return get_target_table().get_column_base(index);
+}
+
+inline const Table& LinkView::get_origin_table() const noexcept
+{
+    return *m_origin_table;
+}
+
+inline Table& LinkView::get_origin_table() noexcept
+{
+    return *m_origin_table;
+}
+
+inline size_t LinkView::get_origin_row_index() const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_row_indexes.get_root_array()->get_ndx_in_parent();
+}
+
+inline void LinkView::set_origin_row_index(size_t row_ndx) noexcept
+{
+    REALM_ASSERT(is_attached());
+    m_row_indexes.get_root_array()->set_ndx_in_parent(row_ndx);
+}
+
+inline const Table& LinkView::get_target_table() const noexcept
+{
+    return m_origin_column->get_target_table();
+}
+
+inline Table& LinkView::get_target_table() noexcept
+{
+    return m_origin_column->get_target_table();
+}
+
+inline void LinkView::refresh_accessor_tree(size_t new_row_ndx) noexcept
+{
+    set_origin_row_index(new_row_ndx);
+    m_row_indexes.init_from_parent();
+}
+
+inline void LinkView::update_from_parent(size_t old_baseline) noexcept
+{
+    if (m_row_indexes.is_attached())
+        m_row_indexes.update_from_parent(old_baseline);
+}
+
+inline Replication* LinkView::get_repl() noexcept
+{
+    typedef _impl::TableFriend tf;
+    return tf::get_repl(*m_origin_table);
+}
+
+
+// The purpose of this class is to give internal access to some, but not all of
+// the non-public parts of LinkView.
+class _impl::LinkListFriend {
+public:
+    static void do_set(LinkView& list, size_t link_ndx, size_t target_row_ndx)
+    {
+        list.do_set(link_ndx, target_row_ndx);
+    }
+
+    static void do_remove(LinkView& list, size_t link_ndx)
+    {
+        list.do_remove(link_ndx);
+    }
+
+    static void do_clear(LinkView& list)
+    {
+        bool broken_reciprocal_backlinks = false;
+        list.do_clear(broken_reciprocal_backlinks);
+    }
+
+    static void do_insert(LinkView& list, size_t link_ndx, size_t target_row_ndx)
+    {
+        list.do_insert(link_ndx, target_row_ndx);
+    }
+
+    static const LinkListColumn& get_origin_column(const LinkView& list)
+    {
+        REALM_ASSERT(list.is_attached());
+        return *list.m_origin_column;
+    }
+};
+
+} // namespace realm
+
+#endif // REALM_LINK_VIEW_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/link_view_fwd.hpp b/node_modules/realm/vendor/realm-ios/include/realm/link_view_fwd.hpp
new file mode 100644
index 0000000..cba8801
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/link_view_fwd.hpp
@@ -0,0 +1,32 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_LINK_VIEW_FWD_HPP
+#define REALM_LINK_VIEW_FWD_HPP
+
+#include <memory>
+
+namespace realm {
+
+class LinkView;
+using LinkViewRef = std::shared_ptr<LinkView>;
+using ConstLinkViewRef = std::shared_ptr<const LinkView>;
+
+} // namespace realm
+
+#endif // REALM_LINK_VIEW_FWD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/metrics/metric_timer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/metrics/metric_timer.hpp
new file mode 100644
index 0000000..27ff716
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/metrics/metric_timer.hpp
@@ -0,0 +1,100 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_METRIC_TIMER_HPP
+#define REALM_METRIC_TIMER_HPP
+
+#include <realm/util/features.h>
+
+#include <chrono>
+#include <memory>
+#include <ostream>
+
+namespace realm {
+namespace metrics {
+
+using nanosecond_storage_t = int64_t;
+
+class MetricTimerResult
+{
+public:
+    MetricTimerResult();
+    ~MetricTimerResult();
+    nanosecond_storage_t get_elapsed_nanoseconds() const;
+    void report_nanoseconds(nanosecond_storage_t time);
+protected:
+    nanosecond_storage_t m_elapsed_nanoseconds;
+};
+
+
+class MetricTimer {
+public:
+    MetricTimer(std::shared_ptr<MetricTimerResult> destination = nullptr);
+    ~MetricTimer();
+
+    void reset();
+
+    /// Returns elapsed time in nanoseconds since last call to reset().
+    nanosecond_storage_t get_elapsed_nanoseconds() const;
+    /// Same as get_elapsed_time().
+    operator nanosecond_storage_t() const;
+
+    /// Format the elapsed time on the form 0h00m, 00m00s, 00.00s, or
+    /// 000.0ms depending on magnitude.
+    static void format(nanosecond_storage_t nanoseconds, std::ostream&);
+
+    static std::string format(nanosecond_storage_t nanoseconds);
+
+private:
+    using clock_type = std::chrono::high_resolution_clock;
+    using time_point = std::chrono::time_point<clock_type>;
+    time_point m_start;
+    time_point m_paused_at;
+    std::shared_ptr<MetricTimerResult> m_dest;
+
+    time_point get_timer_ticks() const;
+    nanosecond_storage_t calc_elapsed_nanoseconds(time_point begin, time_point end) const;
+};
+
+
+inline void MetricTimer::reset()
+{
+    m_start = get_timer_ticks();
+}
+
+inline nanosecond_storage_t MetricTimer::get_elapsed_nanoseconds() const
+{
+    return calc_elapsed_nanoseconds(m_start, get_timer_ticks());
+}
+
+inline MetricTimer::operator nanosecond_storage_t() const
+{
+    return get_elapsed_nanoseconds();
+}
+
+inline std::ostream& operator<<(std::ostream& out, const MetricTimer& timer)
+{
+    MetricTimer::format(timer, out);
+    return out;
+}
+
+
+} // namespace metrics
+} // namespace realm
+
+#endif // REALM_METRIC_TIMER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/metrics/metrics.hpp b/node_modules/realm/vendor/realm-ios/include/realm/metrics/metrics.hpp
new file mode 100644
index 0000000..27a526d
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/metrics/metrics.hpp
@@ -0,0 +1,76 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_METRICS_HPP
+#define REALM_METRICS_HPP
+
+#include <memory>
+
+#include <realm/metrics/query_info.hpp>
+#include <realm/metrics/transaction_info.hpp>
+#include <realm/util/features.h>
+#include "realm/util/fixed_size_buffer.hpp"
+
+namespace realm {
+
+class Group;
+
+namespace metrics {
+
+class Metrics {
+public:
+    Metrics(size_t max_history_size);
+    ~Metrics() noexcept;
+    size_t num_query_metrics() const;
+    size_t num_transaction_metrics() const;
+
+    void add_query(QueryInfo info);
+    void add_transaction(TransactionInfo info);
+
+    void start_read_transaction();
+    void start_write_transaction();
+    void end_read_transaction(size_t total_size, size_t free_space, size_t num_objects, size_t num_versions,
+                              size_t num_decrypted_pages);
+    void end_write_transaction(size_t total_size, size_t free_space, size_t num_objects, size_t num_versions,
+                               size_t num_decrypted_pages);
+    static std::unique_ptr<MetricTimer> report_fsync_time(const Group& g);
+    static std::unique_ptr<MetricTimer> report_write_time(const Group& g);
+
+    using QueryInfoList = util::FixedSizeBuffer<QueryInfo>;
+    using TransactionInfoList = util::FixedSizeBuffer<TransactionInfo>;
+
+    // Get the list of metric objects tracked since the last take
+    std::unique_ptr<QueryInfoList> take_queries();
+    std::unique_ptr<TransactionInfoList> take_transactions();
+private:
+    std::unique_ptr<QueryInfoList> m_query_info;
+    std::unique_ptr<TransactionInfoList> m_transaction_info;
+
+    std::unique_ptr<TransactionInfo> m_pending_read;
+    std::unique_ptr<TransactionInfo> m_pending_write;
+
+    size_t m_max_num_queries;
+    size_t m_max_num_transactions;
+};
+
+} // namespace metrics
+} // namespace realm
+
+
+
+#endif // REALM_METRICS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/metrics/query_info.hpp b/node_modules/realm/vendor/realm-ios/include/realm/metrics/query_info.hpp
new file mode 100644
index 0000000..54b78d8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/metrics/query_info.hpp
@@ -0,0 +1,71 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_QUERY_INFO_HPP
+#define REALM_QUERY_INFO_HPP
+
+#include <memory>
+#include <string>
+#include <sstream>
+
+#include <realm/array.hpp>
+#include <realm/util/features.h>
+#include <realm/metrics/metric_timer.hpp>
+
+namespace realm {
+
+class Query; // forward declare in namespace realm
+
+namespace metrics {
+
+class QueryInfo {
+public:
+
+    enum QueryType {
+        type_Find,
+        type_FindAll,
+        type_Count,
+        type_Sum,
+        type_Average,
+        type_Maximum,
+        type_Minimum,
+        type_Invalid
+    };
+
+    QueryInfo(const Query* query, QueryType type);
+    ~QueryInfo() noexcept;
+
+    std::string get_description() const;
+    std::string get_table_name() const;
+    QueryType get_type() const;
+    nanosecond_storage_t get_query_time_nanoseconds() const;
+
+    static std::unique_ptr<MetricTimer> track(const Query* query, QueryType type);
+    static QueryType type_from_action(Action action);
+
+private:
+    std::string m_description;
+    std::string m_table_name;
+    QueryType m_type;
+    std::shared_ptr<MetricTimerResult> m_query_time;
+};
+
+} // namespace metrics
+} // namespace realm
+
+#endif // REALM_QUERY_INFO_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/metrics/transaction_info.hpp b/node_modules/realm/vendor/realm-ios/include/realm/metrics/transaction_info.hpp
new file mode 100644
index 0000000..efcc2a6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/metrics/transaction_info.hpp
@@ -0,0 +1,76 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_TRANSACTION_INFO_HPP
+#define REALM_TRANSACTION_INFO_HPP
+
+#include <memory>
+#include <string>
+
+#include <realm/metrics/metric_timer.hpp>
+#include <realm/util/features.h>
+
+namespace realm {
+namespace metrics {
+
+class Metrics;
+
+class TransactionInfo {
+public:
+    enum TransactionType {
+        read_transaction,
+        write_transaction
+    };
+    TransactionInfo(TransactionType type);
+    TransactionInfo(const TransactionInfo&) = default;
+    ~TransactionInfo() noexcept;
+
+    TransactionType get_transaction_type() const;
+    // the transaction time is a total amount which includes fsync_time + write_time + user_time
+    nanosecond_storage_t get_transaction_time_nanoseconds() const;
+    nanosecond_storage_t get_fsync_time_nanoseconds() const;
+    nanosecond_storage_t get_write_time_nanoseconds() const;
+    size_t get_disk_size() const;
+    size_t get_free_space() const;
+    size_t get_total_objects() const;
+    size_t get_num_available_versions() const;
+    size_t get_num_decrypted_pages() const;
+
+private:
+    MetricTimerResult m_transaction_time;
+    std::shared_ptr<MetricTimerResult> m_fsync_time;
+    std::shared_ptr<MetricTimerResult> m_write_time;
+    MetricTimer m_transact_timer;
+
+    size_t m_realm_disk_size;
+    size_t m_realm_free_space;
+    size_t m_total_objects;
+    TransactionType m_type;
+    size_t m_num_versions;
+    size_t m_num_decrypted_pages;
+
+    friend class Metrics;
+    void update_stats(size_t disk_size, size_t free_space, size_t total_objects, size_t available_versions,
+                      size_t num_decrypted_pages);
+    void finish_timer();
+};
+
+} // namespace metrics
+} // namespace realm
+
+#endif // REALM_TRANSACTION_INFO_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/mixed.hpp b/node_modules/realm/vendor/realm-ios/include/realm/mixed.hpp
new file mode 100644
index 0000000..243ed45
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/mixed.hpp
@@ -0,0 +1,732 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_MIXED_HPP
+#define REALM_MIXED_HPP
+
+#include <cstdint> // int64_t - not part of C++03, not even required by C++11 (see C++11 section 18.4.1)
+
+#include <cstddef> // size_t
+#include <cstring>
+
+#include <realm/binary_data.hpp>
+#include <realm/data_type.hpp>
+#include <realm/olddatetime.hpp>
+#include <realm/string_data.hpp>
+#include <realm/timestamp.hpp>
+#include <realm/util/assert.hpp>
+#include <realm/utilities.hpp>
+
+namespace realm {
+
+
+/// This class represents a polymorphic Realm value.
+///
+/// At any particular moment an instance of this class stores a
+/// definite value of a definite type. If, for instance, that is an
+/// integer value, you may call get_int() to extract that value. You
+/// may call get_type() to discover what type of value is currently
+/// stored. Calling get_int() on an instance that does not store an
+/// integer, has undefined behavior, and likewise for all the other
+/// types that can be stored.
+///
+/// It is crucial to understand that the act of extracting a value of
+/// a particular type requires definite knowledge about the stored
+/// type. Calling a getter method for any particular type, that is not
+/// the same type as the stored value, has undefined behavior.
+///
+/// While values of numeric types are contained directly in a Mixed
+/// instance, character and binary data are merely referenced. A Mixed
+/// instance never owns the referenced data, nor does it in any other
+/// way attempt to manage its lifetime.
+///
+/// For compatibility with C style strings, when a string (character
+/// data) is stored in a Realm database, it is always followed by a
+/// terminating null character. This is also true when strings are
+/// stored in a mixed type column. This means that in the following
+/// code, if the 'mixed' value of the 8th row stores a string, then \c
+/// c_str will always point to a null-terminated string:
+///
+/// \code{.cpp}
+///
+///   const char* c_str = my_table[7].mixed.data(); // Always null-terminated
+///
+/// \endcode
+///
+/// Note that this assumption does not hold in general for strings in
+/// instances of Mixed. Indeed there is nothing stopping you from
+/// constructing a new Mixed instance that refers to a string without
+/// a terminating null character.
+///
+/// At the present time no soultion has been found that would allow
+/// for a Mixed instance to directly store a reference to a table. The
+/// problem is roughly as follows: From most points of view, the
+/// desirable thing to do, would be to store the table reference in a
+/// Mixed instance as a plain pointer without any ownership
+/// semantics. This would have no negative impact on the performance
+/// of copying and destroying Mixed instances, and it would serve just
+/// fine for passing a table as argument when setting the value of an
+/// entry in a mixed column. In that case a copy of the referenced
+/// table would be inserted into the mixed column.
+///
+/// On the other hand, when retrieving a table reference from a mixed
+/// column, storing it as a plain pointer in a Mixed instance is no
+/// longer an acceptable option. The complex rules for managing the
+/// lifetime of a Table instance, that represents a subtable,
+/// necessitates the use of a "smart pointer" such as
+/// TableRef. Enhancing the Mixed class to be able to act as a
+/// TableRef would be possible, but would also lead to several new
+/// problems. One problem is the risk of a Mixed instance outliving a
+/// stack allocated Table instance that it references. This would be a
+/// fatal error. Another problem is the impact that the nontrivial
+/// table reference has on the performance of copying and destroying
+/// Mixed instances.
+///
+/// \sa StringData
+class Mixed {
+public:
+    Mixed() noexcept;
+
+    Mixed(bool) noexcept;
+    Mixed(int64_t) noexcept;
+    Mixed(float) noexcept;
+    Mixed(double) noexcept;
+    Mixed(StringData) noexcept;
+    Mixed(BinaryData) noexcept;
+    Mixed(OldDateTime) noexcept;
+    Mixed(Timestamp) noexcept;
+
+    // These are shortcuts for Mixed(StringData(c_str)), and are
+    // needed to avoid unwanted implicit conversion of char* to bool.
+    Mixed(char* c_str) noexcept
+    {
+        set_string(c_str);
+    }
+    Mixed(const char* c_str) noexcept
+    {
+        set_string(c_str);
+    }
+
+    struct subtable_tag {
+    };
+    Mixed(subtable_tag) noexcept
+        : m_type(type_Table)
+    {
+    }
+
+    ~Mixed() noexcept
+    {
+    }
+
+    DataType get_type() const noexcept
+    {
+        return m_type;
+    }
+
+    template <class T>
+    T get() const noexcept;
+
+    int64_t get_int() const noexcept;
+    bool get_bool() const noexcept;
+    float get_float() const noexcept;
+    double get_double() const noexcept;
+    StringData get_string() const noexcept;
+    BinaryData get_binary() const noexcept;
+    OldDateTime get_olddatetime() const noexcept;
+    Timestamp get_timestamp() const noexcept;
+
+    void set_int(int64_t) noexcept;
+    void set_bool(bool) noexcept;
+    void set_float(float) noexcept;
+    void set_double(double) noexcept;
+    void set_string(StringData) noexcept;
+    void set_binary(BinaryData) noexcept;
+    void set_binary(const char* data, size_t size) noexcept;
+    void set_olddatetime(OldDateTime) noexcept;
+    void set_timestamp(Timestamp) noexcept;
+
+    template <class Ch, class Tr>
+    friend std::basic_ostream<Ch, Tr>& operator<<(std::basic_ostream<Ch, Tr>&, const Mixed&);
+
+private:
+    DataType m_type;
+    union {
+        int64_t m_int;
+        bool m_bool;
+        float m_float;
+        double m_double;
+        const char* m_data;
+        int_fast64_t m_date;
+        Timestamp m_timestamp;
+    };
+    size_t m_size = 0;
+};
+
+// Note: We cannot compare two mixed values, since when the type of
+// both is type_Table, we would have to compare the two tables, but
+// the mixed values do not provide access to those tables.
+
+// Note: The mixed values are specified as Wrap<Mixed>. If they were
+// not, these operators would apply to simple comparisons, such as int
+// vs int64_t, and cause ambiguity. This is because the constructors
+// of Mixed are not explicit.
+
+// Compare mixed with integer
+template <class T>
+bool operator==(Wrap<Mixed>, const T&) noexcept;
+template <class T>
+bool operator!=(Wrap<Mixed>, const T&) noexcept;
+template <class T>
+bool operator==(const T&, Wrap<Mixed>) noexcept;
+template <class T>
+bool operator!=(const T&, Wrap<Mixed>) noexcept;
+
+// Compare mixed with boolean
+bool operator==(Wrap<Mixed>, bool) noexcept;
+bool operator!=(Wrap<Mixed>, bool) noexcept;
+bool operator==(bool, Wrap<Mixed>) noexcept;
+bool operator!=(bool, Wrap<Mixed>) noexcept;
+
+// Compare mixed with float
+bool operator==(Wrap<Mixed>, float);
+bool operator!=(Wrap<Mixed>, float);
+bool operator==(float, Wrap<Mixed>);
+bool operator!=(float, Wrap<Mixed>);
+
+// Compare mixed with double
+bool operator==(Wrap<Mixed>, double);
+bool operator!=(Wrap<Mixed>, double);
+bool operator==(double, Wrap<Mixed>);
+bool operator!=(double, Wrap<Mixed>);
+
+// Compare mixed with string
+bool operator==(Wrap<Mixed>, StringData) noexcept;
+bool operator!=(Wrap<Mixed>, StringData) noexcept;
+bool operator==(StringData, Wrap<Mixed>) noexcept;
+bool operator!=(StringData, Wrap<Mixed>) noexcept;
+bool operator==(Wrap<Mixed>, const char* c_str) noexcept;
+bool operator!=(Wrap<Mixed>, const char* c_str) noexcept;
+bool operator==(const char* c_str, Wrap<Mixed>) noexcept;
+bool operator!=(const char* c_str, Wrap<Mixed>) noexcept;
+bool operator==(Wrap<Mixed>, char* c_str) noexcept;
+bool operator!=(Wrap<Mixed>, char* c_str) noexcept;
+bool operator==(char* c_str, Wrap<Mixed>) noexcept;
+bool operator!=(char* c_str, Wrap<Mixed>) noexcept;
+
+// Compare mixed with binary data
+bool operator==(Wrap<Mixed>, BinaryData) noexcept;
+bool operator!=(Wrap<Mixed>, BinaryData) noexcept;
+bool operator==(BinaryData, Wrap<Mixed>) noexcept;
+bool operator!=(BinaryData, Wrap<Mixed>) noexcept;
+
+// Compare mixed with date
+bool operator==(Wrap<Mixed>, OldDateTime) noexcept;
+bool operator!=(Wrap<Mixed>, OldDateTime) noexcept;
+bool operator==(OldDateTime, Wrap<Mixed>) noexcept;
+bool operator!=(OldDateTime, Wrap<Mixed>) noexcept;
+
+// Compare mixed with Timestamp
+bool operator==(Wrap<Mixed>, Timestamp) noexcept;
+bool operator!=(Wrap<Mixed>, Timestamp) noexcept;
+bool operator==(Timestamp, Wrap<Mixed>) noexcept;
+bool operator!=(Timestamp, Wrap<Mixed>) noexcept;
+
+// Implementation:
+
+inline Mixed::Mixed() noexcept
+{
+    m_type = type_Int;
+    m_int = 0;
+}
+
+inline Mixed::Mixed(int64_t v) noexcept
+{
+    m_type = type_Int;
+    m_int = v;
+}
+
+inline Mixed::Mixed(bool v) noexcept
+{
+    m_type = type_Bool;
+    m_bool = v;
+}
+
+inline Mixed::Mixed(float v) noexcept
+{
+    m_type = type_Float;
+    m_float = v;
+}
+
+inline Mixed::Mixed(double v) noexcept
+{
+    m_type = type_Double;
+    m_double = v;
+}
+
+inline Mixed::Mixed(StringData v) noexcept
+{
+    m_type = type_String;
+    m_data = v.data();
+    m_size = v.size();
+}
+
+inline Mixed::Mixed(BinaryData v) noexcept
+{
+    m_type = type_Binary;
+    m_data = v.data();
+    m_size = v.size();
+}
+
+inline Mixed::Mixed(OldDateTime v) noexcept
+{
+    m_type = type_OldDateTime;
+    m_date = v.get_olddatetime();
+}
+
+inline Mixed::Mixed(Timestamp v) noexcept
+{
+    m_type = type_Timestamp;
+    m_timestamp = v;
+}
+
+inline int64_t Mixed::get_int() const noexcept
+{
+    REALM_ASSERT(m_type == type_Int);
+    return m_int;
+}
+
+inline bool Mixed::get_bool() const noexcept
+{
+    REALM_ASSERT(m_type == type_Bool);
+    return m_bool;
+}
+
+inline float Mixed::get_float() const noexcept
+{
+    REALM_ASSERT(m_type == type_Float);
+    return m_float;
+}
+
+inline double Mixed::get_double() const noexcept
+{
+    REALM_ASSERT(m_type == type_Double);
+    return m_double;
+}
+
+inline StringData Mixed::get_string() const noexcept
+{
+    REALM_ASSERT(m_type == type_String);
+    return StringData(m_data, m_size);
+}
+
+inline BinaryData Mixed::get_binary() const noexcept
+{
+    REALM_ASSERT(m_type == type_Binary);
+    return BinaryData(m_data, m_size);
+}
+
+inline OldDateTime Mixed::get_olddatetime() const noexcept
+{
+    REALM_ASSERT(m_type == type_OldDateTime);
+    return m_date;
+}
+
+inline Timestamp Mixed::get_timestamp() const noexcept
+{
+    REALM_ASSERT(m_type == type_Timestamp);
+    return m_timestamp;
+}
+
+template <>
+inline int64_t Mixed::get<Int>() const noexcept
+{
+    return get_int();
+}
+
+template <>
+inline bool Mixed::get<bool>() const noexcept
+{
+    return get_bool();
+}
+
+template <>
+inline float Mixed::get<float>() const noexcept
+{
+    return get_float();
+}
+
+template <>
+inline double Mixed::get<double>() const noexcept
+{
+    return get_double();
+}
+
+template <>
+inline OldDateTime Mixed::get<OldDateTime>() const noexcept
+{
+    return get_olddatetime();
+}
+
+template <>
+inline StringData Mixed::get<StringData>() const noexcept
+{
+    return get_string();
+}
+
+template <>
+inline BinaryData Mixed::get<BinaryData>() const noexcept
+{
+    return get_binary();
+}
+
+template <>
+inline Timestamp Mixed::get<Timestamp>() const noexcept
+{
+    return get_timestamp();
+}
+
+
+inline void Mixed::set_int(int64_t v) noexcept
+{
+    m_type = type_Int;
+    m_int = v;
+}
+
+inline void Mixed::set_bool(bool v) noexcept
+{
+    m_type = type_Bool;
+    m_bool = v;
+}
+
+inline void Mixed::set_float(float v) noexcept
+{
+    m_type = type_Float;
+    m_float = v;
+}
+
+inline void Mixed::set_double(double v) noexcept
+{
+    m_type = type_Double;
+    m_double = v;
+}
+
+inline void Mixed::set_string(StringData v) noexcept
+{
+    m_type = type_String;
+    m_data = v.data();
+    m_size = v.size();
+}
+
+inline void Mixed::set_binary(BinaryData v) noexcept
+{
+    set_binary(v.data(), v.size());
+}
+
+inline void Mixed::set_binary(const char* data, size_t size) noexcept
+{
+    m_type = type_Binary;
+    m_data = data;
+    m_size = size;
+}
+
+inline void Mixed::set_olddatetime(OldDateTime v) noexcept
+{
+    m_type = type_OldDateTime;
+    m_date = v.get_olddatetime();
+}
+
+inline void Mixed::set_timestamp(Timestamp v) noexcept
+{
+    m_type = type_Timestamp;
+    m_timestamp = v;
+}
+
+// LCOV_EXCL_START
+template <class Ch, class Tr>
+inline std::basic_ostream<Ch, Tr>& operator<<(std::basic_ostream<Ch, Tr>& out, const Mixed& m)
+{
+    out << "Mixed(";
+    switch (m.m_type) {
+        case type_Int:
+            out << m.m_int;
+            break;
+        case type_Bool:
+            out << m.m_bool;
+            break;
+        case type_Float:
+            out << m.m_float;
+            break;
+        case type_Double:
+            out << m.m_double;
+            break;
+        case type_String:
+            out << StringData(m.m_data, m.m_size);
+            break;
+        case type_Binary:
+            out << BinaryData(m.m_data, m.m_size);
+            break;
+        case type_OldDateTime:
+            out << OldDateTime(m.m_date);
+            break;
+        case type_Timestamp:
+            out << Timestamp(m.m_timestamp);
+            break;
+        case type_Table:
+            out << "subtable";
+            break;
+        case type_Mixed:
+        case type_Link:
+        case type_LinkList:
+            REALM_ASSERT(false);
+    }
+    out << ")";
+    return out;
+}
+// LCOV_EXCL_STOP
+
+
+// Compare mixed with integer
+
+template <class T>
+inline bool operator==(Wrap<Mixed> a, const T& b) noexcept
+{
+    return Mixed(a).get_type() == type_Int && Mixed(a).get_int() == b;
+}
+
+template <class T>
+inline bool operator!=(Wrap<Mixed> a, const T& b) noexcept
+{
+    return Mixed(a).get_type() != type_Int || Mixed(a).get_int() != b;
+}
+
+template <class T>
+inline bool operator==(const T& a, Wrap<Mixed> b) noexcept
+{
+    return type_Int == Mixed(b).get_type() && a == Mixed(b).get_int();
+}
+
+template <class T>
+inline bool operator!=(const T& a, Wrap<Mixed> b) noexcept
+{
+    return type_Int != Mixed(b).get_type() || a != Mixed(b).get_int();
+}
+
+
+// Compare mixed with boolean
+
+inline bool operator==(Wrap<Mixed> a, bool b) noexcept
+{
+    return Mixed(a).get_type() == type_Bool && Mixed(a).get_bool() == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, bool b) noexcept
+{
+    return Mixed(a).get_type() != type_Bool || Mixed(a).get_bool() != b;
+}
+
+inline bool operator==(bool a, Wrap<Mixed> b) noexcept
+{
+    return type_Bool == Mixed(b).get_type() && a == Mixed(b).get_bool();
+}
+
+inline bool operator!=(bool a, Wrap<Mixed> b) noexcept
+{
+    return type_Bool != Mixed(b).get_type() || a != Mixed(b).get_bool();
+}
+
+
+// Compare mixed with float
+
+inline bool operator==(Wrap<Mixed> a, float b)
+{
+    return Mixed(a).get_type() == type_Float && Mixed(a).get_float() == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, float b)
+{
+    return Mixed(a).get_type() != type_Float || Mixed(a).get_float() != b;
+}
+
+inline bool operator==(float a, Wrap<Mixed> b)
+{
+    return type_Float == Mixed(b).get_type() && a == Mixed(b).get_float();
+}
+
+inline bool operator!=(float a, Wrap<Mixed> b)
+{
+    return type_Float != Mixed(b).get_type() || a != Mixed(b).get_float();
+}
+
+
+// Compare mixed with double
+
+inline bool operator==(Wrap<Mixed> a, double b)
+{
+    return Mixed(a).get_type() == type_Double && Mixed(a).get_double() == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, double b)
+{
+    return Mixed(a).get_type() != type_Double || Mixed(a).get_double() != b;
+}
+
+inline bool operator==(double a, Wrap<Mixed> b)
+{
+    return type_Double == Mixed(b).get_type() && a == Mixed(b).get_double();
+}
+
+inline bool operator!=(double a, Wrap<Mixed> b)
+{
+    return type_Double != Mixed(b).get_type() || a != Mixed(b).get_double();
+}
+
+
+// Compare mixed with string
+
+inline bool operator==(Wrap<Mixed> a, StringData b) noexcept
+{
+    return Mixed(a).get_type() == type_String && Mixed(a).get_string() == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, StringData b) noexcept
+{
+    return Mixed(a).get_type() != type_String || Mixed(a).get_string() != b;
+}
+
+inline bool operator==(StringData a, Wrap<Mixed> b) noexcept
+{
+    return type_String == Mixed(b).get_type() && a == Mixed(b).get_string();
+}
+
+inline bool operator!=(StringData a, Wrap<Mixed> b) noexcept
+{
+    return type_String != Mixed(b).get_type() || a != Mixed(b).get_string();
+}
+
+inline bool operator==(Wrap<Mixed> a, const char* b) noexcept
+{
+    return a == StringData(b);
+}
+
+inline bool operator!=(Wrap<Mixed> a, const char* b) noexcept
+{
+    return a != StringData(b);
+}
+
+inline bool operator==(const char* a, Wrap<Mixed> b) noexcept
+{
+    return StringData(a) == b;
+}
+
+inline bool operator!=(const char* a, Wrap<Mixed> b) noexcept
+{
+    return StringData(a) != b;
+}
+
+inline bool operator==(Wrap<Mixed> a, char* b) noexcept
+{
+    return a == StringData(b);
+}
+
+inline bool operator!=(Wrap<Mixed> a, char* b) noexcept
+{
+    return a != StringData(b);
+}
+
+inline bool operator==(char* a, Wrap<Mixed> b) noexcept
+{
+    return StringData(a) == b;
+}
+
+inline bool operator!=(char* a, Wrap<Mixed> b) noexcept
+{
+    return StringData(a) != b;
+}
+
+
+// Compare mixed with binary data
+
+inline bool operator==(Wrap<Mixed> a, BinaryData b) noexcept
+{
+    return Mixed(a).get_type() == type_Binary && Mixed(a).get_binary() == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, BinaryData b) noexcept
+{
+    return Mixed(a).get_type() != type_Binary || Mixed(a).get_binary() != b;
+}
+
+inline bool operator==(BinaryData a, Wrap<Mixed> b) noexcept
+{
+    return type_Binary == Mixed(b).get_type() && a == Mixed(b).get_binary();
+}
+
+inline bool operator!=(BinaryData a, Wrap<Mixed> b) noexcept
+{
+    return type_Binary != Mixed(b).get_type() || a != Mixed(b).get_binary();
+}
+
+
+// Compare mixed with date
+
+inline bool operator==(Wrap<Mixed> a, OldDateTime b) noexcept
+{
+    return Mixed(a).get_type() == type_OldDateTime && OldDateTime(Mixed(a).get_olddatetime()) == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, OldDateTime b) noexcept
+{
+    return Mixed(a).get_type() != type_OldDateTime || OldDateTime(Mixed(a).get_olddatetime()) != b;
+}
+
+inline bool operator==(OldDateTime a, Wrap<Mixed> b) noexcept
+{
+    return type_OldDateTime == Mixed(b).get_type() && a == OldDateTime(Mixed(b).get_olddatetime());
+}
+
+inline bool operator!=(OldDateTime a, Wrap<Mixed> b) noexcept
+{
+    return type_OldDateTime != Mixed(b).get_type() || a != OldDateTime(Mixed(b).get_olddatetime());
+}
+
+// Compare mixed with Timestamp
+
+inline bool operator==(Wrap<Mixed> a, Timestamp b) noexcept
+{
+    return Mixed(a).get_type() == type_Timestamp && Timestamp(Mixed(a).get_timestamp()) == b;
+}
+
+inline bool operator!=(Wrap<Mixed> a, Timestamp b) noexcept
+{
+    return Mixed(a).get_type() != type_Timestamp || Timestamp(Mixed(a).get_timestamp()) != b;
+}
+
+inline bool operator==(Timestamp a, Wrap<Mixed> b) noexcept
+{
+    return type_Timestamp == Mixed(b).get_type() && a == Timestamp(Mixed(b).get_timestamp());
+}
+
+inline bool operator!=(Timestamp a, Wrap<Mixed> b) noexcept
+{
+    return type_Timestamp != Mixed(b).get_type() || a != Timestamp(Mixed(b).get_timestamp());
+}
+
+
+} // namespace realm
+
+#endif // REALM_MIXED_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/null.hpp b/node_modules/realm/vendor/realm-ios/include/realm/null.hpp
new file mode 100644
index 0000000..733e798
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/null.hpp
@@ -0,0 +1,172 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_NULL_HPP
+#define REALM_NULL_HPP
+
+#include <cmath>
+#include <cstring>
+
+#include <realm/util/features.h>
+#include <realm/util/optional.hpp>
+#include <realm/utilities.hpp>
+#include <realm/exceptions.hpp>
+
+namespace realm {
+
+/*
+Represents null in Query, find(), get(), set(), etc.
+
+Float/Double: Realm can both store user-given NaNs and null. Any user-given signaling NaN is converted to
+0x7fa00000 (if float) or 0x7ff4000000000000 (if double). Any user-given quiet NaN is converted to
+0x7fc00000 (if float) or 0x7ff8000000000000 (if double). So Realm does not preserve the optional bits in
+user-given NaNs.
+
+However, since both clang and gcc on x64 and ARM, and also Java on x64, return these bit patterns when
+requesting NaNs, these will actually seem to roundtrip bit-exact for the end-user in most cases.
+
+If set_null() is called, a null is stored in form of the bit pattern 0xffffffff (if float) or
+0xffffffffffffffff (if double). These are quiet NaNs.
+
+Executing a query that involves a float/double column that contains NaNs gives an undefined result. If
+it contains signaling NaNs, it may throw an exception.
+
+Notes on IEEE:
+
+A NaN float is any bit pattern `s 11111111 S xxxxxxxxxxxxxxxxxxxxxx` where `s` and `x` are arbitrary, but at
+least 1 `x` must be 1. If `S` is 1, it's a quiet NaN, else it's a signaling NaN.
+
+A NaN doubule is the same as above, but for `s eeeeeeeeeee S xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`
+
+The `S` bit is at position 22 (float) or 51 (double).
+*/
+
+struct null {
+    null()
+    {
+    }
+    operator int64_t()
+    {
+        throw(LogicError::type_mismatch);
+    }
+    template <class T>
+    operator util::Optional<T>()
+    {
+        return util::none;
+    }
+
+    template <class T>
+    bool operator==(const T&) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class T>
+    bool operator!=(const T&) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class T>
+    bool operator>(const T&) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class T>
+    bool operator>=(const T&) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class T>
+    bool operator<=(const T&) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class T>
+    bool operator<(const T&) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    /// Returns whether `v` bitwise equals the null bit-pattern
+    template <class T>
+    static bool is_null_float(T v)
+    {
+        T i = null::get_null_float<T>();
+        return std::memcmp(&i, &v, sizeof(T)) == 0;
+    }
+
+    /// Returns the quiet NaNs that represent null for floats/doubles in Realm in stored payload.
+    template <class T>
+    static T get_null_float()
+    {
+        typename std::conditional<std::is_same<T, float>::value, uint32_t, uint64_t>::type i;
+        int64_t double_nan = 0x7ff80000000000aa;
+        i = std::is_same<T, float>::value ? 0x7fc000aa : static_cast<decltype(i)>(double_nan);
+        T d = type_punning<T, decltype(i)>(i);
+        REALM_ASSERT_DEBUG(std::isnan(d));
+        REALM_ASSERT_DEBUG(!is_signaling(d));
+        return d;
+    }
+
+    /// Takes a NaN as argument and returns whether or not it's signaling
+    template <class T>
+    static bool is_signaling(T v)
+    {
+        REALM_ASSERT(std::isnan(static_cast<double>(v)));
+        typename std::conditional<std::is_same<T, float>::value, uint32_t, uint64_t>::type i;
+        size_t signal_bit = std::is_same<T, float>::value ? 22 : 51; // If this bit is set, it's quiet
+        i = type_punning<decltype(i), T>(v);
+        return !(i & (1ull << signal_bit));
+    }
+
+    /// Converts any signaling or quiet NaN to their their respective bit patterns that are used on x64 gcc+clang,
+    /// ARM clang and x64 Java.
+    template <class T>
+    static T to_realm(T v)
+    {
+        if (std::isnan(static_cast<double>(v))) {
+            typename std::conditional<std::is_same<T, float>::value, uint32_t, uint64_t>::type i;
+            if (std::is_same<T, float>::value) {
+                i = is_signaling(v) ? 0x7fa00000 : 0x7fc00000;
+            }
+            else {
+                i = static_cast<decltype(i)>(is_signaling(v) ? 0x7ff4000000000000 : 0x7ff8000000000000);
+            }
+            return type_punning<T, decltype(i)>(i);
+        }
+        else {
+            return v;
+        }
+    }
+};
+
+template <class OS>
+OS& operator<<(OS& os, const null&)
+{
+    os << "(null)";
+    return os;
+}
+
+} // namespace realm
+
+#endif // REALM_NULL_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/olddatetime.hpp b/node_modules/realm/vendor/realm-ios/include/realm/olddatetime.hpp
new file mode 100644
index 0000000..b662899
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/olddatetime.hpp
@@ -0,0 +1,157 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_DATETIME_HPP
+#define REALM_DATETIME_HPP
+
+#include <ctime>
+#include <ostream>
+
+namespace realm {
+
+
+class OldDateTime {
+public:
+    OldDateTime() noexcept
+        : m_time(0)
+    {
+    }
+
+    /// Construct from the number of seconds since Jan 1 00:00:00 UTC
+    /// 1970.
+    /// FIXME: See if we can make this private again. Required by query_expression.hpp
+    OldDateTime(int_fast64_t d) noexcept
+        : m_time(d)
+    {
+    }
+
+    /// Return the time as seconds since Jan 1 00:00:00 UTC 1970.
+    int_fast64_t get_olddatetime() const noexcept
+    {
+        return m_time;
+    }
+
+    friend bool operator==(const OldDateTime&, const OldDateTime&) noexcept;
+    friend bool operator!=(const OldDateTime&, const OldDateTime&) noexcept;
+    friend bool operator<(const OldDateTime&, const OldDateTime&) noexcept;
+    friend bool operator<=(const OldDateTime&, const OldDateTime&) noexcept;
+    friend bool operator>(const OldDateTime&, const OldDateTime&) noexcept;
+    friend bool operator>=(const OldDateTime&, const OldDateTime&) noexcept;
+
+    /// Construct from broken down local time.
+    ///
+    /// \note This constructor uses std::mktime() to convert the
+    /// specified local time to seconds since the Epoch, that is, the
+    /// result depends on the current globally specified time zone
+    /// setting.
+    ///
+    /// \param year The year (the minimum valid value is 1970).
+    ///
+    /// \param month The month in the range [1, 12].
+    ///
+    /// \param day The day of the month in the range [1, 31].
+    ///
+    /// \param hours Hours since midnight in the range [0, 23].
+    ///
+    /// \param minutes Minutes after the hour in the range [0, 59].
+    ///
+    /// \param seconds Seconds after the minute in the range [0,
+    /// 60]. Note that the range allows for leap seconds.
+    OldDateTime(int year, int month, int day, int hours = 0, int minutes = 0, int seconds = 0);
+
+    template <class Ch, class Tr>
+    friend std::basic_ostream<Ch, Tr>& operator<<(std::basic_ostream<Ch, Tr>& out, const OldDateTime&);
+
+    // This is used by query_expression.hpp to generalize its templates and simplify the code *alot*; it is needed
+    // because OldDateTime is internally stored in an int64_t column.
+    operator int_fast64_t() noexcept;
+
+private:
+    int_fast64_t m_time; // Seconds since Jan 1 00:00:00 UTC 1970.
+    static std::time_t assemble(int year, int month, int day, int hours, int minutes, int seconds);
+    template <typename T>
+    friend class Value;
+};
+
+
+// Implementation:
+
+inline bool operator==(const OldDateTime& a, const OldDateTime& b) noexcept
+{
+    return a.m_time == b.m_time;
+}
+
+inline bool operator!=(const OldDateTime& a, const OldDateTime& b) noexcept
+{
+    return a.m_time != b.m_time;
+}
+
+inline bool operator<(const OldDateTime& a, const OldDateTime& b) noexcept
+{
+    return a.m_time < b.m_time;
+}
+
+inline bool operator<=(const OldDateTime& a, const OldDateTime& b) noexcept
+{
+    return a.m_time <= b.m_time;
+}
+
+inline bool operator>(const OldDateTime& a, const OldDateTime& b) noexcept
+{
+    return a.m_time > b.m_time;
+}
+
+inline bool operator>=(const OldDateTime& a, const OldDateTime& b) noexcept
+{
+    return a.m_time >= b.m_time;
+}
+
+inline OldDateTime::operator int_fast64_t() noexcept
+{
+    return m_time;
+}
+
+inline OldDateTime::OldDateTime(int year, int month, int day, int hours, int minutes, int seconds)
+    : m_time(assemble(year, month, day, hours, minutes, seconds))
+{
+}
+
+template <class Ch, class Tr>
+inline std::basic_ostream<Ch, Tr>& operator<<(std::basic_ostream<Ch, Tr>& out, const OldDateTime& d)
+{
+    out << "OldDateTime(" << d.m_time << ")";
+    return out;
+}
+
+inline std::time_t OldDateTime::assemble(int year, int month, int day, int hours, int minutes, int seconds)
+{
+    std::tm local_time;
+    local_time.tm_year = year - 1900;
+    local_time.tm_mon = month - 1;
+    local_time.tm_mday = day;
+    local_time.tm_hour = hours;
+    local_time.tm_min = minutes;
+    local_time.tm_sec = seconds;
+    local_time.tm_isdst = -1;
+    return std::mktime(&local_time);
+}
+
+
+} // namespace realm
+
+#endif // REALM_DATETIME_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/owned_data.hpp b/node_modules/realm/vendor/realm-ios/include/realm/owned_data.hpp
new file mode 100644
index 0000000..c707f9d
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/owned_data.hpp
@@ -0,0 +1,96 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_OWNED_DATA_HPP
+#define REALM_OWNED_DATA_HPP
+
+#include <realm/util/assert.hpp>
+
+#include <cstring>
+#include <memory>
+
+namespace realm {
+
+/// A chunk of owned data.
+class OwnedData {
+public:
+    /// Construct a null reference.
+    OwnedData() noexcept
+    {
+    }
+
+    /// If \a data_to_copy is 'null', \a data_size must be zero.
+    OwnedData(const char* data_to_copy, size_t data_size)
+        : m_size(data_size)
+    {
+        REALM_ASSERT_DEBUG(data_to_copy || data_size == 0);
+        if (data_to_copy) {
+            m_data = std::unique_ptr<char[]>(new char[data_size]);
+            memcpy(m_data.get(), data_to_copy, data_size);
+        }
+    }
+
+    /// If \a unique_data is 'null', \a data_size must be zero.
+    OwnedData(std::unique_ptr<char[]> unique_data, size_t data_size) noexcept
+        : m_data(std::move(unique_data))
+        , m_size(data_size)
+    {
+        REALM_ASSERT_DEBUG(m_data || m_size == 0);
+    }
+
+    OwnedData(const OwnedData& other)
+        : OwnedData(other.m_data.get(), other.m_size)
+    {
+    }
+    OwnedData& operator=(const OwnedData& other);
+
+    OwnedData(OwnedData&&) = default;
+    OwnedData& operator=(OwnedData&&) = default;
+
+    const char* data() const
+    {
+        return m_data.get();
+    }
+    size_t size() const
+    {
+        return m_size;
+    }
+
+private:
+    std::unique_ptr<char[]> m_data;
+    size_t m_size = 0;
+};
+
+inline OwnedData& OwnedData::operator=(const OwnedData& other)
+{
+    if (this != &other) {
+        if (other.m_data) {
+            m_data = std::unique_ptr<char[]>(new char[other.m_size]);
+            memcpy(m_data.get(), other.m_data.get(), other.m_size);
+        }
+        else {
+            m_data = nullptr;
+        }
+        m_size = other.m_size;
+    }
+    return *this;
+}
+
+} // namespace realm
+
+#endif // REALM_OWNED_DATA_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/collection_operator_expression.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/collection_operator_expression.hpp
new file mode 100644
index 0000000..4edd5c2
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/collection_operator_expression.hpp
@@ -0,0 +1,226 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_COLLECTION_OPERATOR_EXPRESSION_HPP
+#define REALM_COLLECTION_OPERATOR_EXPRESSION_HPP
+
+#include "property_expression.hpp"
+#include "parser.hpp"
+#include "parser_utils.hpp"
+
+#include <realm/query_expression.hpp>
+
+namespace realm {
+namespace parser {
+
+template <typename RetType, parser::Expression::KeyPathOp AggOpType, class Enable = void>
+struct CollectionOperatorGetter;
+
+template <parser::Expression::KeyPathOp OpType>
+struct CollectionOperatorExpression
+{
+    static constexpr parser::Expression::KeyPathOp operation_type = OpType;
+    std::function<Table *()> table_getter;
+    PropertyExpression pe;
+    size_t post_link_col_ndx;
+    DataType post_link_col_type;
+
+    CollectionOperatorExpression(PropertyExpression&& exp, std::string suffix_path, parser::KeyPathMapping& mapping)
+    : pe(std::move(exp))
+    , post_link_col_ndx(realm::not_found)
+    {
+        table_getter = std::bind(&PropertyExpression::table_getter, pe);
+
+        const bool requires_suffix_path = !(OpType == parser::Expression::KeyPathOp::SizeString
+                                            || OpType == parser::Expression::KeyPathOp::SizeBinary
+                                            || OpType == parser::Expression::KeyPathOp::Count
+                                            || OpType == parser::Expression::KeyPathOp::BacklinkCount);
+
+        if (requires_suffix_path) {
+            Table* pre_link_table = pe.table_getter();
+            REALM_ASSERT(pre_link_table);
+            StringData list_property_name;
+            if (pe.dest_type_is_backlink()) {
+                list_property_name = "linking object";
+            } else {
+                list_property_name = pre_link_table->get_column_name(pe.get_dest_ndx());
+            }
+            realm_precondition(pe.get_dest_type() == type_LinkList || pe.dest_type_is_backlink(),
+                         util::format("The '%1' operation must be used on a list property, but '%2' is not a list",
+                                      util::collection_operator_to_str(OpType), list_property_name));
+
+            ConstTableRef post_link_table;
+            if (pe.dest_type_is_backlink()) {
+                post_link_table = pe.get_dest_table();
+            } else {
+                post_link_table = pe.get_dest_table()->get_link_target(pe.get_dest_ndx());
+            }
+            REALM_ASSERT(post_link_table);
+            StringData printable_post_link_table_name = get_printable_table_name(*post_link_table);
+
+            KeyPath suffix_key_path = key_path_from_string(suffix_path);
+
+            realm_precondition(suffix_path.size() > 0 && suffix_key_path.size() > 0,
+                         util::format("A property from object '%1' must be provided to perform operation '%2'",
+                                      printable_post_link_table_name, util::collection_operator_to_str(OpType)));
+            size_t index = 0;
+            KeyPathElement element = mapping.process_next_path(post_link_table, suffix_key_path, index);
+
+            realm_precondition(suffix_key_path.size() == 1,
+                         util::format("Unable to use '%1' because collection aggreate operations are only supported "
+                                      "for direct properties at this time", suffix_path));
+
+            post_link_col_ndx = element.col_ndx;
+            post_link_col_type = element.col_type;
+        }
+        else {  // !requires_suffix_path
+            if (!pe.link_chain.empty()) {
+                post_link_col_type = pe.get_dest_type();
+            }
+
+            realm_precondition(suffix_path.empty(),
+                         util::format("An extraneous property '%1' was found for operation '%2'",
+                                      suffix_path, util::collection_operator_to_str(OpType)));
+        }
+    }
+    template <typename T>
+    auto value_of_type_for_query() const
+    {
+        return CollectionOperatorGetter<T, OpType>::convert(*this);
+    }
+};
+
+
+// Certain operations are disabled for some types (eg. a sum of timestamps is invalid).
+// The operations that are supported have a specialisation with std::enable_if for that type below
+// any type/operation combination that is not specialised will get the runtime error from the following
+// default implementation. The return type is just a dummy to make things compile.
+template <typename RetType, parser::Expression::KeyPathOp AggOpType, class Enable>
+struct CollectionOperatorGetter {
+    static Columns<RetType> convert(const CollectionOperatorExpression<AggOpType>& op) {
+        throw std::runtime_error(util::format("Predicate error: comparison of type '%1' with result of '%2' is not supported.",
+                                              type_to_str<RetType>(),
+                                              collection_operator_to_str(op.operation_type)));
+    }
+};
+
+template <typename RetType>
+struct CollectionOperatorGetter<RetType, parser::Expression::KeyPathOp::Min,
+typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static SubColumnAggregate<RetType, aggregate_operations::Minimum<RetType> > convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::Min>& expr)
+    {
+        if (expr.pe.dest_type_is_backlink()) {
+            return expr.table_getter()->template column<Link>(*expr.pe.get_dest_table(), expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).min();
+        } else {
+            return expr.table_getter()->template column<Link>(expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).min();
+        }
+    }
+};
+
+template <typename RetType>
+struct CollectionOperatorGetter<RetType, parser::Expression::KeyPathOp::Max,
+typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static SubColumnAggregate<RetType, aggregate_operations::Maximum<RetType> > convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::Max>& expr)
+    {
+        if (expr.pe.dest_type_is_backlink()) {
+            return expr.table_getter()->template column<Link>(*expr.pe.get_dest_table(), expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).max();
+        } else {
+            return expr.table_getter()->template column<Link>(expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).max();
+        }
+    }
+};
+
+template <typename RetType>
+struct CollectionOperatorGetter<RetType, parser::Expression::KeyPathOp::Sum,
+typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static SubColumnAggregate<RetType, aggregate_operations::Sum<RetType> > convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::Sum>& expr)
+    {
+        if (expr.pe.dest_type_is_backlink()) {
+            return expr.table_getter()->template column<Link>(*expr.pe.get_dest_table(), expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).sum();
+        } else {
+            return expr.table_getter()->template column<Link>(expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).sum();
+        }
+    }
+};
+
+template <typename RetType>
+struct CollectionOperatorGetter<RetType, parser::Expression::KeyPathOp::Avg,
+typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static SubColumnAggregate<RetType, aggregate_operations::Average<RetType> > convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::Avg>& expr)
+    {
+        if (expr.pe.dest_type_is_backlink()) {
+            return expr.table_getter()->template column<Link>(*expr.pe.get_dest_table(), expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).average();
+        } else {
+            return expr.table_getter()->template column<Link>(expr.pe.get_dest_ndx()).template column<RetType>(expr.post_link_col_ndx).average();
+        }
+    }
+};
+
+template <typename RetType>
+struct CollectionOperatorGetter<RetType, parser::Expression::KeyPathOp::Count,
+    typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static LinkCount convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::Count>& expr)
+    {
+        if (expr.pe.dest_type_is_backlink()) {
+            return expr.table_getter()->template column<Link>(*expr.pe.get_dest_table(), expr.pe.get_dest_ndx()).count();
+        } else {
+            return expr.table_getter()->template column<Link>(expr.pe.get_dest_ndx()).count();
+        }
+    }
+};
+
+
+template <typename RetType>
+struct CollectionOperatorGetter<RetType, parser::Expression::KeyPathOp::BacklinkCount,
+typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static BacklinkCount<Int> convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::BacklinkCount>& expr)
+    {
+        if (expr.pe.link_chain.empty() || expr.pe.get_dest_ndx() == realm::npos) {
+            // here we are operating on the current table from a "@links.@count" query with no link keypath prefix
+            return expr.table_getter()->template get_backlink_count<Int>();
+        } else {
+            if (expr.pe.dest_type_is_backlink()) {
+                return expr.table_getter()->template column<Link>(*expr.pe.get_dest_table(), expr.pe.get_dest_ndx()).template backlink_count<Int>();
+            } else {
+                return expr.table_getter()->template column<Link>(expr.pe.get_dest_ndx()).template backlink_count<Int>();
+            }
+        }
+    }
+};
+
+
+template <>
+struct CollectionOperatorGetter<Int, parser::Expression::KeyPathOp::SizeString>{
+    static SizeOperator<Size<String> > convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::SizeString>& expr)
+    {
+        return expr.table_getter()->template column<String>(expr.pe.get_dest_ndx()).size();
+    }
+};
+
+template <>
+struct CollectionOperatorGetter<Int, parser::Expression::KeyPathOp::SizeBinary>{
+    static SizeOperator<Size<Binary> > convert(const CollectionOperatorExpression<parser::Expression::KeyPathOp::SizeBinary>& expr)
+    {
+        return expr.table_getter()->template column<Binary>(expr.pe.get_dest_ndx()).size();
+    }
+};
+
+} // namespace parser
+} // namespace realm
+
+#endif // REALM_COLLECTION_OPERATOR_EXPRESSION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/expression_container.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/expression_container.hpp
new file mode 100644
index 0000000..7e596b9
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/expression_container.hpp
@@ -0,0 +1,79 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_EXPRESSION_CONTAINER_HPP
+#define REALM_EXPRESSION_CONTAINER_HPP
+
+#include <realm/util/any.hpp>
+
+#include "collection_operator_expression.hpp"
+#include "parser.hpp"
+#include "property_expression.hpp"
+#include "query_builder.hpp"
+#include "subquery_expression.hpp"
+#include "value_expression.hpp"
+
+namespace realm {
+namespace parser {
+
+class ExpressionContainer
+{
+public:
+    ExpressionContainer(Query& query, const parser::Expression& e, query_builder::Arguments& args, parser::KeyPathMapping& mapping);
+
+    bool is_null();
+
+    PropertyExpression& get_property();
+    ValueExpression& get_value();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::Min>& get_min();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::Max>& get_max();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::Sum>& get_sum();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::Avg>& get_avg();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::Count>& get_count();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::BacklinkCount>& get_backlink_count();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::SizeString>& get_size_string();
+    CollectionOperatorExpression<parser::Expression::KeyPathOp::SizeBinary>& get_size_binary();
+    SubqueryExpression& get_subexpression();
+
+    DataType check_type_compatibility(DataType type);
+    DataType get_comparison_type(ExpressionContainer& rhs);
+
+    enum class ExpressionInternal
+    {
+        exp_Value,
+        exp_Property,
+        exp_OpMin,
+        exp_OpMax,
+        exp_OpSum,
+        exp_OpAvg,
+        exp_OpCount,
+        exp_OpSizeString,
+        exp_OpSizeBinary,
+        exp_OpBacklinkCount,
+        exp_SubQuery
+    };
+
+    ExpressionInternal type;
+private:
+    util::Any storage;
+};
+
+} // namespace parser
+} // namespace realm
+
+#endif // REALM_EXPRESSION_CONTAINER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/keypath_mapping.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/keypath_mapping.hpp
new file mode 100644
index 0000000..01ea65f
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/keypath_mapping.hpp
@@ -0,0 +1,79 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_KEYPATH_MAPPING_HPP
+#define REALM_KEYPATH_MAPPING_HPP
+
+#include <realm/table.hpp>
+
+#include "parser_utils.hpp"
+
+#include <unordered_map>
+#include <string>
+
+namespace realm {
+namespace parser {
+
+struct KeyPathElement
+{
+    ConstTableRef table;
+    size_t col_ndx;
+    DataType col_type;
+    bool is_backlink;
+};
+
+class BacklinksRestrictedError : public std::runtime_error {
+public:
+    BacklinksRestrictedError(const std::string& msg) : std::runtime_error(msg) {}
+    /// runtime_error::what() returns the msg provided in the constructor.
+};
+
+struct TableAndColHash {
+    std::size_t operator () (const std::pair<ConstTableRef, std::string> &p) const;
+};
+
+
+// This class holds state which allows aliasing variable names in key paths used in queries.
+// It is used to allow variable naming in subqueries such as 'SUBQUERY(list, $obj, $obj.intCol = 5).@count'
+// It can also be used to allow querying named backlinks if bindings provide the mappings themselves.
+class KeyPathMapping
+{
+public:
+    KeyPathMapping();
+    // returns true if added, false if duplicate key already exists
+    bool add_mapping(ConstTableRef table, std::string name, std::string alias);
+    void remove_mapping(ConstTableRef table, std::string name);
+    bool has_mapping(ConstTableRef table, std::string name);
+    KeyPathElement process_next_path(ConstTableRef table, KeyPath& path, size_t& index);
+    void set_allow_backlinks(bool allow);
+    bool backlinks_allowed() const
+    {
+        return m_allow_backlinks;
+    }
+    void set_backlink_class_prefix(std::string prefix);
+    static Table* table_getter(TableRef table, const std::vector<KeyPathElement>& links);
+protected:
+    bool m_allow_backlinks;
+    std::string m_backlink_class_prefix;
+    std::unordered_map<std::pair<ConstTableRef, std::string>, std::string, TableAndColHash> m_mapping;
+};
+
+} // namespace parser
+} // namespace realm
+
+#endif // REALM_KEYPATH_MAPPING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/parser.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/parser.hpp
new file mode 100644
index 0000000..f04edc2
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/parser.hpp
@@ -0,0 +1,147 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_PARSER_HPP
+#define REALM_PARSER_HPP
+
+#include <memory>
+#include <string>
+#include <vector>
+#include <realm/string_data.hpp>
+
+namespace realm {
+
+namespace parser {
+
+struct Predicate;
+
+struct Expression
+{
+    enum class Type { None, Number, String, KeyPath, Argument, True, False, Null, Timestamp, Base64, SubQuery } type;
+    enum class KeyPathOp { None, Min, Max, Avg, Sum, Count, SizeString, SizeBinary, BacklinkCount } collection_op;
+    std::string s;
+    std::vector<std::string> time_inputs;
+    std::string op_suffix;
+    std::string subquery_path, subquery_var;
+    std::shared_ptr<Predicate> subquery;
+    Expression(Type t = Type::None, std::string input = "") : type(t), collection_op(KeyPathOp::None), s(input) {}
+    Expression(std::vector<std::string>&& timestamp) : type(Type::Timestamp), collection_op(KeyPathOp::None), time_inputs(timestamp) {}
+    Expression(std::string prefix, KeyPathOp op, std::string suffix) : type(Type::KeyPath), collection_op(op), s(prefix), op_suffix(suffix) {}
+};
+
+struct Predicate
+{
+    enum class Type
+    {
+        Comparison,
+        Or,
+        And,
+        True,
+        False
+    } type = Type::And;
+
+    enum class Operator
+    {
+        None,
+        Equal,
+        NotEqual,
+        LessThan,
+        LessThanOrEqual,
+        GreaterThan,
+        GreaterThanOrEqual,
+        BeginsWith,
+        EndsWith,
+        Contains,
+        Like,
+        In
+    };
+
+    enum class OperatorOption
+    {
+        None,
+        CaseInsensitive,
+    };
+
+    enum class ComparisonType
+    {
+        Unspecified,
+        Any,
+        All,
+        None,
+    };
+
+    struct Comparison
+    {
+        Operator op = Operator::None;
+        OperatorOption option = OperatorOption::None;
+        Expression expr[2] = {{Expression::Type::None, ""}, {Expression::Type::None, ""}};
+        ComparisonType compare_type = ComparisonType::Unspecified;
+    };
+
+    struct Compound
+    {
+        std::vector<Predicate> sub_predicates;
+    };
+
+    Comparison cmpr;
+    Compound   cpnd;
+
+    bool negate = false;
+
+    Predicate(Type t, bool n = false) : type(t), negate(n) {}
+};
+
+struct DescriptorOrderingState
+{
+    struct PropertyState
+    {
+        std::string key_path;
+        std::string table_name;
+        bool ascending;
+    };
+    struct SingleOrderingState
+    {
+        std::vector<PropertyState> properties;
+        size_t limit;
+        enum class DescriptorType { Sort, Distinct, Limit, Include } type;
+    };
+    std::vector<SingleOrderingState> orderings;
+};
+
+struct ParserResult
+{
+    ParserResult(Predicate p, DescriptorOrderingState o)
+    : predicate(p)
+    , ordering(o) {}
+    Predicate predicate;
+    DescriptorOrderingState ordering;
+};
+
+ParserResult parse(const char* query); // assumes c-style null termination
+ParserResult parse(const std::string& query);
+ParserResult parse(const realm::StringData& query);
+
+DescriptorOrderingState parse_include_path(const realm::StringData& path);
+
+// run the analysis tool to check for cycles in the grammar
+// returns the number of problems found and prints some info to std::cout
+size_t analyze_grammar();
+}
+}
+
+#endif // REALM_PARSER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/parser_utils.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/parser_utils.hpp
new file mode 100644
index 0000000..12b79c9
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/parser_utils.hpp
@@ -0,0 +1,87 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_PARSER_UTILS_HPP
+#define REALM_PARSER_UTILS_HPP
+
+#include <realm/data_type.hpp>
+#include <realm/util/to_string.hpp>
+#include "parser.hpp"
+
+#include <sstream>
+#include <stdexcept>
+
+namespace realm {
+
+class Table;
+class Timestamp;
+struct Link;
+
+namespace util {
+
+// check a precondition and throw an exception if it is not met
+// this should be used iff the condition being false indicates a bug in the caller
+// of the function checking its preconditions
+#define realm_precondition(condition, message) if (!REALM_LIKELY(condition)) { throw std::logic_error(message); }
+
+
+template <typename T>
+const char* type_to_str();
+
+template <>
+const char* type_to_str<bool>();
+template <>
+const char* type_to_str<Int>();
+template <>
+const char* type_to_str<Float>();
+template <>
+const char* type_to_str<Double>();
+template <>
+const char* type_to_str<String>();
+template <>
+const char* type_to_str<Binary>();
+template <>
+const char* type_to_str<Timestamp>();
+template <>
+const char* type_to_str<Link>();
+
+const char* data_type_to_str(DataType type);
+const char* collection_operator_to_str(parser::Expression::KeyPathOp op);
+const char* comparison_type_to_str(parser::Predicate::ComparisonType type);
+
+using KeyPath = std::vector<std::string>;
+KeyPath key_path_from_string(const std::string &s);
+std::string key_path_to_string(const KeyPath& keypath);
+StringData get_printable_table_name(StringData name);
+StringData get_printable_table_name(const Table& table);
+
+template<typename T>
+T stot(std::string const& s) {
+    std::istringstream iss(s);
+    T value;
+    iss >> value;
+    if (iss.fail()) {
+        throw std::invalid_argument(util::format("Cannot convert string '%1'", s));
+    }
+    return value;
+}
+
+} // namespace utils
+} // namespace realm
+
+#endif // REALM_PARSER_UTILS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/property_expression.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/property_expression.hpp
new file mode 100644
index 0000000..8f4a7ec
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/property_expression.hpp
@@ -0,0 +1,78 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_PROPERTY_EXPRESSION_HPP
+#define REALM_PROPERTY_EXPRESSION_HPP
+
+#include <realm/parser/keypath_mapping.hpp>
+#include <realm/query.hpp>
+#include <realm/table.hpp>
+
+namespace realm {
+namespace parser {
+
+struct PropertyExpression
+{
+    Query &query;
+    std::vector<KeyPathElement> link_chain;
+    DataType get_dest_type() const;
+    size_t get_dest_ndx() const;
+    ConstTableRef get_dest_table() const;
+    bool dest_type_is_backlink() const;
+
+    PropertyExpression(Query &q, const std::string &key_path_string, parser::KeyPathMapping& mapping);
+
+    Table* table_getter() const;
+
+    template <typename RetType>
+    auto value_of_type_for_query() const
+    {
+        return this->table_getter()->template column<RetType>(get_dest_ndx());
+    }
+};
+
+inline DataType PropertyExpression::get_dest_type() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().col_type;
+}
+
+inline bool PropertyExpression::dest_type_is_backlink() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().is_backlink;
+}
+
+inline size_t PropertyExpression::get_dest_ndx() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().col_ndx;
+}
+
+inline ConstTableRef PropertyExpression::get_dest_table() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().table;
+}
+
+
+} // namespace parser
+} // namespace realm
+
+#endif // REALM_PROPERTY_EXPRESSION_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/query_builder.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/query_builder.hpp
new file mode 100644
index 0000000..34a72b6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/query_builder.hpp
@@ -0,0 +1,158 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_QUERY_BUILDER_HPP
+#define REALM_QUERY_BUILDER_HPP
+
+#include <string>
+#include <memory>
+#include <vector>
+
+#include <realm/binary_data.hpp>
+#include <realm/parser/keypath_mapping.hpp>
+#include <realm/null.hpp>
+#include <realm/string_data.hpp>
+#include <realm/timestamp.hpp>
+#include <realm/table.hpp>
+#include <realm/util/any.hpp>
+#include <realm/util/string_buffer.hpp>
+
+namespace realm {
+class Query;
+class Realm;
+class Table;
+template<typename> class BasicRowExpr;
+using RowExpr = BasicRowExpr<Table>;
+
+namespace parser {
+    struct Predicate;
+    struct DescriptorOrderingState;
+}
+
+namespace query_builder {
+class Arguments;
+
+void apply_predicate(Query& query, const parser::Predicate& predicate, Arguments& arguments,
+                     parser::KeyPathMapping mapping = parser::KeyPathMapping());
+
+void apply_ordering(DescriptorOrdering& ordering, ConstTableRef target, const parser::DescriptorOrderingState& state,
+                    Arguments& arguments, parser::KeyPathMapping mapping = parser::KeyPathMapping());
+void apply_ordering(DescriptorOrdering& ordering, ConstTableRef target, const parser::DescriptorOrderingState& state,
+                    parser::KeyPathMapping mapping = parser::KeyPathMapping());
+
+
+struct AnyContext
+{
+    template<typename T>
+    T unbox(const util::Any& wrapper) {
+        return util::any_cast<T>(wrapper);
+    }
+    bool is_null(const util::Any& wrapper) {
+        if (!wrapper.has_value()) {
+            return true;
+        }
+        if (wrapper.type() == typeid(realm::null)) {
+            return true;
+        }
+        return false;
+    }
+};
+
+class Arguments {
+public:
+    virtual bool bool_for_argument(size_t argument_index) = 0;
+    virtual long long long_for_argument(size_t argument_index) = 0;
+    virtual float float_for_argument(size_t argument_index) = 0;
+    virtual double double_for_argument(size_t argument_index) = 0;
+    virtual StringData string_for_argument(size_t argument_index) = 0;
+    virtual BinaryData binary_for_argument(size_t argument_index) = 0;
+    virtual Timestamp timestamp_for_argument(size_t argument_index) = 0;
+    virtual size_t object_index_for_argument(size_t argument_index) = 0;
+    virtual bool is_argument_null(size_t argument_index) = 0;
+    // dynamic conversion space with lifetime tied to this
+    // it is used for storing literal binary/string data
+    std::vector<util::StringBuffer> buffer_space;
+};
+
+template<typename ValueType, typename ContextType>
+class ArgumentConverter : public Arguments {
+public:
+    ArgumentConverter(ContextType& context, const ValueType* arguments, size_t count)
+    : m_ctx(context)
+    , m_arguments(arguments)
+    , m_count(count)
+    {}
+
+    bool bool_for_argument(size_t i) override { return get<bool>(i); }
+    long long long_for_argument(size_t i) override { return get<int64_t>(i); }
+    float float_for_argument(size_t i) override { return get<float>(i); }
+    double double_for_argument(size_t i) override { return get<double>(i); }
+    StringData string_for_argument(size_t i) override { return get<StringData>(i); }
+    BinaryData binary_for_argument(size_t i) override { return get<BinaryData>(i); }
+    Timestamp timestamp_for_argument(size_t i) override { return get<Timestamp>(i); }
+    size_t object_index_for_argument(size_t i) override { return get<RowExpr>(i).get_index(); }
+    bool is_argument_null(size_t i) override { return m_ctx.is_null(at(i)); }
+
+private:
+    ContextType& m_ctx;
+    const ValueType* m_arguments;
+    size_t m_count;
+
+    const ValueType& at(size_t index) const
+    {
+        if (index >= m_count) {
+            std::string error_message;
+            if (m_count) {
+                error_message = util::format("Request for argument at index %1 but only %2 argument%3 provided", index, m_count, m_count == 1 ? " is" : "s are");
+            } else {
+                error_message = util::format("Request for argument at index %1 but no arguments are provided", index);
+            }
+            throw std::out_of_range(error_message);
+        }
+        return m_arguments[index];
+    }
+
+    template<typename T>
+    T get(size_t index) const
+    {
+        return m_ctx.template unbox<T>(at(index));
+    }
+};
+
+class NoArgsError : public std::runtime_error {
+public:
+    NoArgsError() : std::runtime_error("Attempt to retreive an argument when no arguments were given") {}
+};
+
+class NoArguments : public Arguments {
+public:
+    bool bool_for_argument(size_t) { throw NoArgsError(); }
+    long long long_for_argument(size_t) { throw NoArgsError(); }
+    float float_for_argument(size_t) { throw NoArgsError(); }
+    double double_for_argument(size_t) { throw NoArgsError(); }
+    StringData string_for_argument(size_t) { throw NoArgsError(); }
+    BinaryData binary_for_argument(size_t) { throw NoArgsError(); }
+    Timestamp timestamp_for_argument(size_t) { throw NoArgsError(); }
+    size_t object_index_for_argument(size_t) { throw NoArgsError(); }
+    bool is_argument_null(size_t) { throw NoArgsError(); }
+};
+
+} // namespace query_builder
+} // namespace realm
+
+#endif // REALM_QUERY_BUILDER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/subquery_expression.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/subquery_expression.hpp
new file mode 100644
index 0000000..20c04d1
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/subquery_expression.hpp
@@ -0,0 +1,112 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_SUBQUERY_EXPRESSION_HPP
+#define REALM_SUBQUERY_EXPRESSION_HPP
+
+#include <realm/parser/keypath_mapping.hpp>
+#include <realm/query.hpp>
+#include <realm/query_expression.hpp>
+#include <realm/table.hpp>
+
+#include "parser_utils.hpp"
+
+namespace realm {
+namespace parser {
+
+template <typename RetType, class Enable = void>
+struct SubqueryGetter;
+
+struct SubqueryExpression
+{
+    std::string var_name;
+    Query &query;
+    Query subquery;
+    std::vector<KeyPathElement> link_chain;
+    DataType get_dest_type() const;
+    size_t get_dest_ndx() const;
+    ConstTableRef get_dest_table() const;
+    bool dest_type_is_backlink() const;
+
+
+    SubqueryExpression(Query &q, const std::string &key_path_string, const std::string &variable_name, parser::KeyPathMapping &mapping);
+    Query& get_subquery();
+
+    Table* table_getter() const;
+
+    template <typename T>
+    auto value_of_type_for_query() const
+    {
+        return SubqueryGetter<T>::convert(*this);
+    }
+};
+
+inline DataType SubqueryExpression::get_dest_type() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().col_type;
+}
+
+inline bool SubqueryExpression::dest_type_is_backlink() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().is_backlink;
+}
+
+inline size_t SubqueryExpression::get_dest_ndx() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().col_ndx;
+}
+
+inline ConstTableRef SubqueryExpression::get_dest_table() const
+{
+    REALM_ASSERT_DEBUG(link_chain.size() > 0);
+    return link_chain.back().table;
+}
+
+// Certain operations are disabled for some types (eg. a sum of timestamps is invalid).
+// The operations that are supported have a specialisation with std::enable_if for that type below
+// any type/operation combination that is not specialised will get the runtime error from the following
+// default implementation. The return type is just a dummy to make things compile.
+template <typename RetType, class Enable>
+struct SubqueryGetter {
+    static Columns<RetType> convert(const SubqueryExpression&) {
+        throw std::runtime_error(util::format("Predicate error: comparison of type '%1' with result of a subquery count is not supported.",
+                                              type_to_str<RetType>()));
+    }
+};
+
+template <typename RetType>
+struct SubqueryGetter<RetType,
+typename std::enable_if_t<realm::is_any<RetType, Int, Float, Double>::value> >{
+    static SubQueryCount convert(const SubqueryExpression& expr)
+    {
+        if (expr.dest_type_is_backlink()) {
+            return expr.table_getter()->template column<BackLink>(*expr.get_dest_table(), expr.get_dest_ndx(), expr.subquery).count();
+        } else {
+            return expr.table_getter()->template column<LinkList>(expr.get_dest_ndx(), expr.subquery).count();
+        }
+    }
+};
+
+} // namespace parser
+} // namespace realm
+
+#endif // REALM_SUBQUERY_EXPRESSION_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/parser/value_expression.hpp b/node_modules/realm/vendor/realm-ios/include/realm/parser/value_expression.hpp
new file mode 100644
index 0000000..09ac257
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/parser/value_expression.hpp
@@ -0,0 +1,43 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2015 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_VALUE_EXPRESSION_HPP
+#define REALM_VALUE_EXPRESSION_HPP
+
+#include "parser.hpp"
+#include "query_builder.hpp"
+
+namespace realm {
+namespace parser {
+
+struct ValueExpression
+{
+    const parser::Expression* value;
+    query_builder::Arguments* arguments;
+    std::function<Table *()> table_getter;
+
+    ValueExpression(Query& query, query_builder::Arguments* args, const parser::Expression* v);
+    bool is_null();
+    template <typename RetType>
+    RetType value_of_type_for_query();
+};
+
+} // namespace parser
+} // namespace realm
+
+#endif // REALM_VALUE_EXPRESSION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/query.hpp b/node_modules/realm/vendor/realm-ios/include/realm/query.hpp
new file mode 100644
index 0000000..6d9e5a3
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/query.hpp
@@ -0,0 +1,483 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_QUERY_HPP
+#define REALM_QUERY_HPP
+
+#include <cstdint>
+#include <cstdio>
+#include <climits>
+#include <algorithm>
+#include <string>
+#include <vector>
+
+#define REALM_MULTITHREAD_QUERY 0
+
+#if REALM_MULTITHREAD_QUERY
+// FIXME: Use our C++ thread abstraction API since it provides a much
+// higher level of encapsulation and safety.
+#include <pthread.h>
+#endif
+
+#include <realm/views.hpp>
+#include <realm/table_ref.hpp>
+#include <realm/binary_data.hpp>
+#include <realm/olddatetime.hpp>
+#include <realm/handover_defs.hpp>
+#include <realm/link_view_fwd.hpp>
+#include <realm/descriptor_fwd.hpp>
+#include <realm/row.hpp>
+#include <realm/util/serializer.hpp>
+
+namespace realm {
+
+
+// Pre-declarations
+class ParentNode;
+class Table;
+class TableView;
+class TableViewBase;
+class ConstTableView;
+class Array;
+class Expression;
+class SequentialGetterBase;
+class Group;
+
+namespace metrics {
+class QueryInfo;
+}
+
+struct QueryGroup {
+    enum class State {
+        Default,
+        OrCondition,
+        OrConditionChildren,
+    };
+
+    QueryGroup() = default;
+
+    QueryGroup(const QueryGroup&);
+    QueryGroup& operator=(const QueryGroup&);
+
+    QueryGroup(QueryGroup&&) = default;
+    QueryGroup& operator=(QueryGroup&&) = default;
+
+    QueryGroup(const QueryGroup&, QueryNodeHandoverPatches&);
+
+    std::unique_ptr<ParentNode> m_root_node;
+
+    bool m_pending_not = false;
+    size_t m_subtable_column = not_found;
+    State m_state = State::Default;
+};
+
+class Query final {
+public:
+    Query(const Table& table, TableViewBase* tv = nullptr);
+    Query(const Table& table, std::unique_ptr<TableViewBase>);
+    Query(const Table& table, const LinkViewRef& lv);
+    Query();
+    Query(std::unique_ptr<Expression>);
+    ~Query() noexcept;
+
+    Query(const Query& copy);
+    Query& operator=(const Query& source);
+
+    Query(Query&&);
+    Query& operator=(Query&&);
+
+    // Find links that point to a specific target row
+    Query& links_to(size_t column_ndx, const ConstRow& target_row);
+    // Find links that point to specific target rows
+    Query& links_to(size_t column_ndx, const std::vector<ConstRow>& target_row);
+
+    // Conditions: null
+    Query& equal(size_t column_ndx, null);
+    Query& not_equal(size_t column_ndx, null);
+
+    // Conditions: int64_t
+    Query& equal(size_t column_ndx, int64_t value);
+    Query& not_equal(size_t column_ndx, int64_t value);
+    Query& greater(size_t column_ndx, int64_t value);
+    Query& greater_equal(size_t column_ndx, int64_t value);
+    Query& less(size_t column_ndx, int64_t value);
+    Query& less_equal(size_t column_ndx, int64_t value);
+    Query& between(size_t column_ndx, int64_t from, int64_t to);
+
+    // Conditions: int (we need those because conversion from '1234' is ambiguous with float/double)
+    Query& equal(size_t column_ndx, int value);
+    Query& not_equal(size_t column_ndx, int value);
+    Query& greater(size_t column_ndx, int value);
+    Query& greater_equal(size_t column_ndx, int value);
+    Query& less(size_t column_ndx, int value);
+    Query& less_equal(size_t column_ndx, int value);
+    Query& between(size_t column_ndx, int from, int to);
+
+    // Conditions: 2 int columns
+    Query& equal_int(size_t column_ndx1, size_t column_ndx2);
+    Query& not_equal_int(size_t column_ndx1, size_t column_ndx2);
+    Query& greater_int(size_t column_ndx1, size_t column_ndx2);
+    Query& less_int(size_t column_ndx1, size_t column_ndx2);
+    Query& greater_equal_int(size_t column_ndx1, size_t column_ndx2);
+    Query& less_equal_int(size_t column_ndx1, size_t column_ndx2);
+
+    // Conditions: float
+    Query& equal(size_t column_ndx, float value);
+    Query& not_equal(size_t column_ndx, float value);
+    Query& greater(size_t column_ndx, float value);
+    Query& greater_equal(size_t column_ndx, float value);
+    Query& less(size_t column_ndx, float value);
+    Query& less_equal(size_t column_ndx, float value);
+    Query& between(size_t column_ndx, float from, float to);
+
+    // Conditions: 2 float columns
+    Query& equal_float(size_t column_ndx1, size_t column_ndx2);
+    Query& not_equal_float(size_t column_ndx1, size_t column_ndx2);
+    Query& greater_float(size_t column_ndx1, size_t column_ndx2);
+    Query& greater_equal_float(size_t column_ndx1, size_t column_ndx2);
+    Query& less_float(size_t column_ndx1, size_t column_ndx2);
+    Query& less_equal_float(size_t column_ndx1, size_t column_ndx2);
+
+    // Conditions: double
+    Query& equal(size_t column_ndx, double value);
+    Query& not_equal(size_t column_ndx, double value);
+    Query& greater(size_t column_ndx, double value);
+    Query& greater_equal(size_t column_ndx, double value);
+    Query& less(size_t column_ndx, double value);
+    Query& less_equal(size_t column_ndx, double value);
+    Query& between(size_t column_ndx, double from, double to);
+
+    // Conditions: 2 double columns
+    Query& equal_double(size_t column_ndx1, size_t column_ndx2);
+    Query& not_equal_double(size_t column_ndx1, size_t column_ndx2);
+    Query& greater_double(size_t column_ndx1, size_t column_ndx2);
+    Query& greater_equal_double(size_t column_ndx1, size_t column_ndx2);
+    Query& less_double(size_t column_ndx1, size_t column_ndx2);
+    Query& less_equal_double(size_t column_ndx1, size_t column_ndx2);
+
+    // Conditions: timestamp
+    Query& equal(size_t column_ndx, Timestamp value);
+    Query& not_equal(size_t column_ndx, Timestamp value);
+    Query& greater(size_t column_ndx, Timestamp value);
+    Query& greater_equal(size_t column_ndx, Timestamp value);
+    Query& less_equal(size_t column_ndx, Timestamp value);
+    Query& less(size_t column_ndx, Timestamp value);
+
+    // Conditions: size
+    Query& size_equal(size_t column_ndx, int64_t value);
+    Query& size_not_equal(size_t column_ndx, int64_t value);
+    Query& size_greater(size_t column_ndx, int64_t value);
+    Query& size_greater_equal(size_t column_ndx, int64_t value);
+    Query& size_less_equal(size_t column_ndx, int64_t value);
+    Query& size_less(size_t column_ndx, int64_t value);
+    Query& size_between(size_t column_ndx, int64_t from, int64_t to);
+
+    // Conditions: bool
+    Query& equal(size_t column_ndx, bool value);
+
+    // Conditions: date
+    Query& equal_olddatetime(size_t column_ndx, OldDateTime value)
+    {
+        return equal(column_ndx, int64_t(value.get_olddatetime()));
+    }
+    Query& not_equal_olddatetime(size_t column_ndx, OldDateTime value)
+    {
+        return not_equal(column_ndx, int64_t(value.get_olddatetime()));
+    }
+    Query& greater_olddatetime(size_t column_ndx, OldDateTime value)
+    {
+        return greater(column_ndx, int64_t(value.get_olddatetime()));
+    }
+    Query& greater_equal_olddatetime(size_t column_ndx, OldDateTime value)
+    {
+        return greater_equal(column_ndx, int64_t(value.get_olddatetime()));
+    }
+    Query& less_olddatetime(size_t column_ndx, OldDateTime value)
+    {
+        return less(column_ndx, int64_t(value.get_olddatetime()));
+    }
+    Query& less_equal_olddatetime(size_t column_ndx, OldDateTime value)
+    {
+        return less_equal(column_ndx, int64_t(value.get_olddatetime()));
+    }
+    Query& between_olddatetime(size_t column_ndx, OldDateTime from, OldDateTime to)
+    {
+        return between(column_ndx, int64_t(from.get_olddatetime()), int64_t(to.get_olddatetime()));
+    }
+
+    // Conditions: strings
+    Query& equal(size_t column_ndx, StringData value, bool case_sensitive = true);
+    Query& not_equal(size_t column_ndx, StringData value, bool case_sensitive = true);
+    Query& begins_with(size_t column_ndx, StringData value, bool case_sensitive = true);
+    Query& ends_with(size_t column_ndx, StringData value, bool case_sensitive = true);
+    Query& contains(size_t column_ndx, StringData value, bool case_sensitive = true);
+    Query& like(size_t column_ndx, StringData value, bool case_sensitive = true);
+
+    // These are shortcuts for equal(StringData(c_str)) and
+    // not_equal(StringData(c_str)), and are needed to avoid unwanted
+    // implicit conversion of char* to bool.
+    Query& equal(size_t column_ndx, const char* c_str, bool case_sensitive = true);
+    Query& not_equal(size_t column_ndx, const char* c_str, bool case_sensitive = true);
+
+    // Conditions: binary data
+    Query& equal(size_t column_ndx, BinaryData value, bool case_sensitive = true);
+    Query& not_equal(size_t column_ndx, BinaryData value, bool case_sensitive = true);
+    Query& begins_with(size_t column_ndx, BinaryData value, bool case_sensitive = true);
+    Query& ends_with(size_t column_ndx, BinaryData value, bool case_sensitive = true);
+    Query& contains(size_t column_ndx, BinaryData value, bool case_sensitive = true);
+    Query& like(size_t column_ndx, BinaryData b, bool case_sensitive = true);
+
+    // Negation
+    Query& Not();
+
+    // Grouping
+    Query& group();
+    Query& end_group();
+    Query& subtable(size_t column);
+    Query& end_subtable();
+    Query& Or();
+
+    Query& and_query(const Query& q);
+    Query& and_query(Query&& q);
+    Query operator||(const Query& q);
+    Query operator&&(const Query& q);
+    Query operator!();
+
+
+    // Searching
+    size_t find(size_t begin_at_table_row = size_t(0));
+    TableView find_all(size_t start = 0, size_t end = size_t(-1), size_t limit = size_t(-1));
+
+    // Aggregates
+    size_t count(size_t start = 0, size_t end = size_t(-1), size_t limit = size_t(-1)) const;
+
+    TableView find_all(const DescriptorOrdering& descriptor);
+    size_t count(const DescriptorOrdering& descriptor);
+
+    int64_t sum_int(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                    size_t limit = size_t(-1)) const;
+
+    double average_int(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                       size_t limit = size_t(-1)) const;
+
+    int64_t maximum_int(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                        size_t limit = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    int64_t minimum_int(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                        size_t limit = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    double sum_float(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                     size_t limit = size_t(-1)) const;
+
+    double average_float(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                         size_t limit = size_t(-1)) const;
+
+    float maximum_float(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                        size_t limit = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    float minimum_float(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                        size_t limit = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    double sum_double(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                      size_t limit = size_t(-1)) const;
+
+    double average_double(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                          size_t limit = size_t(-1)) const;
+
+    double maximum_double(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                          size_t limit = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    double minimum_double(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                          size_t limit = size_t(-1), size_t* return_ndx = nullptr) const;
+
+    OldDateTime maximum_olddatetime(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0,
+                                    size_t end = size_t(-1), size_t limit = size_t(-1),
+                                    size_t* return_ndx = nullptr) const;
+
+    OldDateTime minimum_olddatetime(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0,
+                                    size_t end = size_t(-1), size_t limit = size_t(-1),
+                                    size_t* return_ndx = nullptr) const;
+
+    Timestamp maximum_timestamp(size_t column_ndx, size_t* return_ndx, size_t start = 0, size_t end = size_t(-1),
+                                size_t limit = size_t(-1));
+
+    Timestamp minimum_timestamp(size_t column_ndx, size_t* return_ndx, size_t start = 0, size_t end = size_t(-1),
+                                size_t limit = size_t(-1));
+
+    // Deletion
+    size_t remove();
+
+#if REALM_MULTITHREAD_QUERY
+    // Multi-threading
+    TableView find_all_multi(size_t start = 0, size_t end = size_t(-1));
+    ConstTableView find_all_multi(size_t start = 0, size_t end = size_t(-1)) const;
+    int set_threads(unsigned int threadcount);
+#endif
+
+    const TableRef& get_table()
+    {
+        return m_table;
+    }
+
+    // True if matching rows are guaranteed to be returned in table order.
+    bool produces_results_in_table_order() const
+    {
+        return !m_view;
+    }
+
+    // Calls sync_if_needed on the restricting view, if present.
+    // Returns the current version of the table(s) this query depends on,
+    // or util::none if the query is not associated with a table.
+    util::Optional<uint_fast64_t> sync_view_if_needed() const;
+
+    std::string validate();
+
+    std::string get_description() const;
+    std::string get_description(util::serializer::SerialisationState& state) const;
+
+private:
+    Query(Table& table, TableViewBase* tv = nullptr);
+    void create();
+
+    void init() const;
+    size_t find_internal(size_t start = 0, size_t end = size_t(-1)) const;
+    size_t peek_tablerow(size_t row) const;
+    void handle_pending_not();
+    void set_table(TableRef tr);
+
+public:
+    using HandoverPatch = QueryHandoverPatch;
+
+    std::unique_ptr<Query> clone_for_handover(std::unique_ptr<HandoverPatch>& patch, ConstSourcePayload mode) const
+    {
+        patch.reset(new HandoverPatch);
+        return std::make_unique<Query>(*this, *patch, mode);
+    }
+
+    std::unique_ptr<Query> clone_for_handover(std::unique_ptr<HandoverPatch>& patch, MutableSourcePayload mode)
+    {
+        patch.reset(new HandoverPatch);
+        return std::make_unique<Query>(*this, *patch, mode);
+    }
+
+    void apply_and_consume_patch(std::unique_ptr<HandoverPatch>& patch, Group& dest_group)
+    {
+        apply_patch(*patch, dest_group);
+        patch.reset();
+    }
+
+    void apply_patch(HandoverPatch& patch, Group& dest_group);
+    Query(const Query& source, HandoverPatch& patch, ConstSourcePayload mode);
+    Query(Query& source, HandoverPatch& patch, MutableSourcePayload mode);
+
+private:
+    void fetch_descriptor();
+
+    void add_expression_node(std::unique_ptr<Expression>);
+
+    template <class ColumnType>
+    Query& equal(size_t column_ndx1, size_t column_ndx2);
+
+    template <class ColumnType>
+    Query& less(size_t column_ndx1, size_t column_ndx2);
+
+    template <class ColumnType>
+    Query& less_equal(size_t column_ndx1, size_t column_ndx2);
+
+    template <class ColumnType>
+    Query& greater(size_t column_ndx1, size_t column_ndx2);
+
+    template <class ColumnType>
+    Query& greater_equal(size_t column_ndx1, size_t column_ndx2);
+
+    template <class ColumnType>
+    Query& not_equal(size_t column_ndx1, size_t column_ndx2);
+
+    template <typename TConditionFunction, class T>
+    Query& add_condition(size_t column_ndx, T value);
+
+    template <typename TConditionFunction>
+    Query& add_size_condition(size_t column_ndx, int64_t value);
+
+    template <typename T, bool Nullable>
+    double average(size_t column_ndx, size_t* resultcount = nullptr, size_t start = 0, size_t end = size_t(-1),
+                   size_t limit = size_t(-1)) const;
+
+    template <Action action, typename T, typename R, class ColClass>
+    R aggregate(R (ColClass::*method)(size_t, size_t, size_t, size_t*) const, size_t column_ndx, size_t* resultcount,
+                size_t start, size_t end, size_t limit, size_t* return_ndx = nullptr) const;
+
+    void aggregate_internal(Action TAction, DataType TSourceColumn, bool nullable, ParentNode* pn, QueryStateBase* st,
+                            size_t start, size_t end, SequentialGetterBase* source_column) const;
+
+    void find_all(TableViewBase& tv, size_t start = 0, size_t end = size_t(-1), size_t limit = size_t(-1)) const;
+    size_t do_count(size_t start = 0, size_t end = size_t(-1), size_t limit = size_t(-1)) const;
+    void delete_nodes() noexcept;
+
+    bool has_conditions() const
+    {
+        return m_groups.size() > 0 && m_groups[0].m_root_node;
+    }
+    ParentNode* root_node() const
+    {
+        REALM_ASSERT(m_groups.size());
+        return m_groups[0].m_root_node.get();
+    }
+
+    void add_node(std::unique_ptr<ParentNode>);
+
+    friend class Table;
+    friend class TableViewBase;
+    friend class metrics::QueryInfo;
+
+    std::string error_code;
+
+    std::vector<QueryGroup> m_groups;
+
+    // Used to access schema while building query:
+    std::vector<size_t> m_subtable_path;
+
+    ConstDescriptorRef m_current_descriptor;
+    TableRef m_table;
+
+    // points to the base class of the restricting view. If the restricting
+    // view is a link view, m_source_link_view is non-zero. If it is a table view,
+    // m_source_table_view is non-zero.
+    RowIndexes* m_view = nullptr;
+
+    // At most one of these can be non-zero, and if so the non-zero one indicates the restricting view.
+    LinkViewRef m_source_link_view;               // link views are refcounted and shared.
+    TableViewBase* m_source_table_view = nullptr; // table views are not refcounted, and not owned by the query.
+    std::unique_ptr<TableViewBase> m_owned_source_table_view; // <--- except when indicated here
+};
+
+// Implementation:
+
+inline Query& Query::equal(size_t column_ndx, const char* c_str, bool case_sensitive)
+{
+    return equal(column_ndx, StringData(c_str), case_sensitive);
+}
+
+inline Query& Query::not_equal(size_t column_ndx, const char* c_str, bool case_sensitive)
+{
+    return not_equal(column_ndx, StringData(c_str), case_sensitive);
+}
+
+} // namespace realm
+
+#endif // REALM_QUERY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/query_conditions.hpp b/node_modules/realm/vendor/realm-ios/include/realm/query_conditions.hpp
new file mode 100644
index 0000000..bc13bbe
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/query_conditions.hpp
@@ -0,0 +1,856 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_QUERY_CONDITIONS_HPP
+#define REALM_QUERY_CONDITIONS_HPP
+
+#include <cstdint>
+#include <string>
+
+#include <realm/unicode.hpp>
+#include <realm/binary_data.hpp>
+#include <realm/utilities.hpp>
+
+namespace realm {
+
+// Array::VTable only uses the first 4 conditions (enums) in an array of function pointers
+enum { cond_Equal, cond_NotEqual, cond_Greater, cond_Less, cond_VTABLE_FINDER_COUNT, cond_None, cond_LeftNotNull };
+
+// Quick hack to make "Queries with Integer null columns" able to compile in Visual Studio 2015 which doesn't full
+// support sfinae
+// (real cause hasn't been investigated yet, cannot exclude that we don't obey c++11 standard)
+struct HackClass {
+    template <class A, class B, class C>
+    bool can_match(A, B, C)
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C>
+    bool will_match(A, B, C)
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+};
+
+// Does v2 contain v1?
+struct Contains : public HackClass {
+    bool operator()(StringData v1, const char*, const char*, StringData v2, bool = false, bool = false) const
+    {
+        return v2.contains(v1);
+    }
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        return v2.contains(v1);
+    }
+    bool operator()(BinaryData v1, BinaryData v2, bool = false, bool = false) const
+    {
+        return v2.contains(v1);
+    }
+    bool operator()(StringData v1, const std::array<uint8_t, 256> &charmap, StringData v2) const
+    {
+        return v2.contains(v1, charmap);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "CONTAINS";
+    }
+
+    static const int condition = -1;
+};
+
+// Does v2 contain something like v1 (wildcard matching)?
+struct Like : public HackClass {
+    bool operator()(StringData v1, const char*, const char*, StringData v2, bool = false, bool = false) const
+    {
+        return v2.like(v1);
+    }
+    bool operator()(BinaryData b1, const char*, const char*, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return s2.like(s1);
+    }
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        return v2.like(v1);
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return s2.like(s1);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "LIKE";
+    }
+
+    static const int condition = -1;
+};
+
+// Does v2 begin with v1?
+struct BeginsWith : public HackClass {
+    bool operator()(StringData v1, const char*, const char*, StringData v2, bool = false, bool = false) const
+    {
+        return v2.begins_with(v1);
+    }
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        return v2.begins_with(v1);
+    }
+    bool operator()(BinaryData v1, BinaryData v2, bool = false, bool = false) const
+    {
+        return v2.begins_with(v1);
+    }
+
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "BEGINSWITH";
+    }
+
+    static const int condition = -1;
+};
+
+// Does v2 end with v1?
+struct EndsWith : public HackClass {
+    bool operator()(StringData v1, const char*, const char*, StringData v2, bool = false, bool = false) const
+    {
+        return v2.ends_with(v1);
+    }
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        return v2.ends_with(v1);
+    }
+    bool operator()(BinaryData v1, BinaryData v2, bool = false, bool = false) const
+    {
+        return v2.ends_with(v1);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "ENDSWITH";
+    }
+
+    static const int condition = -1;
+};
+
+struct Equal {
+    static const int avx = 0x00; // _CMP_EQ_OQ
+    //    bool operator()(const bool v1, const bool v2, bool v1null = false, bool v2null = false) const { return v1 ==
+    //    v2; }
+    bool operator()(StringData v1, const char*, const char*, StringData v2, bool = false, bool = false) const
+    {
+        return v1 == v2;
+    }
+    bool operator()(BinaryData v1, BinaryData v2, bool = false, bool = false) const
+    {
+        return v1 == v2;
+    }
+
+    template <class T>
+    bool operator()(const T& v1, const T& v2, bool v1null = false, bool v2null = false) const
+    {
+        return (v1null && v2null) || (!v1null && !v2null && v1 == v2);
+    }
+    static const int condition = cond_Equal;
+    bool can_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        return (v >= lbound && v <= ubound);
+    }
+    bool will_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        return (v == 0 && ubound == 0 && lbound == 0);
+    }
+
+    static std::string description()
+    {
+        return "==";
+    }
+};
+
+struct NotEqual {
+    static const int avx = 0x0B; // _CMP_FALSE_OQ
+    bool operator()(StringData v1, const char*, const char*, StringData v2, bool = false, bool = false) const
+    {
+        return v1 != v2;
+    }
+    // bool operator()(BinaryData v1, BinaryData v2, bool = false, bool = false) const { return v1 != v2; }
+
+    template <class T>
+    bool operator()(const T& v1, const T& v2, bool v1null = false, bool v2null = false) const
+    {
+        if (!v1null && !v2null)
+            return v1 != v2;
+
+        if (v1null && v2null)
+            return false;
+
+        return true;
+    }
+
+    static const int condition = cond_NotEqual;
+    bool can_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        return !(v == 0 && ubound == 0 && lbound == 0);
+    }
+    bool will_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        return (v > ubound || v < lbound);
+    }
+
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const = delete;
+
+    static std::string description()
+    {
+        return "!=";
+    }
+};
+
+// Does v2 contain v1?
+struct ContainsIns : public HackClass {
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, StringData v2, bool = false,
+                    bool = false) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+
+        if (v1.size() == 0 && !v2.is_null())
+            return true;
+
+        return search_case_fold(v2, v1_upper, v1_lower, v1.size()) != v2.size();
+    }
+
+    // Slow version, used if caller hasn't stored an upper and lower case version
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+
+        if (v1.size() == 0 && !v2.is_null())
+            return true;
+
+        std::string v1_upper = case_map(v1, true, IgnoreErrors);
+        std::string v1_lower = case_map(v1, false, IgnoreErrors);
+        return search_case_fold(v2, v1_upper.c_str(), v1_lower.c_str(), v1.size()) != v2.size();
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return this->operator()(s1, s2, false, false);
+    }
+    
+    // Case insensitive Boyer-Moore version
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, const std::array<uint8_t, 256> &charmap, StringData v2) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+        
+        if (v1.size() == 0 && !v2.is_null())
+            return true;
+        
+        return contains_ins(v2, v1_upper, v1_lower, v1.size(), charmap);
+    }
+
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "CONTAINS[c]";
+    }
+
+    static const int condition = -1;
+};
+
+// Does v2 contain something like v1 (wildcard matching)?
+struct LikeIns : public HackClass {
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, StringData v2, bool = false,
+                    bool = false) const
+    {
+        if (v2.is_null() || v1.is_null()) {
+            return (v2.is_null() && v1.is_null());
+        }
+
+        return string_like_ins(v2, v1_lower, v1_upper);
+    }
+    bool operator()(BinaryData b1, const char* b1_upper, const char* b1_lower, BinaryData b2, bool = false,
+                    bool = false) const
+    {
+        if (b2.is_null() || b1.is_null()) {
+            return (b2.is_null() && b1.is_null());
+        }
+        StringData s2(b2.data(), b2.size());
+
+        return string_like_ins(s2, b1_lower, b1_upper);
+    }
+
+    // Slow version, used if caller hasn't stored an upper and lower case version
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        if (v2.is_null() || v1.is_null()) {
+            return (v2.is_null() && v1.is_null());
+        }
+
+        std::string v1_upper = case_map(v1, true, IgnoreErrors);
+        std::string v1_lower = case_map(v1, false, IgnoreErrors);
+        return string_like_ins(v2, v1_lower, v1_upper);
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        if (b2.is_null() || b1.is_null()) {
+            return (b2.is_null() && b1.is_null());
+        }
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+
+        std::string s1_upper = case_map(s1, true, IgnoreErrors);
+        std::string s1_lower = case_map(s1, false, IgnoreErrors);
+        return string_like_ins(s2, s1_lower, s1_upper);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "LIKE[c]";
+    }
+
+    static const int condition = -1;
+};
+
+// Does v2 begin with v1?
+struct BeginsWithIns : public HackClass {
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, StringData v2, bool = false,
+                    bool = false) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+        return v1.size() <= v2.size() && equal_case_fold(v2.prefix(v1.size()), v1_upper, v1_lower);
+    }
+
+    // Slow version, used if caller hasn't stored an upper and lower case version
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+
+        if (v1.size() > v2.size())
+            return false;
+        std::string v1_upper = case_map(v1, true, IgnoreErrors);
+        std::string v1_lower = case_map(v1, false, IgnoreErrors);
+        return equal_case_fold(v2.prefix(v1.size()), v1_upper.c_str(), v1_lower.c_str());
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return this->operator()(s1, s2, false, false);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "BEGINSWITH[c]";
+    }
+
+    static const int condition = -1;
+};
+
+// Does v2 end with v1?
+struct EndsWithIns : public HackClass {
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, StringData v2, bool = false,
+                    bool = false) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+
+        return v1.size() <= v2.size() && equal_case_fold(v2.suffix(v1.size()), v1_upper, v1_lower);
+    }
+
+    // Slow version, used if caller hasn't stored an upper and lower case version
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        if (v2.is_null() && !v1.is_null())
+            return false;
+
+        if (v1.size() > v2.size())
+            return false;
+        std::string v1_upper = case_map(v1, true, IgnoreErrors);
+        std::string v1_lower = case_map(v1, false, IgnoreErrors);
+        return equal_case_fold(v2.suffix(v1.size()), v1_upper.c_str(), v1_lower.c_str());
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return this->operator()(s1, s2, false, false);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "ENDSWITH[c]";
+    }
+
+    static const int condition = -1;
+};
+
+struct EqualIns : public HackClass {
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, StringData v2, bool = false,
+                    bool = false) const
+    {
+        if (v1.is_null() != v2.is_null())
+            return false;
+
+        return v1.size() == v2.size() && equal_case_fold(v2, v1_upper, v1_lower);
+    }
+
+    // Slow version, used if caller hasn't stored an upper and lower case version
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        if (v1.is_null() != v2.is_null())
+            return false;
+
+        if (v1.size() != v2.size())
+            return false;
+        std::string v1_upper = case_map(v1, true, IgnoreErrors);
+        std::string v1_lower = case_map(v1, false, IgnoreErrors);
+        return equal_case_fold(v2, v1_upper.c_str(), v1_lower.c_str());
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return this->operator()(s1, s2, false, false);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool operator()(int64_t, int64_t, bool, bool) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "==[c]";
+    }
+
+    static const int condition = -1;
+};
+
+struct NotEqualIns : public HackClass {
+    bool operator()(StringData v1, const char* v1_upper, const char* v1_lower, StringData v2, bool = false,
+                    bool = false) const
+    {
+        if (v1.is_null() != v2.is_null())
+            return true;
+        return v1.size() != v2.size() || !equal_case_fold(v2, v1_upper, v1_lower);
+    }
+
+    // Slow version, used if caller hasn't stored an upper and lower case version
+    bool operator()(StringData v1, StringData v2, bool = false, bool = false) const
+    {
+        if (v1.is_null() != v2.is_null())
+            return true;
+
+        if (v1.size() != v2.size())
+            return true;
+        std::string v1_upper = case_map(v1, true, IgnoreErrors);
+        std::string v1_lower = case_map(v1, false, IgnoreErrors);
+        return !equal_case_fold(v2, v1_upper.c_str(), v1_lower.c_str());
+    }
+    bool operator()(BinaryData b1, BinaryData b2, bool = false, bool = false) const
+    {
+        StringData s1(b1.data(), b1.size());
+        StringData s2(b2.data(), b2.size());
+        return this->operator()(s1, s2, false, false);
+    }
+
+    template <class A, class B>
+    bool operator()(A, B) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    static std::string description()
+    {
+        return "!=[c]";
+    }
+
+    static const int condition = -1;
+};
+
+struct Greater {
+    static const int avx = 0x1E; // _CMP_GT_OQ
+    template <class T>
+    bool operator()(const T& v1, const T& v2, bool v1null = false, bool v2null = false) const
+    {
+        if (v1null || v2null)
+            return false;
+
+        return v1 > v2;
+    }
+    static const int condition = cond_Greater;
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+
+    bool can_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(lbound);
+        return ubound > v;
+    }
+    bool will_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(ubound);
+        return lbound > v;
+    }
+
+    static std::string description()
+    {
+        return ">";
+    }
+};
+
+struct None {
+    template <class T>
+    bool operator()(const T&, const T&, bool = false, bool = false) const
+    {
+        return true;
+    }
+    static const int condition = cond_None;
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool can_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(lbound);
+        static_cast<void>(ubound);
+        static_cast<void>(v);
+        return true;
+    }
+    bool will_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(lbound);
+        static_cast<void>(ubound);
+        static_cast<void>(v);
+        return true;
+    }
+
+    static std::string description()
+    {
+        return "none";
+    }
+};
+
+struct NotNull {
+    template <class T>
+    bool operator()(const T&, const T&, bool v = false, bool = false) const
+    {
+        return !v;
+    }
+    static const int condition = cond_LeftNotNull;
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    bool can_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(lbound);
+        static_cast<void>(ubound);
+        static_cast<void>(v);
+        return true;
+    }
+    bool will_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(lbound);
+        static_cast<void>(ubound);
+        static_cast<void>(v);
+        return true;
+    }
+    static std::string description()
+    {
+        return "!= NULL";
+    }
+};
+
+
+struct Less {
+    static const int avx = 0x11; // _CMP_LT_OQ
+    template <class T>
+    bool operator()(const T& v1, const T& v2, bool v1null = false, bool v2null = false) const
+    {
+        if (v1null || v2null)
+            return false;
+
+        return v1 < v2;
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    static const int condition = cond_Less;
+    bool can_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(ubound);
+        return lbound < v;
+    }
+    bool will_match(int64_t v, int64_t lbound, int64_t ubound)
+    {
+        static_cast<void>(lbound);
+        return ubound < v;
+    }
+    static std::string description()
+    {
+        return "<";
+    }
+};
+
+struct LessEqual : public HackClass {
+    static const int avx = 0x12; // _CMP_LE_OQ
+    template <class T>
+    bool operator()(const T& v1, const T& v2, bool v1null = false, bool v2null = false) const
+    {
+        if (v1null && v2null)
+            return true;
+
+        return (!v1null && !v2null && v1 <= v2);
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    static std::string description()
+    {
+        return "<=";
+    }
+    static const int condition = -1;
+};
+
+struct GreaterEqual : public HackClass {
+    static const int avx = 0x1D; // _CMP_GE_OQ
+    template <class T>
+    bool operator()(const T& v1, const T& v2, bool v1null = false, bool v2null = false) const
+    {
+        if (v1null && v2null)
+            return true;
+
+        return (!v1null && !v2null && v1 >= v2);
+    }
+    template <class A, class B, class C, class D>
+    bool operator()(A, B, C, D) const
+    {
+        REALM_ASSERT(false);
+        return false;
+    }
+    static std::string description()
+    {
+        return ">=";
+    }
+    static const int condition = -1;
+};
+
+
+// CompareLess is a temporary hack to have a generalized way to compare any realm types. Todo, enable correct <
+// operator of StringData (currently gives circular header dependency with utf8.hpp)
+template <class T>
+struct CompareLess {
+    static bool compare(T v1, T v2, bool = false, bool = false)
+    {
+        return v1 < v2;
+    }
+};
+template <>
+struct CompareLess<StringData> {
+    static bool compare(StringData v1, StringData v2, bool = false, bool = false)
+    {
+        bool ret = utf8_compare(v1.data(), v2.data());
+        return ret;
+    }
+};
+
+} // namespace realm
+
+#endif // REALM_QUERY_CONDITIONS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/query_engine.hpp b/node_modules/realm/vendor/realm-ios/include/realm/query_engine.hpp
new file mode 100644
index 0000000..806bc2a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/query_engine.hpp
@@ -0,0 +1,2521 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+/*
+A query consists of node objects, one for each query condition. Each node contains pointers to all other nodes:
+
+node1        node2         node3
+------       -----         -----
+node2*       node1*        node1*
+node3*       node3*        node2*
+
+The construction of all this takes part in query.cpp. Each node has two important functions:
+
+    aggregate(start, end)
+    aggregate_local(start, end)
+
+The aggregate() function executes the aggregate of a query. You can call the method on any of the nodes
+(except children nodes of OrNode and SubtableNode) - it has the same behaviour. The function contains
+scheduling that calls aggregate_local(start, end) on different nodes with different start/end ranges,
+depending on what it finds is most optimal.
+
+The aggregate_local() function contains a tight loop that tests the condition of its own node, and upon match
+it tests all other conditions at that index to report a full match or not. It will remain in the tight loop
+after a full match.
+
+So a call stack with 2 and 9 being local matches of a node could look like this:
+
+aggregate(0, 10)
+    node1->aggregate_local(0, 3)
+        node2->find_first_local(2, 3)
+        node3->find_first_local(2, 3)
+    node3->aggregate_local(3, 10)
+        node1->find_first_local(4, 5)
+        node2->find_first_local(4, 5)
+        node1->find_first_local(7, 8)
+        node2->find_first_local(7, 8)
+
+find_first_local(n, n + 1) is a function that can be used to test a single row of another condition. Note that
+this is very simplified. There are other statistical arguments to the methods, and also, find_first_local() can be
+called from a callback function called by an integer Array.
+
+
+Template arguments in methods:
+----------------------------------------------------------------------------------------------------
+
+TConditionFunction: Each node has a condition from query_conditions.c such as Equal, GreaterEqual, etc
+
+TConditionValue:    Type of values in condition column. That is, int64_t, float, int, bool, etc
+
+TAction:            What to do with each search result, from the enums act_ReturnFirst, act_Count, act_Sum, etc
+
+TResult:            Type of result of actions - float, double, int64_t, etc. Special notes: For act_Count it's
+                    int64_t, for RLM_FIND_ALL it's int64_t which points at destination array.
+
+TSourceColumn:      Type of source column used in actions, or *ignored* if no source column is used (like for
+                    act_Count, act_ReturnFirst)
+
+
+There are two important classes used in queries:
+----------------------------------------------------------------------------------------------------
+SequentialGetter    Column iterator used to get successive values with leaf caching. Used both for condition columns
+                    and aggregate source column
+
+AggregateState      State of the aggregate - contains a state variable that stores intermediate sum, max, min,
+                    etc, etc.
+
+*/
+
+#ifndef REALM_QUERY_ENGINE_HPP
+#define REALM_QUERY_ENGINE_HPP
+
+#include <algorithm>
+#include <functional>
+#include <sstream>
+#include <string>
+#include <array>
+
+#include <realm/array_basic.hpp>
+#include <realm/array_string.hpp>
+#include <realm/column_binary.hpp>
+#include <realm/column_fwd.hpp>
+#include <realm/column_link.hpp>
+#include <realm/column_linklist.hpp>
+#include <realm/column_mixed.hpp>
+#include <realm/column_string.hpp>
+#include <realm/column_string_enum.hpp>
+#include <realm/column_table.hpp>
+#include <realm/column_timestamp.hpp>
+#include <realm/column_type_traits.hpp>
+#include <realm/column_type_traits.hpp>
+#include <realm/impl/sequential_getter.hpp>
+#include <realm/link_view.hpp>
+#include <realm/metrics/query_info.hpp>
+#include <realm/query_conditions.hpp>
+#include <realm/query_operators.hpp>
+#include <realm/table.hpp>
+#include <realm/unicode.hpp>
+#include <realm/util/miscellaneous.hpp>
+#include <realm/util/serializer.hpp>
+#include <realm/util/shared_ptr.hpp>
+#include <realm/util/string_buffer.hpp>
+#include <realm/utilities.hpp>
+
+#include <map>
+#include <unordered_set>
+
+#if REALM_X86_OR_X64_TRUE && defined(_MSC_FULL_VER) && _MSC_FULL_VER >= 160040219
+#include <immintrin.h>
+#endif
+
+namespace realm {
+
+// Number of matches to find in best condition loop before breaking out to probe other conditions. Too low value gives
+// too many constant time overheads everywhere in the query engine. Too high value makes it adapt less rapidly to
+// changes in match frequencies.
+const size_t findlocals = 64;
+
+// Average match distance in linear searches where further increase in distance no longer increases query speed
+// (because time spent on handling each match becomes insignificant compared to time spent on the search).
+const size_t bestdist = 512;
+
+// Minimum number of matches required in a certain condition before it can be used to compute statistics. Too high
+// value can spent too much time in a bad node (with high match frequency). Too low value gives inaccurate statistics.
+const size_t probe_matches = 4;
+
+const size_t bitwidth_time_unit = 64;
+
+typedef bool (*CallbackDummy)(int64_t);
+
+class ParentNode {
+    typedef ParentNode ThisType;
+
+public:
+    ParentNode() = default;
+    virtual ~ParentNode() = default;
+
+    void gather_children(std::vector<ParentNode*>& v)
+    {
+        m_children.clear();
+        size_t i = v.size();
+        v.push_back(this);
+
+        if (m_child)
+            m_child->gather_children(v);
+
+        m_children = v;
+        m_children.erase(m_children.begin() + i);
+        m_children.insert(m_children.begin(), this);
+    }
+
+    double cost() const
+    {
+        return 8 * bitwidth_time_unit / m_dD +
+               m_dT; // dt = 1/64 to 1. Match dist is 8 times more important than bitwidth
+    }
+
+    size_t find_first(size_t start, size_t end);
+
+    virtual void init()
+    {
+        // Verify that the cached column accessor is still valid
+        verify_column(); // throws
+
+        if (m_child)
+            m_child->init();
+
+        m_column_action_specializer = nullptr;
+    }
+
+    void set_table(const Table& table)
+    {
+        if (&table == m_table)
+            return;
+
+        m_table.reset(&table);
+        if (m_child)
+            m_child->set_table(table);
+        table_changed();
+    }
+
+    virtual size_t find_first_local(size_t start, size_t end) = 0;
+
+    virtual void aggregate_local_prepare(Action TAction, DataType col_id, bool nullable);
+
+    template <Action TAction, class TSourceColumn>
+    bool column_action_specialization(QueryStateBase* st, SequentialGetterBase* source_column, size_t r)
+    {
+        // TResult: type of query result
+        // TSourceValue: type of aggregate source
+        using TSourceValue = typename TSourceColumn::value_type;
+        using TResult = typename ColumnTypeTraitsSum<TSourceValue, TAction>::sum_type;
+
+        // Sum of float column must accumulate in double
+        static_assert(!(TAction == act_Sum &&
+                        (std::is_same<TSourceColumn, float>::value && !std::is_same<TResult, double>::value)),
+                      "");
+
+        TSourceValue av{};
+        // uses_val test because compiler cannot see that IntegerColumn::get has no side effect and result is
+        // discarded
+        if (static_cast<QueryState<TResult>*>(st)->template uses_val<TAction>() && source_column != nullptr) {
+            REALM_ASSERT_DEBUG(dynamic_cast<SequentialGetter<TSourceColumn>*>(source_column) != nullptr);
+            av = static_cast<SequentialGetter<TSourceColumn>*>(source_column)->get_next(r);
+        }
+        REALM_ASSERT_DEBUG(dynamic_cast<QueryState<TResult>*>(st) != nullptr);
+        bool cont = static_cast<QueryState<TResult>*>(st)->template match<TAction, 0>(r, 0, av);
+        return cont;
+    }
+
+    virtual size_t aggregate_local(QueryStateBase* st, size_t start, size_t end, size_t local_limit,
+                                   SequentialGetterBase* source_column);
+
+
+    virtual std::string validate()
+    {
+        if (error_code != "")
+            return error_code;
+        if (m_child == nullptr)
+            return "";
+        else
+            return m_child->validate();
+    }
+
+    ParentNode(const ParentNode& from)
+        : ParentNode(from, nullptr)
+    {
+    }
+
+    ParentNode(const ParentNode& from, QueryNodeHandoverPatches* patches)
+        : m_child(from.m_child ? from.m_child->clone(patches) : nullptr)
+        , m_condition_column_idx(from.m_condition_column_idx)
+        , m_dD(from.m_dD)
+        , m_dT(from.m_dT)
+        , m_probes(from.m_probes)
+        , m_matches(from.m_matches)
+        , m_table(patches ? ConstTableRef{} : from.m_table)
+    {
+    }
+
+    void add_child(std::unique_ptr<ParentNode> child)
+    {
+        if (m_child)
+            m_child->add_child(std::move(child));
+        else
+            m_child = std::move(child);
+    }
+
+    virtual std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* = nullptr) const = 0;
+
+    virtual void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group)
+    {
+        if (m_child)
+            m_child->apply_handover_patch(patches, group);
+    }
+
+    virtual void verify_column() const = 0;
+
+    virtual std::string describe(util::serializer::SerialisationState&) const
+    {
+        return "";
+    }
+
+    virtual std::string describe_condition() const
+    {
+        return "matches";
+    }
+
+    virtual std::string describe_expression(util::serializer::SerialisationState& state) const
+    {
+        std::string s;
+        s = describe(state);
+        if (m_child) {
+            s = s + " and " + m_child->describe_expression(state);
+        }
+        return s;
+    }
+
+    std::unique_ptr<ParentNode> m_child;
+    std::vector<ParentNode*> m_children;
+    size_t m_condition_column_idx = npos; // Column of search criteria
+
+    double m_dD;       // Average row distance between each local match at current position
+    double m_dT = 0.0; // Time overhead of testing index i + 1 if we have just tested index i. > 1 for linear scans, 0
+    // for index/tableview
+
+    size_t m_probes = 0;
+    size_t m_matches = 0;
+
+protected:
+    typedef bool (ParentNode::*Column_action_specialized)(QueryStateBase*, SequentialGetterBase*, size_t);
+    Column_action_specialized m_column_action_specializer;
+    ConstTableRef m_table;
+    std::string error_code;
+
+    const ColumnBase& get_column_base(size_t ndx)
+    {
+        return m_table->get_column_base(ndx);
+    }
+
+    template <class ColType>
+    const ColType& get_column(size_t ndx)
+    {
+        auto& col = m_table->get_column_base(ndx);
+        REALM_ASSERT_DEBUG(dynamic_cast<const ColType*>(&col));
+        return static_cast<const ColType&>(col);
+    }
+
+    ColumnType get_real_column_type(size_t ndx)
+    {
+        return m_table->get_real_column_type(ndx);
+    }
+
+    template <class ColType>
+    void copy_getter(SequentialGetter<ColType>& dst, size_t& dst_idx, const SequentialGetter<ColType>& src,
+                     const QueryNodeHandoverPatches* patches)
+    {
+        if (src.m_column) {
+            if (patches)
+                dst_idx = src.m_column->get_column_index();
+            else
+                dst.init(src.m_column);
+        }
+    }
+
+    void do_verify_column(const ColumnBase* col, size_t col_ndx = npos) const
+    {
+        if (col_ndx == npos)
+            col_ndx = m_condition_column_idx;
+        if (m_table && col_ndx != npos) {
+            m_table->verify_column(col_ndx, col);
+        }
+    }
+
+private:
+    virtual void table_changed() = 0;
+};
+
+// For conditions on a subtable (encapsulated in subtable()...end_subtable()). These return the parent row as match if
+// and only if one or more subtable rows match the condition.
+class SubtableNode : public ParentNode {
+public:
+    SubtableNode(size_t column, std::unique_ptr<ParentNode> condition)
+        : m_condition(std::move(condition))
+    {
+        m_dT = 100.0;
+        m_condition_column_idx = column;
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+
+        m_dD = 10.0;
+
+        // m_condition is first node in condition of subtable query.
+        if (m_condition) {
+            // Can't call init() here as usual since the subtable can be degenerate
+            // m_condition->init(table);
+            std::vector<ParentNode*> v;
+            m_condition->gather_children(v);
+        }
+    }
+
+    void table_changed() override
+    {
+        m_col_type = m_table->get_real_column_type(m_condition_column_idx);
+        REALM_ASSERT(m_col_type == col_type_Table || m_col_type == col_type_Mixed);
+        if (m_col_type == col_type_Table)
+            m_column = &m_table->get_column_table(m_condition_column_idx);
+        else // Mixed
+            m_column = &m_table->get_column_mixed(m_condition_column_idx);
+    }
+
+    void verify_column() const override
+    {
+        if (m_table)
+            m_table->verify_column(m_condition_column_idx, m_column);
+    }
+
+    std::string validate() override
+    {
+        if (error_code != "")
+            return error_code;
+        if (m_condition == nullptr)
+            return "Unbalanced subtable/end_subtable block";
+        else
+            return m_condition->validate();
+    }
+
+    std::string describe(util::serializer::SerialisationState&) const override
+    {
+        throw SerialisationError("Serialising a query which contains a subtable expression is currently unsupported.");
+    }
+
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        REALM_ASSERT(m_table);
+        REALM_ASSERT(m_condition);
+
+        for (size_t s = start; s < end; ++s) {
+            ConstTableRef subtable; // TBD: optimize this back to Table*
+            if (m_col_type == col_type_Table)
+                subtable = static_cast<const SubtableColumn*>(m_column)->get_subtable_tableref(s);
+            else {
+                subtable = static_cast<const MixedColumn*>(m_column)->get_subtable_tableref(s);
+                if (!subtable)
+                    continue;
+            }
+
+            if (subtable->is_degenerate())
+                return not_found;
+
+            m_condition->set_table(*subtable);
+            m_condition->init();
+            const size_t subsize = subtable->size();
+            const size_t sub = m_condition->find_first(0, subsize);
+
+            if (sub != not_found)
+                return s;
+        }
+        return not_found;
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new SubtableNode(*this, patches));
+    }
+
+    SubtableNode(const SubtableNode& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_condition(from.m_condition ? from.m_condition->clone(patches) : nullptr)
+        , m_column(from.m_column)
+        , m_col_type(from.m_col_type)
+    {
+        if (m_column && patches)
+            m_condition_column_idx = m_column->get_column_index();
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        m_condition->apply_handover_patch(patches, group);
+        ParentNode::apply_handover_patch(patches, group);
+    }
+
+    std::unique_ptr<ParentNode> m_condition;
+    const ColumnBase* m_column = nullptr;
+    ColumnType m_col_type;
+};
+
+namespace _impl {
+
+template <class ColType>
+struct CostHeuristic;
+
+template <>
+struct CostHeuristic<IntegerColumn> {
+    static constexpr double dD()
+    {
+        return 100.0;
+    }
+    static constexpr double dT()
+    {
+        return 1.0 / 4.0;
+    }
+};
+
+template <>
+struct CostHeuristic<IntNullColumn> {
+    static constexpr double dD()
+    {
+        return 100.0;
+    }
+    static constexpr double dT()
+    {
+        return 1.0 / 4.0;
+    }
+};
+
+// FIXME: Add AdaptiveStringColumn, BasicColumn, etc.
+}
+
+class ColumnNodeBase : public ParentNode {
+protected:
+    ColumnNodeBase(size_t column_idx)
+    {
+        m_condition_column_idx = column_idx;
+    }
+
+    ColumnNodeBase(const ColumnNodeBase& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_last_local_match(from.m_last_local_match)
+        , m_local_matches(from.m_local_matches)
+        , m_local_limit(from.m_local_limit)
+        , m_fastmode_disabled(from.m_fastmode_disabled)
+        , m_action(from.m_action)
+        , m_state(from.m_state)
+        , m_source_column(from.m_source_column)
+    {
+    }
+
+    template <Action TAction, class ColType>
+    bool match_callback(int64_t v)
+    {
+        using TSourceValue = typename ColType::value_type;
+        using QueryStateType = typename ColumnTypeTraitsSum<TSourceValue, TAction>::sum_type;
+
+        size_t i = to_size_t(v);
+        m_last_local_match = i;
+        m_local_matches++;
+
+        auto state = static_cast<QueryState<QueryStateType>*>(m_state);
+        auto source_column = static_cast<SequentialGetter<ColType>*>(m_source_column);
+
+        // Test remaining sub conditions of this node. m_children[0] is the node that called match_callback(), so skip
+        // it
+        for (size_t c = 1; c < m_children.size(); c++) {
+            m_children[c]->m_probes++;
+            size_t m = m_children[c]->find_first_local(i, i + 1);
+            if (m != i)
+                return true;
+        }
+
+        bool b;
+        if (state->template uses_val<TAction>()) { // Compiler cannot see that IntegerColumn::Get has no side effect
+            // and result is discarded
+            TSourceValue av = source_column->get_next(i);
+            b = state->template match<TAction, false>(i, 0, av);
+        }
+        else {
+            b = state->template match<TAction, false>(i, 0, TSourceValue{});
+        }
+
+        return b;
+    }
+
+    // Aggregate bookkeeping
+    size_t m_last_local_match = npos;
+    size_t m_local_matches = 0;
+    size_t m_local_limit = 0;
+    bool m_fastmode_disabled = false;
+    Action m_action;
+    QueryStateBase* m_state = nullptr;
+    SequentialGetterBase* m_source_column =
+        nullptr; // Column of values used in aggregate (act_FindAll, actReturnFirst, act_Sum, etc)
+};
+
+template <class ColType>
+class IntegerNodeBase : public ColumnNodeBase {
+    using ThisType = IntegerNodeBase<ColType>;
+
+public:
+    using TConditionValue = typename ColType::value_type;
+    static const bool nullable = ColType::nullable;
+
+    template <class TConditionFunction, Action TAction, DataType TDataType, bool Nullable>
+    bool find_callback_specialization(size_t s, size_t end_in_leaf)
+    {
+        using AggregateColumnType = typename GetColumnType<TDataType, Nullable>::type;
+        bool cont;
+        size_t start_in_leaf = s - this->m_leaf_start;
+        cont = this->m_leaf_ptr->template find<TConditionFunction, act_CallbackIdx>(
+            m_value, start_in_leaf, end_in_leaf, this->m_leaf_start, nullptr,
+            std::bind(std::mem_fn(&ThisType::template match_callback<TAction, AggregateColumnType>), this,
+                      std::placeholders::_1));
+        return cont;
+    }
+
+protected:
+    using LeafType = typename ColType::LeafType;
+    using LeafInfo = typename ColType::LeafInfo;
+
+    size_t aggregate_local_impl(QueryStateBase* st, size_t start, size_t end, size_t local_limit,
+                                SequentialGetterBase* source_column, int c)
+    {
+        REALM_ASSERT(m_children.size() > 0);
+        m_local_matches = 0;
+        m_local_limit = local_limit;
+        m_last_local_match = start - 1;
+        m_state = st;
+
+        // If there are no other nodes than us (m_children.size() == 1) AND the column used for our condition is
+        // the same as the column used for the aggregate action, then the entire query can run within scope of that
+        // column only, with no references to other columns:
+        bool fastmode = should_run_in_fastmode(source_column);
+        for (size_t s = start; s < end;) {
+            cache_leaf(s);
+
+            size_t end_in_leaf;
+            if (end > m_leaf_end)
+                end_in_leaf = m_leaf_end - m_leaf_start;
+            else
+                end_in_leaf = end - m_leaf_start;
+
+            if (fastmode) {
+                bool cont;
+                size_t start_in_leaf = s - m_leaf_start;
+                cont = m_leaf_ptr->find(c, m_action, m_value, start_in_leaf, end_in_leaf, m_leaf_start,
+                                        static_cast<QueryState<int64_t>*>(st));
+                if (!cont)
+                    return not_found;
+            }
+            // Else, for each match in this node, call our IntegerNodeBase::match_callback to test remaining nodes
+            // and/or extract
+            // aggregate payload from aggregate column:
+            else {
+                m_source_column = source_column;
+                bool cont = (this->*m_find_callback_specialized)(s, end_in_leaf);
+                if (!cont)
+                    return not_found;
+            }
+
+            if (m_local_matches == m_local_limit)
+                break;
+
+            s = end_in_leaf + m_leaf_start;
+        }
+
+        if (m_local_matches == m_local_limit) {
+            m_dD = (m_last_local_match + 1 - start) / (m_local_matches + 1.0);
+            return m_last_local_match + 1;
+        }
+        else {
+            m_dD = (end - start) / (m_local_matches + 1.0);
+            return end;
+        }
+    }
+
+    IntegerNodeBase(TConditionValue value, size_t column_idx)
+        : ColumnNodeBase(column_idx)
+        , m_value(std::move(value))
+    {
+    }
+
+    IntegerNodeBase(const ThisType& from, QueryNodeHandoverPatches* patches)
+        : ColumnNodeBase(from, patches)
+        , m_value(from.m_value)
+        , m_condition_column(from.m_condition_column)
+        , m_find_callback_specialized(from.m_find_callback_specialized)
+    {
+        if (m_condition_column && patches)
+            m_condition_column_idx = m_condition_column->get_column_index();
+    }
+
+    void table_changed() override
+    {
+        m_condition_column = &get_column<ColType>(m_condition_column_idx);
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_condition_column);
+    }
+
+    void init() override
+    {
+        ColumnNodeBase::init();
+
+        m_dT = _impl::CostHeuristic<ColType>::dT();
+        m_dD = _impl::CostHeuristic<ColType>::dD();
+
+        // Clear leaf cache
+        m_leaf_end = 0;
+        m_array_ptr.reset(); // Explicitly destroy the old one first, because we're reusing the memory.
+        m_array_ptr.reset(new (&m_leaf_cache_storage) LeafType(m_table->get_alloc()));
+    }
+
+    void get_leaf(const ColType& col, size_t ndx)
+    {
+        size_t ndx_in_leaf;
+        LeafInfo leaf_info{&m_leaf_ptr, m_array_ptr.get()};
+        col.get_leaf(ndx, ndx_in_leaf, leaf_info);
+        m_leaf_start = ndx - ndx_in_leaf;
+        m_leaf_end = m_leaf_start + m_leaf_ptr->size();
+    }
+
+    void cache_leaf(size_t s)
+    {
+        if (s >= m_leaf_end || s < m_leaf_start) {
+            get_leaf(*m_condition_column, s);
+            size_t w = m_leaf_ptr->get_width();
+            m_dT = (w == 0 ? 1.0 / REALM_MAX_BPNODE_SIZE : w / float(bitwidth_time_unit));
+        }
+    }
+
+    bool should_run_in_fastmode(SequentialGetterBase* source_column) const
+    {
+        return (m_children.size() == 1 &&
+                (source_column == nullptr ||
+                 (!m_fastmode_disabled &&
+                  static_cast<SequentialGetter<ColType>*>(source_column)->m_column == m_condition_column)));
+    }
+
+    // Search value:
+    TConditionValue m_value;
+
+    // Column on which search criteria are applied
+    const ColType* m_condition_column = nullptr;
+
+    // Leaf cache
+    using LeafCacheStorage = typename std::aligned_storage<sizeof(LeafType), alignof(LeafType)>::type;
+    LeafCacheStorage m_leaf_cache_storage;
+    std::unique_ptr<LeafType, PlacementDelete> m_array_ptr;
+    const LeafType* m_leaf_ptr = nullptr;
+    size_t m_leaf_start = npos;
+    size_t m_leaf_end = 0;
+    size_t m_local_end;
+
+    // Aggregate optimization
+    using TFind_callback_specialized = bool (ThisType::*)(size_t, size_t);
+    TFind_callback_specialized m_find_callback_specialized = nullptr;
+};
+
+
+template <class ColType, class TConditionFunction>
+class IntegerNode : public IntegerNodeBase<ColType> {
+    using BaseType = IntegerNodeBase<ColType>;
+    using ThisType = IntegerNode<ColType, TConditionFunction>;
+
+public:
+    static const bool special_null_node = false;
+    using TConditionValue = typename BaseType::TConditionValue;
+
+    IntegerNode(TConditionValue value, size_t column_ndx)
+        : BaseType(value, column_ndx)
+    {
+    }
+    IntegerNode(const IntegerNode& from, QueryNodeHandoverPatches* patches)
+        : BaseType(from, patches)
+    {
+    }
+
+    void aggregate_local_prepare(Action action, DataType col_id, bool is_nullable) override
+    {
+        this->m_fastmode_disabled = (col_id == type_Float || col_id == type_Double);
+        this->m_action = action;
+        this->m_find_callback_specialized = get_specialized_callback(action, col_id, is_nullable);
+    }
+
+    size_t aggregate_local(QueryStateBase* st, size_t start, size_t end, size_t local_limit,
+                           SequentialGetterBase* source_column) override
+    {
+        constexpr int cond = TConditionFunction::condition;
+        return this->aggregate_local_impl(st, start, end, local_limit, source_column, cond);
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        REALM_ASSERT(this->m_table);
+
+        while (start < end) {
+
+            // Cache internal leaves
+            if (start >= this->m_leaf_end || start < this->m_leaf_start) {
+                this->get_leaf(*this->m_condition_column, start);
+            }
+
+            // FIXME: Create a fast bypass when you just need to check 1 row, which is used alot from within core.
+            // It should just call array::get and save the initial overhead of find_first() which has become quite
+            // big. Do this when we have cleaned up core a bit more.
+
+            size_t end2;
+            if (end > this->m_leaf_end)
+                end2 = this->m_leaf_end - this->m_leaf_start;
+            else
+                end2 = end - this->m_leaf_start;
+
+            size_t s;
+            s = this->m_leaf_ptr->template find_first<TConditionFunction>(this->m_value, start - this->m_leaf_start,
+                                                                          end2);
+
+            if (s == not_found) {
+                start = this->m_leaf_end;
+                continue;
+            }
+            else
+                return s + this->m_leaf_start;
+        }
+
+        return not_found;
+    }
+
+    std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        return state.describe_column(ParentNode::m_table, IntegerNodeBase<ColType>::m_condition_column->get_column_index())
+            + " " + describe_condition() + " " + util::serializer::print_value(IntegerNodeBase<ColType>::m_value);
+    }
+
+    std::string describe_condition() const override
+    {
+        return TConditionFunction::description();
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new IntegerNode<ColType, TConditionFunction>(*this, patches));
+    }
+
+protected:
+    using TFind_callback_specialized = typename BaseType::TFind_callback_specialized;
+
+    static TFind_callback_specialized get_specialized_callback(Action action, DataType col_id, bool is_nullable)
+    {
+        switch (action) {
+            case act_Count:
+                return get_specialized_callback_2_int<act_Count>(col_id, is_nullable);
+            case act_Sum:
+                return get_specialized_callback_2<act_Sum>(col_id, is_nullable);
+            case act_Max:
+                return get_specialized_callback_2<act_Max>(col_id, is_nullable);
+            case act_Min:
+                return get_specialized_callback_2<act_Min>(col_id, is_nullable);
+            case act_FindAll:
+                return get_specialized_callback_2_int<act_FindAll>(col_id, is_nullable);
+            case act_CallbackIdx:
+                return get_specialized_callback_2_int<act_CallbackIdx>(col_id, is_nullable);
+            default:
+                break;
+        }
+        REALM_ASSERT(false); // Invalid aggregate function
+        return nullptr;
+    }
+
+    template <Action TAction>
+    static TFind_callback_specialized get_specialized_callback_2(DataType col_id, bool is_nullable)
+    {
+        switch (col_id) {
+            case type_Int:
+                return get_specialized_callback_3<TAction, type_Int>(is_nullable);
+            case type_Float:
+                return get_specialized_callback_3<TAction, type_Float>(is_nullable);
+            case type_Double:
+                return get_specialized_callback_3<TAction, type_Double>(is_nullable);
+            default:
+                break;
+        }
+        REALM_ASSERT(false); // Invalid aggregate source column
+        return nullptr;
+    }
+
+    template <Action TAction>
+    static TFind_callback_specialized get_specialized_callback_2_int(DataType col_id, bool is_nullable)
+    {
+        if (col_id == type_Int) {
+            return get_specialized_callback_3<TAction, type_Int>(is_nullable);
+        }
+        REALM_ASSERT(false); // Invalid aggregate source column
+        return nullptr;
+    }
+
+    template <Action TAction, DataType TDataType>
+    static TFind_callback_specialized get_specialized_callback_3(bool is_nullable)
+    {
+        if (is_nullable) {
+            return &BaseType::template find_callback_specialization<TConditionFunction, TAction, TDataType, true>;
+        }
+        else {
+            return &BaseType::template find_callback_specialization<TConditionFunction, TAction, TDataType, false>;
+        }
+    }
+};
+
+template <class ColType>
+class IntegerNode<ColType, Equal> : public IntegerNodeBase<ColType> {
+public:
+    using BaseType = IntegerNodeBase<ColType>;
+    using TConditionValue = typename BaseType::TConditionValue;
+
+    IntegerNode(TConditionValue value, size_t column_ndx)
+        : BaseType(value, column_ndx)
+    {
+    }
+    ~IntegerNode()
+    {
+        if (m_result) {
+            m_result->destroy();
+        }
+    }
+
+    void init() override
+    {
+        BaseType::init();
+        m_nb_needles = m_needles.size();
+
+        if (has_search_index()) {
+            if (m_result) {
+                m_result->clear();
+            }
+            else {
+                ref_type ref = IntegerColumn::create(Allocator::get_default());
+                m_result = std::make_unique<IntegerColumn>();
+                m_result->init_from_ref(Allocator::get_default(), ref);
+            }
+
+            IntegerNodeBase<ColType>::m_condition_column->find_all(*m_result, this->m_value, 0, realm::npos);
+            m_index_get = 0;
+            m_index_end = m_result->size();
+            IntegerNodeBase<ColType>::m_dT = 0;
+        }
+    }
+
+    void consume_condition(IntegerNode<ColType, Equal>* other)
+    {
+        REALM_ASSERT(this->m_condition_column == other->m_condition_column);
+        REALM_ASSERT(other->m_needles.empty());
+        if (m_needles.empty()) {
+            m_needles.insert(this->m_value);
+        }
+        m_needles.insert(other->m_value);
+    }
+
+    bool has_search_index() const
+    {
+        return IntegerNodeBase<ColType>::m_condition_column->has_search_index();
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        REALM_ASSERT(this->m_table);
+
+        if (has_search_index()) {
+            if (m_index_end == 0)
+                return not_found;
+
+            if (start <= m_index_last_start)
+                m_index_get = 0;
+            else
+                m_index_last_start = start;
+
+            REALM_ASSERT(m_result);
+            while (m_index_get < m_index_end) {
+                // m_results are stored in sorted ascending order, guaranteed by the string index
+                size_t ndx = size_t(m_result->get(m_index_get));
+                if (ndx >= end) {
+                    break;
+                }
+                m_index_get++;
+                if (ndx >= start) {
+                    return ndx;
+                }
+            }
+            return not_found;
+        }
+
+
+        while (start < end) {
+            // Cache internal leaves
+            this->cache_leaf(start);
+
+            size_t end2;
+            if (end > this->m_leaf_end)
+                end2 = this->m_leaf_end - this->m_leaf_start;
+            else
+                end2 = end - this->m_leaf_start;
+
+            auto start2 = start - this->m_leaf_start;
+            size_t s = realm::npos;
+            if (m_nb_needles) {
+                s = find_first_haystack(start2, end2);
+            }
+            else if (end2 - start2 == 1) {
+                if (this->m_leaf_ptr->get(start2) == this->m_value) {
+                    s = start2;
+                }
+            }
+            else {
+                s = this->m_leaf_ptr->template find_first<Equal>(this->m_value, start2, end2);
+            }
+
+            if (s == not_found) {
+                start = this->m_leaf_end;
+                continue;
+            }
+            else
+                return s + this->m_leaf_start;
+        }
+
+        return not_found;
+    }
+
+    std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(this->m_condition_column != nullptr);
+        std::string col_descr = state.describe_column(this->m_table, this->m_condition_column->get_column_index());
+
+        if (m_needles.empty()) {
+            return col_descr + " " + Equal::description() + " " +
+                   util::serializer::print_value(IntegerNodeBase<ColType>::m_value);
+        }
+
+        // FIXME: once the parser supports it, print something like "column IN {n1, n2, n3}"
+        std::string desc = "(";
+        bool is_first = true;
+        for (auto it : m_needles) {
+            if (!is_first)
+                desc += " or ";
+            desc +=
+                col_descr + " " + Equal::description() + " " + util::serializer::print_value(it); // "it" may be null
+            is_first = false;
+        }
+        desc += ")";
+        return desc;
+    }
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new IntegerNode<ColType, Equal>(*this, patches));
+    }
+
+private:
+    std::unordered_set<TConditionValue> m_needles;
+    std::unique_ptr<IntegerColumn> m_result;
+    size_t m_nb_needles = 0;
+    size_t m_index_get = 0;
+    size_t m_index_last_start = 0;
+    size_t m_index_end = 0;
+
+    IntegerNode(const IntegerNode<ColType, Equal>& from, QueryNodeHandoverPatches* patches)
+        : BaseType(from, patches)
+        , m_needles(from.m_needles)
+    {
+    }
+    size_t find_first_haystack(size_t start, size_t end)
+    {
+        const auto not_in_set = m_needles.end();
+        // for a small number of conditions, it is faster to do a linear search than to compute the hash
+        // the decision threshold was determined experimentally to be 22 conditions
+        bool search = m_nb_needles < 22;
+        auto cmp_fn = [this, search, not_in_set](const auto& v) {
+            if (search) {
+                for (auto it = m_needles.begin(); it != not_in_set; ++it) {
+                    if (*it == v)
+                        return true;
+                }
+                return false;
+            }
+            else {
+                return (m_needles.find(v) != not_in_set);
+            }
+        };
+        for (size_t i = start; i < end; ++i) {
+            auto val = this->m_leaf_ptr->get(i);
+            if (cmp_fn(val)) {
+                return i;
+            }
+        }
+        return realm::npos;
+    }
+};
+
+
+// This node is currently used for floats and doubles only
+template <class ColType, class TConditionFunction>
+class FloatDoubleNode : public ParentNode {
+public:
+    using TConditionValue = typename ColType::value_type;
+    static const bool special_null_node = false;
+
+    FloatDoubleNode(TConditionValue v, size_t column_ndx)
+        : m_value(v)
+    {
+        m_condition_column_idx = column_ndx;
+        m_dT = 1.0;
+    }
+    FloatDoubleNode(null, size_t column_ndx)
+        : m_value(null::get_null_float<TConditionValue>())
+    {
+        m_condition_column_idx = column_ndx;
+        m_dT = 1.0;
+    }
+
+    void table_changed() override
+    {
+        m_condition_column.init(&get_column<ColType>(m_condition_column_idx));
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_condition_column.m_column);
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+        m_dD = 100.0;
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        TConditionFunction cond;
+
+        auto find = [&](bool nullability) {
+            bool m_value_nan = nullability ? null::is_null_float(m_value) : false;
+            for (size_t s = start; s < end; ++s) {
+                TConditionValue v = m_condition_column.get_next(s);
+                REALM_ASSERT(!(null::is_null_float(v) && !nullability));
+                if (cond(v, m_value, nullability ? null::is_null_float<TConditionValue>(v) : false, m_value_nan))
+                    return s;
+            }
+            return not_found;
+        };
+
+        // This will inline the second case but no the first. Todo, use templated lambda when switching to c++14
+        if (m_table->is_nullable(m_condition_column_idx))
+            return find(true);
+        else
+            return find(false);
+    }
+
+    std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(m_condition_column.m_column != nullptr);
+        return state.describe_column(ParentNode::m_table, m_condition_column.m_column->get_column_index())
+            + " " + describe_condition() + " " + util::serializer::print_value(FloatDoubleNode::m_value);
+    }
+    std::string describe_condition() const override
+    {
+        return TConditionFunction::description();
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new FloatDoubleNode(*this, patches));
+    }
+
+    FloatDoubleNode(const FloatDoubleNode& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_value(from.m_value)
+    {
+        copy_getter(m_condition_column, m_condition_column_idx, from.m_condition_column, patches);
+    }
+
+protected:
+    TConditionValue m_value;
+    SequentialGetter<ColType> m_condition_column;
+};
+
+template <class ColType, class TConditionFunction>
+class SizeNode : public ParentNode {
+public:
+    SizeNode(int64_t v, size_t column)
+        : m_value(v)
+    {
+        m_condition_column_idx = column;
+    }
+
+    void table_changed() override
+    {
+        m_condition_column = &get_column<ColType>(m_condition_column_idx);
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_condition_column);
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+        m_dD = 10.0;
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        for (size_t s = start; s < end; ++s) {
+            TConditionValue v = m_condition_column->get(s);
+            if (v) {
+                int64_t sz = m_size_operator(v);
+                if (TConditionFunction()(sz, m_value))
+                    return s;
+            }
+        }
+        return not_found;
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new SizeNode(*this, patches));
+    }
+
+    SizeNode(const SizeNode& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_value(from.m_value)
+        , m_condition_column(from.m_condition_column)
+    {
+        if (m_condition_column && patches)
+            m_condition_column_idx = m_condition_column->get_column_index();
+    }
+
+private:
+    using TConditionValue = typename ColType::value_type;
+
+    int64_t m_value;
+    const ColType* m_condition_column = nullptr;
+    Size<TConditionValue> m_size_operator;
+};
+
+
+template <class TConditionFunction>
+class BinaryNode : public ParentNode {
+public:
+    using TConditionValue = BinaryData;
+    static const bool special_null_node = false;
+
+    BinaryNode(BinaryData v, size_t column)
+        : m_value(v)
+    {
+        m_dT = 100.0;
+        m_condition_column_idx = column;
+    }
+
+    BinaryNode(null, size_t column)
+        : BinaryNode(BinaryData{}, column)
+    {
+    }
+
+    void table_changed() override
+    {
+        m_condition_column = &get_column<BinaryColumn>(m_condition_column_idx);
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_condition_column);
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+
+        m_dD = 100.0;
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        TConditionFunction condition;
+        for (size_t s = start; s < end; ++s) {
+            BinaryData value = m_condition_column->get(s);
+            if (condition(m_value.get(), value))
+                return s;
+        }
+        return not_found;
+    }
+
+    virtual std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(m_condition_column != nullptr);
+        return state.describe_column(ParentNode::m_table, m_condition_column->get_column_index())
+            + " " + TConditionFunction::description() + " "
+            + util::serializer::print_value(BinaryNode::m_value.get());
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new BinaryNode(*this, patches));
+    }
+
+    BinaryNode(const BinaryNode& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_value(from.m_value)
+        , m_condition_column(from.m_condition_column)
+    {
+        if (m_condition_column && patches)
+            m_condition_column_idx = m_condition_column->get_column_index();
+    }
+
+private:
+    OwnedBinaryData m_value;
+    const BinaryColumn* m_condition_column;
+};
+
+
+class TimestampNodeBase : public ParentNode {
+public:
+    using TConditionValue = Timestamp;
+    static const bool special_null_node = false;
+    using LeafTypeSeconds = typename IntNullColumn::LeafType;
+    using LeafInfoSeconds = typename IntNullColumn::LeafInfo;
+    using LeafTypeNanos = typename IntegerColumn::LeafType;
+    using LeafInfoNanos = typename IntegerColumn::LeafInfo;
+
+
+    TimestampNodeBase(Timestamp v, size_t column)
+        : m_value(v)
+        , m_needle_seconds(m_value.is_null() ? util::none : util::make_optional(m_value.get_seconds()))
+    {
+        m_condition_column_idx = column;
+    }
+
+    TimestampNodeBase(null, size_t column)
+        : TimestampNodeBase(Timestamp{}, column)
+    {
+    }
+
+    void table_changed() override
+    {
+        m_condition_column = &get_column<TimestampColumn>(m_condition_column_idx);
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_condition_column);
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+
+        m_dD = 100.0;
+
+        // Clear leaf cache
+        m_leaf_end_seconds = 0;
+        m_array_ptr_seconds.reset(); // Explicitly destroy the old one first, because we're reusing the memory.
+        m_array_ptr_seconds.reset(new (&m_leaf_cache_storage_seconds) LeafTypeSeconds(m_table->get_alloc()));
+        m_leaf_end_nanos = 0;
+        m_array_ptr_nanos.reset(); // Explicitly destroy the old one first, because we're reusing the memory.
+        m_array_ptr_nanos.reset(new (&m_leaf_cache_storage_nanos) LeafTypeNanos(m_table->get_alloc()));
+        m_condition_column_is_nullable = m_condition_column->is_nullable();
+    }
+
+protected:
+    void get_leaf_seconds(const TimestampColumn& col, size_t ndx)
+    {
+        size_t ndx_in_leaf;
+        LeafInfoSeconds leaf_info_seconds{&m_leaf_ptr_seconds, m_array_ptr_seconds.get()};
+        col.get_seconds_leaf(ndx, ndx_in_leaf, leaf_info_seconds);
+        m_leaf_start_seconds = ndx - ndx_in_leaf;
+        m_leaf_end_seconds = m_leaf_start_seconds + m_leaf_ptr_seconds->size();
+    }
+
+    void get_leaf_nanos(const TimestampColumn& col, size_t ndx)
+    {
+        size_t ndx_in_leaf;
+        LeafInfoNanos leaf_info_nanos{&m_leaf_ptr_nanos, m_array_ptr_nanos.get()};
+        col.get_nanoseconds_leaf(ndx, ndx_in_leaf, leaf_info_nanos);
+        m_leaf_start_nanos = ndx - ndx_in_leaf;
+        m_leaf_end_nanos = m_leaf_start_nanos + m_leaf_ptr_nanos->size();
+    }
+
+    util::Optional<int64_t> get_seconds_and_cache(size_t ndx)
+    {
+        // Cache internal leaves
+        if (ndx >= this->m_leaf_end_seconds || ndx < this->m_leaf_start_seconds) {
+            this->get_leaf_seconds(*this->m_condition_column, ndx);
+        }
+        const size_t ndx_in_leaf = ndx - m_leaf_start_seconds;
+        return this->m_leaf_ptr_seconds->get(ndx_in_leaf);
+    }
+
+    int32_t get_nanoseconds_and_cache(size_t ndx)
+    {
+        // Cache internal leaves
+        if (ndx >= this->m_leaf_end_nanos || ndx < this->m_leaf_start_nanos) {
+            this->get_leaf_nanos(*this->m_condition_column, ndx);
+        }
+        return int32_t(this->m_leaf_ptr_nanos->get(ndx - this->m_leaf_start_nanos));
+    }
+
+    TimestampNodeBase(const TimestampNodeBase& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_value(from.m_value)
+        , m_needle_seconds(from.m_needle_seconds)
+        , m_condition_column(from.m_condition_column)
+        , m_condition_column_is_nullable(from.m_condition_column_is_nullable)
+    {
+        if (m_condition_column && patches)
+            m_condition_column_idx = m_condition_column->get_column_index();
+    }
+
+    Timestamp m_value;
+    util::Optional<int64_t> m_needle_seconds;
+    const TimestampColumn* m_condition_column;
+    bool m_condition_column_is_nullable = false;
+
+    // Leaf cache seconds
+    using LeafCacheStorageSeconds =
+        typename std::aligned_storage<sizeof(LeafTypeSeconds), alignof(LeafTypeSeconds)>::type;
+    LeafCacheStorageSeconds m_leaf_cache_storage_seconds;
+    std::unique_ptr<LeafTypeSeconds, PlacementDelete> m_array_ptr_seconds;
+    const LeafTypeSeconds* m_leaf_ptr_seconds = nullptr;
+    size_t m_leaf_start_seconds = npos;
+    size_t m_leaf_end_seconds = 0;
+
+    // Leaf cache nanoseconds
+    using LeafCacheStorageNanos = typename std::aligned_storage<sizeof(LeafTypeNanos), alignof(LeafTypeNanos)>::type;
+    LeafCacheStorageNanos m_leaf_cache_storage_nanos;
+    std::unique_ptr<LeafTypeNanos, PlacementDelete> m_array_ptr_nanos;
+    const LeafTypeNanos* m_leaf_ptr_nanos = nullptr;
+    size_t m_leaf_start_nanos = npos;
+    size_t m_leaf_end_nanos = 0;
+};
+
+template <class TConditionFunction>
+class TimestampNode : public TimestampNodeBase {
+public:
+    using TimestampNodeBase::TimestampNodeBase;
+
+    template <class Condition>
+    size_t find_first_local_seconds(size_t start, size_t end)
+    {
+        while (start < end) {
+            // Cache internal leaves
+            if (start >= this->m_leaf_end_seconds || start < this->m_leaf_start_seconds) {
+                this->get_leaf_seconds(*this->m_condition_column, start);
+            }
+
+            size_t end2;
+            if (end > this->m_leaf_end_seconds)
+                end2 = this->m_leaf_end_seconds - this->m_leaf_start_seconds;
+            else
+                end2 = end - this->m_leaf_start_seconds;
+
+            size_t s = this->m_leaf_ptr_seconds->template find_first<Condition>(
+                m_needle_seconds, start - this->m_leaf_start_seconds, end2);
+
+            if (s == not_found) {
+                start = this->m_leaf_end_seconds;
+                continue;
+            }
+            return s + this->m_leaf_start_seconds;
+        }
+        return not_found;
+    }
+
+    // see query_engine.cpp for operator specialisations
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        REALM_ASSERT(this->m_table);
+
+        size_t ret = m_condition_column->find<TConditionFunction>(m_value, start, end);
+        return ret;
+    }
+
+    virtual std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(m_condition_column != nullptr);
+        return state.describe_column(ParentNode::m_table, m_condition_column->get_column_index()) + " " +
+               TConditionFunction::description() + " " + util::serializer::print_value(TimestampNode::m_value);
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new TimestampNode(*this, patches));
+    }
+};
+
+template <>
+size_t TimestampNode<Greater>::find_first_local(size_t start, size_t end);
+template <>
+size_t TimestampNode<Less>::find_first_local(size_t start, size_t end);
+template <>
+size_t TimestampNode<GreaterEqual>::find_first_local(size_t start, size_t end);
+template <>
+size_t TimestampNode<LessEqual>::find_first_local(size_t start, size_t end);
+template <>
+size_t TimestampNode<Equal>::find_first_local(size_t start, size_t end);
+template <>
+size_t TimestampNode<NotEqual>::find_first_local(size_t start, size_t end);
+template <>
+size_t TimestampNode<NotNull>::find_first_local(size_t start, size_t end);
+
+class StringNodeBase : public ParentNode {
+public:
+    using TConditionValue = StringData;
+    static const bool special_null_node = true;
+
+    StringNodeBase(StringData v, size_t column)
+        : m_value(v.is_null() ? util::none : util::make_optional(std::string(v)))
+    {
+        m_condition_column_idx = column;
+    }
+
+    void table_changed() override
+    {
+        m_condition_column = &get_column_base(m_condition_column_idx);
+        m_column_type = get_real_column_type(m_condition_column_idx);
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_condition_column);
+    }
+
+    bool has_search_index() const
+    {
+        return m_condition_column->has_search_index();
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+
+        m_dT = 10.0;
+        m_probes = 0;
+        m_matches = 0;
+        m_end_s = 0;
+        m_leaf_start = 0;
+        m_leaf_end = 0;
+    }
+
+    void clear_leaf_state()
+    {
+        m_leaf.reset(nullptr);
+    }
+
+    StringNodeBase(const StringNodeBase& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_value(from.m_value)
+        , m_condition_column(from.m_condition_column)
+        , m_column_type(from.m_column_type)
+        , m_leaf_type(from.m_leaf_type)
+    {
+        if (m_condition_column && patches)
+            m_condition_column_idx = m_condition_column->get_column_index();
+    }
+
+    virtual std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(m_condition_column != nullptr);
+        StringData sd;
+        if (bool(StringNodeBase::m_value)) {
+            sd = StringData(StringNodeBase::m_value.value());
+        }
+        return state.describe_column(ParentNode::m_table, m_condition_column->get_column_index())
+            + " " + describe_condition() + " " + util::serializer::print_value(sd);
+    }
+
+protected:
+    util::Optional<std::string> m_value;
+
+    const ColumnBase* m_condition_column = nullptr;
+    ColumnType m_column_type;
+
+    // Used for linear scan through short/long-string
+    std::unique_ptr<const ArrayParent> m_leaf;
+    StringColumn::LeafType m_leaf_type;
+    size_t m_end_s = 0;
+    size_t m_leaf_start = 0;
+    size_t m_leaf_end = 0;
+    
+    inline StringData get_string(size_t s)
+    {
+        StringData t;
+        
+        if (m_column_type == col_type_StringEnum) {
+            // enum
+            t = static_cast<const StringEnumColumn*>(m_condition_column)->get(s);
+        }
+        else {
+            // short or long
+            const StringColumn* asc = static_cast<const StringColumn*>(m_condition_column);
+            REALM_ASSERT_3(s, <, asc->size());
+            if (s >= m_end_s || s < m_leaf_start) {
+                // we exceeded current leaf's range
+                clear_leaf_state();
+                size_t ndx_in_leaf;
+                m_leaf = asc->get_leaf(s, ndx_in_leaf, m_leaf_type);
+                m_leaf_start = s - ndx_in_leaf;
+                
+                if (m_leaf_type == StringColumn::leaf_type_Small)
+                    m_end_s = m_leaf_start + static_cast<const ArrayString&>(*m_leaf).size();
+                else if (m_leaf_type == StringColumn::leaf_type_Medium)
+                    m_end_s = m_leaf_start + static_cast<const ArrayStringLong&>(*m_leaf).size();
+                else
+                    m_end_s = m_leaf_start + static_cast<const ArrayBigBlobs&>(*m_leaf).size();
+            }
+            
+            if (m_leaf_type == StringColumn::leaf_type_Small)
+                t = static_cast<const ArrayString&>(*m_leaf).get(s - m_leaf_start);
+            else if (m_leaf_type == StringColumn::leaf_type_Medium)
+                t = static_cast<const ArrayStringLong&>(*m_leaf).get(s - m_leaf_start);
+            else
+                t = static_cast<const ArrayBigBlobs&>(*m_leaf).get_string(s - m_leaf_start);
+        }
+        return t;
+    }
+};
+
+// Conditions for strings. Note that Equal is specialized later in this file!
+template <class TConditionFunction>
+class StringNode : public StringNodeBase {
+public:
+    StringNode(StringData v, size_t column)
+        : StringNodeBase(v, column)
+    {
+        auto upper = case_map(v, true);
+        auto lower = case_map(v, false);
+        if (!upper || !lower) {
+            error_code = "Malformed UTF-8: " + std::string(v);
+        }
+        else {
+            m_ucase = std::move(*upper);
+            m_lcase = std::move(*lower);
+        }
+    }
+
+    void init() override
+    {
+        clear_leaf_state();
+
+        m_dD = 100.0;
+
+        StringNodeBase::init();
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        TConditionFunction cond;
+
+        for (size_t s = start; s < end; ++s) {
+            StringData t = get_string(s);
+            
+            if (cond(StringData(m_value), m_ucase.c_str(), m_lcase.c_str(), t))
+                return s;
+        }
+        return not_found;
+    }
+
+    virtual std::string describe_condition() const override
+    {
+        return TConditionFunction::description();
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new StringNode<TConditionFunction>(*this, patches));
+    }
+
+    StringNode(const StringNode& from, QueryNodeHandoverPatches* patches)
+        : StringNodeBase(from, patches)
+        , m_ucase(from.m_ucase)
+        , m_lcase(from.m_lcase)
+    {
+    }
+
+protected:
+    std::string m_ucase;
+    std::string m_lcase;
+};
+
+// Specialization for Contains condition on Strings - we specialize because we can utilize Boyer-Moore
+template <>
+class StringNode<Contains> : public StringNodeBase {
+public:
+    StringNode(StringData v, size_t column)
+    : StringNodeBase(v, column), m_charmap()
+    {
+        if (v.size() == 0)
+            return;
+        
+        // Build a dictionary of char-to-last distances in the search string
+        // (zero indicates that the char is not in needle)
+        size_t last_char_pos = v.size()-1;
+        for (size_t i = 0; i < last_char_pos; ++i) {
+            // we never jump longer increments than 255 chars, even if needle is longer (to fit in one byte)
+            uint8_t jump = last_char_pos-i < 255 ? static_cast<uint8_t>(last_char_pos-i) : 255;
+            
+            unsigned char c = v[i];
+            m_charmap[c] = jump;
+        }
+    }
+    
+    void init() override
+    {
+        clear_leaf_state();
+        
+        m_dD = 100.0;
+        
+        StringNodeBase::init();
+    }
+    
+    
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        Contains cond;
+        
+        for (size_t s = start; s < end; ++s) {
+            StringData t = get_string(s);
+            
+            if (cond(StringData(m_value), m_charmap, t))
+                return s;
+        }
+        return not_found;
+    }
+
+    virtual std::string describe_condition() const override
+    {
+        return Contains::description();
+    }
+
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new StringNode<Contains>(*this, patches));
+    }
+    
+    StringNode(const StringNode& from, QueryNodeHandoverPatches* patches)
+    : StringNodeBase(from, patches)
+    , m_charmap(from.m_charmap)
+    {
+    }
+    
+protected:
+    std::array<uint8_t, 256> m_charmap;
+};
+
+// Specialization for ContainsIns condition on Strings - we specialize because we can utilize Boyer-Moore
+template <>
+class StringNode<ContainsIns> : public StringNodeBase {
+public:
+    StringNode(StringData v, size_t column)
+    : StringNodeBase(v, column), m_charmap()
+    {
+        auto upper = case_map(v, true);
+        auto lower = case_map(v, false);
+        if (!upper || !lower) {
+            error_code = "Malformed UTF-8: " + std::string(v);
+        }
+        else {
+            m_ucase = std::move(*upper);
+            m_lcase = std::move(*lower);
+        }
+
+        if (v.size() == 0)
+            return;
+
+        // Build a dictionary of char-to-last distances in the search string
+        // (zero indicates that the char is not in needle)
+        size_t last_char_pos = m_ucase.size()-1;
+        for (size_t i = 0; i < last_char_pos; ++i) {
+            // we never jump longer increments than 255 chars, even if needle is longer (to fit in one byte)
+            uint8_t jump = last_char_pos-i < 255 ? static_cast<uint8_t>(last_char_pos-i) : 255;
+
+            unsigned char uc = m_ucase[i];
+            unsigned char lc = m_lcase[i];
+            m_charmap[uc] = jump;
+            m_charmap[lc] = jump;
+        }
+
+    }
+
+    void init() override
+    {
+        clear_leaf_state();
+
+        m_dD = 100.0;
+
+        StringNodeBase::init();
+    }
+
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        ContainsIns cond;
+
+        for (size_t s = start; s < end; ++s) {
+            StringData t = get_string(s);
+            // The current behaviour is to return all results when querying for a null string.
+            // See comment above Query_NextGen_StringConditions on why every string including "" contains null.
+            if (!bool(m_value)) {
+                return s;
+            }
+            if (cond(StringData(m_value), m_ucase.c_str(), m_lcase.c_str(), m_charmap, t))
+                return s;
+        }
+        return not_found;
+    }
+
+    virtual std::string describe_condition() const override
+    {
+        return ContainsIns::description();
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new StringNode<ContainsIns>(*this, patches));
+    }
+
+    StringNode(const StringNode& from, QueryNodeHandoverPatches* patches)
+    : StringNodeBase(from, patches)
+    , m_charmap(from.m_charmap)
+    , m_ucase(from.m_ucase)
+    , m_lcase(from.m_lcase)
+    {
+    }
+
+protected:
+    std::array<uint8_t, 256> m_charmap;
+    std::string m_ucase;
+    std::string m_lcase;
+};
+
+class StringNodeEqualBase : public StringNodeBase {
+public:
+    StringNodeEqualBase(StringData v, size_t column)
+        : StringNodeBase(v, column)
+    {
+    }
+    StringNodeEqualBase(const StringNodeEqualBase& from, QueryNodeHandoverPatches* patches)
+        : StringNodeBase(from, patches)
+    {
+    }
+    ~StringNodeEqualBase() noexcept override
+    {
+        deallocate();
+    }
+
+    void deallocate() noexcept;
+    void init() override;
+    size_t find_first_local(size_t start, size_t end) override;
+
+    virtual std::string describe_condition() const override
+    {
+        return Equal::description();
+    }
+
+protected:
+    inline BinaryData str_to_bin(const StringData& s) noexcept
+    {
+        return BinaryData(s.data(), s.size());
+    }
+
+    virtual void _search_index_init() = 0;
+    virtual size_t _find_first_local(size_t start, size_t end) = 0;
+
+    size_t m_key_ndx = not_found;
+    size_t m_last_indexed;
+
+    // Used for linear scan through enum-string
+    SequentialGetter<StringEnumColumn> m_cse;
+
+    // Used for index lookup
+    std::unique_ptr<IntegerColumn> m_index_matches;
+    bool m_index_matches_destroy = false;
+    std::unique_ptr<SequentialGetter<IntegerColumn>> m_index_getter;
+    size_t m_results_start;
+    size_t m_results_end;
+    size_t m_last_start;
+};
+
+// Specialization for Equal condition on Strings - we specialize because we can utilize indexes (if they exist) for
+// Equal. This specialisation also supports combining other StringNode<Equal> conditions into itself in order to
+// optimise the non-indexed linear search that can be happen when many conditions are OR'd together in an "IN" query.
+// Future optimization: make specialization for greater, notequal, etc
+template <>
+class StringNode<Equal> : public StringNodeEqualBase {
+public:
+    using StringNodeEqualBase::StringNodeEqualBase;
+
+    void _search_index_init() override;
+
+    void consume_condition(StringNode<Equal>* other);
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new StringNode<Equal>(*this, patches));
+    }
+
+    std::string describe(util::serializer::SerialisationState& state) const override;
+
+    StringNode<Equal>(const StringNode& from, QueryNodeHandoverPatches* patches)
+    : StringNodeEqualBase(from, patches)
+    {
+        for (auto it = from.m_needles.begin(); it != from.m_needles.end(); ++it) {
+            if (it->data() == nullptr && it->size() == 0) {
+                m_needles.insert(StringData()); // nulls
+            }
+            else {
+                m_needle_storage.emplace_back(StringBuffer());
+                m_needle_storage.back().append(it->data(), it->size());
+                m_needles.insert(StringData(m_needle_storage.back().data(), m_needle_storage.back().size()));
+            }
+        }
+    }
+
+private:
+    template <class ArrayType>
+    size_t find_first_in(ArrayType& array, size_t begin, size_t end);
+
+    size_t _find_first_local(size_t start, size_t end) override;
+    std::unordered_set<StringData> m_needles;
+    std::vector<StringBuffer> m_needle_storage;
+};
+
+
+// Specialization for EqualIns condition on Strings - we specialize because we can utilize indexes (if they exist) for
+// EqualIns.
+template <>
+class StringNode<EqualIns> : public StringNodeEqualBase {
+public:
+    StringNode(StringData v, size_t column)
+        : StringNodeEqualBase(v, column)
+    {
+        auto upper = case_map(v, true);
+        auto lower = case_map(v, false);
+        if (!upper || !lower) {
+            error_code = "Malformed UTF-8: " + std::string(v);
+        }
+        else {
+            m_ucase = std::move(*upper);
+            m_lcase = std::move(*lower);
+        }
+    }
+
+    void _search_index_init() override;
+
+    virtual std::string describe_condition() const override
+    {
+        return EqualIns::description();
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new StringNode(*this, patches));
+    }
+
+    StringNode(const StringNode& from, QueryNodeHandoverPatches* patches)
+        : StringNodeEqualBase(from, patches)
+        , m_ucase(from.m_ucase)
+        , m_lcase(from.m_lcase)
+    {
+    }
+
+private:
+    std::string m_ucase;
+    std::string m_lcase;
+
+    size_t _find_first_local(size_t start, size_t end) override;
+};
+
+// OR node contains at least two node pointers: Two or more conditions to OR
+// together in m_conditions, and the next AND condition (if any) in m_child.
+//
+// For 'second.equal(23).begin_group().first.equal(111).Or().first.equal(222).end_group().third().equal(555)', this
+// will first set m_conditions[0] = left-hand-side through constructor, and then later, when .first.equal(222) is
+// invoked, invocation will set m_conditions[1] = right-hand-side through Query& Query::Or() (see query.cpp).
+// In there, m_child is also set to next AND condition (if any exists) following the OR.
+class OrNode : public ParentNode {
+public:
+    OrNode(std::unique_ptr<ParentNode> condition)
+    {
+        m_dT = 50.0;
+        if (condition)
+            m_conditions.emplace_back(std::move(condition));
+    }
+
+    OrNode(const OrNode& other, QueryNodeHandoverPatches* patches)
+        : ParentNode(other, patches)
+    {
+        for (const auto& condition : other.m_conditions) {
+            m_conditions.emplace_back(condition->clone(patches));
+        }
+    }
+
+    void table_changed() override
+    {
+        for (auto& condition : m_conditions) {
+            condition->set_table(*m_table);
+        }
+    }
+
+    void verify_column() const override
+    {
+        for (auto& condition : m_conditions) {
+            condition->verify_column();
+        }
+    }
+
+    std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        std::string s;
+        for (size_t i = 0; i < m_conditions.size(); ++i) {
+            if (m_conditions[i]) {
+                s += m_conditions[i]->describe_expression(state);
+                if (i != m_conditions.size() - 1) {
+                    s += " or ";
+                }
+            }
+        }
+        if (m_conditions.size() > 1) {
+            s = "(" + s + ")";
+        }
+        return s;
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+
+        m_dD = 10.0;
+
+        std::sort(m_conditions.begin(), m_conditions.end(),
+                  [](auto& a, auto& b) { return a->m_condition_column_idx < b->m_condition_column_idx; });
+
+        combine_conditions<StringNode<Equal>>();
+        combine_conditions<IntegerNode<IntegerColumn, Equal>>();
+        combine_conditions<IntegerNode<IntNullColumn, Equal>>();
+
+        m_start.clear();
+        m_start.resize(m_conditions.size(), 0);
+
+        m_last.clear();
+        m_last.resize(m_conditions.size(), 0);
+
+        m_was_match.clear();
+        m_was_match.resize(m_conditions.size(), false);
+
+        std::vector<ParentNode*> v;
+        for (auto& condition : m_conditions) {
+            condition->init();
+            v.clear();
+            condition->gather_children(v);
+        }
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        if (start >= end)
+            return not_found;
+
+        size_t index = not_found;
+
+        for (size_t c = 0; c < m_conditions.size(); ++c) {
+            // out of order search; have to discard cached results
+            if (start < m_start[c]) {
+                m_last[c] = 0;
+                m_was_match[c] = false;
+            }
+            // already searched this range and didn't match
+            else if (m_last[c] >= end)
+                continue;
+            // already search this range and *did* match
+            else if (m_was_match[c] && m_last[c] >= start) {
+                if (index > m_last[c])
+                    index = m_last[c];
+                continue;
+            }
+
+            m_start[c] = start;
+            size_t fmax = std::max(m_last[c], start);
+            size_t f = m_conditions[c]->find_first(fmax, end);
+            m_was_match[c] = f != not_found;
+            m_last[c] = f == not_found ? end : f;
+            if (f != not_found && index > m_last[c])
+                index = m_last[c];
+        }
+
+        return index;
+    }
+
+    std::string validate() override
+    {
+        if (error_code != "")
+            return error_code;
+        if (m_conditions.size() == 0)
+            return "Missing left-hand side of OR";
+        if (m_conditions.size() == 1)
+            return "Missing right-hand side of OR";
+        std::string s;
+        if (m_child != 0)
+            s = m_child->validate();
+        if (s != "")
+            return s;
+        for (size_t i = 0; i < m_conditions.size(); ++i) {
+            s = m_conditions[i]->validate();
+            if (s != "")
+                return s;
+        }
+        return "";
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new OrNode(*this, patches));
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        for (auto it = m_conditions.rbegin(); it != m_conditions.rend(); ++it)
+            (*it)->apply_handover_patch(patches, group);
+
+        ParentNode::apply_handover_patch(patches, group);
+    }
+
+    std::vector<std::unique_ptr<ParentNode>> m_conditions;
+
+private:
+    template<class QueryNodeType>
+    void combine_conditions() {
+        QueryNodeType* first_match = nullptr;
+        QueryNodeType* advance = nullptr;
+        auto it = m_conditions.begin();
+        while (it != m_conditions.end()) {
+            // Only try to optimize on QueryNodeType conditions without search index
+            auto node = it->get();
+            if ((first_match = dynamic_cast<QueryNodeType*>(node)) && first_match->m_child == nullptr &&
+                !first_match->has_search_index()) {
+                auto col_ndx = first_match->m_condition_column_idx;
+                auto next = it + 1;
+                while (next != m_conditions.end() && (*next)->m_condition_column_idx == col_ndx) {
+                    auto next_node = next->get();
+                    if ((advance = dynamic_cast<QueryNodeType*>(next_node)) && next_node->m_child == nullptr) {
+                        first_match->consume_condition(advance);
+                        next = m_conditions.erase(next);
+                    }
+                    else {
+                        ++next;
+                    }
+                }
+                it = next;
+            }
+            else {
+                ++it;
+            }
+        }
+    }
+
+    // start index of the last find for each cond
+    std::vector<size_t> m_start;
+    // last looked at index of the lasft find for each cond
+    // is a matching index if m_was_match is true
+    std::vector<size_t> m_last;
+    std::vector<bool> m_was_match;
+};
+
+
+class NotNode : public ParentNode {
+public:
+    NotNode(std::unique_ptr<ParentNode> condition)
+        : m_condition(std::move(condition))
+    {
+        m_dT = 50.0;
+    }
+
+    void table_changed() override
+    {
+        m_condition->set_table(*m_table);
+    }
+
+    void verify_column() const override
+    {
+        m_condition->verify_column();
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+
+        m_dD = 10.0;
+
+        std::vector<ParentNode*> v;
+
+        m_condition->init();
+        v.clear();
+        m_condition->gather_children(v);
+
+        // Heuristics bookkeeping:
+        m_known_range_start = 0;
+        m_known_range_end = 0;
+        m_first_in_known_range = not_found;
+    }
+
+    size_t find_first_local(size_t start, size_t end) override;
+
+    std::string validate() override
+    {
+        if (error_code != "")
+            return error_code;
+        if (m_condition == 0)
+            return "Missing argument to Not";
+        std::string s;
+        if (m_child != 0)
+            s = m_child->validate();
+        if (s != "")
+            return s;
+        s = m_condition->validate();
+        if (s != "")
+            return s;
+        return "";
+    }
+
+    virtual std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        if (m_condition) {
+            return "!(" + m_condition->describe_expression(state) + ")";
+        }
+        return "!()";
+    }
+
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new NotNode(*this, patches));
+    }
+
+    NotNode(const NotNode& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_condition(from.m_condition ? from.m_condition->clone(patches) : nullptr)
+        , m_known_range_start(from.m_known_range_start)
+        , m_known_range_end(from.m_known_range_end)
+        , m_first_in_known_range(from.m_first_in_known_range)
+    {
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        m_condition->apply_handover_patch(patches, group);
+        ParentNode::apply_handover_patch(patches, group);
+    }
+
+    std::unique_ptr<ParentNode> m_condition;
+
+private:
+    // FIXME This heuristic might as well be reused for all condition nodes.
+    size_t m_known_range_start;
+    size_t m_known_range_end;
+    size_t m_first_in_known_range;
+
+    bool evaluate_at(size_t rowndx);
+    void update_known(size_t start, size_t end, size_t first);
+    size_t find_first_loop(size_t start, size_t end);
+    size_t find_first_covers_known(size_t start, size_t end);
+    size_t find_first_covered_by_known(size_t start, size_t end);
+    size_t find_first_overlap_lower(size_t start, size_t end);
+    size_t find_first_overlap_upper(size_t start, size_t end);
+    size_t find_first_no_overlap(size_t start, size_t end);
+};
+
+
+// Compare two columns with eachother row-by-row
+template <class ColType, class TConditionFunction>
+class TwoColumnsNode : public ParentNode {
+public:
+    using TConditionValue = typename ColType::value_type;
+
+    TwoColumnsNode(size_t column1, size_t column2)
+    {
+        m_dT = 100.0;
+        m_condition_column_idx1 = column1;
+        m_condition_column_idx2 = column2;
+    }
+
+    ~TwoColumnsNode() noexcept override
+    {
+        delete[] m_value.data();
+    }
+
+    void table_changed() override
+    {
+        m_getter1.init(&get_column<ColType>(m_condition_column_idx1));
+        m_getter2.init(&get_column<ColType>(m_condition_column_idx2));
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_getter1.m_column, m_condition_column_idx1);
+        do_verify_column(m_getter2.m_column, m_condition_column_idx2);
+    }
+
+    virtual std::string describe(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(m_getter1.m_column != nullptr && m_getter2.m_column != nullptr);
+        return state.describe_column(ParentNode::m_table, m_getter1.m_column->get_column_index())
+            + " " + describe_condition() + " "
+            + state.describe_column(ParentNode::m_table,m_getter2.m_column->get_column_index());
+    }
+
+    virtual std::string describe_condition() const override
+    {
+        return TConditionFunction::description();
+    }
+
+    void init() override
+    {
+        ParentNode::init();
+        m_dD = 100.0;
+    }
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        size_t s = start;
+
+        while (s < end) {
+            if (std::is_same<TConditionValue, int64_t>::value) {
+                // For int64_t we've created an array intrinsics named compare_leafs which template expands bitwidths
+                // of boths arrays to make Get faster.
+                m_getter1.cache_next(s);
+                m_getter2.cache_next(s);
+
+                QueryState<int64_t> qs;
+                bool resume = m_getter1.m_leaf_ptr->template compare_leafs<TConditionFunction, act_ReturnFirst>(
+                    m_getter2.m_leaf_ptr, s - m_getter1.m_leaf_start, m_getter1.local_end(end), 0, &qs,
+                    CallbackDummy());
+
+                if (resume)
+                    s = m_getter1.m_leaf_end;
+                else
+                    return to_size_t(qs.m_state) + m_getter1.m_leaf_start;
+            }
+            else {
+// This is for float and double.
+
+#if 0 && defined(REALM_COMPILER_AVX)
+// AVX has been disabled because of array alignment (see https://app.asana.com/0/search/8836174089724/5763107052506)
+//
+// For AVX you can call things like if (sseavx<1>()) to test for AVX, and then utilize _mm256_movemask_ps (VC)
+// or movemask_cmp_ps (gcc/clang)
+//
+// See https://github.com/rrrlasse/realm/tree/AVX for an example of utilizing AVX for a two-column search which has
+// been benchmarked to: floats: 288 ms vs 552 by using AVX compared to 2-level-unrolled FPU loop. doubles: 415 ms vs
+// 475 (more bandwidth bound). Tests against SSE have not been performed; AVX may not pay off. Please benchmark
+#endif
+
+                TConditionValue v1 = m_getter1.get_next(s);
+                TConditionValue v2 = m_getter2.get_next(s);
+                TConditionFunction C;
+
+                if (C(v1, v2))
+                    return s;
+                else
+                    s++;
+            }
+        }
+        return not_found;
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(new TwoColumnsNode<ColType, TConditionFunction>(*this, patches));
+    }
+
+    TwoColumnsNode(const TwoColumnsNode& from, QueryNodeHandoverPatches* patches)
+        : ParentNode(from, patches)
+        , m_value(from.m_value)
+        , m_condition_column(from.m_condition_column)
+        , m_column_type(from.m_column_type)
+        , m_condition_column_idx1(from.m_condition_column_idx1)
+        , m_condition_column_idx2(from.m_condition_column_idx2)
+    {
+        if (m_condition_column)
+            m_condition_column_idx = m_condition_column->get_column_index();
+        copy_getter(m_getter1, m_condition_column_idx1, from.m_getter1, patches);
+        copy_getter(m_getter2, m_condition_column_idx2, from.m_getter2, patches);
+    }
+
+private:
+    BinaryData m_value;
+    const BinaryColumn* m_condition_column = nullptr;
+    ColumnType m_column_type;
+
+    size_t m_condition_column_idx1 = not_found;
+    size_t m_condition_column_idx2 = not_found;
+
+    SequentialGetter<ColType> m_getter1;
+    SequentialGetter<ColType> m_getter2;
+};
+
+
+// For Next-Generation expressions like col1 / col2 + 123 > col4 * 100.
+class ExpressionNode : public ParentNode {
+public:
+    ExpressionNode(std::unique_ptr<Expression>);
+
+    void init() override;
+    size_t find_first_local(size_t start, size_t end) override;
+
+    void table_changed() override;
+    void verify_column() const override;
+
+    virtual std::string describe(util::serializer::SerialisationState& state) const override;
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override;
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override;
+
+private:
+    ExpressionNode(const ExpressionNode& from, QueryNodeHandoverPatches* patches);
+
+    std::unique_ptr<Expression> m_expression;
+};
+
+
+struct LinksToNodeHandoverPatch : public QueryNodeHandoverPatch {
+    std::vector<std::unique_ptr<RowBaseHandoverPatch>> m_target_rows;
+    size_t m_origin_column;
+};
+
+class LinksToNode : public ParentNode {
+public:
+    LinksToNode(size_t origin_column_index, const ConstRow& target_row)
+        : m_origin_column(origin_column_index)
+        , m_target_rows(1, target_row)
+    {
+        m_dD = 10.0;
+        m_dT = 50.0;
+    }
+
+    LinksToNode(size_t origin_column_index, const std::vector<ConstRow>& target_rows)
+        : m_origin_column(origin_column_index)
+        , m_target_rows(target_rows)
+    {
+        m_dD = 10.0;
+        m_dT = 50.0;
+    }
+
+    void table_changed() override
+    {
+        m_column_type = m_table->get_column_type(m_origin_column);
+        m_column = &const_cast<Table*>(m_table.get())->get_column_link_base(m_origin_column);
+        REALM_ASSERT(m_column_type == type_Link || m_column_type == type_LinkList);
+    }
+
+    void verify_column() const override
+    {
+        do_verify_column(m_column, m_origin_column);
+    }
+
+    virtual std::string describe(util::serializer::SerialisationState&) const override
+    {
+        throw SerialisationError("Serialising a query which links to an object is currently unsupported.");
+        // We can do something like the following when core gets stable keys
+        //return describe_column() + " " + describe_condition() + " " + util::serializer::print_value(m_target_row.get_index());
+    }
+    virtual std::string describe_condition() const override
+    {
+        return "links to";
+    }
+
+
+    size_t find_first_local(size_t start, size_t end) override
+    {
+        REALM_ASSERT(m_column);
+        if (m_column_type == type_Link) {
+            LinkColumn& cl = static_cast<LinkColumn&>(*m_column);
+            for (auto& row : m_target_rows) {
+                if (row.is_attached()) {
+                    // LinkColumn stores link to row N as the integer N + 1
+                    auto pos = cl.find_first(row.get_index() + 1, start, end);
+                    if (pos != realm::npos) {
+                        return pos;
+                    }
+                }
+            }
+        }
+        else if (m_column_type == type_LinkList) {
+            LinkListColumn& cll = static_cast<LinkListColumn&>(*m_column);
+
+            for (size_t i = start; i < end; i++) {
+                LinkViewRef lv = cll.get(i);
+                for (auto& row : m_target_rows) {
+                    if (row.is_attached()) {
+                        if (lv->find(row.get_index()) != not_found)
+                            return i;
+                    }
+                }
+            }
+        }
+
+        return not_found;
+    }
+
+    std::unique_ptr<ParentNode> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<ParentNode>(patches ? new LinksToNode(*this, patches) : new LinksToNode(*this));
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        REALM_ASSERT(patches.size());
+        std::unique_ptr<QueryNodeHandoverPatch> abstract_patch = std::move(patches.back());
+        patches.pop_back();
+
+        auto patch = dynamic_cast<LinksToNodeHandoverPatch*>(abstract_patch.get());
+        REALM_ASSERT(patch);
+
+        m_origin_column = patch->m_origin_column;
+        auto sz = patch->m_target_rows.size();
+        m_target_rows.resize(sz);
+        for (size_t i = 0; i < sz; i++) {
+            m_target_rows[i].apply_and_consume_patch(patch->m_target_rows[i], group);
+        }
+
+        ParentNode::apply_handover_patch(patches, group);
+    }
+
+private:
+    size_t m_origin_column = npos;
+    std::vector<ConstRow> m_target_rows;
+    LinkColumnBase* m_column = nullptr;
+    DataType m_column_type;
+
+    LinksToNode(const LinksToNode& source, QueryNodeHandoverPatches* patches)
+        : ParentNode(source, patches)
+    {
+        auto patch = std::make_unique<LinksToNodeHandoverPatch>();
+        patch->m_origin_column = source.m_column->get_column_index();
+        auto sz = source.m_target_rows.size();
+        patch->m_target_rows.resize(sz);
+        for (size_t i = 0; i < sz; i++) {
+            ConstRow::generate_patch(source.m_target_rows[i], patch->m_target_rows[i]);
+        }
+        patches->push_back(std::move(patch));
+    }
+};
+
+} // namespace realm
+
+#endif // REALM_QUERY_ENGINE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/query_expression.hpp b/node_modules/realm/vendor/realm-ios/include/realm/query_expression.hpp
new file mode 100644
index 0000000..bd6e1a8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/query_expression.hpp
@@ -0,0 +1,4145 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+/*
+This file lets you write queries in C++ syntax like: Expression* e = (first + 1 / second >= third + 12.3);
+
+Type conversion/promotion semantics is the same as in the C++ expressions, e.g float + int > double == float +
+(float)int > double.
+
+
+Grammar:
+-----------------------------------------------------------------------------------------------------------------------
+    Expression:         Subexpr2<T>  Compare<Cond, T>  Subexpr2<T>
+                        operator! Expression
+
+    Subexpr2<T>:        Value<T>
+                        Columns<T>
+                        Subexpr2<T>  Operator<Oper<T>  Subexpr2<T>
+                        power(Subexpr2<T>) // power(x) = x * x, as example of unary operator
+
+    Value<T>:           T
+
+    Operator<Oper<T>>:  +, -, *, /
+
+    Compare<Cond, T>:   ==, !=, >=, <=, >, <
+
+    T:                  bool, int, int64_t, float, double, StringData
+
+
+Class diagram
+-----------------------------------------------------------------------------------------------------------------------
+Subexpr2
+    void evaluate(size_t i, ValueBase* destination)
+
+Compare: public Subexpr2
+    size_t find_first(size_t start, size_t end)     // main method that executes query
+
+    unique_ptr<Subexpr2> m_left;                               // left expression subtree
+    unique_ptr<Subexpr2> m_right;                              // right expression subtree
+
+Operator: public Subexpr2
+    void evaluate(size_t i, ValueBase* destination)
+    unique_ptr<Subexpr2> m_left;                               // left expression subtree
+    unique_ptr<Subexpr2> m_right;                              // right expression subtree
+
+Value<T>: public Subexpr2
+    void evaluate(size_t i, ValueBase* destination)
+    T m_v[8];
+
+Columns<T>: public Subexpr2
+    void evaluate(size_t i, ValueBase* destination)
+    SequentialGetter<T> sg;                         // class bound to a column, lets you read values in a fast way
+    Table* m_table;
+
+class ColumnAccessor<>: public Columns<double>
+
+
+Call diagram:
+-----------------------------------------------------------------------------------------------------------------------
+Example of 'table.first > 34.6 + table.second':
+
+size_t Compare<Greater>::find_first()-------------+
+         |                                        |
+         |                                        |
+         |                                        |
+         +--> Columns<float>::evaluate()          +--------> Operator<Plus>::evaluate()
+                                                                |               |
+                                               Value<float>::evaluate()    Columns<float>::evaluate()
+
+Operator, Value and Columns have an evaluate(size_t i, ValueBase* destination) method which returns a Value<T>
+containing 8 values representing table rows i...i + 7.
+
+So Value<T> contains 8 concecutive values and all operations are based on these chunks. This is
+to save overhead by virtual calls needed for evaluating a query that has been dynamically constructed at runtime.
+
+
+Memory allocation:
+-----------------------------------------------------------------------------------------------------------------------
+Subexpressions created by the end-user are stack allocated. They are cloned to the heap when passed to UnaryOperator,
+Operator, and Compare. Those types own the clones and deallocate them when destroyed.
+
+
+Caveats, notes and todos
+-----------------------------------------------------------------------------------------------------------------------
+    * Perhaps disallow columns from two different tables in same expression
+    * The name Columns (with s) an be confusing because we also have Column (without s)
+    * We have Columns::m_table, Query::m_table and ColumnAccessorBase::m_table that point at the same thing, even with
+      ColumnAccessor<> extending Columns. So m_table is redundant, but this is in order to keep class dependencies and
+      entanglement low so that the design is flexible (if you perhaps later want a Columns class that is not dependent
+      on ColumnAccessor)
+
+Nulls
+-----------------------------------------------------------------------------------------------------------------------
+First note that at array level, nulls are distinguished between non-null in different ways:
+String:
+    m_data == 0 && m_size == 0
+
+Integer, Bool, OldDateTime stored in ArrayIntNull:
+    value == get(0) (entry 0 determins a magic value that represents nulls)
+
+Float/double:
+    null::is_null(value) which tests if value bit-matches one specific bit pattern reserved for null
+
+The Columns class encapsulates all this into a simple class that, for any type T has
+    evaluate(size_t index) that reads values from a column, taking nulls in count
+    get(index)
+    set(index)
+    is_null(index)
+    set_null(index)
+*/
+
+#ifndef REALM_QUERY_EXPRESSION_HPP
+#define REALM_QUERY_EXPRESSION_HPP
+
+#include <realm/column_link.hpp>
+#include <realm/column_linklist.hpp>
+#include <realm/column_table.hpp>
+#include <realm/column_string.hpp>
+#include <realm/column_timestamp.hpp>
+#include <realm/column_type_traits.hpp>
+#include <realm/impl/sequential_getter.hpp>
+#include <realm/link_view.hpp>
+#include <realm/metrics/query_info.hpp>
+#include <realm/query_operators.hpp>
+#include <realm/util/optional.hpp>
+#include <realm/util/serializer.hpp>
+
+#include <numeric>
+#include <algorithm>
+
+// Normally, if a next-generation-syntax condition is supported by the old query_engine.hpp, a query_engine node is
+// created because it's faster (by a factor of 5 - 10). Because many of our existing next-generation-syntax unit
+// unit tests are indeed simple enough to fallback to old query_engine, query_expression gets low test coverage. Undef
+// flag to get higher query_expression test coverage. This is a good idea to try out each time you develop on/modify
+// query_expression.
+
+#define REALM_OLDQUERY_FALLBACK
+
+namespace realm {
+
+template <class T>
+T minimum(T a, T b)
+{
+    return a < b ? a : b;
+}
+
+#ifdef REALM_OLDQUERY_FALLBACK
+// Hack to avoid template instantiation errors. See create(). Todo, see if we can simplify only_numeric somehow
+namespace _impl {
+
+template <class T, class U>
+inline T only_numeric(U in)
+{
+    return static_cast<T>(util::unwrap(in));
+}
+
+template <class T>
+inline int only_numeric(const StringData&)
+{
+    REALM_ASSERT(false);
+    return 0;
+}
+
+template <class T>
+inline int only_numeric(const BinaryData&)
+{
+    REALM_ASSERT(false);
+    return 0;
+}
+
+template <class T>
+inline StringData only_string_op_types(T in)
+{
+    REALM_ASSERT(false);
+    static_cast<void>(in);
+    return StringData();
+}
+
+inline BinaryData only_string_op_types(BinaryData in)
+{
+    return in;
+}
+
+template <>
+inline StringData only_string_op_types<StringData>(StringData in)
+{
+    return in;
+}
+
+template <class T, class U>
+inline T no_timestamp(U in)
+{
+    return static_cast<T>(util::unwrap(in));
+}
+
+template <class T>
+inline int no_timestamp(const Timestamp&)
+{
+    REALM_ASSERT(false);
+    return 0;
+}
+
+} // namespace _impl
+
+#endif // REALM_OLDQUERY_FALLBACK
+
+template <class T>
+struct Plus {
+    T operator()(T v1, T v2) const
+    {
+        return v1 + v2;
+    }
+    static std::string description()
+    {
+        return "+";
+    }
+    typedef T type;
+};
+
+template <class T>
+struct Minus {
+    T operator()(T v1, T v2) const
+    {
+        return v1 - v2;
+    }
+    static std::string description()
+    {
+        return "-";
+    }
+    typedef T type;
+};
+
+template <class T>
+struct Div {
+    T operator()(T v1, T v2) const
+    {
+        return v1 / v2;
+    }
+    static std::string description()
+    {
+        return "/";
+    }
+    typedef T type;
+};
+
+template <class T>
+struct Mul {
+    T operator()(T v1, T v2) const
+    {
+        return v1 * v2;
+    }
+    static std::string description()
+    {
+        return "*";
+    }
+    typedef T type;
+};
+
+// Unary operator
+template <class T>
+struct Pow {
+    T operator()(T v) const
+    {
+        return v * v;
+    }
+    static std::string description()
+    {
+        return "^";
+    }
+    typedef T type;
+};
+
+// Finds a common type for T1 and T2 according to C++ conversion/promotion in arithmetic (float + int => float, etc)
+template <class T1, class T2, bool T1_is_int = std::numeric_limits<T1>::is_integer || std::is_same<T1, null>::value,
+          bool T2_is_int = std::numeric_limits<T2>::is_integer || std::is_same<T2, null>::value,
+          bool T1_is_widest = (sizeof(T1) > sizeof(T2) || std::is_same<T2, null>::value)>
+struct Common;
+template <class T1, class T2, bool b>
+struct Common<T1, T2, b, b, true> {
+    typedef T1 type;
+};
+template <class T1, class T2, bool b>
+struct Common<T1, T2, b, b, false> {
+    typedef T2 type;
+};
+template <class T1, class T2, bool b>
+struct Common<T1, T2, false, true, b> {
+    typedef T1 type;
+};
+template <class T1, class T2, bool b>
+struct Common<T1, T2, true, false, b> {
+    typedef T2 type;
+};
+
+
+struct RowIndex {
+    enum DetachedTag {
+        Detached,
+    };
+
+    explicit RowIndex()
+        : m_row_index(npos)
+    {
+    }
+    explicit RowIndex(size_t row_index)
+        : m_row_index(row_index)
+    {
+    }
+    RowIndex(DetachedTag)
+        : m_row_index()
+    {
+    }
+
+    bool is_attached() const
+    {
+        return bool(m_row_index);
+    }
+    bool is_null() const
+    {
+        return is_attached() && *m_row_index == npos;
+    }
+
+    bool operator==(const RowIndex& other) const
+    {
+        // Row indexes that are detached are never equal to any other row index.
+        if (!is_attached() || !other.is_attached())
+            return false;
+        return m_row_index == other.m_row_index;
+    }
+    bool operator!=(const RowIndex& other) const
+    {
+        return !(*this == other);
+    }
+private:
+    util::Optional<size_t> m_row_index;
+};
+
+struct ValueBase {
+    static const size_t chunk_size = 8;
+    virtual void export_bool(ValueBase& destination) const = 0;
+    virtual void export_Timestamp(ValueBase& destination) const = 0;
+    virtual void export_int(ValueBase& destination) const = 0;
+    virtual void export_float(ValueBase& destination) const = 0;
+    virtual void export_int64_t(ValueBase& destination) const = 0;
+    virtual void export_double(ValueBase& destination) const = 0;
+    virtual void export_StringData(ValueBase& destination) const = 0;
+    virtual void export_BinaryData(ValueBase& destination) const = 0;
+    virtual void export_RowIndex(ValueBase& destination) const = 0;
+    virtual void export_null(ValueBase& destination) const = 0;
+    virtual void import(const ValueBase& destination) = 0;
+
+    // If true, all values in the class come from a link list of a single field in the parent table (m_table). If
+    // false, then values come from successive rows of m_table (query operations are operated on in bulks for speed)
+    bool m_from_link_list;
+
+    // Number of values stored in the class.
+    size_t m_values;
+};
+
+class Expression {
+public:
+    Expression()
+    {
+    }
+    virtual ~Expression()
+    {
+    }
+
+    virtual double init()
+    {
+        return 50.0; // Default dT
+    }
+
+    virtual size_t find_first(size_t start, size_t end) const = 0;
+    virtual void set_base_table(const Table* table) = 0;
+    virtual void verify_column() const = 0;
+    virtual const Table* get_base_table() const = 0;
+    virtual std::string description(util::serializer::SerialisationState& state) const = 0;
+
+    virtual std::unique_ptr<Expression> clone(QueryNodeHandoverPatches*) const = 0;
+    virtual void apply_handover_patch(QueryNodeHandoverPatches&, Group&)
+    {
+    }
+};
+
+template <typename T, typename... Args>
+std::unique_ptr<Expression> make_expression(Args&&... args)
+{
+    return std::unique_ptr<Expression>(new T(std::forward<Args>(args)...));
+}
+
+class Subexpr {
+public:
+    virtual ~Subexpr()
+    {
+    }
+
+    virtual std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* = nullptr) const = 0;
+    virtual void apply_handover_patch(QueryNodeHandoverPatches&, Group&)
+    {
+    }
+
+    // When the user constructs a query, it always "belongs" to one single base/parent table (regardless of
+    // any links or not and regardless of any queries assembled with || or &&). When you do a Query::find(),
+    // then Query::m_table is set to this table, and set_base_table() is called on all Columns and LinkMaps in
+    // the query expression tree so that they can set/update their internals as required.
+    //
+    // During thread-handover of a Query, set_base_table() is also called to make objects point at the new table
+    // instead of the old one from the old thread.
+    virtual void set_base_table(const Table*)
+    {
+    }
+
+    virtual void verify_column() const = 0;
+    virtual std::string description(util::serializer::SerialisationState& state) const = 0;
+
+    // Recursively fetch tables of columns in expression tree. Used when user first builds a stand-alone expression
+    // and
+    // binds it to a Query at a later time
+    virtual const Table* get_base_table() const
+    {
+        return nullptr;
+    }
+
+    virtual bool has_constant_evaluation() const
+    {
+        return false;
+    }
+
+    virtual bool has_search_index() const
+    {
+        return false;
+    }
+
+    virtual std::vector<size_t> find_all(util::Optional<Mixed>) const
+    {
+        return {};
+    }
+
+    virtual void evaluate(size_t index, ValueBase& destination) = 0;
+};
+
+template <typename T, typename... Args>
+std::unique_ptr<Subexpr> make_subexpr(Args&&... args)
+{
+    return std::unique_ptr<Subexpr>(new T(std::forward<Args>(args)...));
+}
+
+template <class T>
+class Columns;
+template <class T>
+class Value;
+class ConstantStringValue;
+template <class T>
+class Subexpr2;
+template <class oper, class TLeft = Subexpr, class TRight = Subexpr>
+class Operator;
+template <class oper, class TLeft = Subexpr>
+class UnaryOperator;
+template <class oper, class TLeft = Subexpr>
+class SizeOperator;
+template <class TCond, class T, class TLeft = Subexpr, class TRight = Subexpr>
+class Compare;
+template <bool has_links>
+class UnaryLinkCompare;
+class ColumnAccessorBase;
+
+
+// Handle cases where left side is a constant (int, float, int64_t, double, StringData)
+template <class Cond, class L, class R>
+Query create(L left, const Subexpr2<R>& right)
+{
+// Purpose of below code is to intercept the creation of a condition and test if it's supported by the old
+// query_engine.hpp which is faster. If it's supported, create a query_engine.hpp node, otherwise create a
+// query_expression.hpp node.
+//
+// This method intercepts only Value <cond> Subexpr2. Interception of Subexpr2 <cond> Subexpr is elsewhere.
+
+#ifdef REALM_OLDQUERY_FALLBACK // if not defined, then never fallback to query_engine.hpp; always use query_expression
+    const Columns<R>* column = dynamic_cast<const Columns<R>*>(&right);
+    // TODO: recognize size operator expressions
+    // auto size_operator = dynamic_cast<const SizeOperator<Size<StringData>, Subexpr>*>(&right);
+
+    if (column && ((std::numeric_limits<L>::is_integer && std::numeric_limits<R>::is_integer) ||
+                   (std::is_same<L, double>::value && std::is_same<R, double>::value) ||
+                   (std::is_same<L, float>::value && std::is_same<R, float>::value) ||
+                   (std::is_same<L, Timestamp>::value && std::is_same<R, Timestamp>::value) ||
+                   (std::is_same<L, StringData>::value && std::is_same<R, StringData>::value) ||
+                   (std::is_same<L, BinaryData>::value && std::is_same<R, BinaryData>::value)) &&
+        !column->links_exist()) {
+        const Table* t = column->get_base_table();
+        Query q = Query(*t);
+
+        if (std::is_same<Cond, Less>::value)
+            q.greater(column->column_ndx(), _impl::only_numeric<R>(left));
+        else if (std::is_same<Cond, Greater>::value)
+            q.less(column->column_ndx(), _impl::only_numeric<R>(left));
+        else if (std::is_same<Cond, Equal>::value)
+            q.equal(column->column_ndx(), left);
+        else if (std::is_same<Cond, NotEqual>::value)
+            q.not_equal(column->column_ndx(), left);
+        else if (std::is_same<Cond, LessEqual>::value)
+            q.greater_equal(column->column_ndx(), _impl::only_numeric<R>(left));
+        else if (std::is_same<Cond, GreaterEqual>::value)
+            q.less_equal(column->column_ndx(), _impl::only_numeric<R>(left));
+        else if (std::is_same<Cond, EqualIns>::value)
+            q.equal(column->column_ndx(), _impl::only_string_op_types(left), false);
+        else if (std::is_same<Cond, NotEqualIns>::value)
+            q.not_equal(column->column_ndx(), _impl::only_string_op_types(left), false);
+        else if (std::is_same<Cond, BeginsWith>::value)
+            q.begins_with(column->column_ndx(), _impl::only_string_op_types(left));
+        else if (std::is_same<Cond, BeginsWithIns>::value)
+            q.begins_with(column->column_ndx(), _impl::only_string_op_types(left), false);
+        else if (std::is_same<Cond, EndsWith>::value)
+            q.ends_with(column->column_ndx(), _impl::only_string_op_types(left));
+        else if (std::is_same<Cond, EndsWithIns>::value)
+            q.ends_with(column->column_ndx(), _impl::only_string_op_types(left), false);
+        else if (std::is_same<Cond, Contains>::value)
+            q.contains(column->column_ndx(), _impl::only_string_op_types(left));
+        else if (std::is_same<Cond, ContainsIns>::value)
+            q.contains(column->column_ndx(), _impl::only_string_op_types(left), false);
+        else if (std::is_same<Cond, Like>::value)
+            q.like(column->column_ndx(), _impl::only_string_op_types(left));
+        else if (std::is_same<Cond, LikeIns>::value)
+            q.like(column->column_ndx(), _impl::only_string_op_types(left), false);
+        else {
+            // query_engine.hpp does not support this Cond. Please either add support for it in query_engine.hpp or
+            // fallback to using use 'return new Compare<>' instead.
+            REALM_ASSERT(false);
+        }
+        // Return query_engine.hpp node
+        return q;
+    }
+    else
+#endif
+    {
+        // Return query_expression.hpp node
+        using CommonType = typename Common<L, R>::type;
+        using ValueType =
+            typename std::conditional<std::is_same<L, StringData>::value, ConstantStringValue, Value<L>>::type;
+        return make_expression<Compare<Cond, CommonType>>(make_subexpr<ValueType>(left), right.clone());
+    }
+}
+
+
+// All overloads where left-hand-side is Subexpr2<L>:
+//
+// left-hand-side       operator                              right-hand-side
+// Subexpr2<L>          +, -, *, /, <, >, ==, !=, <=, >=      R, Subexpr2<R>
+//
+// For L = R = {int, int64_t, float, double, StringData, Timestamp}:
+template <class L, class R>
+class Overloads {
+    typedef typename Common<L, R>::type CommonType;
+
+    std::unique_ptr<Subexpr> clone_subexpr() const
+    {
+        return static_cast<const Subexpr2<L>&>(*this).clone();
+    }
+
+public:
+    // Arithmetic, right side constant
+    Operator<Plus<CommonType>> operator+(R right) const
+    {
+        return {clone_subexpr(), make_subexpr<Value<R>>(right)};
+    }
+    Operator<Minus<CommonType>> operator-(R right) const
+    {
+        return {clone_subexpr(), make_subexpr<Value<R>>(right)};
+    }
+    Operator<Mul<CommonType>> operator*(R right) const
+    {
+        return {clone_subexpr(), make_subexpr<Value<R>>(right)};
+    }
+    Operator<Div<CommonType>> operator/(R right) const
+    {
+        return {clone_subexpr(), make_subexpr<Value<R>>(right)};
+    }
+
+    // Arithmetic, right side subexpression
+    Operator<Plus<CommonType>> operator+(const Subexpr2<R>& right) const
+    {
+        return {clone_subexpr(), right.clone()};
+    }
+    Operator<Minus<CommonType>> operator-(const Subexpr2<R>& right) const
+    {
+        return {clone_subexpr(), right.clone()};
+    }
+    Operator<Mul<CommonType>> operator*(const Subexpr2<R>& right) const
+    {
+        return {clone_subexpr(), right.clone()};
+    }
+    Operator<Div<CommonType>> operator/(const Subexpr2<R>& right) const
+    {
+        return {clone_subexpr(), right.clone()};
+    }
+
+    // Compare, right side constant
+    Query operator>(R right)
+    {
+        return create<Less>(right, static_cast<Subexpr2<L>&>(*this));
+    }
+    Query operator<(R right)
+    {
+        return create<Greater>(right, static_cast<Subexpr2<L>&>(*this));
+    }
+    Query operator>=(R right)
+    {
+        return create<LessEqual>(right, static_cast<Subexpr2<L>&>(*this));
+    }
+    Query operator<=(R right)
+    {
+        return create<GreaterEqual>(right, static_cast<Subexpr2<L>&>(*this));
+    }
+    Query operator==(R right)
+    {
+        return create<Equal>(right, static_cast<Subexpr2<L>&>(*this));
+    }
+    Query operator!=(R right)
+    {
+        return create<NotEqual>(right, static_cast<Subexpr2<L>&>(*this));
+    }
+
+    // Purpose of this method is to intercept the creation of a condition and test if it's supported by the old
+    // query_engine.hpp which is faster. If it's supported, create a query_engine.hpp node, otherwise create a
+    // query_expression.hpp node.
+    //
+    // This method intercepts Subexpr2 <cond> Subexpr2 only. Value <cond> Subexpr2 is intercepted elsewhere.
+    template <class Cond>
+    Query create2(const Subexpr2<R>& right)
+    {
+#ifdef REALM_OLDQUERY_FALLBACK // if not defined, never fallback query_engine; always use query_expression
+        // Test if expressions are of type Columns. Other possibilities are Value and Operator.
+        const Columns<R>* left_col = dynamic_cast<const Columns<R>*>(static_cast<Subexpr2<L>*>(this));
+        const Columns<R>* right_col = dynamic_cast<const Columns<R>*>(&right);
+
+        // query_engine supports 'T-column <op> <T-column>' for T = {int64_t, float, double}, op = {<, >, ==, !=, <=,
+        // >=},
+        // but only if both columns are non-nullable, and aren't in linked tables.
+        if (left_col && right_col && std::is_same<L, R>::value && !left_col->is_nullable() &&
+            !right_col->is_nullable() && !left_col->links_exist() && !right_col->links_exist() &&
+            !std::is_same<L, Timestamp>::value) {
+            const Table* t = left_col->get_base_table();
+            Query q = Query(*t);
+
+            if (std::numeric_limits<L>::is_integer || std::is_same<L, OldDateTime>::value) {
+                if (std::is_same<Cond, Less>::value)
+                    q.less_int(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, Greater>::value)
+                    q.greater_int(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, Equal>::value)
+                    q.equal_int(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, NotEqual>::value)
+                    q.not_equal_int(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, LessEqual>::value)
+                    q.less_equal_int(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, GreaterEqual>::value)
+                    q.greater_equal_int(left_col->column_ndx(), right_col->column_ndx());
+                else {
+                    REALM_ASSERT(false);
+                }
+            }
+            else if (std::is_same<L, float>::value) {
+                if (std::is_same<Cond, Less>::value)
+                    q.less_float(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, Greater>::value)
+                    q.greater_float(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, Equal>::value)
+                    q.equal_float(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, NotEqual>::value)
+                    q.not_equal_float(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, LessEqual>::value)
+                    q.less_equal_float(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, GreaterEqual>::value)
+                    q.greater_equal_float(left_col->column_ndx(), right_col->column_ndx());
+                else {
+                    REALM_ASSERT(false);
+                }
+            }
+            else if (std::is_same<L, double>::value) {
+                if (std::is_same<Cond, Less>::value)
+                    q.less_double(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, Greater>::value)
+                    q.greater_double(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, Equal>::value)
+                    q.equal_double(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, NotEqual>::value)
+                    q.not_equal_double(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, LessEqual>::value)
+                    q.less_equal_double(left_col->column_ndx(), right_col->column_ndx());
+                else if (std::is_same<Cond, GreaterEqual>::value)
+                    q.greater_equal_double(left_col->column_ndx(), right_col->column_ndx());
+                else {
+                    REALM_ASSERT(false);
+                }
+            }
+            else {
+                REALM_ASSERT(false);
+            }
+            // Return query_engine.hpp node
+            return q;
+        }
+        else
+#endif
+        {
+            // Return query_expression.hpp node
+            return make_expression<Compare<Cond, typename Common<L, R>::type>>(clone_subexpr(), right.clone());
+        }
+    }
+
+    // Compare, right side subexpression
+    Query operator==(const Subexpr2<R>& right)
+    {
+        return create2<Equal>(right);
+    }
+    Query operator!=(const Subexpr2<R>& right)
+    {
+        return create2<NotEqual>(right);
+    }
+    Query operator>(const Subexpr2<R>& right)
+    {
+        return create2<Greater>(right);
+    }
+    Query operator<(const Subexpr2<R>& right)
+    {
+        return create2<Less>(right);
+    }
+    Query operator>=(const Subexpr2<R>& right)
+    {
+        return create2<GreaterEqual>(right);
+    }
+    Query operator<=(const Subexpr2<R>& right)
+    {
+        return create2<LessEqual>(right);
+    }
+};
+
+// With this wrapper class we can define just 20 overloads inside Overloads<L, R> instead of 5 * 20 = 100. Todo: We
+// can
+// consider if it's simpler/better to remove this class completely and just list all 100 overloads manually anyway.
+template <class T>
+class Subexpr2 : public Subexpr,
+                 public Overloads<T, const char*>,
+                 public Overloads<T, int>,
+                 public Overloads<T, float>,
+                 public Overloads<T, double>,
+                 public Overloads<T, int64_t>,
+                 public Overloads<T, StringData>,
+                 public Overloads<T, bool>,
+                 public Overloads<T, Timestamp>,
+                 public Overloads<T, OldDateTime>,
+                 public Overloads<T, null> {
+public:
+    virtual ~Subexpr2()
+    {
+    }
+
+#define RLM_U2(t, o) using Overloads<T, t>::operator o;
+#define RLM_U(o)                                                                                                     \
+    RLM_U2(int, o)                                                                                                   \
+    RLM_U2(float, o)                                                                                                 \
+    RLM_U2(double, o)                                                                                                \
+    RLM_U2(int64_t, o)                                                                                               \
+    RLM_U2(StringData, o) RLM_U2(bool, o) RLM_U2(OldDateTime, o) RLM_U2(Timestamp, o) RLM_U2(null, o)
+    RLM_U(+) RLM_U(-) RLM_U(*) RLM_U(/) RLM_U(>) RLM_U(<) RLM_U(==) RLM_U(!=) RLM_U(>=) RLM_U(<=)
+};
+
+// Subexpr2<Link> only provides equality comparisons. Their implementations can be found later in this file.
+template <>
+class Subexpr2<Link> : public Subexpr {
+};
+
+template <>
+class Subexpr2<StringData> : public Subexpr, public Overloads<StringData, StringData> {
+public:
+    Query equal(StringData sd, bool case_sensitive = true);
+    Query equal(const Subexpr2<StringData>& col, bool case_sensitive = true);
+    Query not_equal(StringData sd, bool case_sensitive = true);
+    Query not_equal(const Subexpr2<StringData>& col, bool case_sensitive = true);
+    Query begins_with(StringData sd, bool case_sensitive = true);
+    Query begins_with(const Subexpr2<StringData>& col, bool case_sensitive = true);
+    Query ends_with(StringData sd, bool case_sensitive = true);
+    Query ends_with(const Subexpr2<StringData>& col, bool case_sensitive = true);
+    Query contains(StringData sd, bool case_sensitive = true);
+    Query contains(const Subexpr2<StringData>& col, bool case_sensitive = true);
+    Query like(StringData sd, bool case_sensitive = true);
+    Query like(const Subexpr2<StringData>& col, bool case_sensitive = true);
+};
+
+template <>
+class Subexpr2<BinaryData> : public Subexpr, public Overloads<BinaryData, BinaryData> {
+public:
+    Query equal(BinaryData sd, bool case_sensitive = true);
+    Query equal(const Subexpr2<BinaryData>& col, bool case_sensitive = true);
+    Query not_equal(BinaryData sd, bool case_sensitive = true);
+    Query not_equal(const Subexpr2<BinaryData>& col, bool case_sensitive = true);
+    Query begins_with(BinaryData sd, bool case_sensitive = true);
+    Query begins_with(const Subexpr2<BinaryData>& col, bool case_sensitive = true);
+    Query ends_with(BinaryData sd, bool case_sensitive = true);
+    Query ends_with(const Subexpr2<BinaryData>& col, bool case_sensitive = true);
+    Query contains(BinaryData sd, bool case_sensitive = true);
+    Query contains(const Subexpr2<BinaryData>& col, bool case_sensitive = true);
+    Query like(BinaryData sd, bool case_sensitive = true);
+    Query like(const Subexpr2<BinaryData>& col, bool case_sensitive = true);
+};
+
+
+/*
+This class is used to store N values of type T = {int64_t, bool, OldDateTime or StringData}, and allows an entry
+to be null too. It's used by the Value class for internal storage.
+
+To indicate nulls, we could have chosen a separate bool vector or some other bitmask construction. But for
+performance, we customize indication of nulls to match the same indication that is used in the persisted database
+file
+
+Queries in query_expression.hpp execute by processing chunks of 8 rows at a time. Assume you have a column:
+
+    price (int) = {1, 2, 3, null, 1, 6, 6, 9, 5, 2, null}
+
+And perform a query:
+
+    Query q = (price + 2 == 5);
+
+query_expression.hpp will then create a NullableVector<int> = {5, 5, 5, 5, 5, 5, 5, 5} and then read values
+NullableVector<int> = {1, 2, 3, null, 1, 6, 6, 9} from the column, and then perform `+` and `==` on these chunks.
+
+See the top of this file for more information on all this.
+
+Assume the user specifies the null constant in a query:
+
+Query q = (price == null)
+
+The query system will then construct a NullableVector of type `null` (NullableVector<null>). This allows compile
+time optimizations for these cases.
+*/
+
+template <class T, size_t prealloc = 8>
+struct NullableVector {
+    using Underlying = typename util::RemoveOptional<T>::type;
+    using t_storage =
+        typename std::conditional<std::is_same<Underlying, bool>::value || std::is_same<Underlying, int>::value,
+                                  int64_t, Underlying>::type;
+
+    NullableVector()
+    {
+    }
+
+    NullableVector& operator=(const NullableVector& other)
+    {
+        if (this != &other) {
+            init(other.m_size);
+            realm::safe_copy_n(other.m_first, other.m_size, m_first);
+            m_null = other.m_null;
+        }
+        return *this;
+    }
+
+    NullableVector(const NullableVector& other)
+    {
+        init(other.m_size);
+        realm::safe_copy_n(other.m_first, other.m_size, m_first);
+        m_null = other.m_null;
+    }
+
+    ~NullableVector()
+    {
+        dealloc();
+    }
+
+    T operator[](size_t index) const
+    {
+        REALM_ASSERT_3(index, <, m_size);
+        return static_cast<T>(m_first[index]);
+    }
+
+    inline bool is_null(size_t index) const
+    {
+        REALM_ASSERT((std::is_same<t_storage, int64_t>::value));
+        return m_first[index] == m_null;
+    }
+
+    inline void set_null(size_t index)
+    {
+        REALM_ASSERT((std::is_same<t_storage, int64_t>::value));
+        m_first[index] = m_null;
+    }
+
+    template <typename Type = t_storage>
+    typename std::enable_if<std::is_same<Type, int64_t>::value, void>::type set(size_t index, t_storage value)
+    {
+        REALM_ASSERT((std::is_same<t_storage, int64_t>::value));
+
+        // If value collides with magic null value, then switch to a new unique representation for null
+        if (REALM_UNLIKELY(value == m_null)) {
+            // adding a prime will generate 2^64 unique values. Todo: Only works on 2's complement architecture
+            uint64_t candidate = static_cast<uint64_t>(m_null) + 0xfffffffbULL;
+            while (std::find(m_first, m_first + m_size, static_cast<int64_t>(candidate)) != m_first + m_size)
+                candidate += 0xfffffffbULL;
+            std::replace(m_first, m_first + m_size, m_null, static_cast<int64_t>(candidate));
+        }
+        m_first[index] = value;
+    }
+
+    template <typename Type = T>
+    typename std::enable_if<realm::is_any<Type, float, double, OldDateTime, BinaryData, StringData, RowIndex,
+                                          Timestamp, ConstTableRef, null>::value,
+                            void>::type
+    set(size_t index, t_storage value)
+    {
+        m_first[index] = value;
+    }
+
+    inline util::Optional<T> get(size_t index) const
+    {
+        if (is_null(index))
+            return util::none;
+
+        return util::make_optional((*this)[index]);
+    }
+
+    inline void set(size_t index, util::Optional<Underlying> value)
+    {
+        if (value) {
+            Underlying v = *value;
+            set(index, v);
+        }
+        else {
+            set_null(index);
+        }
+    }
+
+    void fill(T value)
+    {
+        for (size_t t = 0; t < m_size; t++) {
+            if (std::is_same<T, null>::value)
+                set_null(t);
+            else
+                set(t, value);
+        }
+    }
+
+    void init(size_t size)
+    {
+        if (size == m_size)
+            return;
+
+        dealloc();
+        m_size = size;
+        if (m_size > 0) {
+            if (m_size > prealloc)
+                m_first = reinterpret_cast<t_storage*>(new t_storage[m_size]);
+            else
+                m_first = m_cache;
+        }
+    }
+
+    void init(size_t size, T values)
+    {
+        init(size);
+        fill(values);
+    }
+
+    void dealloc()
+    {
+        if (m_first) {
+            if (m_size > prealloc)
+                delete[] m_first;
+            m_first = nullptr;
+        }
+    }
+
+    t_storage m_cache[prealloc];
+    t_storage* m_first = &m_cache[0];
+    size_t m_size = 0;
+
+    int64_t m_null = reinterpret_cast<int64_t>(&m_null); // choose magic value to represent nulls
+};
+
+// Double
+// NOTE: fails in gcc 4.8 without `inline`. Do not remove. Same applies for all methods below.
+template <>
+inline bool NullableVector<double>::is_null(size_t index) const
+{
+    return null::is_null_float(m_first[index]);
+}
+
+template <>
+inline void NullableVector<double>::set_null(size_t index)
+{
+    m_first[index] = null::get_null_float<double>();
+}
+
+// Float
+template <>
+inline bool NullableVector<float>::is_null(size_t index) const
+{
+    return null::is_null_float(m_first[index]);
+}
+
+template <>
+inline void NullableVector<float>::set_null(size_t index)
+{
+    m_first[index] = null::get_null_float<float>();
+}
+
+
+// Null
+template <>
+inline void NullableVector<null>::set_null(size_t)
+{
+    return;
+}
+template <>
+inline bool NullableVector<null>::is_null(size_t) const
+{
+    return true;
+}
+
+
+// OldDateTime
+template <>
+inline bool NullableVector<OldDateTime>::is_null(size_t index) const
+{
+    return m_first[index].get_olddatetime() == m_null;
+}
+
+
+template <>
+inline void NullableVector<OldDateTime>::set_null(size_t index)
+{
+    m_first[index] = m_null;
+}
+
+// StringData
+
+template <>
+inline bool NullableVector<StringData>::is_null(size_t index) const
+{
+    return m_first[index].is_null();
+}
+
+template <>
+inline void NullableVector<StringData>::set_null(size_t index)
+{
+    m_first[index] = StringData();
+}
+
+// BinaryData
+
+template <>
+inline bool NullableVector<BinaryData>::is_null(size_t index) const
+{
+    return m_first[index].is_null();
+}
+
+template <>
+inline void NullableVector<BinaryData>::set_null(size_t index)
+{
+    m_first[index] = BinaryData();
+}
+
+// RowIndex
+template <>
+inline bool NullableVector<RowIndex>::is_null(size_t index) const
+{
+    return m_first[index].is_null();
+}
+template <>
+inline void NullableVector<RowIndex>::set_null(size_t index)
+{
+    m_first[index] = RowIndex();
+}
+
+
+// Timestamp
+
+template <>
+inline bool NullableVector<Timestamp>::is_null(size_t index) const
+{
+    return m_first[index].is_null();
+}
+
+template <>
+inline void NullableVector<Timestamp>::set_null(size_t index)
+{
+    m_first[index] = Timestamp{};
+}
+
+// ConstTableRef
+template <>
+inline bool NullableVector<ConstTableRef>::is_null(size_t index) const
+{
+    return !bool(m_first[index]);
+}
+template <>
+inline void NullableVector<ConstTableRef>::set_null(size_t index)
+{
+    m_first[index].reset();
+}
+
+template <typename Operator>
+struct OperatorOptionalAdapter {
+    template <typename L, typename R>
+    util::Optional<typename Operator::type> operator()(const util::Optional<L>& left, const util::Optional<R>& right)
+    {
+        if (!left || !right)
+            return util::none;
+        return Operator()(*left, *right);
+    }
+
+    template <typename T>
+    util::Optional<typename Operator::type> operator()(const util::Optional<T>& arg)
+    {
+        if (!arg)
+            return util::none;
+        return Operator()(*arg);
+    }
+};
+
+
+struct TrueExpression : Expression {
+    size_t find_first(size_t start, size_t end) const override
+    {
+        REALM_ASSERT(start <= end);
+        if (start != end)
+            return start;
+
+        return realm::not_found;
+    }
+    void set_base_table(const Table*) override
+    {
+    }
+    const Table* get_base_table() const override
+    {
+        return nullptr;
+    }
+    void verify_column() const override
+    {
+    }
+    std::string description(util::serializer::SerialisationState&) const override
+    {
+        return "TRUEPREDICATE";
+    }
+    std::unique_ptr<Expression> clone(QueryNodeHandoverPatches*) const override
+    {
+        return std::unique_ptr<Expression>(new TrueExpression(*this));
+    }
+};
+
+
+struct FalseExpression : Expression {
+    size_t find_first(size_t, size_t) const override
+    {
+        return realm::not_found;
+    }
+    void set_base_table(const Table*) override
+    {
+    }
+    void verify_column() const override
+    {
+    }
+    std::string description(util::serializer::SerialisationState&) const override
+    {
+        return "FALSEPREDICATE";
+    }
+    const Table* get_base_table() const override
+    {
+        return nullptr;
+    }
+    std::unique_ptr<Expression> clone(QueryNodeHandoverPatches*) const override
+    {
+        return std::unique_ptr<Expression>(new FalseExpression(*this));
+    }
+};
+
+
+// Stores N values of type T. Can also exchange data with other ValueBase of different types
+template <class T>
+class Value : public ValueBase, public Subexpr2<T> {
+public:
+    Value()
+    {
+        init(false, 1, T());
+    }
+    Value(T v)
+    {
+        init(false, 1, v);
+    }
+
+    Value(bool from_link_list, size_t values)
+    {
+        init(from_link_list, values, T());
+    }
+
+    Value(bool from_link_list, size_t values, T v)
+    {
+        init(from_link_list, values, v);
+    }
+
+    Value(const Value&) = default;
+    Value& operator=(const Value&) = default;
+
+    void init(bool from_link_list, size_t values, T v)
+    {
+        m_storage.init(values, v);
+        ValueBase::m_from_link_list = from_link_list;
+        ValueBase::m_values = values;
+    }
+
+    void init(bool from_link_list, size_t values)
+    {
+        m_storage.init(values);
+        ValueBase::m_from_link_list = from_link_list;
+        ValueBase::m_values = values;
+    }
+
+    void verify_column() const override
+    {
+    }
+
+    std::string description(util::serializer::SerialisationState&) const override
+    {
+        if (ValueBase::m_from_link_list) {
+            return util::serializer::print_value(util::to_string(ValueBase::m_values)
+                                        + (ValueBase::m_values == 1 ? " value" : " values"));
+        }
+        if (m_storage.m_size > 0) {
+            return util::serializer::print_value(m_storage[0]);
+        }
+        return "";
+    }
+
+    bool has_constant_evaluation() const override
+    {
+        return true;
+    }
+
+    void evaluate(size_t, ValueBase& destination) override
+    {
+        destination.import(*this);
+    }
+
+
+    template <class TOperator>
+    REALM_FORCEINLINE void fun(const Value* left, const Value* right)
+    {
+        OperatorOptionalAdapter<TOperator> o;
+
+        if (!left->m_from_link_list && !right->m_from_link_list) {
+            // Operate on values one-by-one (one value is one row; no links)
+            size_t min = std::min(left->m_values, right->m_values);
+            init(false, min);
+
+            for (size_t i = 0; i < min; i++) {
+                m_storage.set(i, o(left->m_storage.get(i), right->m_storage.get(i)));
+            }
+        }
+        else if (left->m_from_link_list && right->m_from_link_list) {
+            // FIXME: Many-to-many links not supported yet. Need to specify behaviour
+            REALM_ASSERT_DEBUG(false);
+        }
+        else if (!left->m_from_link_list && right->m_from_link_list) {
+            // Right values come from link. Left must come from single row.
+            REALM_ASSERT_DEBUG(left->m_values > 0);
+            init(true, right->m_values);
+
+            auto left_value = left->m_storage.get(0);
+            for (size_t i = 0; i < right->m_values; i++) {
+                m_storage.set(i, o(left_value, right->m_storage.get(i)));
+            }
+        }
+        else if (left->m_from_link_list && !right->m_from_link_list) {
+            // Same as above, but with left values coming from links
+            REALM_ASSERT_DEBUG(right->m_values > 0);
+            init(true, left->m_values);
+
+            auto right_value = right->m_storage.get(0);
+            for (size_t i = 0; i < left->m_values; i++) {
+                m_storage.set(i, o(left->m_storage.get(i), right_value));
+            }
+        }
+    }
+
+    template <class TOperator>
+    REALM_FORCEINLINE void fun(const Value* value)
+    {
+        init(value->m_from_link_list, value->m_values);
+
+        OperatorOptionalAdapter<TOperator> o;
+        for (size_t i = 0; i < value->m_values; i++) {
+            m_storage.set(i, o(value->m_storage.get(i)));
+        }
+    }
+
+
+    // Below import and export methods are for type conversion between float, double, int64_t, etc.
+    template <class D>
+    typename std::enable_if<std::is_convertible<T, D>::value>::type REALM_FORCEINLINE
+    export2(ValueBase& destination) const
+    {
+        Value<D>& d = static_cast<Value<D>&>(destination);
+        d.init(ValueBase::m_from_link_list, ValueBase::m_values, D());
+        for (size_t t = 0; t < ValueBase::m_values; t++) {
+            if (m_storage.is_null(t))
+                d.m_storage.set_null(t);
+            else {
+                d.m_storage.set(t, static_cast<D>(m_storage[t]));
+            }
+        }
+    }
+
+    template <class D>
+    typename std::enable_if<!std::is_convertible<T, D>::value>::type REALM_FORCEINLINE export2(ValueBase&) const
+    {
+        // export2 is instantiated for impossible conversions like T=StringData, D=int64_t. These are never
+        // performed at runtime but would result in a compiler error if we did not provide this implementation.
+        REALM_ASSERT_DEBUG(false);
+    }
+
+    REALM_FORCEINLINE void export_Timestamp(ValueBase& destination) const override
+    {
+        export2<Timestamp>(destination);
+    }
+
+    REALM_FORCEINLINE void export_bool(ValueBase& destination) const override
+    {
+        export2<bool>(destination);
+    }
+
+    REALM_FORCEINLINE void export_int64_t(ValueBase& destination) const override
+    {
+        export2<int64_t>(destination);
+    }
+
+    REALM_FORCEINLINE void export_float(ValueBase& destination) const override
+    {
+        export2<float>(destination);
+    }
+
+    REALM_FORCEINLINE void export_int(ValueBase& destination) const override
+    {
+        export2<int>(destination);
+    }
+
+    REALM_FORCEINLINE void export_double(ValueBase& destination) const override
+    {
+        export2<double>(destination);
+    }
+    REALM_FORCEINLINE void export_StringData(ValueBase& destination) const override
+    {
+        export2<StringData>(destination);
+    }
+    REALM_FORCEINLINE void export_BinaryData(ValueBase& destination) const override
+    {
+        export2<BinaryData>(destination);
+    }
+    REALM_FORCEINLINE void export_RowIndex(ValueBase& destination) const override
+    {
+        export2<RowIndex>(destination);
+    }
+    REALM_FORCEINLINE void export_null(ValueBase& destination) const override
+    {
+        Value<null>& d = static_cast<Value<null>&>(destination);
+        d.init(m_from_link_list, m_values);
+    }
+
+    REALM_FORCEINLINE void import(const ValueBase& source) override
+    {
+        if (std::is_same<T, int>::value)
+            source.export_int(*this);
+        else if (std::is_same<T, Timestamp>::value)
+            source.export_Timestamp(*this);
+        else if (std::is_same<T, bool>::value)
+            source.export_bool(*this);
+        else if (std::is_same<T, float>::value)
+            source.export_float(*this);
+        else if (std::is_same<T, double>::value)
+            source.export_double(*this);
+        else if (std::is_same<T, int64_t>::value || std::is_same<T, bool>::value ||
+                 std::is_same<T, OldDateTime>::value)
+            source.export_int64_t(*this);
+        else if (std::is_same<T, StringData>::value)
+            source.export_StringData(*this);
+        else if (std::is_same<T, BinaryData>::value)
+            source.export_BinaryData(*this);
+        else if (std::is_same<T, RowIndex>::value)
+            source.export_RowIndex(*this);
+        else if (std::is_same<T, null>::value)
+            source.export_null(*this);
+        else
+            REALM_ASSERT_DEBUG(false);
+    }
+
+    // Given a TCond (==, !=, >, <, >=, <=) and two Value<T>, return index of first match
+    template <class TCond>
+    REALM_FORCEINLINE static size_t compare_const(const Value<T>* left, Value<T>* right)
+    {
+        TCond c;
+
+        size_t sz = right->ValueBase::m_values;
+        bool left_is_null = left->m_storage.is_null(0);
+        for (size_t m = 0; m < sz; m++) {
+            if (c(left->m_storage[0], right->m_storage[m], left_is_null, right->m_storage.is_null(m)))
+                return right->m_from_link_list ? 0 : m;
+        }
+
+        return not_found; // no match
+    }
+
+    template <class TCond>
+    REALM_FORCEINLINE static size_t compare(Value<T>* left, Value<T>* right)
+    {
+        TCond c;
+
+        if (!left->m_from_link_list && !right->m_from_link_list) {
+            // Compare values one-by-one (one value is one row; no link lists)
+            size_t min = minimum(left->ValueBase::m_values, right->ValueBase::m_values);
+            for (size_t m = 0; m < min; m++) {
+
+                if (c(left->m_storage[m], right->m_storage[m], left->m_storage.is_null(m),
+                      right->m_storage.is_null(m)))
+                    return m;
+            }
+        }
+        else if (left->m_from_link_list && right->m_from_link_list) {
+            // FIXME: Many-to-many links not supported yet. Need to specify behaviour
+            REALM_ASSERT_DEBUG(false);
+        }
+        else if (!left->m_from_link_list && right->m_from_link_list) {
+            // Right values come from link list. Left must come from single row. Semantics: Match if at least 1
+            // linked-to-value fulfills the condition
+            REALM_ASSERT_DEBUG(left->m_values > 0);
+            for (size_t r = 0; r < right->m_values; r++) {
+                if (c(left->m_storage[0], right->m_storage[r], left->m_storage.is_null(0),
+                      right->m_storage.is_null(r)))
+                    return 0;
+            }
+        }
+        else if (left->m_from_link_list && !right->m_from_link_list) {
+            // Same as above, but with left values coming from link list.
+            REALM_ASSERT_DEBUG(right->m_values > 0);
+            for (size_t l = 0; l < left->m_values; l++) {
+                if (c(left->m_storage[l], right->m_storage[0], left->m_storage.is_null(l),
+                      right->m_storage.is_null(0)))
+                    return 0;
+            }
+        }
+
+        return not_found; // no match
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches*) const override
+    {
+        return make_subexpr<Value<T>>(*this);
+    }
+
+    NullableVector<T> m_storage;
+};
+
+class ConstantStringValue : public Value<StringData> {
+public:
+    ConstantStringValue(const StringData& string)
+        : Value()
+        , m_string(string.is_null() ? util::none : util::make_optional(std::string(string)))
+    {
+        init(false, 1, m_string);
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches*) const override
+    {
+        return std::unique_ptr<Subexpr>(new ConstantStringValue(*this));
+    }
+
+private:
+    ConstantStringValue(const ConstantStringValue& other)
+        : Value()
+        , m_string(other.m_string)
+    {
+        init(other.m_from_link_list, other.m_values, m_string);
+    }
+
+    util::Optional<std::string> m_string;
+};
+
+// All overloads where left-hand-side is L:
+//
+// left-hand-side       operator                              right-hand-side
+// L                    +, -, *, /, <, >, ==, !=, <=, >=      Subexpr2<R>
+//
+// For L = R = {int, int64_t, float, double, Timestamp}:
+// Compare numeric values
+template <class R>
+Query operator>(double left, const Subexpr2<R>& right)
+{
+    return create<Greater>(left, right);
+}
+template <class R>
+Query operator>(float left, const Subexpr2<R>& right)
+{
+    return create<Greater>(left, right);
+}
+template <class R>
+Query operator>(int left, const Subexpr2<R>& right)
+{
+    return create<Greater>(left, right);
+}
+template <class R>
+Query operator>(int64_t left, const Subexpr2<R>& right)
+{
+    return create<Greater>(left, right);
+}
+template <class R>
+Query operator>(Timestamp left, const Subexpr2<R>& right)
+{
+    return create<Greater>(left, right);
+}
+
+template <class R>
+Query operator<(double left, const Subexpr2<R>& right)
+{
+    return create<Less>(left, right);
+}
+template <class R>
+Query operator<(float left, const Subexpr2<R>& right)
+{
+    return create<Less>(left, right);
+}
+template <class R>
+Query operator<(int left, const Subexpr2<R>& right)
+{
+    return create<Less>(left, right);
+}
+template <class R>
+Query operator<(int64_t left, const Subexpr2<R>& right)
+{
+    return create<Less>(left, right);
+}
+template <class R>
+Query operator<(Timestamp left, const Subexpr2<R>& right)
+{
+    return create<Less>(left, right);
+}
+template <class R>
+Query operator==(double left, const Subexpr2<R>& right)
+{
+    return create<Equal>(left, right);
+}
+template <class R>
+Query operator==(float left, const Subexpr2<R>& right)
+{
+    return create<Equal>(left, right);
+}
+template <class R>
+Query operator==(int left, const Subexpr2<R>& right)
+{
+    return create<Equal>(left, right);
+}
+template <class R>
+Query operator==(int64_t left, const Subexpr2<R>& right)
+{
+    return create<Equal>(left, right);
+}
+template <class R>
+Query operator==(Timestamp left, const Subexpr2<R>& right)
+{
+    return create<Equal>(left, right);
+}
+template <class R>
+Query operator>=(double left, const Subexpr2<R>& right)
+{
+    return create<GreaterEqual>(left, right);
+}
+template <class R>
+Query operator>=(float left, const Subexpr2<R>& right)
+{
+    return create<GreaterEqual>(left, right);
+}
+template <class R>
+Query operator>=(int left, const Subexpr2<R>& right)
+{
+    return create<GreaterEqual>(left, right);
+}
+template <class R>
+Query operator>=(int64_t left, const Subexpr2<R>& right)
+{
+    return create<GreaterEqual>(left, right);
+}
+template <class R>
+Query operator>=(Timestamp left, const Subexpr2<R>& right)
+{
+    return create<GreaterEqual>(left, right);
+}
+template <class R>
+Query operator<=(double left, const Subexpr2<R>& right)
+{
+    return create<LessEqual>(left, right);
+}
+template <class R>
+Query operator<=(float left, const Subexpr2<R>& right)
+{
+    return create<LessEqual>(left, right);
+}
+template <class R>
+Query operator<=(int left, const Subexpr2<R>& right)
+{
+    return create<LessEqual>(left, right);
+}
+template <class R>
+Query operator<=(int64_t left, const Subexpr2<R>& right)
+{
+    return create<LessEqual>(left, right);
+}
+template <class R>
+Query operator<=(Timestamp left, const Subexpr2<R>& right)
+{
+    return create<LessEqual>(left, right);
+}
+template <class R>
+Query operator!=(double left, const Subexpr2<R>& right)
+{
+    return create<NotEqual>(left, right);
+}
+template <class R>
+Query operator!=(float left, const Subexpr2<R>& right)
+{
+    return create<NotEqual>(left, right);
+}
+template <class R>
+Query operator!=(int left, const Subexpr2<R>& right)
+{
+    return create<NotEqual>(left, right);
+}
+template <class R>
+Query operator!=(int64_t left, const Subexpr2<R>& right)
+{
+    return create<NotEqual>(left, right);
+}
+template <class R>
+Query operator!=(Timestamp left, const Subexpr2<R>& right)
+{
+    return create<NotEqual>(left, right);
+}
+
+// Arithmetic
+template <class R>
+Operator<Plus<typename Common<R, double>::type>> operator+(double left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<double>>(left), right.clone()};
+}
+template <class R>
+Operator<Plus<typename Common<R, float>::type>> operator+(float left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<float>>(left), right.clone()};
+}
+template <class R>
+Operator<Plus<typename Common<R, int>::type>> operator+(int left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int>>(left), right.clone()};
+}
+template <class R>
+Operator<Plus<typename Common<R, int64_t>::type>> operator+(int64_t left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int64_t>>(left), right.clone()};
+}
+template <class R>
+Operator<Minus<typename Common<R, double>::type>> operator-(double left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<double>>(left), right.clone()};
+}
+template <class R>
+Operator<Minus<typename Common<R, float>::type>> operator-(float left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<float>>(left), right.clone()};
+}
+template <class R>
+Operator<Minus<typename Common<R, int>::type>> operator-(int left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int>>(left), right.clone()};
+}
+template <class R>
+Operator<Minus<typename Common<R, int64_t>::type>> operator-(int64_t left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int64_t>>(left), right.clone()};
+}
+template <class R>
+Operator<Mul<typename Common<R, double>::type>> operator*(double left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<double>>(left), right.clone()};
+}
+template <class R>
+Operator<Mul<typename Common<R, float>::type>> operator*(float left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<float>>(left), right.clone()};
+}
+template <class R>
+Operator<Mul<typename Common<R, int>::type>> operator*(int left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int>>(left), right.clone()};
+}
+template <class R>
+Operator<Mul<typename Common<R, int64_t>::type>> operator*(int64_t left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int64_t>>(left), right.clone()};
+}
+template <class R>
+Operator<Div<typename Common<R, double>::type>> operator/(double left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<double>>(left), right.clone()};
+}
+template <class R>
+Operator<Div<typename Common<R, float>::type>> operator/(float left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<float>>(left), right.clone()};
+}
+template <class R>
+Operator<Div<typename Common<R, int>::type>> operator/(int left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int>>(left), right.clone()};
+}
+template <class R>
+Operator<Div<typename Common<R, int64_t>::type>> operator/(int64_t left, const Subexpr2<R>& right)
+{
+    return {make_subexpr<Value<int64_t>>(left), right.clone()};
+}
+
+// Unary operators
+template <class T>
+UnaryOperator<Pow<T>> power(const Subexpr2<T>& left)
+{
+    return {left.clone()};
+}
+
+// Classes used for LinkMap (see below).
+struct LinkMapFunction {
+    // Your consume() method is given row index of the linked-to table as argument, and you must return whether or
+    // not you want the LinkMapFunction to exit (return false) or continue (return true) harvesting the link tree
+    // for the current main table row index (it will be a link tree if you have multiple type_LinkList columns
+    // in a link()->link() query.
+    virtual bool consume(size_t row_index) = 0;
+};
+
+struct FindNullLinks : public LinkMapFunction {
+    bool consume(size_t row_index) override
+    {
+        static_cast<void>(row_index);
+        m_has_link = true;
+        return false; // we've found a row index, so this can't be a null-link, so exit link harvesting
+    }
+
+    bool m_has_link = false;
+};
+
+struct MakeLinkVector : public LinkMapFunction {
+    MakeLinkVector(std::vector<size_t>& result)
+        : m_links(result)
+    {
+    }
+
+    bool consume(size_t row_index) override
+    {
+        m_links.push_back(row_index);
+        return true; // continue evaluation
+    }
+    std::vector<size_t>& m_links;
+};
+
+struct UnaryLinkResult : public LinkMapFunction {
+    UnaryLinkResult()
+        : m_result(realm::not_found)
+    {
+    }
+    bool consume(size_t row_index) override
+    {
+        m_result = row_index;
+        return false; // exit search, only one result ever expected
+    }
+    size_t m_result;
+};
+
+struct CountLinks : public LinkMapFunction {
+    bool consume(size_t) override
+    {
+        m_link_count++;
+        return true;
+    }
+
+    size_t result() const
+    {
+        return m_link_count;
+    }
+
+    size_t m_link_count = 0;
+};
+
+struct CountBacklinks : public LinkMapFunction {
+    CountBacklinks(const Table* t)
+        : m_table(t)
+    {
+    }
+
+    bool consume(size_t row_index) override
+    {
+        m_link_count += m_table->get_backlink_count(row_index);
+        return true;
+    }
+
+    size_t result() const
+    {
+        return m_link_count;
+    }
+
+    const Table* m_table;
+    size_t m_link_count = 0;
+};
+
+
+/*
+The LinkMap and LinkMapFunction classes are used for query conditions on links themselves (contrary to conditions on
+the value payload they point at).
+
+MapLink::map_links() takes a row index of the link column as argument and follows any link chain stated in the query
+(through the link()->link() methods) until the final payload table is reached, and then applies LinkMapFunction on
+the linked-to row index(es).
+
+If all link columns are type_Link, then LinkMapFunction is only invoked for a single row index. If one or more
+columns are type_LinkList, then it may result in multiple row indexes.
+
+The reason we use this map pattern is that we can exit the link-tree-traversal as early as possible, e.g. when we've
+found the first link that points to row '5'. Other solutions could be a std::vector<size_t> harvest_all_links(), or an
+iterator pattern. First solution can't exit, second solution requires internal state.
+*/
+class LinkMap {
+public:
+    LinkMap() = default;
+    LinkMap(const Table* table, std::vector<size_t> columns)
+        : m_link_column_indexes(std::move(columns))
+    {
+        set_base_table(table);
+    }
+
+    LinkMap(LinkMap const& other, QueryNodeHandoverPatches* patches)
+        : LinkMap(other)
+    {
+        if (!patches)
+            return;
+
+        m_link_column_indexes.clear();
+        const Table* table = base_table();
+        m_tables.clear();
+        for (auto column : m_link_columns) {
+            m_link_column_indexes.push_back(column->get_column_index());
+            if (table->get_real_column_type(m_link_column_indexes.back()) == col_type_BackLink)
+                table = &static_cast<const BacklinkColumn*>(column)->get_origin_table();
+            else
+                table = &static_cast<const LinkColumnBase*>(column)->get_target_table();
+        }
+    }
+
+    void set_base_table(const Table* table)
+    {
+        if (table == base_table())
+            return;
+
+        m_tables.clear();
+        m_tables.push_back(table);
+        m_link_columns.clear();
+        m_link_types.clear();
+        m_only_unary_links = true;
+
+        for (size_t link_column_index : m_link_column_indexes) {
+            // Link column can be either LinkList or single Link
+            const Table* t = m_tables.back();
+            ColumnType type = t->get_real_column_type(link_column_index);
+            REALM_ASSERT(Table::is_link_type(type) || type == col_type_BackLink);
+            m_link_types.push_back(type);
+
+            if (type == col_type_LinkList) {
+                const LinkListColumn& cll = t->get_column_link_list(link_column_index);
+                m_link_columns.push_back(&cll);
+                m_only_unary_links = false;
+                m_tables.push_back(&cll.get_target_table());
+            }
+            else if (type == col_type_Link) {
+                const LinkColumn& cl = t->get_column_link(link_column_index);
+                m_link_columns.push_back(&cl);
+                m_tables.push_back(&cl.get_target_table());
+            }
+            else if (type == col_type_BackLink) {
+                const BacklinkColumn& bl = t->get_column_backlink(link_column_index);
+                m_link_columns.push_back(&bl);
+                m_only_unary_links = false;
+                m_tables.push_back(&bl.get_origin_table());
+            }
+        }
+    }
+
+    void verify_columns() const
+    {
+        for (size_t i = 0; i < m_link_column_indexes.size(); i++) {
+            m_tables[i]->verify_column(m_link_column_indexes[i], m_link_columns[i]);
+        }
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const
+    {
+        std::string s;
+        for (size_t i = 0; i < m_link_column_indexes.size(); ++i) {
+            if (i < m_tables.size() && m_tables[i]) {
+                s += state.get_column_name(m_tables[i]->get_table_ref(), m_link_column_indexes[i]);
+                if (i != m_link_column_indexes.size() - 1) {
+                    s += util::serializer::value_separator;
+                }
+            }
+        }
+        return s;
+    }
+
+    size_t get_unary_link_or_not_found(size_t index) const
+    {
+        REALM_ASSERT(m_only_unary_links);
+        UnaryLinkResult res;
+        map_links(index, res);
+        return res.m_result;
+    }
+
+    std::vector<size_t> get_links(size_t index) const
+    {
+        std::vector<size_t> res;
+        get_links(index, res);
+        return res;
+    }
+
+    std::vector<size_t> get_origin_ndxs(size_t index, size_t column = 0) const;
+
+    size_t count_links(size_t row)
+    {
+        CountLinks counter;
+        map_links(row, counter);
+        return counter.result();
+    }
+
+    size_t count_all_backlinks(size_t row)
+    {
+        CountBacklinks counter(target_table());
+        map_links(row, counter);
+        return counter.result();
+    }
+
+    void map_links(size_t row, LinkMapFunction& lm) const
+    {
+        map_links(0, row, lm);
+    }
+
+    bool only_unary_links() const
+    {
+        return m_only_unary_links;
+    }
+
+    const Table* base_table() const
+    {
+        return m_tables.empty() ? nullptr : m_tables[0];
+    }
+
+    const Table* target_table() const
+    {
+        REALM_ASSERT(!m_tables.empty());
+        return m_tables.back();
+    }
+
+    bool links_exist() const
+    {
+        return !m_link_columns.empty();
+    }
+
+    std::vector<const ColumnBase*> m_link_columns;
+
+private:
+    void map_links(size_t column, size_t row, LinkMapFunction& lm) const
+    {
+        bool last = (column + 1 == m_link_columns.size());
+        ColumnType type = m_link_types[column];
+        if (type == col_type_Link) {
+            const LinkColumn& cl = *static_cast<const LinkColumn*>(m_link_columns[column]);
+            size_t r = to_size_t(cl.get(row));
+            if (r == 0)
+                return;
+            r--; // LinkColumn stores link to row N as N + 1
+            if (last) {
+                bool continue2 = lm.consume(r);
+                if (!continue2)
+                    return;
+            }
+            else
+                map_links(column + 1, r, lm);
+        }
+        else if (type == col_type_LinkList) {
+            const LinkListColumn& cll = *static_cast<const LinkListColumn*>(m_link_columns[column]);
+            ConstLinkViewRef lvr = cll.get(row);
+            for (size_t t = 0; t < lvr->size(); t++) {
+                size_t r = lvr->get(t).get_index();
+                if (last) {
+                    bool continue2 = lm.consume(r);
+                    if (!continue2)
+                        return;
+                }
+                else
+                    map_links(column + 1, r, lm);
+            }
+        }
+        else if (type == col_type_BackLink) {
+            const BacklinkColumn& bl = *static_cast<const BacklinkColumn*>(m_link_columns[column]);
+            size_t count = bl.get_backlink_count(row);
+            for (size_t i = 0; i < count; ++i) {
+                size_t r = bl.get_backlink(row, i);
+                if (last) {
+                    bool continue2 = lm.consume(r);
+                    if (!continue2)
+                        return;
+                }
+                else
+                    map_links(column + 1, r, lm);
+            }
+        }
+    }
+
+    void get_links(size_t row, std::vector<size_t>& result) const
+    {
+        MakeLinkVector mlv = MakeLinkVector(result);
+        map_links(row, mlv);
+    }
+
+    std::vector<size_t> m_link_column_indexes;
+    std::vector<ColumnType> m_link_types;
+    std::vector<const Table*> m_tables;
+    bool m_only_unary_links = true;
+
+    template <class>
+    friend Query compare(const Subexpr2<Link>&, const ConstRow&);
+};
+
+template <class T, class S, class I>
+Query string_compare(const Subexpr2<StringData>& left, T right, bool case_insensitive);
+template <class S, class I>
+Query string_compare(const Subexpr2<StringData>& left, const Subexpr2<StringData>& right, bool case_insensitive);
+
+template <class T>
+Value<T> make_value_for_link(bool only_unary_links, size_t size)
+{
+    Value<T> value;
+    if (only_unary_links) {
+        REALM_ASSERT(size <= 1);
+        value.init(false, 1);
+        value.m_storage.set_null(0);
+    }
+    else {
+        value.init(true, size);
+    }
+    return value;
+}
+
+
+// If we add a new Realm type T and quickly want Query support for it, then simply inherit from it like
+// `template <> class Columns<T> : public SimpleQuerySupport<T>` and you're done. Any operators of the set
+// { ==, >=, <=, !=, >, < } that are supported by T will be supported by the "query expression syntax"
+// automatically. NOTE: This method of Query support will be slow because it goes through Table::get<T>.
+// To get faster Query support, either add SequentialGetter support (faster) or create a query_engine.hpp
+// node for it (super fast).
+
+template <class T>
+class SimpleQuerySupport : public Subexpr2<T> {
+public:
+    SimpleQuerySupport(size_t column, const Table* table, std::vector<size_t> links = {})
+        : m_column_ndx(column)
+        , m_link_map(table, std::move(links))
+    {
+        m_column = &m_link_map.target_table()->get_column_base(m_column_ndx);
+    }
+
+    bool is_nullable() const noexcept
+    {
+        return m_link_map.base_table()->is_nullable(m_column->get_column_index());
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        if (table != get_base_table()) {
+            m_link_map.set_base_table(table);
+            m_column = &m_link_map.target_table()->get_column_base(m_column_ndx);
+        }
+    }
+
+    bool has_search_index() const override
+    {
+        return m_link_map.target_table()->has_search_index(m_column_ndx);
+    }
+
+    std::vector<size_t> find_all(util::Optional<Mixed> value) const override
+    {
+        std::vector<size_t> ret;
+        ref_type ref = IntegerColumn::create(Allocator::get_default());
+        IntegerColumn result;
+        result.init_from_ref(Allocator::get_default(), ref);
+
+        T val{};
+        if (value) {
+            val = value->get<T>();
+        }
+
+        auto col = dynamic_cast<const typename ColumnTypeTraits<T>::column_type*>(m_column);
+        col->find_all(result, val, 0, realm::npos);
+
+        auto sz = result.size();
+        for (size_t i = 0; i < sz; i++) {
+            auto ndxs = m_link_map.get_origin_ndxs(size_t(result.get(i)));
+            ret.insert(ret.end(), ndxs.begin(), ndxs.end());
+        }
+        result.destroy();
+
+        return ret;
+    }
+
+    void verify_column() const override
+    {
+        // verify links
+        m_link_map.verify_columns();
+        // verify target table
+        const Table* target_table = m_link_map.target_table();
+        if (target_table && m_column_ndx != npos) {
+            target_table->verify_column(m_column_ndx, m_column);
+        }
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        Value<T>& d = static_cast<Value<T>&>(destination);
+        size_t col = column_ndx();
+
+        if (links_exist()) {
+            if (m_link_map.only_unary_links()) {
+                const Table* target_table = m_link_map.target_table();
+                d.init(false, 1);
+                d.m_storage.set_null(0);
+                size_t link_translation_index = this->m_link_map.get_unary_link_or_not_found(index);
+                if (link_translation_index != realm::not_found) {
+                    d.m_storage.set(0, target_table->get<T>(col, link_translation_index));
+                }
+            }
+            else {
+                std::vector<size_t> links = m_link_map.get_links(index);
+                constexpr bool has_only_unary_links = false;
+                Value<T> v = make_value_for_link<T>(has_only_unary_links, links.size());
+                for (size_t t = 0; t < links.size(); t++) {
+                    size_t link_to = links[t];
+                    v.m_storage.set(t, m_link_map.target_table()->template get<T>(col, link_to));
+                }
+                destination.import(v);
+            }
+        }
+        else {
+            // Not a link column
+            const Table* target_table = m_link_map.target_table();
+            for (size_t t = 0; t < destination.m_values && index + t < target_table->size(); t++) {
+                d.m_storage.set(t, target_table->get<T>(col, index + t));
+            }
+        }
+    }
+
+    bool links_exist() const
+    {
+        return m_link_map.m_link_columns.size() > 0;
+    }
+
+    bool only_unary_links() const
+    {
+        return m_link_map.only_unary_links();
+    }
+
+    LinkMap get_link_map() const
+    {
+        return m_link_map;
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        return state.describe_columns(m_link_map, m_column_ndx);
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches = nullptr) const override
+    {
+        return make_subexpr<Columns<T>>(static_cast<const Columns<T>&>(*this), patches);
+    }
+
+    SimpleQuerySupport(SimpleQuerySupport const& other, QueryNodeHandoverPatches* patches)
+        : Subexpr2<T>(other)
+        , m_column_ndx(other.m_column_ndx)
+        , m_column(other.m_column)
+        , m_link_map(other.m_link_map, patches)
+    {
+        if (patches && m_column) {
+            m_column_ndx = column_ndx();
+            m_column = nullptr;
+        }
+    }
+
+    size_t column_ndx() const
+    {
+        return m_column->get_column_index();
+    }
+
+    SizeOperator<Size<T>> size()
+    {
+        return SizeOperator<Size<T>>(this->clone(nullptr));
+    }
+
+private:
+    // Column index of payload column of m_table
+    mutable size_t m_column_ndx;
+    const ColumnBase* m_column;
+    LinkMap m_link_map;
+};
+
+
+template <>
+class Columns<Timestamp> : public SimpleQuerySupport<Timestamp> {
+    using SimpleQuerySupport::SimpleQuerySupport;
+};
+
+template <>
+class Columns<BinaryData> : public SimpleQuerySupport<BinaryData> {
+    using SimpleQuerySupport::SimpleQuerySupport;
+};
+
+template <>
+class Columns<StringData> : public SimpleQuerySupport<StringData> {
+public:
+    Columns(size_t column, const Table* table, std::vector<size_t> links = {})
+        : SimpleQuerySupport(column, table, links)
+    {
+    }
+
+    Columns(Columns const& other, QueryNodeHandoverPatches* patches = nullptr)
+        : SimpleQuerySupport(other, patches)
+    {
+    }
+
+    Columns(Columns&& other)
+        : SimpleQuerySupport(other)
+    {
+    }
+};
+
+template <class T, class S, class I>
+Query string_compare(const Subexpr2<StringData>& left, T right, bool case_sensitive)
+{
+    StringData sd(right);
+    if (case_sensitive)
+        return create<S>(sd, left);
+    else
+        return create<I>(sd, left);
+}
+
+template <class S, class I>
+Query string_compare(const Subexpr2<StringData>& left, const Subexpr2<StringData>& right, bool case_sensitive)
+{
+    if (case_sensitive)
+        return make_expression<Compare<S, StringData>>(right.clone(), left.clone());
+    else
+        return make_expression<Compare<I, StringData>>(right.clone(), left.clone());
+}
+
+template <class T, class S, class I>
+Query binary_compare(const Subexpr2<BinaryData>& left, T right, bool case_sensitive)
+{
+    BinaryData data(right);
+    if (case_sensitive)
+        return create<S>(data, left);
+    else
+        return create<I>(data, left);
+}
+
+template <class S, class I>
+Query binary_compare(const Subexpr2<BinaryData>& left, const Subexpr2<BinaryData>& right, bool case_sensitive)
+{
+    if (case_sensitive)
+        return make_expression<Compare<S, BinaryData>>(right.clone(), left.clone());
+    else
+        return make_expression<Compare<I, BinaryData>>(right.clone(), left.clone());
+}
+
+
+// Columns<String> == Columns<String>
+inline Query operator==(const Columns<StringData>& left, const Columns<StringData>& right)
+{
+    return string_compare<Equal, EqualIns>(left, right, true);
+}
+
+// Columns<String> != Columns<String>
+inline Query operator!=(const Columns<StringData>& left, const Columns<StringData>& right)
+{
+    return string_compare<NotEqual, NotEqualIns>(left, right, true);
+}
+
+// String == Columns<String>
+template <class T>
+Query operator==(T left, const Columns<StringData>& right)
+{
+    return operator==(right, left);
+}
+
+// String != Columns<String>
+template <class T>
+Query operator!=(T left, const Columns<StringData>& right)
+{
+    return operator!=(right, left);
+}
+
+// Columns<String> == String
+template <class T>
+Query operator==(const Columns<StringData>& left, T right)
+{
+    return string_compare<T, Equal, EqualIns>(left, right, true);
+}
+
+// Columns<String> != String
+template <class T>
+Query operator!=(const Columns<StringData>& left, T right)
+{
+    return string_compare<T, NotEqual, NotEqualIns>(left, right, true);
+}
+
+
+inline Query operator==(const Columns<BinaryData>& left, BinaryData right)
+{
+    return create<Equal>(right, left);
+}
+
+inline Query operator==(BinaryData left, const Columns<BinaryData>& right)
+{
+    return create<Equal>(left, right);
+}
+
+inline Query operator!=(const Columns<BinaryData>& left, BinaryData right)
+{
+    return create<NotEqual>(right, left);
+}
+
+inline Query operator!=(BinaryData left, const Columns<BinaryData>& right)
+{
+    return create<NotEqual>(left, right);
+}
+
+
+// This class is intended to perform queries on the *pointers* of links, contrary to performing queries on *payload*
+// in linked-to tables. Queries can be "find first link that points at row X" or "find first null-link". Currently
+// only "find first null link" and "find first non-null link" is supported. More will be added later. When we add
+// more, I propose to remove the <bool has_links> template argument from this class and instead template it by
+// a criteria-class (like the FindNullLinks class below in find_first()) in some generalized fashion.
+template <bool has_links>
+class UnaryLinkCompare : public Expression {
+public:
+    UnaryLinkCompare(LinkMap lm)
+        : m_link_map(std::move(lm))
+    {
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+    }
+
+    // Return main table of query (table on which table->where()... is invoked). Note that this is not the same as
+    // any linked-to payload tables
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    size_t find_first(size_t start, size_t end) const override
+    {
+        for (; start < end;) {
+            FindNullLinks fnl;
+            m_link_map.map_links(start, fnl);
+            if (fnl.m_has_link == has_links)
+                return start;
+
+            start++;
+        }
+
+        return not_found;
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        return state.describe_columns(m_link_map, realm::npos) + (has_links ? " != NULL" : " == NULL");
+    }
+
+    std::unique_ptr<Expression> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<Expression>(new UnaryLinkCompare(*this, patches));
+    }
+
+private:
+    UnaryLinkCompare(const UnaryLinkCompare& other, QueryNodeHandoverPatches* patches = nullptr)
+        : Expression(other)
+        , m_link_map(other.m_link_map, patches)
+    {
+    }
+
+    mutable LinkMap m_link_map;
+};
+
+class LinkCount : public Subexpr2<Int> {
+public:
+    LinkCount(LinkMap link_map)
+        : m_link_map(std::move(link_map))
+    {
+    }
+    LinkCount(LinkCount const& other, QueryNodeHandoverPatches* patches)
+        : Subexpr2<Int>(other)
+        , m_link_map(other.m_link_map, patches)
+    {
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<LinkCount>(*this, patches);
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        size_t count = m_link_map.count_links(index);
+        destination.import(Value<Int>(false, 1, count));
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        return state.describe_columns(m_link_map, realm::npos) + util::serializer::value_separator + "@count";
+    }
+
+private:
+    LinkMap m_link_map;
+};
+
+// Gives a count of all backlinks across all columns for the specified row.
+// The unused template parameter is a hack to avoid a circular dependency between table.hpp and query_expression.hpp.
+template <class>
+class BacklinkCount : public Subexpr2<Int> {
+public:
+    BacklinkCount(LinkMap link_map)
+    : m_link_map(std::move(link_map))
+    {
+    }
+    BacklinkCount(const Table* table, std::vector<size_t> links = {})
+    : m_link_map(table, std::move(links))
+    {
+    }
+    BacklinkCount(BacklinkCount const& other, QueryNodeHandoverPatches* patches)
+    : Subexpr2<Int>(other)
+    , m_link_map(other.m_link_map, patches)
+    {
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<BacklinkCount<Int> >(*this, patches);
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        size_t count;
+        if (m_link_map.links_exist()) {
+            count = m_link_map.count_all_backlinks(index);
+        }
+        else {
+            count = m_link_map.target_table()->get_backlink_count(index);
+        }
+        destination.import(Value<Int>(false, 1, count));
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        std::string s;
+        if (m_link_map.links_exist()) {
+            s += state.describe_columns(m_link_map, realm::npos) + util::serializer::value_separator;
+        }
+        s += "@links.@count";
+        return s;
+    }
+private:
+    LinkMap m_link_map;
+};
+
+
+template <class oper, class TExpr>
+class SizeOperator : public Subexpr2<Int> {
+public:
+    SizeOperator(std::unique_ptr<TExpr> left)
+        : m_expr(std::move(left))
+    {
+    }
+
+    // See comment in base class
+    void set_base_table(const Table* table) override
+    {
+        m_expr->set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_expr->verify_column();
+    }
+
+    // Recursively fetch tables of columns in expression tree. Used when user first builds a stand-alone expression
+    // and binds it to a Query at a later time
+    const Table* get_base_table() const override
+    {
+        return m_expr->get_base_table();
+    }
+
+    // destination = operator(left)
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        REALM_ASSERT_DEBUG(dynamic_cast<Value<Int>*>(&destination) != nullptr);
+        Value<Int>* d = static_cast<Value<Int>*>(&destination);
+        REALM_ASSERT(d);
+
+        Value<T> v;
+        m_expr->evaluate(index, v);
+
+        size_t sz = v.m_values;
+        d->init(v.m_from_link_list, sz);
+
+        for (size_t i = 0; i < sz; i++) {
+            auto elem = v.m_storage.get(i);
+            if (!elem) {
+                d->m_storage.set_null(i);
+            }
+            else {
+                d->m_storage.set(i, oper()(*elem));
+            }
+        }
+    }
+
+    std::string description(util::serializer::SerialisationState& state) const override
+    {
+        if (m_expr) {
+            return m_expr->description(state) + util::serializer::value_separator + "@size";
+        }
+        return "@size";
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<Subexpr>(new SizeOperator(*this, patches));
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        m_expr->apply_handover_patch(patches, group);
+    }
+
+private:
+    SizeOperator(const SizeOperator& other, QueryNodeHandoverPatches* patches)
+        : m_expr(other.m_expr->clone(patches))
+    {
+    }
+
+    typedef typename oper::type T;
+    std::unique_ptr<TExpr> m_expr;
+};
+
+struct ConstantRowValueHandoverPatch : public QueryNodeHandoverPatch {
+    std::unique_ptr<RowBaseHandoverPatch> row_patch;
+};
+
+class ConstantRowValue : public Subexpr2<Link> {
+public:
+    ConstantRowValue(const ConstRow& row)
+        : m_row(row)
+    {
+    }
+
+    void set_base_table(const Table*) override
+    {
+    }
+
+    void verify_column() const override
+    {
+    }
+
+    const Table* get_base_table() const override
+    {
+        return nullptr;
+    }
+
+    void evaluate(size_t, ValueBase& destination) override
+    {
+        if (m_row.is_attached()) {
+            Value<RowIndex> v(RowIndex(m_row.get_index()));
+            destination.import(v);
+        }
+        else {
+            Value<RowIndex> v(RowIndex::Detached);
+            destination.import(v);
+        }
+    }
+
+    virtual std::string description(util::serializer::SerialisationState&) const override
+    {
+        throw SerialisationError("Serialising a query which links to an object is currently unsupported.");
+        // TODO: we can do something like the following when core gets stable keys:
+        //if (!m_row.is_attached()) {
+        //    return util::serializer::print_value("detached object");
+        //}
+        //return util::serializer::print_value(m_row.get_index());
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<Subexpr>(new ConstantRowValue(*this, patches));
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        REALM_ASSERT(patches.size());
+        std::unique_ptr<QueryNodeHandoverPatch> abstract_patch = std::move(patches.back());
+        patches.pop_back();
+
+        auto patch = dynamic_cast<ConstantRowValueHandoverPatch*>(abstract_patch.get());
+        REALM_ASSERT(patch);
+
+        m_row.apply_and_consume_patch(patch->row_patch, group);
+    }
+
+private:
+    ConstantRowValue(const ConstantRowValue& source, QueryNodeHandoverPatches* patches)
+        : m_row(patches ? ConstRow() : source.m_row)
+    {
+        if (!patches)
+            return;
+
+        std::unique_ptr<ConstantRowValueHandoverPatch> patch(new ConstantRowValueHandoverPatch);
+        ConstRow::generate_patch(source.m_row, patch->row_patch);
+        patches->emplace_back(patch.release());
+    }
+
+    ConstRow m_row;
+};
+
+template <typename T>
+class SubColumns;
+
+// This is for LinkList and BackLink too since they're declared as typedefs of Link.
+template <>
+class Columns<Link> : public Subexpr2<Link> {
+public:
+    Query is_null()
+    {
+        if (m_link_map.m_link_columns.size() > 1)
+            throw util::runtime_error("Combining link() and is_null() is currently not supported");
+        // Todo, it may be useful to support the above, but we would need to figure out an intuitive behaviour
+        return make_expression<UnaryLinkCompare<false>>(m_link_map);
+    }
+
+    Query is_not_null()
+    {
+        if (m_link_map.m_link_columns.size() > 1)
+            throw util::runtime_error("Combining link() and is_not_null() is currently not supported");
+        // Todo, it may be useful to support the above, but we would need to figure out an intuitive behaviour
+        return make_expression<UnaryLinkCompare<true>>(m_link_map);
+    }
+
+    LinkCount count() const
+    {
+        return LinkCount(m_link_map);
+    }
+
+    template <class T>
+    BacklinkCount<T> backlink_count() const
+    {
+        return BacklinkCount<T>(m_link_map);
+    }
+
+    template <typename C>
+    SubColumns<C> column(size_t column_ndx) const
+    {
+        return SubColumns<C>(Columns<C>(column_ndx, m_link_map.target_table()), m_link_map);
+    }
+
+    const LinkMap& link_map() const
+    {
+        return m_link_map;
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+    }
+
+    std::string description(util::serializer::SerialisationState& state) const override
+    {
+        return state.describe_columns(m_link_map, realm::npos);
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<Subexpr>(new Columns<Link>(*this, patches));
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override;
+
+
+private:
+    LinkMap m_link_map;
+    friend class Table;
+
+    Columns(size_t column_ndx, const Table* table, const std::vector<size_t>& links = {})
+        : m_link_map(table, links)
+    {
+        static_cast<void>(column_ndx);
+    }
+    Columns(const Columns& other, QueryNodeHandoverPatches* patches)
+        : Subexpr2<Link>(other)
+        , m_link_map(other.m_link_map, patches)
+    {
+    }
+};
+
+template <typename T>
+class ListColumns;
+template <typename T, typename Operation>
+class ListColumnAggregate;
+namespace aggregate_operations {
+template <typename T>
+class Minimum;
+template <typename T>
+class Maximum;
+template <typename T>
+class Sum;
+template <typename T>
+class Average;
+}
+
+template <>
+class Columns<SubTable> : public Subexpr2<SubTable> {
+public:
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+        m_column = &m_link_map.target_table()->get_column_table(m_column_ndx);
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+        m_link_map.target_table()->verify_column(m_column_ndx, m_column);
+    }
+
+    std::string description(util::serializer::SerialisationState&) const override
+    {
+        throw SerialisationError("Serialisation of query expressions involving subtables is not yet supported.");
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<Subexpr>(new Columns<SubTable>(*this, patches));
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        evaluate_internal(index, destination, ValueBase::chunk_size);
+    }
+
+    void evaluate_internal(size_t index, ValueBase& destination, size_t nb_elements);
+
+    template <typename T>
+    ListColumns<T> column(size_t ndx) const
+    {
+        return ListColumns<T>(ndx, Columns<SubTable>(*this, nullptr));
+    }
+
+    template <typename T>
+    ListColumns<T> list() const
+    {
+        return column<T>(0);
+    }
+
+    SizeOperator<Size<ConstTableRef>> size()
+    {
+        return SizeOperator<Size<ConstTableRef>>(this->clone(nullptr));
+    }
+
+private:
+    LinkMap m_link_map;
+    size_t m_column_ndx;
+    const SubtableColumn* m_column = nullptr;
+    friend class Table;
+    template <class T>
+    friend class ListColumnsBase;
+    template <class T, class U>
+    friend class ListColumnAggregate;
+
+    Columns(size_t column_ndx, const Table* table, const std::vector<size_t>& links = {})
+        : m_link_map(table, links)
+        , m_column_ndx(column_ndx)
+        , m_column(&m_link_map.target_table()->get_column_table(column_ndx))
+    {
+    }
+
+    Columns(const Columns<SubTable>& other, QueryNodeHandoverPatches* patches)
+        : Subexpr2<SubTable>(other)
+        , m_link_map(other.m_link_map, patches)
+        , m_column_ndx(other.m_column_ndx)
+        , m_column(other.m_column)
+    {
+        if (m_column && patches)
+            m_column_ndx = m_column->get_column_index();
+    }
+};
+
+template <typename T>
+class ListColumnsBase : public Subexpr2<T> {
+public:
+    ListColumnsBase(size_t column_ndx, Columns<SubTable> column)
+        : m_column_ndx(column_ndx)
+        , m_subtable_column(std::move(column))
+    {
+    }
+
+    ListColumnsBase(const ListColumnsBase& other, QueryNodeHandoverPatches* patches)
+        : m_column_ndx(other.m_column_ndx)
+        , m_subtable_column(other.m_subtable_column, patches)
+    {
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<ListColumns<T>>(*this, patches);
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_subtable_column.get_base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_subtable_column.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_subtable_column.verify_column();
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        Value<ConstTableRef> subtables;
+        m_subtable_column.evaluate_internal(index, subtables, 1);
+        size_t sz = 0;
+        for (size_t i = 0; i < subtables.m_values; i++) {
+            auto val = subtables.m_storage[i];
+            if (val)
+                sz += val->size();
+        }
+        auto v = make_value_for_link<typename util::RemoveOptional<T>::type>(false, sz);
+        size_t k = 0;
+        for (size_t i = 0; i < subtables.m_values; i++) {
+            auto table = subtables.m_storage[i];
+            if (table) {
+                size_t s = table->size();
+                for (size_t j = 0; j < s; j++) {
+                    if (!table->is_null(m_column_ndx, j)) {
+                        v.m_storage.set(k++, table->get<T>(m_column_ndx, j));
+                    }
+                }
+            }
+        }
+        destination.import(v);
+    }
+
+    virtual std::string description(util::serializer::SerialisationState&) const override
+    {
+        throw SerialisationError("Serialisation of subtable expressions is not yet supported.");
+    }
+
+    ListColumnAggregate<T, aggregate_operations::Minimum<T>> min() const
+    {
+        return {m_column_ndx, m_subtable_column};
+    }
+
+    ListColumnAggregate<T, aggregate_operations::Maximum<T>> max() const
+    {
+        return {m_column_ndx, m_subtable_column};
+    }
+
+    ListColumnAggregate<T, aggregate_operations::Sum<T>> sum() const
+    {
+        return {m_column_ndx, m_subtable_column};
+    }
+
+    ListColumnAggregate<T, aggregate_operations::Average<T>> average() const
+    {
+        return {m_column_ndx, m_subtable_column};
+    }
+
+
+private:
+    // Storing the column index here could be a potential problem if the column
+    // changes id due to insertion/deletion.
+    size_t m_column_ndx;
+    Columns<SubTable> m_subtable_column;
+};
+
+template <class T>
+class ListColumns : public ListColumnsBase<T> {
+public:
+    using ListColumnsBase<T>::ListColumnsBase;
+};
+
+template <>
+class ListColumns<StringData> : public ListColumnsBase<StringData> {
+public:
+    ListColumns(size_t column_ndx, Columns<SubTable> column)
+        : ListColumnsBase(column_ndx, column)
+    {
+    }
+
+    ListColumns(const ListColumnsBase& other, QueryNodeHandoverPatches* patches)
+        : ListColumnsBase(other, patches)
+    {
+    }
+
+    ListColumns(ListColumns&& other)
+        : ListColumnsBase(other)
+    {
+    }
+};
+
+template <typename T, typename Operation>
+class ListColumnAggregate : public Subexpr2<typename Operation::ResultType> {
+public:
+    using R = typename Operation::ResultType;
+
+    ListColumnAggregate(size_t column_ndx, Columns<SubTable> column)
+        : m_column_ndx(column_ndx)
+        , m_subtable_column(std::move(column))
+    {
+    }
+
+    ListColumnAggregate(const ListColumnAggregate& other, QueryNodeHandoverPatches* patches)
+        : m_column_ndx(other.m_column_ndx)
+        , m_subtable_column(other.m_subtable_column, patches)
+    {
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<ListColumnAggregate>(*this, patches);
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_subtable_column.get_base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_subtable_column.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_subtable_column.verify_column();
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        Value<ConstTableRef> subtables;
+        m_subtable_column.evaluate_internal(index, subtables, 1);
+        REALM_ASSERT_DEBUG(subtables.m_values > 0 || subtables.m_from_link_list);
+        size_t sz = subtables.m_values;
+        // The result is an aggregate value for each table
+        auto v = make_value_for_link<R>(!subtables.m_from_link_list, sz);
+        for (unsigned i = 0; i < sz; i++) {
+            auto table = subtables.m_storage[i];
+            Operation op;
+            if (table) {
+                size_t s = table->size();
+                for (unsigned j = 0; j < s; j++) {
+                    op.accumulate(table->get<T>(m_column_ndx, j));
+                }
+            }
+            if (op.is_null()) {
+                v.m_storage.set_null(i);
+            }
+            else {
+                v.m_storage.set(i, op.result());
+            }
+        }
+        destination.import(v);
+    }
+
+    virtual std::string description(util::serializer::SerialisationState&) const override
+    {
+        throw SerialisationError("Serialisation of queries involving subtable expressions is not yet supported.");
+    }
+
+private:
+    size_t m_column_ndx;
+    Columns<SubTable> m_subtable_column;
+};
+
+template <class Operator>
+Query compare(const Subexpr2<Link>& left, const ConstRow& row)
+{
+    static_assert(std::is_same<Operator, Equal>::value || std::is_same<Operator, NotEqual>::value,
+                  "Links can only be compared for equality.");
+    const Columns<Link>* column = dynamic_cast<const Columns<Link>*>(&left);
+    if (column) {
+        const LinkMap& link_map = column->link_map();
+        REALM_ASSERT(link_map.target_table() == row.get_table() || !row.is_attached());
+#ifdef REALM_OLDQUERY_FALLBACK
+        if (link_map.m_link_columns.size() == 1) {
+            // We can fall back to Query::links_to for != and == operations on links, but only
+            // for == on link lists. This is because negating query.links_to() is equivalent to
+            // to "ALL linklist != row" rather than the "ANY linklist != row" semantics we're after.
+            if (link_map.m_link_types[0] == col_type_Link ||
+                (link_map.m_link_types[0] == col_type_LinkList && std::is_same<Operator, Equal>::value)) {
+                const Table* t = column->get_base_table();
+                Query query(*t);
+
+                if (std::is_same<Operator, NotEqual>::value) {
+                    // Negate the following `links_to`.
+                    query.Not();
+                }
+                query.links_to(link_map.m_link_column_indexes[0], row);
+                return query;
+            }
+        }
+#endif
+    }
+    return make_expression<Compare<Operator, RowIndex>>(left.clone(), make_subexpr<ConstantRowValue>(row));
+}
+
+inline Query operator==(const Subexpr2<Link>& left, const ConstRow& row)
+{
+    return compare<Equal>(left, row);
+}
+inline Query operator!=(const Subexpr2<Link>& left, const ConstRow& row)
+{
+    return compare<NotEqual>(left, row);
+}
+inline Query operator==(const ConstRow& row, const Subexpr2<Link>& right)
+{
+    return compare<Equal>(right, row);
+}
+inline Query operator!=(const ConstRow& row, const Subexpr2<Link>& right)
+{
+    return compare<NotEqual>(right, row);
+}
+
+template <class Operator>
+Query compare(const Subexpr2<Link>& left, null)
+{
+    static_assert(std::is_same<Operator, Equal>::value || std::is_same<Operator, NotEqual>::value,
+                  "Links can only be compared for equality.");
+    return make_expression<Compare<Operator, RowIndex>>(left.clone(), make_subexpr<Value<RowIndex>>());
+}
+
+inline Query operator==(const Subexpr2<Link>& left, null)
+{
+    return compare<Equal>(left, null());
+}
+inline Query operator!=(const Subexpr2<Link>& left, null)
+{
+    return compare<NotEqual>(left, null());
+}
+inline Query operator==(null, const Subexpr2<Link>& right)
+{
+    return compare<Equal>(right, null());
+}
+inline Query operator!=(null, const Subexpr2<Link>& right)
+{
+    return compare<NotEqual>(right, null());
+}
+
+
+template <class T>
+class Columns : public Subexpr2<T> {
+public:
+    using ColType = typename ColumnTypeTraits<T>::column_type;
+
+    Columns(size_t column, const Table* table, std::vector<size_t> links = {})
+        : m_link_map(table, std::move(links))
+        , m_column_ndx(column)
+        , m_nullable(m_link_map.target_table()->is_nullable(m_column_ndx))
+    {
+    }
+
+    Columns(const Columns& other, QueryNodeHandoverPatches* patches = nullptr)
+        : m_link_map(other.m_link_map, patches)
+        , m_column_ndx(other.m_column_ndx)
+        , m_nullable(other.m_nullable)
+    {
+        if (!other.m_sg)
+            return;
+
+        if (patches) {
+            m_column_ndx = other.get_column_base().get_column_index();
+        }
+        else {
+            if (m_nullable && std::is_same<typename ColType::value_type, int64_t>::value) {
+                init<IntNullColumn>(&other.get_column_base());
+            }
+            else {
+                init<ColType>(&other.get_column_base());
+            }
+        }
+    }
+
+    Columns& operator=(const Columns& other)
+    {
+        if (this != &other) {
+            m_link_map = other.m_link_map;
+            m_sg.reset();
+            m_column_ndx = other.m_column_ndx;
+            m_nullable = other.m_nullable;
+        }
+        return *this;
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<Columns<T>>(*this, patches);
+    }
+
+    // See comment in base class
+    void set_base_table(const Table* table) override
+    {
+        if (m_sg && table == get_base_table())
+            return;
+
+        m_link_map.set_base_table(table);
+        m_nullable = m_link_map.target_table()->is_nullable(m_column_ndx);
+
+        const ColumnBase* c = &m_link_map.target_table()->get_column_base(m_column_ndx);
+        if (m_nullable && std::is_same<typename ColType::value_type, int64_t>::value) {
+            init<IntNullColumn>(c);
+        }
+        else {
+            init<ColType>(c);
+        }
+    }
+
+    bool has_search_index() const override
+    {
+        return m_link_map.target_table()->has_search_index(m_column_ndx);
+    }
+
+    std::vector<size_t> find_all(util::Optional<Mixed> value) const override
+    {
+        std::vector<size_t> ret;
+        ref_type ref = IntegerColumn::create(Allocator::get_default());
+        IntegerColumn result;
+        result.init_from_ref(Allocator::get_default(), ref);
+        if (m_nullable && std::is_same<typename ColType::value_type, int64_t>::value) {
+            util::Optional<int64_t> val;
+            if (value) {
+                val = value->get_int();
+            }
+            auto sgc = static_cast<SequentialGetter<IntNullColumn>*>(m_sg.get());
+            sgc->m_column->find_all(result, val, 0, realm::npos);
+        }
+        else {
+            T val{};
+            if (value) {
+                val = value->get<T>();
+            }
+            auto sgc = static_cast<SequentialGetter<ColType>*>(m_sg.get());
+            sgc->m_column->find_all(result, val, 0, realm::npos);
+        }
+
+        auto sz = result.size();
+        for (size_t i = 0; i < sz; i++) {
+            auto ndxs = m_link_map.get_origin_ndxs(size_t(result.get(i)));
+            ret.insert(ret.end(), ndxs.begin(), ndxs.end());
+        }
+        result.destroy();
+
+        return ret;
+    }
+
+
+    void verify_column() const override
+    {
+        // verify links
+        m_link_map.verify_columns();
+        // verify target table
+        const Table* target_table = m_link_map.target_table();
+        if (target_table && m_column_ndx != npos) {
+            target_table->verify_column(m_column_ndx, &get_column_base());
+        }
+    }
+
+    template <class ActualColType>
+    void init(const ColumnBase* c)
+    {
+        REALM_ASSERT_DEBUG(dynamic_cast<const ActualColType*>(c));
+        if (m_sg == nullptr) {
+            m_sg.reset(new SequentialGetter<ActualColType>());
+        }
+        static_cast<SequentialGetter<ActualColType>&>(*m_sg).init(static_cast<const ActualColType*>(c));
+    }
+
+    // Recursively fetch tables of columns in expression tree. Used when user first builds a stand-alone expression
+    // and binds it to a Query at a later time
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    template <class ColType2 = ColType>
+    void evaluate_internal(size_t index, ValueBase& destination)
+    {
+        REALM_ASSERT_DEBUG(m_sg.get());
+        REALM_ASSERT_DEBUG(dynamic_cast<SequentialGetter<ColType2>*>(m_sg.get()));
+
+        using U = typename ColType2::value_type;
+        auto sgc = static_cast<SequentialGetter<ColType2>*>(m_sg.get());
+        REALM_ASSERT_DEBUG(sgc->m_column);
+
+        if (links_exist()) {
+            // LinkList with more than 0 values. Create Value with payload for all fields
+
+            std::vector<size_t> links = m_link_map.get_links(index);
+            auto v = make_value_for_link<typename util::RemoveOptional<U>::type>(m_link_map.only_unary_links(),
+                                                                                 links.size());
+
+            for (size_t t = 0; t < links.size(); t++) {
+                size_t link_to = links[t];
+                sgc->cache_next(link_to);
+
+                if (sgc->m_column->is_null(link_to))
+                    v.m_storage.set_null(t);
+                else
+                    v.m_storage.set(t, sgc->get_next(link_to));
+            }
+            destination.import(v);
+        }
+        else {
+            // Not a Link column
+            // make sequential getter load the respective leaf to access data at column row 'index'
+            sgc->cache_next(index);
+            size_t colsize = sgc->m_column->size();
+
+            // Now load `ValueBase::chunk_size` rows from from the leaf into m_storage. If it's an integer
+            // leaf, then it contains the method get_chunk() which copies these values in a super fast way (first
+            // case of the `if` below. Otherwise, copy the values one by one in a for-loop (the `else` case).
+            if (std::is_same<U, int64_t>::value && index + ValueBase::chunk_size <= sgc->m_leaf_end) {
+                Value<int64_t> v(false, ValueBase::chunk_size);
+
+                // If you want to modify 'default_size' then update Array::get_chunk()
+                REALM_ASSERT_3(ValueBase::chunk_size, ==, 8);
+
+                auto sgc_2 = static_cast<SequentialGetter<ColType>*>(m_sg.get());
+                sgc_2->m_leaf_ptr->get_chunk(index - sgc->m_leaf_start, v.m_storage.m_first);
+
+                destination.import(v);
+            }
+            else {
+                size_t rows = colsize - index;
+                if (rows > ValueBase::chunk_size)
+                    rows = ValueBase::chunk_size;
+                Value<typename util::RemoveOptional<U>::type> v(false, rows);
+
+                for (size_t t = 0; t < rows; t++)
+                    v.m_storage.set(t, sgc->get_next(index + t));
+
+                destination.import(v);
+            }
+        }
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        return state.describe_columns(m_link_map, m_column_ndx);
+    }
+
+    // Load values from Column into destination
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        if (m_nullable && std::is_same<typename ColType::value_type, int64_t>::value) {
+            evaluate_internal<IntNullColumn>(index, destination);
+        }
+        else {
+            evaluate_internal<ColType>(index, destination);
+        }
+    }
+
+    bool links_exist() const
+    {
+        return m_link_map.m_link_columns.size() > 0;
+    }
+
+    bool only_unary_links() const
+    {
+        return m_link_map.only_unary_links();
+    }
+
+    bool is_nullable() const
+    {
+        return m_nullable;
+    }
+
+    LinkMap get_link_map() const
+    {
+        return m_link_map;
+    }
+
+    size_t column_ndx() const noexcept
+    {
+        return m_sg ? get_column_base().get_column_index() : m_column_ndx;
+    }
+
+private:
+    LinkMap m_link_map;
+
+    // Fast (leaf caching) value getter for payload column (column in table on which query condition is executed)
+    std::unique_ptr<SequentialGetterBase> m_sg;
+
+    // Column index of payload column of m_table
+    size_t m_column_ndx;
+
+    // set to false by default for stand-alone Columns declaration that are not yet associated with any table
+    // or oclumn. Call init() to update it or use a constructor that takes table + column index as argument.
+    bool m_nullable = false;
+
+    const ColumnBase& get_column_base() const noexcept
+    {
+        if (m_nullable && std::is_same<int64_t, T>::value)
+            return *static_cast<SequentialGetter<IntNullColumn>&>(*m_sg).m_column;
+        else
+            return *static_cast<SequentialGetter<ColType>&>(*m_sg).m_column;
+    }
+};
+
+template <typename T, typename Operation>
+class SubColumnAggregate;
+
+template <typename T>
+class SubColumns : public Subexpr {
+public:
+    SubColumns(Columns<T> column, LinkMap link_map)
+        : m_column(std::move(column))
+        , m_link_map(std::move(link_map))
+    {
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches*) const override
+    {
+        return make_subexpr<SubColumns<T>>(*this);
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+        m_column.set_base_table(m_link_map.target_table());
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+        m_column.verify_column();
+    }
+
+    void evaluate(size_t, ValueBase&) override
+    {
+        // SubColumns can only be used in an expression in conjunction with its aggregate methods.
+        REALM_ASSERT(false);
+    }
+
+    virtual std::string description(util::serializer::SerialisationState&) const override
+    {
+        return ""; // by itself there are no conditions, see SubColumnAggregate
+    }
+
+    SubColumnAggregate<T, aggregate_operations::Minimum<T>> min() const
+    {
+        return {m_column, m_link_map};
+    }
+
+    SubColumnAggregate<T, aggregate_operations::Maximum<T>> max() const
+    {
+        return {m_column, m_link_map};
+    }
+
+    SubColumnAggregate<T, aggregate_operations::Sum<T>> sum() const
+    {
+        return {m_column, m_link_map};
+    }
+
+    SubColumnAggregate<T, aggregate_operations::Average<T>> average() const
+    {
+        return {m_column, m_link_map};
+    }
+
+private:
+    Columns<T> m_column;
+    LinkMap m_link_map;
+};
+
+template <typename T, typename Operation>
+class SubColumnAggregate : public Subexpr2<typename Operation::ResultType> {
+public:
+    SubColumnAggregate(Columns<T> column, LinkMap link_map)
+        : m_column(std::move(column))
+        , m_link_map(std::move(link_map))
+    {
+    }
+    SubColumnAggregate(SubColumnAggregate const& other, QueryNodeHandoverPatches* patches)
+        : m_column(other.m_column, patches)
+        , m_link_map(other.m_link_map, patches)
+    {
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<SubColumnAggregate>(*this, patches);
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+        m_column.set_base_table(m_link_map.target_table());
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+        m_column.verify_column();
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        std::vector<size_t> links = m_link_map.get_links(index);
+        std::sort(links.begin(), links.end());
+
+        Operation op;
+        for (size_t link_index = 0; link_index < links.size();) {
+            Value<T> value;
+            size_t link = links[link_index];
+            m_column.evaluate(link, value);
+
+            // Columns<T>::evaluate fetches values in chunks of ValueBase::default_size. Process all values
+            // within the chunk that came from rows that we link to.
+            const auto& value_storage = value.m_storage;
+            for (size_t value_index = 0; value_index < value.m_values;) {
+                if (!value_storage.is_null(value_index)) {
+                    op.accumulate(value_storage[value_index]);
+                }
+                if (++link_index >= links.size()) {
+                    break;
+                }
+
+                size_t previous_link = link;
+                link = links[link_index];
+                value_index += link - previous_link;
+            }
+        }
+        if (op.is_null()) {
+            destination.import(Value<null>(false, 1, null()));
+        }
+        else {
+            destination.import(Value<typename Operation::ResultType>(false, 1, op.result()));
+        }
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        util::serializer::SerialisationState empty_state;
+        return state.describe_columns(m_link_map, realm::npos) + util::serializer::value_separator + Operation::description() + util::serializer::value_separator + m_column.description(empty_state);
+    }
+
+private:
+    Columns<T> m_column;
+    LinkMap m_link_map;
+};
+
+struct SubQueryCountHandoverPatch : QueryNodeHandoverPatch {
+    QueryHandoverPatch m_query;
+};
+
+class SubQueryCount : public Subexpr2<Int> {
+public:
+    SubQueryCount(Query q, LinkMap link_map)
+        : m_query(std::move(q))
+        , m_link_map(std::move(link_map))
+    {
+    }
+
+    const Table* get_base_table() const override
+    {
+        return m_link_map.base_table();
+    }
+
+    void set_base_table(const Table* table) override
+    {
+        m_link_map.set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_link_map.verify_columns();
+    }
+
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        std::vector<size_t> links = m_link_map.get_links(index);
+        std::sort(links.begin(), links.end());
+
+        size_t count = std::accumulate(links.begin(), links.end(), size_t(0), [this](size_t running_count, size_t link) {
+            return running_count + m_query.count(link, link + 1, 1);
+        });
+
+        destination.import(Value<Int>(false, 1, size_t(count)));
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        REALM_ASSERT(m_link_map.base_table() != nullptr);
+        std::string target = state.describe_columns(m_link_map, realm::npos);
+        std::string var_name = state.get_variable_name(m_link_map.base_table()->get_table_ref());
+        state.subquery_prefix_list.push_back(var_name);
+        std::string desc = "SUBQUERY(" + target + ", " + var_name + ", " + m_query.get_description(state) + ")"
+            + util::serializer::value_separator + "@count";
+        state.subquery_prefix_list.pop_back();
+        return desc;
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        if (patches)
+            return std::unique_ptr<Subexpr>(new SubQueryCount(*this, patches));
+
+        return make_subexpr<SubQueryCount>(*this);
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        REALM_ASSERT(patches.size());
+        std::unique_ptr<QueryNodeHandoverPatch> abstract_patch = std::move(patches.back());
+        patches.pop_back();
+
+        auto patch = dynamic_cast<SubQueryCountHandoverPatch*>(abstract_patch.get());
+        REALM_ASSERT(patch);
+
+        m_query.apply_patch(patch->m_query, group);
+    }
+
+private:
+    SubQueryCount(const SubQueryCount& other, QueryNodeHandoverPatches* patches)
+        : m_link_map(other.m_link_map, patches)
+    {
+        std::unique_ptr<SubQueryCountHandoverPatch> patch(new SubQueryCountHandoverPatch);
+        m_query = Query(other.m_query, patch->m_query, ConstSourcePayload::Copy);
+        patches->emplace_back(patch.release());
+    }
+
+    Query m_query;
+    LinkMap m_link_map;
+};
+
+// The unused template parameter is a hack to avoid a circular dependency between table.hpp and query_expression.hpp.
+template <class>
+class SubQuery {
+public:
+    SubQuery(Columns<Link> link_column, Query query)
+        : m_query(std::move(query))
+        , m_link_map(link_column.link_map())
+    {
+        REALM_ASSERT(m_link_map.target_table() == m_query.get_table());
+    }
+
+    SubQueryCount count() const
+    {
+        return SubQueryCount(m_query, m_link_map);
+    }
+
+private:
+    Query m_query;
+    LinkMap m_link_map;
+};
+
+namespace aggregate_operations {
+template <typename T, typename Derived, typename R = T>
+class BaseAggregateOperation {
+    static_assert(std::is_same<T, Int>::value || std::is_same<T, Float>::value || std::is_same<T, Double>::value,
+                  "Numeric aggregates can only be used with subcolumns of numeric types");
+
+public:
+    using ResultType = R;
+
+    void accumulate(T value)
+    {
+        m_count++;
+        m_result = Derived::apply(m_result, value);
+    }
+
+    bool is_null() const
+    {
+        return m_count == 0;
+    }
+    ResultType result() const
+    {
+        return m_result;
+    }
+
+protected:
+    size_t m_count = 0;
+    ResultType m_result = Derived::initial_value();
+};
+
+template <typename T>
+class Minimum : public BaseAggregateOperation<T, Minimum<T>> {
+public:
+    static T initial_value()
+    {
+        return std::numeric_limits<T>::max();
+    }
+    static T apply(T a, T b)
+    {
+        return std::min(a, b);
+    }
+    static std::string description()
+    {
+        return "@min";
+    }
+};
+
+template <typename T>
+class Maximum : public BaseAggregateOperation<T, Maximum<T>> {
+public:
+    static T initial_value()
+    {
+        return std::numeric_limits<T>::min();
+    }
+    static T apply(T a, T b)
+    {
+        return std::max(a, b);
+    }
+    static std::string description()
+    {
+        return "@max";
+    }
+};
+
+template <typename T>
+class Sum : public BaseAggregateOperation<T, Sum<T>> {
+public:
+    static T initial_value()
+    {
+        return T();
+    }
+    static T apply(T a, T b)
+    {
+        return a + b;
+    }
+    bool is_null() const
+    {
+        return false;
+    }
+    static std::string description()
+    {
+        return "@sum";
+    }
+};
+
+template <typename T>
+class Average : public BaseAggregateOperation<T, Average<T>, double> {
+    using Base = BaseAggregateOperation<T, Average<T>, double>;
+
+public:
+    static double initial_value()
+    {
+        return 0;
+    }
+    static double apply(double a, T b)
+    {
+        return a + b;
+    }
+    double result() const
+    {
+        return Base::m_result / Base::m_count;
+    }
+    static std::string description()
+    {
+        return "@avg";
+    }
+
+};
+}
+
+template <class oper, class TLeft>
+class UnaryOperator : public Subexpr2<typename oper::type> {
+public:
+    UnaryOperator(std::unique_ptr<TLeft> left)
+        : m_left(std::move(left))
+    {
+    }
+
+    UnaryOperator(const UnaryOperator& other, QueryNodeHandoverPatches* patches)
+        : m_left(other.m_left->clone(patches))
+    {
+    }
+
+    UnaryOperator& operator=(const UnaryOperator& other)
+    {
+        if (this != &other) {
+            m_left = other.m_left->clone();
+        }
+        return *this;
+    }
+
+    UnaryOperator(UnaryOperator&&) = default;
+    UnaryOperator& operator=(UnaryOperator&&) = default;
+
+    // See comment in base class
+    void set_base_table(const Table* table) override
+    {
+        m_left->set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_left->verify_column();
+    }
+
+    // Recursively fetch tables of columns in expression tree. Used when user first builds a stand-alone expression
+    // and binds it to a Query at a later time
+    const Table* get_base_table() const override
+    {
+        return m_left->get_base_table();
+    }
+
+    // destination = operator(left)
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        Value<T> result;
+        Value<T> left;
+        m_left->evaluate(index, left);
+        result.template fun<oper>(&left);
+        destination.import(result);
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        if (m_left) {
+            return m_left->description(state);
+        }
+        return "";
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<UnaryOperator>(*this, patches);
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        m_left->apply_handover_patch(patches, group);
+    }
+
+private:
+    typedef typename oper::type T;
+    std::unique_ptr<TLeft> m_left;
+};
+
+
+template <class oper, class TLeft, class TRight>
+class Operator : public Subexpr2<typename oper::type> {
+public:
+    Operator(std::unique_ptr<TLeft> left, std::unique_ptr<TRight> right)
+        : m_left(std::move(left))
+        , m_right(std::move(right))
+    {
+    }
+
+    Operator(const Operator& other, QueryNodeHandoverPatches* patches)
+        : m_left(other.m_left->clone(patches))
+        , m_right(other.m_right->clone(patches))
+    {
+    }
+
+    Operator& operator=(const Operator& other)
+    {
+        if (this != &other) {
+            m_left = other.m_left->clone();
+            m_right = other.m_right->clone();
+        }
+        return *this;
+    }
+
+    Operator(Operator&&) = default;
+    Operator& operator=(Operator&&) = default;
+
+    // See comment in base class
+    void set_base_table(const Table* table) override
+    {
+        m_left->set_base_table(table);
+        m_right->set_base_table(table);
+    }
+
+    void verify_column() const override
+    {
+        m_left->verify_column();
+        m_right->verify_column();
+    }
+
+    // Recursively fetch tables of columns in expression tree. Used when user first builds a stand-alone expression
+    // and
+    // binds it to a Query at a later time
+    const Table* get_base_table() const override
+    {
+        const Table* l = m_left->get_base_table();
+        const Table* r = m_right->get_base_table();
+
+        // Queries do not support multiple different tables; all tables must be the same.
+        REALM_ASSERT(l == nullptr || r == nullptr || l == r);
+
+        // nullptr pointer means expression which isn't yet associated with any table, or is a Value<T>
+        return l ? l : r;
+    }
+
+    // destination = operator(left, right)
+    void evaluate(size_t index, ValueBase& destination) override
+    {
+        Value<T> result;
+        Value<T> left;
+        Value<T> right;
+        m_left->evaluate(index, left);
+        m_right->evaluate(index, right);
+        result.template fun<oper>(&left, &right);
+        destination.import(result);
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        std::string s;
+        if (m_left) {
+            s += m_left->description(state);
+        }
+        s += (" " + oper::description() + " ");
+        if (m_right) {
+            s += m_right->description(state);
+        }
+        return s;
+    }
+
+    std::unique_ptr<Subexpr> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return make_subexpr<Operator>(*this, patches);
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        m_right->apply_handover_patch(patches, group);
+        m_left->apply_handover_patch(patches, group);
+    }
+
+private:
+    typedef typename oper::type T;
+    std::unique_ptr<TLeft> m_left;
+    std::unique_ptr<TRight> m_right;
+};
+
+namespace {
+template <class T>
+inline Mixed get_mixed(const Value<T>& val)
+{
+    return Mixed(val.m_storage[0]);
+}
+
+template <>
+inline Mixed get_mixed(const Value<RowIndex>&)
+{
+    REALM_ASSERT(false);
+    return Mixed();
+}
+
+template <>
+inline Mixed get_mixed(const Value<int>& val)
+{
+    return Mixed(int64_t(val.m_storage[0]));
+}
+} // namespace
+
+template <class TCond, class T, class TLeft, class TRight>
+class Compare : public Expression {
+public:
+    Compare(std::unique_ptr<TLeft> left, std::unique_ptr<TRight> right)
+        : m_left(std::move(left))
+        , m_right(std::move(right))
+    {
+        m_left_is_const = m_left->has_constant_evaluation();
+        if (m_left_is_const) {
+            m_left->evaluate(-1/*unused*/, m_left_value);
+        }
+    }
+
+    // See comment in base class
+    void set_base_table(const Table* table) override
+    {
+        m_left->set_base_table(table);
+        m_right->set_base_table(table);
+    }
+
+    double init() override
+    {
+        double dT = m_left_is_const ? 10.0 : 50.0;
+        if (std::is_same<TCond, Equal>::value && m_left_is_const && m_right->has_search_index()) {
+            if (m_left_value.m_storage.is_null(0)) {
+                m_matches = m_right->find_all(util::Optional<Mixed>());
+            }
+            else {
+                m_matches = m_right->find_all(get_mixed(m_left_value));
+            }
+            // Sort
+            std::sort(m_matches.begin(), m_matches.end());
+            // Remove all duplicates
+            m_matches.erase(std::unique(m_matches.begin(), m_matches.end()), m_matches.end());
+
+            m_has_matches = true;
+            m_index_get = 0;
+            m_index_end = m_matches.size();
+            dT = 0;
+        }
+
+        return dT;
+    }
+
+    void verify_column() const override
+    {
+        m_left->verify_column();
+        m_right->verify_column();
+    }
+
+    // Recursively fetch tables of columns in expression tree. Used when user first builds a stand-alone expression
+    // and binds it to a Query at a later time
+    const Table* get_base_table() const override
+    {
+        const Table* l = m_left->get_base_table();
+        const Table* r = m_right->get_base_table();
+
+        // All main tables in each subexpression of a query (table.columns() or table.link()) must be the same.
+        REALM_ASSERT(l == nullptr || r == nullptr || l == r);
+
+        // nullptr pointer means expression which isn't yet associated with any table, or is a Value<T>
+        return l ? l : r;
+    }
+
+    size_t find_first(size_t start, size_t end) const override
+    {
+        if (m_has_matches) {
+            if (m_index_end == 0)
+                return not_found;
+
+            if (start <= m_index_last_start)
+                m_index_get = 0;
+            else
+                m_index_last_start = start;
+
+            while (m_index_get < m_index_end) {
+                size_t ndx = m_matches[m_index_get];
+                if (ndx >= end) {
+                    break;
+                }
+                m_index_get++;
+                if (ndx >= start) {
+                    return ndx;
+                }
+            }
+            return not_found;
+        }
+
+        size_t match;
+
+        Value<T> left;
+        Value<T> right;
+
+        for (; start < end;) {
+            if (m_left_is_const) {
+                m_right->evaluate(start, right);
+                match = Value<T>::template compare_const<TCond>(&m_left_value, &right);
+            }
+            else {
+                m_left->evaluate(start, left);
+                m_right->evaluate(start, right);
+                match = Value<T>::template compare<TCond>(&left, &right);
+            }
+
+            if (match != not_found && match + start < end)
+                return start + match;
+
+            size_t rows =
+                (left.m_from_link_list || right.m_from_link_list) ? 1 : minimum(right.m_values, left.m_values);
+            start += rows;
+        }
+
+        return not_found; // no match
+    }
+
+    virtual std::string description(util::serializer::SerialisationState& state) const override
+    {
+        if (std::is_same<TCond, BeginsWith>::value
+            || std::is_same<TCond, BeginsWithIns>::value
+            || std::is_same<TCond, EndsWith>::value
+            || std::is_same<TCond, EndsWithIns>::value
+            || std::is_same<TCond, Contains>::value
+            || std::is_same<TCond, ContainsIns>::value
+            || std::is_same<TCond, Like>::value
+            || std::is_same<TCond, LikeIns>::value) {
+            // these string conditions have the arguments reversed but the order is important
+            // operations ==, and != can be reversed because the produce the same results both ways
+            return util::serializer::print_value(m_right->description(state) + " " + TCond::description()
+                                                 + " " + m_left->description(state));
+        }
+        return util::serializer::print_value(m_left->description(state) + " " + TCond::description()
+                                             + " " + m_right->description(state));
+    }
+
+    std::unique_ptr<Expression> clone(QueryNodeHandoverPatches* patches) const override
+    {
+        return std::unique_ptr<Expression>(new Compare(*this, patches));
+    }
+
+    void apply_handover_patch(QueryNodeHandoverPatches& patches, Group& group) override
+    {
+        m_right->apply_handover_patch(patches, group);
+        m_left->apply_handover_patch(patches, group);
+    }
+
+private:
+    Compare(const Compare& other, QueryNodeHandoverPatches* patches)
+        : m_left(other.m_left->clone(patches))
+        , m_right(other.m_right->clone(patches))
+        , m_left_is_const(other.m_left_is_const)
+    {
+        if (m_left_is_const) {
+            m_left->evaluate(-1/*unused*/, m_left_value);
+        }
+    }
+
+    std::unique_ptr<TLeft> m_left;
+    std::unique_ptr<TRight> m_right;
+    bool m_left_is_const;
+    Value<T> m_left_value;
+    bool m_has_matches = false;
+    std::vector<size_t> m_matches;
+    mutable size_t m_index_get = 0;
+    mutable size_t m_index_last_start = 0;
+    size_t m_index_end = 0;
+};
+
+}
+#endif // REALM_QUERY_EXPRESSION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/query_operators.hpp b/node_modules/realm/vendor/realm-ios/include/realm/query_operators.hpp
new file mode 100644
index 0000000..203af84
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/query_operators.hpp
@@ -0,0 +1,71 @@
+/*************************************************************************
+ *
+ * Copyright 2017 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_QUERY_OPERATORS_HPP
+#define REALM_QUERY_OPERATORS_HPP
+
+#include <realm/binary_data.hpp>
+#include <realm/link_view.hpp>
+#include <realm/string_data.hpp>
+#include <realm/table.hpp>
+
+namespace realm {
+
+// This is not supported in the general case
+template <class T>
+struct Size;
+
+template <>
+struct Size<StringData> {
+    int64_t operator()(StringData v) const
+    {
+        return v.size();
+    }
+    typedef StringData type;
+};
+
+template <>
+struct Size<BinaryData> {
+    int64_t operator()(BinaryData v) const
+    {
+        return v.size();
+    }
+    typedef BinaryData type;
+};
+
+template <>
+struct Size<ConstTableRef> {
+    int64_t operator()(ConstTableRef v) const
+    {
+        return v->size();
+    }
+    typedef ConstTableRef type;
+};
+
+template <>
+struct Size<ConstLinkViewRef> {
+    int64_t operator()(ConstLinkViewRef v) const
+    {
+        return v->size();
+    }
+    typedef ConstLinkViewRef type;
+};
+
+} // namespace realm
+
+#endif // REALM_QUERY_OPERATORS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/realm_nmmintrin.h b/node_modules/realm/vendor/realm-ios/include/realm/realm_nmmintrin.h
new file mode 100644
index 0000000..8144da6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/realm_nmmintrin.h
@@ -0,0 +1,182 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_NMMINTRIN_H
+#define REALM_NMMINTRIN_H
+
+/*
+    We must support runtime detection of CPU support of SSE when distributing Realm as a closed source library.
+
+    This is a problem on gcc and llvm: To use SSE intrinsics we need to pass -msse on the command line (to get offered
+    __builtin_ accessors used by intrinsics functions). However, the -msse flag allows gcc to emit SSE instructions
+    in its code generation/optimization. This is unwanted because the binary would crash on non-SSE CPUs.
+
+    Since there exists no flag in gcc that enables intrinsics but probits SSE in code generation, we define our
+    own intrinsics to be assembled by the back end assembler and omit passing -msse to gcc.
+*/
+
+#ifndef _MSC_VER
+
+#ifdef REALM_COMPILER_SSE
+#include <emmintrin.h> // SSE2 (using __m128i)
+#endif
+
+namespace realm {
+
+#if 0
+#ifdef REALM_COMPILER_AVX
+typedef float __m256 __attribute__((__vector_size__(32), __may_alias__));
+typedef double __m256d __attribute__((__vector_size__(32), __may_alias__));
+
+const int _CMP_EQ_OQ = 0x00; // Equal (ordered, non-signaling)
+const int _CMP_NEQ_OQ = 0x0c; // Not-equal (ordered, non-signaling)
+const int _CMP_LT_OQ = 0x11; // Less-than (ordered, non-signaling)
+const int _CMP_LE_OQ = 0x12; // Less-than-or-equal (ordered, non-signaling)
+const int _CMP_GE_OQ = 0x1d; // Greater-than-or-equal (ordered, non-signaling)
+const int _CMP_GT_OQ = 0x1e; // Greater-than (ordered, non-signaling)
+
+
+template<int op>
+static int movemask_cmp_ps(__m256* y1, __m256* y2)
+{
+    int ret;
+    __asm__("vmovaps %0, %%ymm0"                    :                   : "m"(*y1)                      : "%xmm0"   );
+    __asm__("vmovaps %0, %%ymm1"                    :                   : "m"(*y2)                      : "%xmm1"   );
+    __asm__("vcmpps %0, %%ymm0, %%ymm1, %%ymm0"     :                   : "I"(op)                       : "%xmm0"   );
+    __asm__("vmovmskps %%ymm0, %0"                  : "=r"(ret)         :                               :           );
+    return ret;
+}
+
+template<int op>
+static inline int movemask_cmp_pd(__m256d* y1, __m256d* y2)
+{
+    int ret;
+    __asm__("vmovapd %0, %%ymm0"                    :                   : "m"(*y1)                      : "%xmm0"   );
+    __asm__("vmovapd %0, %%ymm1"                    :                   : "m"(*y2)                      : "%xmm1"   );
+    __asm__("vcmppd %0, %%ymm0, %%ymm1, %%ymm0"     :                   : "I"(op)                       : "%xmm0"   );
+    __asm__("vmovmskpd %%ymm0, %0"                  : "=r"(ret)         :                               :           );
+    return ret;
+}
+
+
+
+static inline int movemask_cmp_ps(__m256* y1, __m256* y2, int op)
+{
+    // todo, use constexpr;
+    if (op == _CMP_EQ_OQ)
+        return movemask_cmp_ps<_CMP_NEQ_OQ>(y1, y2);
+    else if (op == _CMP_NEQ_OQ)
+        return movemask_cmp_ps<_CMP_NEQ_OQ>(y1, y2);
+    else if (op == _CMP_LT_OQ)
+        return movemask_cmp_ps<_CMP_LT_OQ>(y1, y2);
+    else if (op == _CMP_LE_OQ)
+        return movemask_cmp_ps<_CMP_LE_OQ>(y1, y2);
+    else if (op == _CMP_GE_OQ)
+        return movemask_cmp_ps<_CMP_GE_OQ>(y1, y2);
+    else if (op == _CMP_GT_OQ)
+        return movemask_cmp_ps<_CMP_GT_OQ>(y1, y2);
+
+    REALM_ASSERT(false);
+    return 0;
+}
+
+static inline int movemask_cmp_pd(__m256d* y1, __m256d* y2, int op)
+{
+    // todo, use constexpr;
+    if (op == _CMP_EQ_OQ)
+        return movemask_cmp_pd<_CMP_NEQ_OQ>(y1, y2);
+    else if (op == _CMP_NEQ_OQ)
+        return movemask_cmp_pd<_CMP_NEQ_OQ>(y1, y2);
+    else if (op == _CMP_LT_OQ)
+        return movemask_cmp_pd<_CMP_LT_OQ>(y1, y2);
+    else if (op == _CMP_LE_OQ)
+        return movemask_cmp_pd<_CMP_LE_OQ>(y1, y2);
+    else if (op == _CMP_GE_OQ)
+        return movemask_cmp_pd<_CMP_GE_OQ>(y1, y2);
+    else if (op == _CMP_GT_OQ)
+        return movemask_cmp_pd<_CMP_GT_OQ>(y1, y2);
+
+    REALM_ASSERT(false);
+    return 0;
+}
+
+
+#endif
+#endif
+
+// Instructions introduced by SSE 3 and 4.2
+static inline __m128i _mm_cmpgt_epi64(__m128i xmm1, __m128i xmm2)
+{
+    __asm__("pcmpgtq %1, %0" : "+x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i _mm_cmpeq_epi64(__m128i xmm1, __m128i xmm2)
+{
+    __asm__("pcmpeqq %1, %0" : "+x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i __attribute__((always_inline)) _mm_min_epi8(__m128i xmm1, __m128i xmm2)
+{
+    __asm__("pminsb %1, %0" : "+x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i __attribute__((always_inline)) _mm_max_epi8(__m128i xmm1, __m128i xmm2)
+{
+    __asm__("pmaxsb %1, %0" : "+x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i __attribute__((always_inline)) _mm_max_epi32(__m128i xmm1, __m128i xmm2)
+{
+    __asm__("pmaxsd %1, %0" : "+x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i __attribute__((always_inline)) _mm_min_epi32(__m128i xmm1, __m128i xmm2)
+{
+    __asm__("pminsd %1, %0" : "+x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i __attribute__((always_inline)) _mm_cvtepi8_epi16(__m128i xmm2)
+{
+    __m128i xmm1;
+    __asm__("pmovsxbw %1, %0" : "=x" (xmm1) : "xm" (xmm2) : "xmm1");
+    return xmm1;
+}
+static inline __m128i __attribute__((always_inline)) _mm_cvtepi16_epi32(__m128i xmm2)
+{
+    __m128i xmm1;
+    asm("pmovsxwd %1, %0" : "=x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+static inline __m128i __attribute__((always_inline)) _mm_cvtepi32_epi64(__m128i xmm2)
+{
+    __m128i xmm1;
+    __asm__("pmovsxdq %1, %0" : "=x" (xmm1) : "xm" (xmm2));
+    return xmm1;
+}
+
+} // namespace realm
+
+#endif
+#endif
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/replication.hpp b/node_modules/realm/vendor/realm-ios/include/realm/replication.hpp
new file mode 100644
index 0000000..92a5782
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/replication.hpp
@@ -0,0 +1,512 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_REPLICATION_HPP
+#define REALM_REPLICATION_HPP
+
+#include <algorithm>
+#include <limits>
+#include <memory>
+#include <exception>
+#include <string>
+
+#include <realm/util/assert.hpp>
+#include <realm/util/safe_int_ops.hpp>
+#include <realm/util/buffer.hpp>
+#include <realm/util/string_buffer.hpp>
+#include <realm/impl/cont_transact_hist.hpp>
+#include <realm/impl/transact_log.hpp>
+
+namespace realm {
+namespace util {
+class Logger;
+}
+
+// FIXME: Be careful about the possibility of one modification function being called by another where both do
+// transaction logging.
+
+// FIXME: The current table/subtable selection scheme assumes that a TableRef of a subtable is not accessed after any
+// modification of one of its ancestor tables.
+
+// FIXME: Checking on same Table* requires that ~Table checks and nullifies on match. Another option would be to store
+// m_selected_table as a TableRef. Yet another option would be to assign unique identifiers to each Table instance via
+// Allocator. Yet another option would be to explicitely invalidate subtables recursively when parent is modified.
+
+/// Replication is enabled by passing an instance of an implementation of this
+/// class to the SharedGroup constructor.
+class Replication : public _impl::TransactLogConvenientEncoder, protected _impl::TransactLogStream {
+public:
+    // Be sure to keep this type aligned with what is actually used in
+    // SharedGroup.
+    using version_type = _impl::History::version_type;
+    using InputStream = _impl::NoCopyInputStream;
+    class TransactLogApplier;
+    class Interrupted; // Exception
+    class SimpleIndexTranslator;
+
+    enum class TransactionType { trans_Read, trans_Write };
+
+    /// CAUTION: These values are stored in Realm files, so value reassignment
+    /// is not allowed.
+    enum HistoryType {
+        /// No history available. No support for either continuous transactions
+        /// or inter-client synchronization.
+        hist_None = 0,
+
+        /// Out-of-Realm history supporting continuous transactions.
+        ///
+        /// NOTE: This history type is no longer in use. The value needs to stay
+        /// reserved in case someone tries to open an old Realm file.
+        hist_OutOfRealm = 1,
+
+        /// In-Realm history supporting continuous transactions
+        /// (make_in_realm_history()).
+        hist_InRealm = 2,
+
+        /// In-Realm history supporting continuous transactions and client-side
+        /// synchronization protocol (realm::sync::ClientHistory).
+        hist_SyncClient = 3,
+
+        /// In-Realm history supporting continuous transactions and server-side
+        /// synchronization protocol (realm::_impl::ServerHistory).
+        hist_SyncServer = 4
+    };
+
+    virtual std::string get_database_path() const = 0;
+
+    /// Called during construction of the associated SharedGroup object.
+    ///
+    /// \param shared_group The assocoated SharedGroup object.
+    virtual void initialize(SharedGroup& shared_group) = 0;
+
+    /// Called by the associated SharedGroup object when a session is
+    /// initiated. A *session* is a sequence of of temporally overlapping
+    /// accesses to a specific Realm file, where each access consists of a
+    /// SharedGroup object through which the Realm file is open. Session
+    /// initiation occurs during the first opening of the Realm file within such
+    /// a session.
+    ///
+    /// Session initiation fails if this function throws.
+    ///
+    /// \param version The current version of the associated Realm. Out-of-Realm
+    /// history implementation can use this to trim off history entries that
+    /// were successfully added to the history, but for which the corresponding
+    /// subsequent commits on the Realm file failed.
+    ///
+    /// The default implementation does nothing.
+    virtual void initiate_session(version_type version) = 0;
+
+    /// Called by the associated SharedGroup object when a session is
+    /// terminated. See initiate_session() for the definition of a
+    /// session. Session termination occurs upon closing the Realm through the
+    /// last SharedGroup object within the session.
+    ///
+    /// The default implementation does nothing.
+    virtual void terminate_session() noexcept = 0;
+
+    /// \defgroup replication_transactions
+    //@{
+
+    /// From the point of view of the Replication class, a transaction is
+    /// initiated when, and only when the associated SharedGroup object calls
+    /// initiate_transact() and the call is successful. The associated
+    /// SharedGroup object must terminate every initiated transaction either by
+    /// calling finalize_commit() or by calling abort_transact(). It may only
+    /// call finalize_commit(), however, after calling prepare_commit(), and
+    /// only when prepare_commit() succeeds. If prepare_commit() fails (i.e.,
+    /// throws) abort_transact() must still be called.
+    ///
+    /// The associated SharedGroup object is supposed to terminate a transaction
+    /// as soon as possible, and is required to terminate it before attempting
+    /// to initiate a new one.
+    ///
+    /// initiate_transact() is called by the associated SharedGroup object as
+    /// part of the initiation of a transaction, and at a time where the caller
+    /// has acquired exclusive write access to the local Realm. The Replication
+    /// implementation is allowed to perform "precursor transactions" on the
+    /// local Realm at this time. During the initiated transaction, the
+    /// associated SharedGroup object must inform the Replication object of all
+    /// modifying operations by calling set_value() and friends.
+    ///
+    /// FIXME: There is currently no way for implementations to perform
+    /// precursor transactions, since a regular transaction would cause a dead
+    /// lock when it tries to acquire a write lock. Consider giving access to
+    /// special non-locking precursor transactions via an extra argument to this
+    /// function.
+    ///
+    /// prepare_commit() serves as the first phase of a two-phase commit. This
+    /// function is called by the associated SharedGroup object immediately
+    /// before the commit operation on the local Realm. The associated
+    /// SharedGroup object will then, as the second phase, either call
+    /// finalize_commit() or abort_transact() depending on whether the commit
+    /// operation succeeded or not. The Replication implementation is allowed to
+    /// modify the Realm via the associated SharedGroup object at this time
+    /// (important to in-Realm histories).
+    ///
+    /// initiate_transact() and prepare_commit() are allowed to block the
+    /// calling thread if, for example, they need to communicate over the
+    /// network. If a calling thread is blocked in one of these functions, it
+    /// must be possible to interrupt the blocking operation by having another
+    /// thread call interrupt(). The contract is as follows: When interrupt() is
+    /// called, then any execution of initiate_transact() or prepare_commit(),
+    /// initiated before the interruption, must complete without blocking, or
+    /// the execution must be aborted by throwing an Interrupted exception. If
+    /// initiate_transact() or prepare_commit() throws Interrupted, it counts as
+    /// a failed operation.
+    ///
+    /// finalize_commit() is called by the associated SharedGroup object
+    /// immediately after a successful commit operation on the local Realm. This
+    /// happens at a time where modification of the Realm is no longer possible
+    /// via the associated SharedGroup object. In the case of in-Realm
+    /// histories, the changes are automatically finalized as part of the commit
+    /// operation performed by the caller prior to the invocation of
+    /// finalize_commit(), so in that case, finalize_commit() might not need to
+    /// do anything.
+    ///
+    /// abort_transact() is called by the associated SharedGroup object to
+    /// terminate a transaction without committing. That is, any transaction
+    /// that is not terminated by finalize_commit() is terminated by
+    /// abort_transact(). This could be due to an explicit rollback, or due to a
+    /// failed commit attempt.
+    ///
+    /// Note that finalize_commit() and abort_transact() are not allowed to
+    /// throw.
+    ///
+    /// \param current_version The version of the snapshot that the current
+    /// transaction is based on.
+    ///
+    /// \param history_updated Pass true only when the history has already been
+    /// updated to reflect the currently bound snapshot, such as when
+    /// _impl::History::update_early_from_top_ref() was called during the
+    /// transition from a read transaction to the current write transaction.
+    ///
+    /// \return prepare_commit() returns the version of the new snapshot
+    /// produced by the transaction.
+    ///
+    /// \throw Interrupted Thrown by initiate_transact() and prepare_commit() if
+    /// a blocking operation was interrupted.
+
+    void initiate_transact(TransactionType transaction_type, version_type current_version, bool history_updated);
+    version_type prepare_commit(version_type current_version);
+    void finalize_commit() noexcept;
+    void abort_transact() noexcept;
+
+    //@}
+
+
+    /// Interrupt any blocking call to a function in this class. This function
+    /// may be called asyncronously from any thread, but it may not be called
+    /// from a system signal handler.
+    ///
+    /// Some of the public function members of this class may block, but only
+    /// when it it is explicitely stated in the documention for those functions.
+    ///
+    /// FIXME: Currently we do not state blocking behaviour for all the
+    /// functions that can block.
+    ///
+    /// After any function has returned with an interruption indication, the
+    /// only functions that may safely be called are abort_transact() and the
+    /// destructor. If a client, after having received an interruption
+    /// indication, calls abort_transact() and then clear_interrupt(), it may
+    /// resume normal operation through this Replication object.
+    void interrupt() noexcept;
+
+    /// May be called by a client to reset this Replication object after an
+    /// interrupted transaction. It is not an error to call this function in a
+    /// situation where no interruption has occured.
+    void clear_interrupt() noexcept;
+
+    /// Apply a changeset to the specified group.
+    ///
+    /// \param changeset The changes to be applied.
+    ///
+    /// \param group The destination group to apply the changeset to.
+    ///
+    /// \param logger If specified, and the library was compiled in debug mode,
+    /// then a line describing each individual operation is writted to the
+    /// specified logger.
+    ///
+    /// \throw BadTransactLog If the changeset could not be successfully parsed,
+    /// or ended prematurely.
+    static void apply_changeset(InputStream& changeset, Group& group, util::Logger* logger = nullptr);
+
+    /// Returns the type of history maintained by this Replication
+    /// implementation, or \ref hist_None if no history is maintained by it.
+    ///
+    /// This type is used to ensure that all session participants agree on
+    /// history type, and that the Realm file contains a compatible type of
+    /// history, at the beginning of a new session.
+    ///
+    /// As a special case, if there is no top array (Group::m_top) at the
+    /// beginning of a new session, then the history type is still undecided and
+    /// all history types (as returned by get_history_type()) are threfore
+    /// allowed for the session initiator. Note that this case only arises if
+    /// there was no preceding session, or if no transaction was sucessfully
+    /// committed during any of the preceding sessions. As soon as a transaction
+    /// is successfully committed, the Realm contains at least a top array, and
+    /// from that point on, the history type is generally fixed, although still
+    /// subject to certain allowed changes (as mentioned below).
+    ///
+    /// For the sake of backwards compatibility with older Realm files that does
+    /// not store any history type, the following rule shall apply:
+    ///
+    ///   - If the top array of a Realm file (Group::m_top) does not contain a
+    ///     history type, because it is too short, it shall be understood as
+    ///     implicitly storing the type \ref hist_None.
+    ///
+    /// Note: In what follows, the meaning of *preceding session* is: The last
+    /// preceding session that modified the Realm by sucessfully committing a
+    /// new snapshot.
+    ///
+    /// It shall be allowed to switch to a \ref hist_InRealm history if the
+    /// stored history type is \ref hist_None. This can be done simply by adding
+    /// a new history to the Realm file. This is possible because histories of
+    /// this type a transient in nature, and need not survive from one session
+    /// to the next.
+    ///
+    /// On the other hand, as soon as a history of type \ref hist_InRealm is
+    /// added to a Realm file, that history type is binding for all subsequent
+    /// sessions. In theory, this constraint is not necessary, and a later
+    /// switch to \ref hist_None would be possible because of the transient
+    /// nature of it, however, because the \ref hist_InRealm history remains in
+    /// the Realm file, there are practical complications, and for that reason,
+    /// such switching shall not be supported.
+    ///
+    /// The \ref hist_SyncClient history type can only be used if the stored
+    /// history type is also \ref hist_SyncClient, or when there is no top array
+    /// yet. Likewise, the \ref hist_SyncServer history type can only be used if
+    /// the stored history type is also \ref hist_SyncServer, or when there is
+    /// no top array yet. Additionally, when the stored history type is \ref
+    /// hist_SyncClient or \ref hist_SyncServer, then all subsequent sessions
+    /// must have the same type. These restrictions apply because such a history
+    /// needs to be maintained persistently across sessions.
+    ///
+    /// In general, if there is no stored history type (no top array) at the
+    /// beginning of a new session, or if the stored type disagrees with what is
+    /// returned by get_history_type() (which is possible due to particular
+    /// allowed changes of history type), the actual history type (as returned
+    /// by get_history_type()) used during that session, must be stored in the
+    /// Realm during the first successfully committed transaction in that
+    /// session. But note that there is still no need to expand the top array to
+    /// store the history type \ref hist_None, due to the rule mentioned above.
+    ///
+    /// This function must return \ref hist_None when, and only when
+    /// get_history() returns null.
+    virtual HistoryType get_history_type() const noexcept = 0;
+
+    /// Returns the schema version of the history maintained by this Replication
+    /// implementation, or 0 if no history is maintained by it. All session
+    /// participants must agree on history schema version.
+    ///
+    /// Must return 0 if get_history_type() returns \ref hist_None.
+    virtual int get_history_schema_version() const noexcept = 0;
+
+    /// Implementation may assume that this function is only ever called with a
+    /// stored schema version that is less than what was returned by
+    /// get_history_schema_version().
+    virtual bool is_upgradable_history_schema(int stored_schema_version) const noexcept = 0;
+
+    /// The implementation may assume that this function is only ever called if
+    /// is_upgradable_history_schema() was called with the same stored schema
+    /// version, and returned true. This implies that the specified stored
+    /// schema version is always strictly less than what was returned by
+    /// get_history_schema_version().
+    virtual void upgrade_history_schema(int stored_schema_version) = 0;
+
+    /// Returns an object that gives access to the history of changesets in a
+    /// way that allows for continuous transactions to work
+    /// (Group::advance_transact() in particular).
+    ///
+    /// This function must return null when, and only when get_history_type()
+    /// returns \ref hist_None.
+    virtual _impl::History* get_history() = 0;
+
+    /// Returns false by default, but must return true if, and only if this
+    /// history object represents a session participant that is a sync
+    /// agent. This is used to enforce the "maximum one sync agent per session"
+    /// constraint.
+    virtual bool is_sync_agent() const noexcept;
+
+    virtual ~Replication() noexcept
+    {
+    }
+
+protected:
+    Replication();
+
+
+    //@{
+
+    /// do_initiate_transact() is called by initiate_transact(), and likewise
+    /// for do_prepare_commit), do_finalize_commit(), and do_abort_transact().
+    ///
+    /// With respect to exception safety, the Replication implementation has two
+    /// options: It can prepare to accept the accumulated changeset in
+    /// do_prepapre_commit() by allocating all required resources, and delay the
+    /// actual acceptance to do_finalize_commit(), which requires that the final
+    /// acceptance can be done without any risk of failure. Alternatively, the
+    /// Replication implementation can fully accept the changeset in
+    /// do_prepapre_commit() (allowing for failure), and then discard that
+    /// changeset during the next invocation of do_initiate_transact() if
+    /// `current_version` indicates that the previous transaction failed.
+
+    virtual void do_initiate_transact(TransactionType, version_type current_version) = 0;
+    virtual version_type do_prepare_commit(version_type orig_version) = 0;
+    virtual void do_finalize_commit() noexcept = 0;
+    virtual void do_abort_transact() noexcept = 0;
+
+    //@}
+
+
+    virtual void do_interrupt() noexcept = 0;
+
+    virtual void do_clear_interrupt() noexcept = 0;
+
+    friend class _impl::TransactReverser;
+};
+
+
+class Replication::Interrupted : public std::exception {
+public:
+    const char* what() const noexcept override
+    {
+        return "Interrupted";
+    }
+};
+
+
+class TrivialReplication : public Replication {
+public:
+    ~TrivialReplication() noexcept
+    {
+    }
+
+    std::string get_database_path() const override;
+protected:
+    typedef Replication::version_type version_type;
+
+    TrivialReplication(const std::string& database_file);
+
+    virtual version_type prepare_changeset(const char* data, size_t size, version_type orig_version) = 0;
+    virtual void finalize_changeset() noexcept = 0;
+
+    static void apply_changeset(const char* data, size_t size, SharedGroup& target, util::Logger* logger = nullptr);
+
+    BinaryData get_uncommitted_changes() const noexcept;
+
+    void initialize(SharedGroup&) override;
+    void do_initiate_transact(TransactionType, version_type) override;
+    version_type do_prepare_commit(version_type orig_version) override;
+    void do_finalize_commit() noexcept override;
+    void do_abort_transact() noexcept override;
+    void do_interrupt() noexcept override;
+    void do_clear_interrupt() noexcept override;
+    void transact_log_reserve(size_t n, char** new_begin, char** new_end) override;
+    void transact_log_append(const char* data, size_t size, char** new_begin, char** new_end) override;
+
+private:
+    const std::string m_database_file;
+    util::Buffer<char> m_transact_log_buffer;
+    void internal_transact_log_reserve(size_t, char** new_begin, char** new_end);
+
+    size_t transact_log_size();
+};
+
+
+// Implementation:
+
+inline Replication::Replication()
+    : _impl::TransactLogConvenientEncoder(static_cast<_impl::TransactLogStream&>(*this))
+{
+}
+
+inline void Replication::initiate_transact(TransactionType transaction_type, version_type current_version,
+                                           bool history_updated)
+{
+    if (auto hist = get_history()) {
+        hist->set_updated(history_updated);
+    }
+    do_initiate_transact(transaction_type, current_version);
+    reset_selection_caches();
+}
+
+inline Replication::version_type Replication::prepare_commit(version_type orig_version)
+{
+    return do_prepare_commit(orig_version);
+}
+
+inline void Replication::finalize_commit() noexcept
+{
+    do_finalize_commit();
+}
+
+inline void Replication::abort_transact() noexcept
+{
+    do_abort_transact();
+}
+
+inline void Replication::interrupt() noexcept
+{
+    do_interrupt();
+}
+
+inline void Replication::clear_interrupt() noexcept
+{
+    do_clear_interrupt();
+}
+
+inline bool Replication::is_sync_agent() const noexcept
+{
+    return false;
+}
+
+inline TrivialReplication::TrivialReplication(const std::string& database_file)
+    : m_database_file(database_file)
+{
+}
+
+inline BinaryData TrivialReplication::get_uncommitted_changes() const noexcept
+{
+    const char* data = m_transact_log_buffer.data();
+    size_t size = write_position() - data;
+    return BinaryData(data, size);
+}
+
+inline size_t TrivialReplication::transact_log_size()
+{
+    return write_position() - m_transact_log_buffer.data();
+}
+
+inline void TrivialReplication::transact_log_reserve(size_t n, char** new_begin, char** new_end)
+{
+    internal_transact_log_reserve(n, new_begin, new_end);
+}
+
+inline void TrivialReplication::internal_transact_log_reserve(size_t n, char** new_begin, char** new_end)
+{
+    char* data = m_transact_log_buffer.data();
+    size_t size = write_position() - data;
+    m_transact_log_buffer.reserve_extra(size, n);
+    data = m_transact_log_buffer.data(); // May have changed
+    *new_begin = data + size;
+    *new_end = data + m_transact_log_buffer.size();
+}
+
+} // namespace realm
+
+#endif // REALM_REPLICATION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/row.hpp b/node_modules/realm/vendor/realm-ios/include/realm/row.hpp
new file mode 100644
index 0000000..66b7c58
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/row.hpp
@@ -0,0 +1,862 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_ROW_HPP
+#define REALM_ROW_HPP
+
+#include <cstdint>
+
+#include <realm/util/type_traits.hpp>
+#include <realm/mixed.hpp>
+#include <realm/table_ref.hpp>
+#include <realm/link_view_fwd.hpp>
+#include <realm/handover_defs.hpp>
+
+namespace realm {
+
+template <class>
+class BasicRow;
+
+
+/// This class is a "mixin" and contains the common set of functions for several
+/// distinct row-like classes.
+///
+/// There is a direct and natural correspondance between the functions in this
+/// class and functions in Table of the same name. For example:
+///
+///     table[i].get_int(j) == table.get_int(i,j)
+///
+/// The effect of calling most of the row accessor functions on a detached
+/// accessor is unspecified and may lead to general corruption, and/or a
+/// crash. The exceptions are is_attached(), detach(), get_table(), get_index(),
+/// and the destructor. Note however, that get_index() will still return an
+/// unspecified value for a deatched accessor.
+///
+/// When a row accessor is evaluated in a boolean context, it evaluates to true
+/// if, and only if it is attached.
+///
+/// \tparam T A const or non-const table type (currently either `Table` or
+/// `const Table`).
+///
+/// \tparam R A specific row accessor class (BasicRow or BasicRowExpr) providing
+/// members `T* impl_get_table() const`, `size_t impl_get_row_ndx()
+/// const`, and `void impl_detach()`. Neither are allowed to throw.
+///
+/// \sa Table
+/// \sa BasicRow
+template <class T, class R>
+class RowFuncs {
+public:
+    typedef T table_type;
+
+    typedef BasicTableRef<const T> ConstTableRef;
+    typedef BasicTableRef<T> TableRef; // Same as ConstTableRef if `T` is 'const'
+
+    typedef typename util::CopyConst<T, LinkView>::type L;
+    using ConstLinkViewRef = std::shared_ptr<const L>;
+    using LinkViewRef = std::shared_ptr<L>; // Same as ConstLinkViewRef if `T` is 'const'
+
+    int_fast64_t get_int(size_t col_ndx) const noexcept;
+    bool get_bool(size_t col_ndx) const noexcept;
+    float get_float(size_t col_ndx) const noexcept;
+    double get_double(size_t col_ndx) const noexcept;
+    StringData get_string(size_t col_ndx) const noexcept;
+    BinaryData get_binary(size_t col_ndx) const noexcept;
+    OldDateTime get_olddatetime(size_t col_ndx) const noexcept;
+    Timestamp get_timestamp(size_t col_ndx) const noexcept;
+    ConstTableRef get_subtable(size_t col_ndx) const;
+    TableRef get_subtable(size_t col_ndx);
+    size_t get_subtable_size(size_t col_ndx) const noexcept;
+    size_t get_link(size_t col_ndx) const noexcept;
+    bool is_null_link(size_t col_ndx) const noexcept;
+    bool is_null(size_t col_ndx) const noexcept;
+    ConstLinkViewRef get_linklist(size_t col_ndx) const;
+    LinkViewRef get_linklist(size_t col_ndx);
+    bool linklist_is_empty(size_t col_ndx) const noexcept;
+    size_t get_link_count(size_t col_ndx) const noexcept;
+    Mixed get_mixed(size_t col_ndx) const noexcept;
+    DataType get_mixed_type(size_t col_ndx) const noexcept;
+
+    template <typename U>
+    U get(size_t col_ndx) const noexcept;
+
+    void set_int(size_t col_ndx, int_fast64_t value);
+    void set_int_unique(size_t col_ndx, int_fast64_t value);
+    void add_int(size_t col_ndx, int_fast64_t value);
+    void set_bool(size_t col_ndx, bool value);
+    void set_float(size_t col_ndx, float value);
+    void set_double(size_t col_ndx, double value);
+    void set_string(size_t col_ndx, StringData value);
+    void set_string_unique(size_t col_ndx, StringData value);
+    void set_binary(size_t col_ndx, BinaryData value);
+    void set_olddatetime(size_t col_ndx, OldDateTime value);
+    void set_timestamp(size_t col_ndx, Timestamp value);
+    void set_subtable(size_t col_ndx, const Table* value);
+    void set_link(size_t col_ndx, size_t value);
+    void nullify_link(size_t col_ndx);
+    void set_mixed(size_t col_ndx, Mixed value);
+    void set_mixed_subtable(size_t col_ndx, const Table* value);
+    void set_null(size_t col_ndx);
+    void set_null_unique(size_t col_ndx);
+
+    template <typename U>
+    void set(size_t col_ndx, U&& value, bool is_default = false);
+
+    template <typename U>
+    void set_unique(size_t col_ndx, U&& value);
+
+    void insert_substring(size_t col_ndx, size_t pos, StringData);
+    void remove_substring(size_t col_ndx, size_t pos, size_t size);
+
+    //@{
+    /// Note that these operations will cause the row accessor to be detached.
+    void remove();
+    void move_last_over();
+    //@}
+
+    size_t get_backlink_count() const noexcept;
+    size_t get_backlink_count(const Table& src_table, size_t src_col_ndx) const noexcept;
+    size_t get_backlink(const Table& src_table, size_t src_col_ndx, size_t backlink_ndx) const noexcept;
+
+    size_t get_column_count() const noexcept;
+    DataType get_column_type(size_t col_ndx) const noexcept;
+    StringData get_column_name(size_t col_ndx) const noexcept;
+    size_t get_column_index(StringData name) const noexcept;
+
+    /// Returns true if, and only if this accessor is currently attached to a
+    /// row.
+    ///
+    /// A row accesor may get detached from the underlying row for various
+    /// reasons (see below). When it does, it no longer refers to anything, and
+    /// can no longer be used, except for calling is_attached(), detach(),
+    /// get_table(), get_index(), and the destructor. The consequences of
+    /// calling other methods on a detached row accessor are unspecified. There
+    /// are a few Realm functions (Table::find_pkey_int()) that return a
+    /// detached row accessor to indicate a 'null' result. In all other cases,
+    /// however, row accessors obtained by calling functions in the Realm API
+    /// are always in the 'attached' state immediately upon return from those
+    /// functions.
+    ///
+    /// A row accessor becomes detached if the underlying row is removed, if the
+    /// associated table accessor becomes detached, or if the detach() method is
+    /// called. A row accessor does not become detached for any other reason.
+    bool is_attached() const noexcept;
+
+    /// Detach this accessor from the row it was attached to. This function has
+    /// no effect if the accessor was already detached (idempotency).
+    void detach() noexcept;
+
+    /// The table containing the row to which this accessor is currently
+    /// bound. For a detached accessor, the returned value is null.
+    const table_type* get_table() const noexcept;
+    table_type* get_table() noexcept;
+
+    /// The index of the row to which this accessor is currently bound. For a
+    /// detached accessor, the returned value is unspecified.
+    size_t get_index() const noexcept;
+
+    explicit operator bool() const noexcept;
+
+private:
+    const T* table() const noexcept;
+    T* table() noexcept;
+    size_t row_ndx() const noexcept;
+};
+
+
+/// This class is a special kind of row accessor. It differes from a real row
+/// accessor (BasicRow) by having a trivial and fast copy constructor and
+/// descructor. It is supposed to be used as the return type of functions such
+/// as Table::operator[](), and then to be used as a basis for constructing a
+/// real row accessor. Objects of this class are intended to only ever exist as
+/// temporaries.
+///
+/// In contrast to a real row accessor (`BasicRow`), objects of this class do
+/// not keep the parent table "alive", nor are they maintained (adjusted) across
+/// row insertions and row removals like real row accessors are.
+///
+/// \sa BasicRow
+template <class T>
+class BasicRowExpr : public RowFuncs<T, BasicRowExpr<T>> {
+public:
+    BasicRowExpr() noexcept = default;
+
+    template <class U>
+    BasicRowExpr(const BasicRowExpr<U>&) noexcept;
+
+    template <class U>
+    BasicRowExpr(const BasicRow<U>&) noexcept;
+
+private:
+    T* m_table = nullptr;       // nullptr if detached.
+    size_t m_row_ndx = 0; // Undefined if detached.
+
+    BasicRowExpr(T*, size_t init_row_ndx) noexcept;
+
+    T* impl_get_table() const noexcept;
+    size_t impl_get_row_ndx() const noexcept;
+    void impl_detach() noexcept;
+
+    // Make impl_get_table(), impl_get_row_ndx(), and impl_detach() accessible
+    // from RowFuncs.
+    friend class RowFuncs<T, BasicRowExpr<T>>;
+
+    // Make m_table and m_row_ndx accessible from BasicRowExpr(const
+    // BasicRowExpr<U>&) for any U.
+    template <class>
+    friend class BasicRowExpr;
+
+    // Make m_table and m_row_ndx accessible from
+    // BasicRow::BaicRow(BasicRowExpr<U>) for any U.
+    template <class>
+    friend class BasicRow;
+
+    // Make BasicRowExpr(T*, size_t) accessible from Table.
+    friend class Table;
+};
+
+// fwd decl
+class Group;
+
+class RowBase {
+protected:
+    TableRef m_table; // nullptr if detached.
+    size_t m_row_ndx = -1; // Undefined if detached.
+
+    void attach(Table*, size_t row_ndx) noexcept;
+    void reattach(Table*, size_t row_ndx) noexcept;
+    void impl_detach() noexcept;
+
+    RowBase()
+    {
+    }
+
+    RowBase(const RowBase&) = delete;
+    using HandoverPatch = RowBaseHandoverPatch;
+
+    RowBase(const RowBase& source, HandoverPatch& patch);
+
+public:
+    static void generate_patch(const RowBase& source, HandoverPatch& patch);
+    void apply_patch(HandoverPatch& patch, Group& group);
+
+private:
+    RowBase* m_prev = nullptr; // nullptr if first, undefined if detached.
+    RowBase* m_next = nullptr; // nullptr if last, undefined if detached.
+
+    // Table needs to be able to modify m_table and m_row_ndx.
+    friend class Table;
+};
+
+
+/// An accessor class for table rows (a.k.a. a "row accessor").
+///
+/// For as long as it remains attached, a row accessor will keep the parent
+/// table accessor alive. In case the lifetime of the parent table is not
+/// managed by reference counting (such as when the table is an automatic
+/// variable on the stack), the destruction of the table will cause all
+/// remaining row accessors to be detached.
+///
+/// While attached, a row accessor is bound to a particular row of the parent
+/// table. If that row is removed, the accesssor becomes detached. If rows are
+/// inserted or removed before it (at lower row index), then the accessor is
+/// automatically adjusted to account for the change in index of the row to
+/// which the accessor is bound. In other words, a row accessor is bound to the
+/// contents of a row, not to a row index. See also is_attached().
+///
+/// Row accessors are created and used as follows:
+///
+///     Row row       = table[7];  // 8th row of `table`
+///     ConstRow crow = ctable[2]; // 3rd row of const `ctable`
+///     Row first_row = table.front();
+///     Row last_row  = table.back();
+///
+///     float v = row.get_float(1); // Get the float in the 2nd column
+///     row.set_string(0, "foo");   // Update the string in the 1st column
+///
+///     Table* t = row.get_table();      // The parent table
+///     size_t i = row.get_index(); // The current row index
+///
+/// \sa RowFuncs
+template <class T>
+class BasicRow : private RowBase, public RowFuncs<T, BasicRow<T>> {
+public:
+    BasicRow() noexcept;
+
+    template <class U>
+    BasicRow(BasicRowExpr<U>) noexcept;
+
+    BasicRow(const BasicRow<T>&) noexcept;
+
+    template <class U>
+    BasicRow(const BasicRow<U>&) noexcept;
+
+    template <class U>
+    BasicRow& operator=(BasicRowExpr<U>) noexcept;
+
+    template <class U>
+    BasicRow& operator=(BasicRow<U>) noexcept;
+
+    BasicRow& operator=(const BasicRow<T>&) noexcept;
+
+    ~BasicRow() noexcept;
+
+private:
+    T* impl_get_table() const noexcept;
+    size_t impl_get_row_ndx() const noexcept;
+
+    // Make impl_get_table(), impl_get_row_ndx(), and impl_detach() accessible
+    // from RowFuncs.
+    friend class RowFuncs<T, BasicRow<T>>;
+
+    // Make m_table and m_row_ndx accessible from BasicRow(const BasicRow<U>&)
+    // for any U.
+    template <class>
+    friend class BasicRow;
+
+    // Make m_table and m_row_ndx accessible from BasicRowExpr(const
+    // BasicRow<U>&) for any U.
+    template <class>
+    friend class BasicRowExpr;
+
+public:
+    std::unique_ptr<BasicRow<T>> clone_for_handover(std::unique_ptr<HandoverPatch>& patch) const
+    {
+        patch.reset(new HandoverPatch);
+        std::unique_ptr<BasicRow<T>> retval(new BasicRow<T>(*this, *patch));
+        return retval;
+    }
+
+    static void generate_patch(const BasicRow& row, std::unique_ptr<HandoverPatch>& patch)
+    {
+        patch.reset(new HandoverPatch);
+        RowBase::generate_patch(row, *patch);
+    }
+
+    void apply_and_consume_patch(std::unique_ptr<HandoverPatch>& patch, Group& group)
+    {
+        apply_patch(*patch, group);
+        patch.reset();
+    }
+
+    void apply_patch(HandoverPatch& patch, Group& group)
+    {
+        RowBase::apply_patch(patch, group);
+    }
+
+private:
+    BasicRow(const BasicRow<T>& source, HandoverPatch& patch)
+        : RowBase(source, patch)
+    {
+    }
+    friend class SharedGroup;
+};
+
+typedef BasicRow<Table> Row;
+typedef BasicRow<const Table> ConstRow;
+
+
+// Implementation
+
+template <class T, class R>
+inline int_fast64_t RowFuncs<T, R>::get_int(size_t col_ndx) const noexcept
+{
+    return table()->get_int(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline bool RowFuncs<T, R>::get_bool(size_t col_ndx) const noexcept
+{
+    return table()->get_bool(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline float RowFuncs<T, R>::get_float(size_t col_ndx) const noexcept
+{
+    return table()->get_float(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline double RowFuncs<T, R>::get_double(size_t col_ndx) const noexcept
+{
+    return table()->get_double(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline StringData RowFuncs<T, R>::get_string(size_t col_ndx) const noexcept
+{
+    return table()->get_string(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline BinaryData RowFuncs<T, R>::get_binary(size_t col_ndx) const noexcept
+{
+    return table()->get_binary(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline OldDateTime RowFuncs<T, R>::get_olddatetime(size_t col_ndx) const noexcept
+{
+    return table()->get_olddatetime(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline Timestamp RowFuncs<T, R>::get_timestamp(size_t col_ndx) const noexcept
+{
+    return table()->get_timestamp(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline typename RowFuncs<T, R>::ConstTableRef RowFuncs<T, R>::get_subtable(size_t col_ndx) const
+{
+    return table()->get_subtable(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline typename RowFuncs<T, R>::TableRef RowFuncs<T, R>::get_subtable(size_t col_ndx)
+{
+    return table()->get_subtable(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_subtable_size(size_t col_ndx) const noexcept
+{
+    return table()->get_subtable_size(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_link(size_t col_ndx) const noexcept
+{
+    return table()->get_link(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline bool RowFuncs<T, R>::is_null_link(size_t col_ndx) const noexcept
+{
+    return table()->is_null_link(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline bool RowFuncs<T, R>::is_null(size_t col_ndx) const noexcept
+{
+    return table()->is_null(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline typename RowFuncs<T, R>::ConstLinkViewRef RowFuncs<T, R>::get_linklist(size_t col_ndx) const
+{
+    return table()->get_linklist(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline typename RowFuncs<T, R>::LinkViewRef RowFuncs<T, R>::get_linklist(size_t col_ndx)
+{
+    return table()->get_linklist(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline bool RowFuncs<T, R>::linklist_is_empty(size_t col_ndx) const noexcept
+{
+    return table()->linklist_is_empty(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_link_count(size_t col_ndx) const noexcept
+{
+    return table()->get_link_count(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline Mixed RowFuncs<T, R>::get_mixed(size_t col_ndx) const noexcept
+{
+    return table()->get_mixed(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline DataType RowFuncs<T, R>::get_mixed_type(size_t col_ndx) const noexcept
+{
+    return table()->get_mixed_type(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+template <class U>
+inline U RowFuncs<T, R>::get(size_t col_ndx) const noexcept
+{
+    return table()->template get<U>(col_ndx, row_ndx());
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_int(size_t col_ndx, int_fast64_t value)
+{
+    table()->set_int(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_int_unique(size_t col_ndx, int_fast64_t value)
+{
+    table()->set_int_unique(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::add_int(size_t col_ndx, int_fast64_t value)
+{
+    table()->add_int(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_bool(size_t col_ndx, bool value)
+{
+    table()->set_bool(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_float(size_t col_ndx, float value)
+{
+    table()->set_float(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_double(size_t col_ndx, double value)
+{
+    table()->set_double(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_string(size_t col_ndx, StringData value)
+{
+    table()->set_string(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_string_unique(size_t col_ndx, StringData value)
+{
+    table()->set_string_unique(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_binary(size_t col_ndx, BinaryData value)
+{
+    table()->set_binary(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_olddatetime(size_t col_ndx, OldDateTime value)
+{
+    table()->set_olddatetime(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_timestamp(size_t col_ndx, Timestamp value)
+{
+    table()->set_timestamp(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_subtable(size_t col_ndx, const Table* value)
+{
+    table()->set_subtable(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_link(size_t col_ndx, size_t value)
+{
+    table()->set_link(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::nullify_link(size_t col_ndx)
+{
+    table()->nullify_link(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_mixed(size_t col_ndx, Mixed value)
+{
+    table()->set_mixed(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_mixed_subtable(size_t col_ndx, const Table* value)
+{
+    table()->set_mixed_subtable(col_ndx, row_ndx(), value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_null(size_t col_ndx)
+{
+    table()->set_null(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::set_null_unique(size_t col_ndx)
+{
+    table()->set_null_unique(col_ndx, row_ndx()); // Throws
+}
+
+template <class T, class R>
+template <class U>
+inline void RowFuncs<T, R>::set(size_t col_ndx, U&& value, bool is_default)
+{
+    table()->set(col_ndx, row_ndx(), std::forward<U>(value), is_default); // Throws
+}
+
+template <class T, class R>
+template <class U>
+inline void RowFuncs<T, R>::set_unique(size_t col_ndx, U&& value)
+{
+    table()->set_unique(col_ndx, row_ndx(), std::forward<U>(value)); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::insert_substring(size_t col_ndx, size_t pos, StringData value)
+{
+    table()->insert_substring(col_ndx, row_ndx(), pos, value); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::remove_substring(size_t col_ndx, size_t pos, size_t size)
+{
+    table()->remove_substring(col_ndx, row_ndx(), pos, size); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::remove()
+{
+    table()->remove(row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::move_last_over()
+{
+    table()->move_last_over(row_ndx()); // Throws
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_backlink_count() const noexcept
+{
+    return table()->get_backlink_count(row_ndx());
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_backlink_count(const Table& src_table, size_t src_col_ndx) const noexcept
+{
+    return table()->get_backlink_count(row_ndx(), src_table, src_col_ndx);
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_backlink(const Table& src_table, size_t src_col_ndx, size_t backlink_ndx) const
+    noexcept
+{
+    return table()->get_backlink(row_ndx(), src_table, src_col_ndx, backlink_ndx);
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_column_count() const noexcept
+{
+    return table()->get_column_count();
+}
+
+template <class T, class R>
+inline DataType RowFuncs<T, R>::get_column_type(size_t col_ndx) const noexcept
+{
+    return table()->get_column_type(col_ndx);
+}
+
+template <class T, class R>
+inline StringData RowFuncs<T, R>::get_column_name(size_t col_ndx) const noexcept
+{
+    return table()->get_column_name(col_ndx);
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_column_index(StringData name) const noexcept
+{
+    return table()->get_column_index(name);
+}
+
+template <class T, class R>
+inline bool RowFuncs<T, R>::is_attached() const noexcept
+{
+    return static_cast<const R*>(this)->impl_get_table();
+}
+
+template <class T, class R>
+inline void RowFuncs<T, R>::detach() noexcept
+{
+    static_cast<R*>(this)->impl_detach();
+}
+
+template <class T, class R>
+inline const T* RowFuncs<T, R>::get_table() const noexcept
+{
+    return table();
+}
+
+template <class T, class R>
+inline T* RowFuncs<T, R>::get_table() noexcept
+{
+    return table();
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::get_index() const noexcept
+{
+    return row_ndx();
+}
+
+template <class T, class R>
+inline RowFuncs<T, R>::operator bool() const noexcept
+{
+    return is_attached();
+}
+
+template <class T, class R>
+inline const T* RowFuncs<T, R>::table() const noexcept
+{
+    return static_cast<const R*>(this)->impl_get_table();
+}
+
+template <class T, class R>
+inline T* RowFuncs<T, R>::table() noexcept
+{
+    return static_cast<R*>(this)->impl_get_table();
+}
+
+template <class T, class R>
+inline size_t RowFuncs<T, R>::row_ndx() const noexcept
+{
+    return static_cast<const R*>(this)->impl_get_row_ndx();
+}
+
+
+template <class T>
+template <class U>
+inline BasicRowExpr<T>::BasicRowExpr(const BasicRowExpr<U>& expr) noexcept
+    : m_table(expr.m_table)
+    , m_row_ndx(expr.m_row_ndx)
+{
+}
+
+template <class T>
+template <class U>
+inline BasicRowExpr<T>::BasicRowExpr(const BasicRow<U>& row) noexcept
+    : m_table(row.m_table.get())
+    , m_row_ndx(row.m_row_ndx)
+{
+}
+
+template <class T>
+inline BasicRowExpr<T>::BasicRowExpr(T* init_table, size_t init_row_ndx) noexcept
+    : m_table(init_table)
+    , m_row_ndx(init_row_ndx)
+{
+}
+
+template <class T>
+inline T* BasicRowExpr<T>::impl_get_table() const noexcept
+{
+    return m_table;
+}
+
+template <class T>
+inline size_t BasicRowExpr<T>::impl_get_row_ndx() const noexcept
+{
+    return m_row_ndx;
+}
+
+template <class T>
+inline void BasicRowExpr<T>::impl_detach() noexcept
+{
+    m_table = nullptr;
+}
+
+
+template <class T>
+inline BasicRow<T>::BasicRow() noexcept
+{
+}
+
+template <class T>
+inline BasicRow<T>::BasicRow(const BasicRow<T>& row) noexcept
+    : RowBase()
+{
+    attach(const_cast<Table*>(row.m_table.get()), row.m_row_ndx);
+}
+
+template <class T>
+template <class U>
+inline BasicRow<T>::BasicRow(BasicRowExpr<U> expr) noexcept
+{
+    T* expr_table = expr.m_table; // Check that pointer types are compatible
+    attach(const_cast<Table*>(expr_table), expr.m_row_ndx);
+}
+
+template <class T>
+template <class U>
+inline BasicRow<T>::BasicRow(const BasicRow<U>& row) noexcept
+{
+    T* row_table = row.m_table.get(); // Check that pointer types are compatible
+    attach(const_cast<Table*>(row_table), row.m_row_ndx);
+}
+
+template <class T>
+template <class U>
+inline BasicRow<T>& BasicRow<T>::operator=(BasicRowExpr<U> expr) noexcept
+{
+    T* expr_table = expr.m_table; // Check that pointer types are compatible
+    reattach(const_cast<Table*>(expr_table), expr.m_row_ndx);
+    return *this;
+}
+
+template <class T>
+template <class U>
+inline BasicRow<T>& BasicRow<T>::operator=(BasicRow<U> row) noexcept
+{
+    T* row_table = row.m_table.get(); // Check that pointer types are compatible
+    reattach(const_cast<Table*>(row_table), row.m_row_ndx);
+    return *this;
+}
+
+template <class T>
+inline BasicRow<T>& BasicRow<T>::operator=(const BasicRow<T>& row) noexcept
+{
+    reattach(const_cast<Table*>(row.m_table.get()), row.m_row_ndx);
+    return *this;
+}
+
+template <class T>
+inline BasicRow<T>::~BasicRow() noexcept
+{
+    RowBase::impl_detach();
+}
+
+template <class T>
+inline T* BasicRow<T>::impl_get_table() const noexcept
+{
+    return m_table.get();
+}
+
+template <class T>
+inline size_t BasicRow<T>::impl_get_row_ndx() const noexcept
+{
+    return m_row_ndx;
+}
+
+} // namespace realm
+
+#endif // REALM_ROW_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/spec.hpp b/node_modules/realm/vendor/realm-ios/include/realm/spec.hpp
new file mode 100644
index 0000000..6b793f0
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/spec.hpp
@@ -0,0 +1,388 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SPEC_HPP
+#define REALM_SPEC_HPP
+
+#include <realm/util/features.h>
+#include <realm/array.hpp>
+#include <realm/array_string.hpp>
+#include <realm/array_integer.hpp>
+#include <realm/data_type.hpp>
+#include <realm/column_type.hpp>
+
+namespace realm {
+
+class Table;
+
+class Spec {
+public:
+    ~Spec() noexcept;
+
+    Allocator& get_alloc() const noexcept;
+
+    bool has_strong_link_columns() noexcept;
+
+    void insert_column(size_t column_ndx, ColumnType type, StringData name, ColumnAttr attr = col_attr_None);
+    void rename_column(size_t column_ndx, StringData new_name);
+
+    /// Erase the column at the specified index, and move columns at
+    /// succeeding indexes to the next lower index.
+    ///
+    /// This function is guaranteed to *never* throw if the spec is
+    /// used in a non-transactional context, or if the spec has
+    /// already been successfully modified within the current write
+    /// transaction.
+    void erase_column(size_t column_ndx);
+
+    //@{
+    // If a new Spec is constructed from the returned subspec
+    // reference, it is the responsibility of the application that the
+    // parent Spec object (this) is kept alive for at least as long as
+    // the new Spec object.
+    Spec* get_subtable_spec(size_t column_ndx) noexcept;
+    //@}
+
+    // Column info
+    size_t get_column_count() const noexcept;
+    size_t get_public_column_count() const noexcept;
+    DataType get_public_column_type(size_t column_ndx) const noexcept;
+    ColumnType get_column_type(size_t column_ndx) const noexcept;
+    StringData get_column_name(size_t column_ndx) const noexcept;
+
+    /// Returns size_t(-1) if the specified column is not found.
+    size_t get_column_index(StringData name) const noexcept;
+
+    // Column Attributes
+    ColumnAttr get_column_attr(size_t column_ndx) const noexcept;
+
+    size_t get_subspec_ndx(size_t column_ndx) const noexcept;
+    ref_type get_subspec_ref(size_t subspec_ndx) const noexcept;
+    Spec* get_subspec_by_ndx(size_t subspec_ndx) noexcept;
+    const Spec* get_subspec_by_ndx(size_t subspec_ndx) const noexcept;
+
+    // Auto Enumerated string columns
+    void upgrade_string_to_enum(size_t column_ndx, ref_type keys_ref, ArrayParent*& keys_parent, size_t& keys_ndx);
+    size_t get_enumkeys_ndx(size_t column_ndx) const noexcept;
+    ref_type get_enumkeys_ref(size_t column_ndx, ArrayParent** keys_parent = nullptr,
+                              size_t* keys_ndx = nullptr) noexcept;
+
+    // Links
+    size_t get_opposite_link_table_ndx(size_t column_ndx) const noexcept;
+    void set_opposite_link_table_ndx(size_t column_ndx, size_t table_ndx);
+
+    // Backlinks
+    bool has_backlinks() const noexcept;
+    size_t first_backlink_column_index() const noexcept;
+    size_t backlink_column_count() const noexcept;
+    void set_backlink_origin_column(size_t backlink_col_ndx, size_t origin_col_ndx);
+    size_t get_origin_column_ndx(size_t backlink_col_ndx) const noexcept;
+    size_t find_backlink_column(size_t origin_table_ndx, size_t origin_col_ndx) const noexcept;
+
+    /// Get position in `Table::m_columns` of the specified column. It may be
+    /// different from the specified logical column index due to the presence of
+    /// search indexes, since their top refs are stored in Table::m_columns as
+    /// well.
+    size_t get_column_ndx_in_parent(size_t column_ndx) const;
+
+    //@{
+    /// Compare two table specs for equality.
+    bool operator==(const Spec&) const noexcept;
+    bool operator!=(const Spec&) const noexcept;
+    //@}
+
+    void detach() noexcept;
+    void destroy() noexcept;
+
+    size_t get_ndx_in_parent() const noexcept;
+    void set_ndx_in_parent(size_t) noexcept;
+
+#ifdef REALM_DEBUG
+    void verify() const;
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+#endif
+
+private:
+    // Underlying array structure.
+    //
+    // `m_subspecs` contains one entry for each subtable column, one entry for
+    // each link or link list columns, two entries for each backlink column, and
+    // zero entries for all other column types. For subtable columns the entry
+    // is a ref pointing to the subtable spec, for link and link list columns it
+    // is the group-level table index of the target table, and for backlink
+    // columns the first entry is the group-level table index of the origin
+    // table, and the second entry is the index of the origin column in the
+    // origin table.
+    Array m_top;
+    ArrayInteger m_types; // 1st slot in m_top
+    ArrayString m_names;  // 2nd slot in m_top
+    ArrayInteger m_attr;  // 3rd slot in m_top
+    Array m_subspecs;     // 4th slot in m_top (optional)
+    Array m_enumkeys;     // 5th slot in m_top (optional)
+    struct SubspecPtr {
+        SubspecPtr(bool is_spec_ptr = false)
+            : m_is_spec_ptr(is_spec_ptr)
+        {
+        }
+        std::unique_ptr<Spec> m_spec;
+        bool m_is_spec_ptr;
+    };
+    using SubspecPtrs = std::vector<SubspecPtr>;
+    SubspecPtrs m_subspec_ptrs;
+    bool m_has_strong_link_columns;
+
+    Spec(Allocator&) noexcept; // Unattached
+
+    bool init(ref_type) noexcept;
+    void init(MemRef) noexcept;
+    void update_has_strong_link_columns() noexcept;
+    void reset_subspec_ptrs();
+    void adj_subspec_ptrs();
+
+    // Returns true in case the ref has changed.
+    bool init_from_parent() noexcept;
+
+    ref_type get_ref() const noexcept;
+
+    /// Called in the context of Group::commit() to ensure that
+    /// attached table accessors stay valid across a commit. Please
+    /// note that this works only for non-transactional commits. Table
+    /// accessors obtained during a transaction are always detached
+    /// when the transaction ends.
+    bool update_from_parent(size_t old_baseline) noexcept;
+
+    void set_parent(ArrayParent*, size_t ndx_in_parent) noexcept;
+
+    void set_column_type(size_t column_ndx, ColumnType type);
+    void set_column_attr(size_t column_ndx, ColumnAttr attr);
+
+    /// Construct an empty spec and return just the reference to the
+    /// underlying memory.
+    static MemRef create_empty_spec(Allocator&);
+
+    struct ColumnInfo {
+        size_t m_column_ref_ndx = 0; ///< Index within Table::m_columns
+        bool m_has_search_index = false;
+    };
+
+    ColumnInfo get_column_info(size_t column_ndx) const noexcept;
+
+    size_t get_subspec_ndx_after(size_t column_ndx, size_t skip_column_ndx) const noexcept;
+    size_t get_subspec_entries_for_col_type(ColumnType type) const noexcept;
+    bool has_subspec() const noexcept;
+
+    // Returns false if the spec has no columns, otherwise it returns
+    // true and sets `type` to the type of the first column.
+    static bool get_first_column_type_from_ref(ref_type, Allocator&, ColumnType& type) noexcept;
+
+    friend class Replication;
+    friend class Group;
+    friend class Table;
+};
+
+// Implementation:
+
+inline Allocator& Spec::get_alloc() const noexcept
+{
+    return m_top.get_alloc();
+}
+
+inline bool Spec::has_strong_link_columns() noexcept
+{
+    return m_has_strong_link_columns;
+}
+
+inline ref_type Spec::get_subspec_ref(size_t subspec_ndx) const noexcept
+{
+    REALM_ASSERT(subspec_ndx < m_subspecs.size());
+
+    // Note that this addresses subspecs directly, indexing
+    // by number of sub-table columns
+    return m_subspecs.get_as_ref(subspec_ndx);
+}
+
+// Uninitialized Spec (call init() to init)
+inline Spec::Spec(Allocator& alloc) noexcept
+    : m_top(alloc)
+    , m_types(alloc)
+    , m_names(alloc)
+    , m_attr(alloc)
+    , m_subspecs(alloc)
+    , m_enumkeys(alloc)
+{
+}
+
+inline Spec* Spec::get_subtable_spec(size_t column_ndx) noexcept
+{
+    REALM_ASSERT(column_ndx < get_column_count());
+    REALM_ASSERT(get_column_type(column_ndx) == col_type_Table);
+    size_t subspec_ndx = get_subspec_ndx(column_ndx);
+    return get_subspec_by_ndx(subspec_ndx);
+}
+
+inline const Spec* Spec::get_subspec_by_ndx(size_t subspec_ndx) const noexcept
+{
+    return const_cast<Spec*>(this)->get_subspec_by_ndx(subspec_ndx);
+}
+
+inline bool Spec::init_from_parent() noexcept
+{
+    ref_type ref = m_top.get_ref_from_parent();
+    return init(ref);
+}
+
+inline void Spec::destroy() noexcept
+{
+    m_top.destroy_deep();
+}
+
+inline size_t Spec::get_ndx_in_parent() const noexcept
+{
+    return m_top.get_ndx_in_parent();
+}
+
+inline void Spec::set_ndx_in_parent(size_t ndx) noexcept
+{
+    m_top.set_ndx_in_parent(ndx);
+}
+
+inline ref_type Spec::get_ref() const noexcept
+{
+    return m_top.get_ref();
+}
+
+inline void Spec::set_parent(ArrayParent* parent, size_t ndx_in_parent) noexcept
+{
+    m_top.set_parent(parent, ndx_in_parent);
+}
+
+inline void Spec::rename_column(size_t column_ndx, StringData new_name)
+{
+    REALM_ASSERT(column_ndx < m_types.size());
+    m_names.set(column_ndx, new_name);
+}
+
+inline size_t Spec::get_column_count() const noexcept
+{
+    // This is the total count of columns, including backlinks (not public)
+    return m_types.size();
+}
+
+inline size_t Spec::get_public_column_count() const noexcept
+{
+    // Backlinks are the last columns, and do not have names, so getting
+    // the number of names gives us the count of user facing columns
+    return m_names.size();
+}
+
+inline ColumnType Spec::get_column_type(size_t ndx) const noexcept
+{
+    REALM_ASSERT(ndx < get_column_count());
+    return ColumnType(m_types.get(ndx));
+}
+
+inline void Spec::set_column_type(size_t column_ndx, ColumnType type)
+{
+    REALM_ASSERT(column_ndx < get_column_count());
+
+    // At this point we only support upgrading to string enum
+    REALM_ASSERT(ColumnType(m_types.get(column_ndx)) == col_type_String);
+    REALM_ASSERT(type == col_type_StringEnum);
+
+    m_types.set(column_ndx, type); // Throws
+
+    update_has_strong_link_columns();
+}
+
+inline ColumnAttr Spec::get_column_attr(size_t ndx) const noexcept
+{
+    REALM_ASSERT(ndx < get_column_count());
+    return ColumnAttr(m_attr.get(ndx));
+}
+
+inline void Spec::set_column_attr(size_t column_ndx, ColumnAttr attr)
+{
+    REALM_ASSERT(column_ndx < get_column_count());
+
+    // At this point we only allow one attr at a time
+    // so setting it will overwrite existing. In the future
+    // we will allow combinations.
+    m_attr.set(column_ndx, attr);
+
+    update_has_strong_link_columns();
+}
+
+inline StringData Spec::get_column_name(size_t ndx) const noexcept
+{
+    REALM_ASSERT(ndx < get_column_count());
+    return m_names.get(ndx);
+}
+
+inline size_t Spec::get_column_index(StringData name) const noexcept
+{
+    return m_names.find_first(name);
+}
+
+inline bool Spec::get_first_column_type_from_ref(ref_type top_ref, Allocator& alloc, ColumnType& type) noexcept
+{
+    const char* top_header = alloc.translate(top_ref);
+    ref_type types_ref = to_ref(Array::get(top_header, 0));
+    const char* types_header = alloc.translate(types_ref);
+    if (Array::get_size_from_header(types_header) == 0)
+        return false;
+    type = ColumnType(Array::get(types_header, 0));
+    return true;
+}
+
+inline bool Spec::has_backlinks() const noexcept
+{
+    // backlinks are always last and do not have names.
+    return m_names.size() < m_types.size();
+
+    // Fixme: It's bad design that backlinks are stored and recognized like this. Backlink columns
+    // should be a column type like any other, and we should find another way to hide them away from
+    // the user.
+}
+
+inline size_t Spec::first_backlink_column_index() const noexcept
+{
+    return m_names.size();
+}
+
+inline size_t Spec::backlink_column_count() const noexcept
+{
+    return m_types.size() - m_names.size();
+}
+
+// Spec will have a subspec when it contains a column which is one of:
+// link, linklist, backlink, or subtable. It is possible for m_top.size()
+// to contain an entry for m_subspecs (at index 3) but this reference
+// may be empty if the spec contains enumkeys (at index 4) but no subspec types.
+inline bool Spec::has_subspec() const noexcept
+{
+    return (m_top.size() >= 4) && (m_top.get_as_ref(3) != 0);
+}
+
+inline bool Spec::operator!=(const Spec& s) const noexcept
+{
+    return !(*this == s);
+}
+
+} // namespace realm
+
+#endif // REALM_SPEC_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/string_data.hpp b/node_modules/realm/vendor/realm-ios/include/realm/string_data.hpp
new file mode 100644
index 0000000..0917fc9
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/string_data.hpp
@@ -0,0 +1,410 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_STRING_HPP
+#define REALM_STRING_HPP
+
+#include <realm/null.hpp>
+#include <realm/util/features.h>
+#include <realm/util/optional.hpp>
+
+#include <algorithm>
+#include <array>
+#include <cfloat>
+#include <cmath>
+#include <cstddef>
+#include <cstring>
+#include <ostream>
+#include <string>
+
+namespace realm {
+
+/// Selects CityHash64 on 64-bit platforms, and Murmur2 on 32-bit platforms.
+/// This is what libc++ does, and it is a good general choice for a
+/// non-cryptographic hash function (suitable for std::unordered_map etc.).
+size_t murmur2_or_cityhash(const unsigned char* data, size_t len) noexcept;
+
+uint_least32_t murmur2_32(const unsigned char* data, size_t len) noexcept;
+uint_least64_t cityhash_64(const unsigned char* data, size_t len) noexcept;
+
+
+/// A reference to a chunk of character data.
+///
+/// An instance of this class can be thought of as a type tag on a region of
+/// memory. It does not own the referenced memory, nor does it in any other way
+/// attempt to manage the lifetime of it.
+///
+/// A null character inside the referenced region is considered a part of the
+/// string by Realm.
+///
+/// For compatibility with C-style strings, when a string is stored in a Realm
+/// database, it is always followed by a terminating null character, regardless
+/// of whether the string itself has internal null characters. This means that
+/// when a StringData object is extracted from Realm, the referenced region is
+/// guaranteed to be followed immediately by an extra null character, but that
+/// null character is not inside the referenced region. Therefore, all of the
+/// following forms are guaranteed to return a pointer to a null-terminated
+/// string:
+///
+/// \code{.cpp}
+///
+///   group.get_table_name(...).data()
+///   table.get_column_name().data()
+///   table.get_string(...).data()
+///   table.get_mixed(...).get_string().data()
+///
+/// \endcode
+///
+/// Note that in general, no assumptions can be made about what follows a string
+/// that is referenced by a StringData object, or whether anything follows it at
+/// all. In particular, the receiver of a StringData object cannot assume that
+/// the referenced string is followed by a null character unless there is an
+/// externally provided guarantee.
+///
+/// This class makes it possible to distinguish between a 'null' reference and a
+/// reference to the empty string (see is_null()).
+///
+/// \sa BinaryData
+/// \sa Mixed
+class StringData {
+public:
+    /// Construct a null reference.
+    StringData() noexcept;
+
+    /// If \a external_data is 'null', \a data_size must be zero.
+    StringData(const char* external_data, size_t data_size) noexcept;
+
+    template <class T, class A>
+    StringData(const std::basic_string<char, T, A>&);
+
+    template <class T, class A>
+    operator std::basic_string<char, T, A>() const;
+
+    // StringData does not store data, callers must manage their own strings.
+    template <class T, class A>
+    StringData(const std::basic_string<char, T, A>&&) = delete;
+
+    template <class T, class A>
+    StringData(const util::Optional<std::basic_string<char, T, A>>&);
+
+    StringData(const null&) noexcept;
+
+    /// Initialize from a zero terminated C style string. Pass null to construct
+    /// a null reference.
+    StringData(const char* c_str) noexcept;
+
+    char operator[](size_t i) const noexcept;
+
+    const char* data() const noexcept;
+    size_t size() const noexcept;
+
+    /// Is this a null reference?
+    ///
+    /// An instance of StringData is a null reference when, and only when the
+    /// stored size is zero (size()) and the stored pointer is the null pointer
+    /// (data()).
+    ///
+    /// In the case of the empty string, the stored size is still zero, but the
+    /// stored pointer is **not** the null pointer. It could for example point
+    /// to the empty string literal. Note that the actual value of the pointer
+    /// is immaterial in this case (as long as it is not zero), because when the
+    /// size is zero, it is an error to dereference the pointer.
+    ///
+    /// Conversion of a StringData object to `bool` yields the logical negation
+    /// of the result of calling this function. In other words, a StringData
+    /// object is converted to true if it is not the null reference, otherwise
+    /// it is converted to false.
+    bool is_null() const noexcept;
+
+    friend bool operator==(const StringData&, const StringData&) noexcept;
+    friend bool operator!=(const StringData&, const StringData&) noexcept;
+
+    //@{
+    /// Trivial bytewise lexicographical comparison.
+    friend bool operator<(const StringData&, const StringData&) noexcept;
+    friend bool operator>(const StringData&, const StringData&) noexcept;
+    friend bool operator<=(const StringData&, const StringData&) noexcept;
+    friend bool operator>=(const StringData&, const StringData&) noexcept;
+    //@}
+
+    bool begins_with(StringData) const noexcept;
+    bool ends_with(StringData) const noexcept;
+    bool contains(StringData) const noexcept;
+    bool contains(StringData d, const std::array<uint8_t, 256> &charmap) const noexcept;
+    
+    // Wildcard matching ('?' for single char, '*' for zero or more chars)
+    // case insensitive version in unicode.hpp
+    bool like(StringData) const noexcept;
+
+    //@{
+    /// Undefined behavior if \a n, \a i, or <tt>i+n</tt> is greater than
+    /// size().
+    StringData prefix(size_t n) const noexcept;
+    StringData suffix(size_t n) const noexcept;
+    StringData substr(size_t i, size_t n) const noexcept;
+    StringData substr(size_t i) const noexcept;
+    //@}
+
+    template <class C, class T>
+    friend std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>&, const StringData&);
+
+    explicit operator bool() const noexcept;
+
+    /// If the StringData is NULL, the hash is 0. Otherwise, the function
+    /// `murmur2_or_cityhash()` is called on the data.
+    size_t hash() const noexcept;
+
+private:
+    const char* m_data;
+    size_t m_size;
+
+    static bool matchlike(const StringData& text, const StringData& pattern) noexcept;
+    static bool matchlike_ins(const StringData& text, const StringData& pattern_upper,
+                              const StringData& pattern_lower) noexcept;
+
+    friend bool string_like_ins(StringData, StringData) noexcept;
+    friend bool string_like_ins(StringData, StringData, StringData) noexcept;
+};
+
+
+// Implementation:
+
+inline StringData::StringData() noexcept
+    : m_data(nullptr)
+    , m_size(0)
+{
+}
+
+inline StringData::StringData(const char* external_data, size_t data_size) noexcept
+    : m_data(external_data)
+    , m_size(data_size)
+{
+    REALM_ASSERT_DEBUG(external_data || data_size == 0);
+}
+
+template <class T, class A>
+inline StringData::StringData(const std::basic_string<char, T, A>& s)
+    : m_data(s.data())
+    , m_size(s.size())
+{
+}
+
+template <class T, class A>
+inline StringData::operator std::basic_string<char, T, A>() const
+{
+    return std::basic_string<char, T, A>(m_data, m_size);
+}
+
+template <class T, class A>
+inline StringData::StringData(const util::Optional<std::basic_string<char, T, A>>& s)
+    : m_data(s ? s->data() : nullptr)
+    , m_size(s ? s->size() : 0)
+{
+}
+
+inline StringData::StringData(const null&) noexcept
+    : m_data(nullptr)
+    , m_size(0)
+{
+}
+
+inline StringData::StringData(const char* c_str) noexcept
+    : m_data(c_str)
+    , m_size(0)
+{
+    if (c_str)
+        m_size = std::char_traits<char>::length(c_str);
+}
+
+inline char StringData::operator[](size_t i) const noexcept
+{
+    return m_data[i];
+}
+
+inline const char* StringData::data() const noexcept
+{
+    return m_data;
+}
+
+inline size_t StringData::size() const noexcept
+{
+    return m_size;
+}
+
+inline bool StringData::is_null() const noexcept
+{
+    return !m_data;
+}
+
+inline bool operator==(const StringData& a, const StringData& b) noexcept
+{
+    return a.m_size == b.m_size && a.is_null() == b.is_null() && safe_equal(a.m_data, a.m_data + a.m_size, b.m_data);
+}
+
+inline bool operator!=(const StringData& a, const StringData& b) noexcept
+{
+    return !(a == b);
+}
+
+inline bool operator<(const StringData& a, const StringData& b) noexcept
+{
+    if (a.is_null() && !b.is_null()) {
+        // Null strings are smaller than all other strings, and not
+        // equal to empty strings.
+        return true;
+    }
+    return std::lexicographical_compare(a.m_data, a.m_data + a.m_size, b.m_data, b.m_data + b.m_size);
+}
+
+inline bool operator>(const StringData& a, const StringData& b) noexcept
+{
+    return b < a;
+}
+
+inline bool operator<=(const StringData& a, const StringData& b) noexcept
+{
+    return !(b < a);
+}
+
+inline bool operator>=(const StringData& a, const StringData& b) noexcept
+{
+    return !(a < b);
+}
+
+inline bool StringData::begins_with(StringData d) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+    return d.m_size <= m_size && safe_equal(m_data, m_data + d.m_size, d.m_data);
+}
+
+inline bool StringData::ends_with(StringData d) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+    return d.m_size <= m_size && safe_equal(m_data + m_size - d.m_size, m_data + m_size, d.m_data);
+}
+
+inline bool StringData::contains(StringData d) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+
+    return d.m_size == 0 || std::search(m_data, m_data + m_size, d.m_data, d.m_data + d.m_size) != m_data + m_size;
+}
+
+/// This method takes an array that maps chars to distance that can be moved (and zero for chars not in needle),
+/// allowing the method to apply Boyer-Moore for quick substring search
+/// The map is calculated in the StringNode<Contains> class (so it can be reused across searches)
+inline bool StringData::contains(StringData d, const std::array<uint8_t, 256> &charmap) const noexcept
+{
+    if (is_null() && !d.is_null())
+        return false;
+    
+    size_t needle_size = d.size();
+    if (needle_size == 0)
+        return true;
+    
+    // Prepare vars to avoid lookups in loop
+    size_t last_char_pos = d.size()-1;
+    unsigned char lastChar = d[last_char_pos];
+    
+    // Do Boyer-Moore search
+    size_t p = last_char_pos;
+    while (p < m_size) {
+        unsigned char c = m_data[p]; // Get candidate for last char
+        
+        if (c == lastChar) {
+            StringData candidate = substr(p-needle_size+1, needle_size);
+            if (candidate == d)
+                return true; // text found!
+        }
+        
+        // If we don't have a match, see how far we can move char_pos
+        if (charmap[c] == 0)
+            p += needle_size; // char was not present in search string
+        else
+            p += charmap[c];
+    }
+    
+    return false;
+}
+    
+inline bool StringData::like(StringData d) const noexcept
+{
+    if (is_null() || d.is_null()) {
+        return (is_null() && d.is_null());
+    }
+
+    return matchlike(*this, d);
+}
+
+inline StringData StringData::prefix(size_t n) const noexcept
+{
+    return substr(0, n);
+}
+
+inline StringData StringData::suffix(size_t n) const noexcept
+{
+    return substr(m_size - n);
+}
+
+inline StringData StringData::substr(size_t i, size_t n) const noexcept
+{
+    return StringData(m_data + i, n);
+}
+
+inline StringData StringData::substr(size_t i) const noexcept
+{
+    return substr(i, m_size - i);
+}
+
+template <class C, class T>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, const StringData& d)
+{
+    for (const char* i = d.m_data; i != d.m_data + d.m_size; ++i)
+        out << *i;
+    return out;
+}
+
+inline StringData::operator bool() const noexcept
+{
+    return !is_null();
+}
+
+inline size_t StringData::hash() const noexcept
+{
+    if (is_null())
+        return 0;
+    auto unsigned_data = reinterpret_cast<const unsigned char*>(m_data);
+    return murmur2_or_cityhash(unsigned_data, m_size);
+}
+
+} // namespace realm
+
+namespace std {
+template <>
+struct hash<::realm::StringData> {
+    inline size_t operator()(const ::realm::StringData& str) const noexcept
+    {
+        return str.hash();
+    }
+};
+} // namespace std
+
+#endif // REALM_STRING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset.hpp
new file mode 100644
index 0000000..7a79240
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset.hpp
@@ -0,0 +1,701 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2017] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_CHANGESET_HPP
+#define REALM_SYNC_CHANGESET_HPP
+
+#include <realm/sync/instructions.hpp>
+#include <realm/util/optional.hpp>
+#include <realm/util/allocation_metrics.hpp>
+#include <realm/util/metered/vector.hpp>
+
+#include <type_traits>
+
+namespace realm {
+namespace sync {
+
+using InternStrings = util::metered::vector<StringBufferRange>;
+
+struct BadChangesetError : ExceptionWithBacktrace<std::exception> {
+    const char* m_message;
+    BadChangesetError() : BadChangesetError("Bad changeset") {}
+    BadChangesetError(const char* msg) : m_message(msg) {}
+    const char* message() const noexcept override
+    {
+        return m_message;
+    }
+};
+
+struct Changeset {
+    struct Range;
+    using timestamp_type = uint_fast64_t;
+    using file_ident_type = uint_fast64_t;
+    using version_type = uint_fast64_t; // FIXME: Get from `History`.
+    using StringBuffer = util::BasicStringBuffer<MeteredAllocator>;
+
+    Changeset();
+    struct share_buffers_tag {};
+    Changeset(const Changeset&, share_buffers_tag);
+    Changeset(Changeset&&) = default;
+    Changeset& operator=(Changeset&&) = default;
+    Changeset(const Changeset&) = delete;
+    Changeset& operator=(const Changeset&) = delete;
+
+    InternString intern_string(StringData); // Slow!
+    InternString find_string(StringData) const noexcept; // Slow!
+    StringData string_data() const noexcept;
+
+    StringBuffer& string_buffer() noexcept;
+    const StringBuffer& string_buffer() const noexcept;
+    const InternStrings& interned_strings() const noexcept;
+    InternStrings& interned_strings() noexcept;
+
+    StringBufferRange get_intern_string(InternString) const noexcept;
+    util::Optional<StringBufferRange> try_get_intern_string(InternString) const noexcept;
+    util::Optional<StringData> try_get_string(StringBufferRange) const noexcept;
+    StringData get_string(StringBufferRange) const noexcept;
+    StringData get_string(InternString) const noexcept;
+    StringBufferRange append_string(StringData);
+
+    /// Mark the changeset as "dirty" (i.e. modified by the merge algorithm).
+    void set_dirty(bool dirty = true) noexcept;
+
+    /// Whether or not the changeset is "dirty" (i.e. has been modified by the
+    /// merge algorithm).
+    bool is_dirty() const noexcept;
+
+    // Interface to imitate std::vector:
+    template <bool is_const> struct IteratorImpl;
+    using iterator = IteratorImpl<false>;
+    using const_iterator = IteratorImpl<true>;
+    using value_type = Instruction;
+    iterator begin() noexcept;
+    iterator end() noexcept;
+    const_iterator begin() const noexcept;
+    const_iterator end() const noexcept;
+    const_iterator cbegin() const noexcept;
+    const_iterator cend() const noexcept;
+    bool empty() const noexcept;
+
+    /// Size of the Changeset, not counting tombstones.
+    ///
+    /// FIXME: This is an O(n) operation.
+    size_t size() const noexcept;
+
+    void clear() noexcept;
+
+    //@{
+    /// Insert instructions, invalidating all iterators.
+    iterator insert(const_iterator pos, Instruction);
+    template <class InputIt>
+    iterator insert(const_iterator pos, InputIt begin, InputIt end);
+    //@}
+
+    /// Erase an instruction, invalidating all iterators.
+    iterator erase(const_iterator);
+
+    /// Insert an instruction at the end, invalidating all iterators.
+    void push_back(const Instruction&);
+
+    //@{
+    /// Insert instructions at \a position without invalidating other
+    /// iterators.
+    ///
+    /// Only iterators created before any call to `insert_stable()` may be
+    /// considered stable across calls to `insert_stable()`. In addition,
+    /// "iterator stability" has a very specific meaning here: Other copies of
+    /// \a position in the program will point to the newly inserted elements
+    /// after calling `insert_stable()`, rather than point to the value at the
+    /// position prior to insertion. This is different from, say, a tree
+    /// structure, where iterator stability signifies the property that
+    /// iterators keep pointing to the same element after insertion before or
+    /// after that position.
+    ///
+    /// For the purpose of supporting `ChangesetIndex`, and the OT merge
+    /// algorithm, these semantics are acceptable, since prepended instructions
+    /// can never create new object or table references.
+    iterator insert_stable(const_iterator position, Instruction);
+    template <class InputIt>
+    iterator insert_stable(const_iterator position, InputIt begin, InputIt end);
+    //@}
+
+    /// Erase instruction at \a position without invalidating other iterators.
+    /// If erasing the object would invalidate other iterators, it is turned
+    /// into a tombstone instead, and subsequent derefencing of the iterator
+    /// will return `nullptr`. An iterator pointing to a tombstone remains valid
+    /// and can be incremented.
+    ///
+    /// Only iterators created before any call to `insert_stable()` may be
+    /// considered stable across calls to `erase_stable()`. If other copies of
+    /// \a position exist in the program, they will either point to the
+    /// subsequent element if that element was previously inserted with
+    /// `insert_stable()`, or otherwise it will be turned into a tombstone.
+    iterator erase_stable(const_iterator position);
+
+#if REALM_DEBUG
+    struct Reflector;
+    struct Printer;
+    void verify() const;
+    void print(std::ostream&) const;
+    void print() const; // prints to std::err
+#endif
+
+    /// The version that this changeset produced. Note: This may not be the
+    /// version produced by this changeset on the client on which this changeset
+    /// originated, but may for instance be the version produced on the server
+    /// after receiving and re-sending this changeset to another client.
+    ///
+    /// FIXME: The explanation above is confusing. The truth is that if this
+    /// changeset was received by a client from the server, then \a version is
+    /// the version that was produced on the server by this changeset.
+    ///
+    /// FIXME: This property, as well as \a last_integrated_remote_version, \a
+    /// origin_timestamp, and \a origin_file_ident should probably be removed
+    /// from this class, as they are not a logical part of a changeset, and also
+    /// are difficult to document without knowing more about what context the
+    /// changeset object occurs. Also, functions such as
+    /// InstructionApplier::apply() that a changeset as argument, but do not
+    /// care about those properties.
+    version_type version = 0;
+
+    /// On clients, the last integrated server version. On the server, this is
+    /// the last integrated client version.
+    ///
+    /// FIXME: The explanation above is confusing. The truth is that if this
+    /// changeset was received by a client from the server, then \a
+    /// last_integrated_remote_version is the last client version that was
+    /// integrated by the server at the server version referencened by \a
+    /// version.
+    version_type last_integrated_remote_version = 0;
+
+    /// Timestamp at origin when the original untransformed changeset was
+    /// produced.
+    timestamp_type origin_timestamp = 0;
+
+    /// The identifier of the file in the context of which the original
+    /// untransformed changeset was produced.
+    file_ident_type origin_file_ident = 0;
+
+private:
+    struct MultiInstruction {
+        util::metered::vector<Instruction> instructions;
+    };
+    static_assert(sizeof(MultiInstruction) <= Instruction::max_instruction_size, "Instruction::max_instruction_size too low");
+
+    // In order to achieve iterator semi-stability (just enough to be able to
+    // run the merge algorithm while maintaining a ChangesetIndex), a Changeset
+    // is really a list of lists. A Changeset is a vector of
+    // `InstructionContainer`s, and each `InstructionContainer` represents 0-N
+    // "real" instructions.
+    //
+    // As an optimization, there is a special case for when the
+    // `InstructionContainer` represents exactly 1 instruction, in which case it
+    // is represented inside the `InstructionContainer` without any additional
+    // allocations or indirections. The `InstructionContainer` derived from
+    // the `Instruction` struct, and co-opts the `type` field such that if the
+    // (invalid) value of `type` is 0xff, the contents of the `Instruction` are
+    // instead interpreted as an instance of `MultiInstruction`, which holds
+    // a vector of `Instruction`s.
+    //
+    // The size of the `MultiInstruction` may also be zero, in which case it is
+    // considered a "tombstone" - always as a result of a call to
+    // `Changeset::erase_stable()`. The potential existence of these tombstones
+    // is the reason that the value type of `Changeset::iterator` is
+    // `Instruction*`, rather than `Instruction&`.
+    //
+    // FIXME: It would be better if `Changeset::iterator::value_type` could be
+    // `util::Optional<Instruction&>`, but this is prevented by a bug in
+    // `util::Optional`.
+    struct InstructionContainer : Instruction {
+        InstructionContainer();
+        InstructionContainer(const Instruction& instr);
+        InstructionContainer(InstructionContainer&&) noexcept;
+        InstructionContainer(const InstructionContainer&);
+        ~InstructionContainer();
+        InstructionContainer& operator=(InstructionContainer&&) noexcept;
+        InstructionContainer& operator=(const InstructionContainer&);
+
+        bool is_multi() const noexcept;
+        void convert_to_multi();
+        void insert(size_t position, Instruction instr);
+        void erase(size_t position);
+        size_t size() const noexcept;
+        bool is_empty() const noexcept;
+
+        Instruction& at(size_t pos) noexcept;
+        const Instruction& at(size_t pos) const noexcept;
+
+        MultiInstruction& get_multi() noexcept;
+        const MultiInstruction& get_multi() const noexcept;
+    };
+
+    util::metered::vector<InstructionContainer> m_instructions;
+    std::shared_ptr<StringBuffer> m_string_buffer;
+    std::shared_ptr<InternStrings> m_strings;
+    bool m_is_dirty = false;
+
+    iterator const_iterator_to_iterator(const_iterator);
+};
+
+/// An iterator type that hides the implementation details of the support for
+/// iterator stability.
+///
+/// A `Changeset::iterator` is composed of an
+/// `std::vector<InstructionContainer>::iterator` and a `size_t` representing
+/// the index into the current `InstructionContainer`. If that container is
+/// empty, and the position is zero, the iterator is pointing to a tombstone.
+template <bool is_const>
+struct Changeset::IteratorImpl {
+    using list_type = util::metered::vector<InstructionContainer>;
+    using inner_iterator_type = std::conditional_t<is_const, list_type::const_iterator, list_type::iterator>;
+
+    // reference_type is a pointer because we have no way to create a reference
+    // to a tombstone instruction. Alternatively, it could have been
+    // `util::Optional<Instruction&>`, but that runs into other issues.
+    using reference_type = std::conditional_t<is_const, const Instruction*, Instruction*>;
+
+    using pointer_type   = std::conditional_t<is_const, const Instruction*, Instruction*>;
+    using difference_type = std::ptrdiff_t;
+
+    IteratorImpl() : m_pos(0) {}
+    template <bool is_const_ = is_const>
+    IteratorImpl(const IteratorImpl<false>& other, std::enable_if_t<is_const_>* = nullptr)
+        : m_inner(other.m_inner), m_pos(other.m_pos) {}
+    IteratorImpl(inner_iterator_type inner, size_t pos = 0) : m_inner(inner), m_pos(pos) {}
+
+    inline IteratorImpl& operator++()
+    {
+        ++m_pos;
+        if (m_pos >= m_inner->size()) {
+            ++m_inner;
+            m_pos = 0;
+        }
+        return *this;
+    }
+
+    IteratorImpl operator++(int)
+    {
+        auto copy = *this;
+        ++(*this);
+        return copy;
+    }
+
+    IteratorImpl& operator--()
+    {
+        if (m_pos == 0) {
+            --m_inner;
+            m_pos = m_inner->size();
+            if (m_pos != 0)
+                --m_pos;
+        }
+        else {
+            --m_pos;
+        }
+        return *this;
+    }
+
+    IteratorImpl operator--(int)
+    {
+        auto copy = *this;
+        --(*this);
+        return copy;
+    }
+
+    reference_type operator*() const
+    {
+        if (m_inner->size()) {
+            return &m_inner->at(m_pos);
+        }
+        // It was a tombstone.
+        return nullptr;
+    }
+
+    pointer_type operator->() const
+    {
+        if (m_inner->size()) {
+            return &m_inner->at(m_pos);
+        }
+        // It was a tombstone.
+        return nullptr;
+    }
+
+    bool operator==(const IteratorImpl& other) const
+    {
+        return m_inner == other.m_inner && m_pos == other.m_pos;
+    }
+
+    bool operator!=(const IteratorImpl& other) const
+    {
+        return !(*this == other);
+    }
+
+    bool operator<(const IteratorImpl& other) const
+    {
+        if (m_inner == other.m_inner)
+            return m_pos < other.m_pos;
+        return m_inner < other.m_inner;
+    }
+
+    bool operator<=(const IteratorImpl& other) const
+    {
+        if (m_inner == other.m_inner)
+            return m_pos <= other.m_pos;
+        return m_inner < other.m_inner;
+    }
+
+    bool operator>(const IteratorImpl& other) const
+    {
+        if (m_inner == other.m_inner)
+            return m_pos > other.m_pos;
+        return m_inner > other.m_inner;
+    }
+
+    bool operator>=(const IteratorImpl& other) const
+    {
+        if (m_inner == other.m_inner)
+            return m_pos >= other.m_pos;
+        return m_inner > other.m_inner;
+    }
+
+    inner_iterator_type m_inner;
+    size_t m_pos;
+};
+
+struct Changeset::Range {
+    iterator begin;
+    iterator end;
+};
+
+#if REALM_DEBUG
+struct Changeset::Reflector {
+    struct Tracer {
+        virtual void name(StringData) = 0;
+        virtual void field(StringData, StringData) = 0;
+        virtual void field(StringData, ObjectID) = 0;
+        virtual void field(StringData, int64_t) = 0;
+        virtual void field(StringData, double) = 0;
+        virtual void after_each() {}
+        virtual void before_each() {}
+    };
+
+    Reflector(Tracer& tracer, const Changeset& log) :
+        m_tracer(tracer), m_log(log)
+    {}
+
+    void visit_all() const;
+private:
+    Tracer& m_tracer;
+    const Changeset& m_log;
+
+    friend struct Instruction; // permit access for visit()
+#define REALM_DEFINE_REFLECTOR_VISITOR(X) void operator()(const Instruction::X&) const;
+    REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_DEFINE_REFLECTOR_VISITOR)
+#undef REALM_DEFINE_REFLECTOR_VISITOR
+};
+
+struct Changeset::Printer : Changeset::Reflector::Tracer {
+    explicit Printer(std::ostream& os) : m_out(os)
+    {}
+
+    // ChangesetReflector::Tracer interface:
+    void name(StringData) final;
+    void field(StringData, StringData) final;
+    void field(StringData, ObjectID) final;
+    void field(StringData, int64_t) final;
+    void field(StringData, double) final;
+    void after_each() final;
+
+private:
+    std::ostream& m_out;
+    bool m_first = true;
+    void pad_or_ellipsis(StringData, int width) const;
+    void print_field(StringData name, std::string value);
+};
+#endif // REALM_DEBUG
+
+
+
+/// Implementation:
+
+inline Changeset::iterator Changeset::begin() noexcept
+{
+    return m_instructions.begin();
+}
+
+inline Changeset::iterator Changeset::end() noexcept
+{
+    return m_instructions.end();
+}
+
+inline Changeset::const_iterator Changeset::begin() const noexcept
+{
+    return m_instructions.begin();
+}
+
+inline Changeset::const_iterator Changeset::end() const noexcept
+{
+    return m_instructions.end();
+}
+
+inline Changeset::const_iterator Changeset::cbegin() const noexcept
+{
+    return m_instructions.cbegin();
+}
+
+inline Changeset::const_iterator Changeset::cend() const noexcept
+{
+    return m_instructions.end();
+}
+
+inline bool Changeset::empty() const noexcept
+{
+    return size() == 0;
+}
+
+inline size_t Changeset::size() const noexcept
+{
+    size_t sum = 0;
+    for (auto& x: m_instructions)
+        sum += x.size();
+    return sum;
+}
+
+inline void Changeset::clear() noexcept
+{
+    m_instructions.clear();
+}
+
+inline util::Optional<StringBufferRange> Changeset::try_get_intern_string(InternString string) const noexcept
+{
+    if (string.value >= m_strings->size())
+        return util::none;
+    return (*m_strings)[string.value];
+}
+
+inline StringBufferRange Changeset::get_intern_string(InternString string) const noexcept
+{
+    auto str = try_get_intern_string(string);
+    REALM_ASSERT(str);
+    return *str;
+}
+
+inline InternStrings& Changeset::interned_strings() noexcept
+{
+    return *m_strings;
+}
+
+inline const InternStrings& Changeset::interned_strings() const noexcept
+{
+    return *m_strings;
+}
+
+inline auto Changeset::string_buffer() noexcept -> StringBuffer&
+{
+    return *m_string_buffer;
+}
+
+inline auto Changeset::string_buffer() const noexcept -> const StringBuffer&
+{
+    return *m_string_buffer;
+}
+
+inline util::Optional<StringData> Changeset::try_get_string(StringBufferRange range) const noexcept
+{
+    if (range.offset > m_string_buffer->size())
+        return util::none;
+    if (range.offset + range.size > m_string_buffer->size())
+        return util::none;
+    return StringData{m_string_buffer->data() + range.offset, range.size};
+}
+
+inline StringData Changeset::get_string(StringBufferRange range) const noexcept
+{
+    auto string = try_get_string(range);
+    REALM_ASSERT(string);
+    return *string;
+}
+
+inline StringData Changeset::get_string(InternString string) const noexcept
+{
+    return get_string(get_intern_string(string));
+}
+
+inline StringData Changeset::string_data() const noexcept
+{
+    return StringData{m_string_buffer->data(), m_string_buffer->size()};
+}
+
+inline StringBufferRange Changeset::append_string(StringData string)
+{
+    m_string_buffer->reserve(1024); // we expect more strings
+    size_t offset = m_string_buffer->size();
+    m_string_buffer->append(string.data(), string.size());
+    return StringBufferRange{uint32_t(offset), uint32_t(string.size())};
+}
+
+inline bool Changeset::is_dirty() const noexcept
+{
+    return m_is_dirty;
+}
+
+inline void Changeset::set_dirty(bool dirty) noexcept
+{
+    m_is_dirty = dirty;
+}
+
+inline Changeset::iterator Changeset::insert(const_iterator pos, Instruction instr)
+{
+    Instruction* p = &instr;
+    return insert(pos, p, p + 1);
+}
+
+template <class InputIt>
+inline Changeset::iterator Changeset::insert(const_iterator pos, InputIt begin, InputIt end)
+{
+    if (pos.m_pos == 0)
+        return m_instructions.insert(pos.m_inner, begin, end);
+    return insert_stable(pos, begin, end);
+}
+
+inline Changeset::iterator Changeset::erase(const_iterator pos)
+{
+    if (pos.m_inner->size() <= 1)
+        return m_instructions.erase(pos.m_inner);
+    return erase_stable(pos);
+}
+
+inline Changeset::iterator Changeset::insert_stable(const_iterator pos, Instruction instr)
+{
+    Instruction* p = &instr;
+    return insert_stable(pos, p, p + 1);
+}
+
+template <class InputIt>
+inline Changeset::iterator Changeset::insert_stable(const_iterator cpos, InputIt begin, InputIt end)
+{
+    iterator pos = const_iterator_to_iterator(cpos);
+    size_t i = 0;
+    for (auto it = begin; it != end; ++it, ++i) {
+        pos.m_inner->insert(pos.m_pos + i, *it);
+    }
+    return pos;
+}
+
+inline Changeset::iterator Changeset::erase_stable(const_iterator cpos)
+{
+    auto pos = const_iterator_to_iterator(cpos);
+    auto begin = m_instructions.begin();
+    auto end = m_instructions.end();
+    REALM_ASSERT(pos.m_inner >= begin);
+    REALM_ASSERT(pos.m_inner < end);
+    pos.m_inner->erase(pos.m_pos);
+    if (pos.m_pos >= pos.m_inner->size()) {
+        do {
+            ++pos.m_inner;
+        } while (pos.m_inner != end && pos.m_inner->is_empty());
+        pos.m_pos = 0;
+    }
+    return pos;
+}
+
+inline void Changeset::push_back(const Instruction& instr)
+{
+    m_instructions.emplace_back(instr);
+}
+
+inline auto Changeset::const_iterator_to_iterator(const_iterator cpos) -> iterator
+{
+    size_t offset = cpos.m_inner - m_instructions.cbegin();
+    return iterator{m_instructions.begin() + offset, cpos.m_pos};
+}
+
+inline Changeset::InstructionContainer::~InstructionContainer()
+{
+    if (is_multi()) {
+        get_multi().~MultiInstruction();
+    }
+    // Instruction subtypes are required to be POD-types (trivially
+    // destructible), and this is checked by a static_assert in
+    // instructions.hpp. Therefore, it is safe to do nothing if this is not a
+    // multi-instruction.
+}
+
+inline bool Changeset::InstructionContainer::is_multi() const noexcept
+{
+    return type == Type(InstrTypeMultiInstruction);
+}
+
+inline size_t Changeset::InstructionContainer::size() const noexcept
+{
+    if (is_multi())
+        return get_multi().instructions.size();
+    return 1;
+}
+
+inline bool Changeset::InstructionContainer::is_empty() const noexcept
+{
+    if (is_multi()) {
+        return get_multi().instructions.empty();
+    }
+    return false;
+}
+
+inline Instruction& Changeset::InstructionContainer::at(size_t pos) noexcept
+{
+    REALM_ASSERT(pos < size());
+    if (is_multi())
+        return get_multi().instructions[pos];
+    return *this;
+}
+
+inline const Instruction& Changeset::InstructionContainer::at(size_t pos) const noexcept
+{
+    REALM_ASSERT(pos < size());
+    if (is_multi())
+        return get_multi().instructions[pos];
+    return *this;
+}
+
+inline Changeset::MultiInstruction& Changeset::InstructionContainer::get_multi() noexcept
+{
+    REALM_ASSERT(is_multi());
+    return *reinterpret_cast<MultiInstruction*>(&m_storage);
+}
+
+inline const Changeset::MultiInstruction& Changeset::InstructionContainer::get_multi() const noexcept
+{
+    REALM_ASSERT(is_multi());
+    return *reinterpret_cast<const MultiInstruction*>(&m_storage);
+}
+
+} // namespace sync
+} // namespace realm
+
+namespace std {
+
+template <bool is_const>
+struct iterator_traits<realm::sync::Changeset::IteratorImpl<is_const>> {
+    using difference_type = std::ptrdiff_t;
+    using iterator_category = std::bidirectional_iterator_tag;
+};
+
+} // namespace std
+
+#endif // REALM_SYNC_CHANGESET_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_cooker.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_cooker.hpp
new file mode 100644
index 0000000..3d003be
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_cooker.hpp
@@ -0,0 +1,40 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#include <realm/sync/history.hpp>
+
+#ifndef REALM_SYNC_CHANGESET_COOKER_HPP
+#define REALM_SYNC_CHANGESET_COOKER_HPP
+
+namespace realm {
+namespace sync {
+
+/// Copy raw changesets unmodified.
+class TrivialChangesetCooker: public ClientHistory::ChangesetCooker {
+public:
+    bool cook_changeset(const Group&, const char* changeset,
+                        std::size_t changeset_size,
+                        util::AppendBuffer<char>&) override;
+};
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_CHANGESET_COOKER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_encoder.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_encoder.hpp
new file mode 100644
index 0000000..5c3618a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_encoder.hpp
@@ -0,0 +1,122 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2017] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_CHANGESET_ENCODER_HPP
+#define REALM_SYNC_CHANGESET_ENCODER_HPP
+
+#include <realm/sync/changeset.hpp>
+#include <realm/util/metered/unordered_map.hpp>
+#include <realm/util/metered/string.hpp>
+
+namespace realm {
+namespace sync {
+
+struct ChangesetEncoder: InstructionHandler {
+    using Buffer = util::AppendBuffer<char, MeteredAllocator>;
+
+    Buffer release() noexcept;
+    void reset() noexcept;
+    const Buffer& buffer() const noexcept;
+    InternString intern_string(StringData);
+
+    void set_intern_string(uint32_t index, StringBufferRange) override;
+    // FIXME: This doesn't copy the input, but the drawback is that there can
+    // only be a single StringBufferRange per instruction. Luckily, no
+    // instructions exist that require two or more.
+    StringBufferRange add_string_range(StringData) override;
+    void operator()(const Instruction&) override;
+
+#define REALM_DEFINE_INSTRUCTION_HANDLER(X) void operator()(const Instruction::X&);
+    REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_DEFINE_INSTRUCTION_HANDLER)
+#undef REALM_DEFINE_INSTRUCTION_HANDLER
+
+    void encode_single(const Changeset& log);
+
+protected:
+    template<class E> static void encode(E& encoder, const Instruction&);
+
+    StringData get_string(StringBufferRange) const noexcept;
+
+private:
+    template<class... Args>
+    void append(Instruction::Type t, Args&&...);
+    void append_string(StringBufferRange); // does not intern the string
+    void append_bytes(const void*, size_t);
+
+    template<class T> void append_int(T);
+    void append_payload(const Instruction::Payload&);
+    void append_value(DataType);
+    void append_value(bool);
+    void append_value(uint8_t);
+    void append_value(int64_t);
+    void append_value(uint32_t);
+    void append_value(uint64_t);
+    void append_value(float);
+    void append_value(double);
+    void append_value(InternString);
+    void append_value(sync::ObjectID);
+    void append_value(Timestamp);
+
+    Buffer m_buffer;
+    util::metered::map<std::string, uint32_t> m_intern_strings_rev;
+    StringData m_string_range;
+};
+
+template <class Allocator>
+void encode_changeset(const Changeset&, util::AppendBuffer<char, Allocator>& out_buffer);
+
+
+// Implementation
+
+inline auto ChangesetEncoder::buffer() const noexcept -> const Buffer&
+{
+    return m_buffer;
+}
+
+inline void ChangesetEncoder::operator()(const Instruction& instr)
+{
+    encode(*this, instr); // Throws
+}
+
+template<class E> inline void ChangesetEncoder::encode(E& encoder, const Instruction& instr)
+{
+    instr.visit(encoder); // Throws
+}
+
+inline StringData ChangesetEncoder::get_string(StringBufferRange range) const noexcept
+{
+    const char* data = m_string_range.data() + range.offset;
+    std::size_t size = std::size_t(range.size);
+    return StringData{data, size};
+}
+
+template <class Allocator>
+void encode_changeset(const Changeset& changeset, util::AppendBuffer<char, Allocator>& out_buffer)
+{
+    ChangesetEncoder encoder;
+    encoder.encode_single(changeset); // Throws
+    auto& buffer = encoder.buffer();
+    out_buffer.append(buffer.data(), buffer.size()); // Throws
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_CHANGESET_ENCODER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_parser.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_parser.hpp
new file mode 100644
index 0000000..f331569
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/changeset_parser.hpp
@@ -0,0 +1,47 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2017] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_CHANGESET_PARSER_HPP
+#define REALM_SYNC_CHANGESET_PARSER_HPP
+
+#include <realm/sync/changeset.hpp>
+#include <realm/impl/input_stream.hpp>
+
+namespace realm {
+namespace sync {
+
+struct ChangesetParser {
+    /// Throws BadChangesetError if parsing fails.
+    ///
+    /// FIXME: Consider using std::error_code instead of throwing exceptions on
+    /// parse errors.
+    void parse(_impl::NoCopyInputStream&, InstructionHandler&);
+private:
+    struct State;
+};
+
+void parse_changeset(_impl::NoCopyInputStream&, Changeset& out_log);
+void parse_changeset(_impl::InputStream&, Changeset& out_log);
+
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_CHANGESET_PARSER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/client.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/client.hpp
new file mode 100644
index 0000000..f5e477b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/client.hpp
@@ -0,0 +1,1365 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2012] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_SYNC_CLIENT_HPP
+#define REALM_SYNC_CLIENT_HPP
+
+#include <cstddef>
+#include <cstdint>
+#include <memory>
+#include <utility>
+#include <functional>
+#include <exception>
+#include <string>
+
+#include <realm/util/buffer.hpp>
+#include <realm/util/logger.hpp>
+#include <realm/util/network.hpp>
+#include <realm/impl/cont_transact_hist.hpp>
+#include <realm/sync/protocol.hpp>
+#include <realm/sync/history.hpp>
+
+namespace realm {
+namespace sync {
+
+
+class Client {
+public:
+    enum class Error;
+
+    enum class ReconnectMode {
+        /// This is the mode that should always be used in production. In this
+        /// mode the client uses a scheme for determining a reconnect delay that
+        /// prevents it from creating too many connection requests in a short
+        /// amount of time (i.e., a server hammering protection mechanism).
+        normal,
+
+        /// For testing purposes only.
+        ///
+        /// Never reconnect automatically after the connection is closed due to
+        /// an error. Allow immediate reconnect if the connection was closed
+        /// voluntarily (e.g., due to sessions being abandoned).
+        ///
+        /// In this mode, Client::cancel_reconnect_delay() and
+        /// Session::cancel_reconnect_delay() can still be used to trigger
+        /// another reconnection attempt (with no delay) after an error has
+        /// caused the connection to be closed.
+        testing
+    };
+
+    using port_type = util::network::Endpoint::port_type;
+    using RoundtripTimeHandler = void(milliseconds_type roundtrip_time);
+
+    static constexpr milliseconds_type default_connect_timeout        = 120000; // 2 minutes
+    static constexpr milliseconds_type default_connection_linger_time =  30000; // 30 seconds
+    static constexpr milliseconds_type default_ping_keepalive_period  =  60000; // 1 minute
+    static constexpr milliseconds_type default_pong_keepalive_timeout = 120000; // 2 minutes
+    static constexpr milliseconds_type default_fast_reconnect_limit   =  60000; // 1 minute
+
+    struct Config {
+        Config() {}
+
+        /// An optional custom platform description to be sent to server as part
+        /// of a user agent description (HTTP `User-Agent` header).
+        ///
+        /// If left empty, the platform description will be whatever is returned
+        /// by util::get_platform_info().
+        std::string user_agent_platform_info;
+
+        /// Optional information about the application to be added to the user
+        /// agent description as sent to the server. The intention is that the
+        /// application describes itself using the following (rough) syntax:
+        ///
+        ///     <application info>  ::=  (<space> <layer>)*
+        ///     <layer>             ::=  <name> "/" <version> [<space> <details>]
+        ///     <name>              ::=  (<alnum>)+
+        ///     <version>           ::=  <digit> (<alnum> | "." | "-" | "_")*
+        ///     <details>           ::=  <parentherized>
+        ///     <parentherized>     ::=  "(" (<nonpar> | <parentherized>)* ")"
+        ///
+        /// Where `<space>` is a single space character, `<digit>` is a decimal
+        /// digit, `<alnum>` is any alphanumeric character, and `<nonpar>` is
+        /// any character other than `(` and `)`.
+        ///
+        /// When multiple levels are present, the innermost layer (the one that
+        /// is closest to this API) should appear first.
+        ///
+        /// Example:
+        ///
+        ///     RealmJS/2.13.0 RealmStudio/2.9.0
+        ///
+        /// Note: The user agent description is not intended for machine
+        /// interpretation, but should still follow the specified syntax such
+        /// that it remains easily interpretable by human beings.
+        std::string user_agent_application_info;
+
+        /// The maximum number of Realm files that will be kept open
+        /// concurrently by this client. The client keeps a cache of open Realm
+        /// files for efficiency reasons.
+        long max_open_files = 256;
+
+        /// An optional logger to be used by the client. If no logger is
+        /// specified, the client will use an instance of util::StderrLogger
+        /// with the log level threshold set to util::Logger::Level::info. The
+        /// client does not require a thread-safe logger, and it guarantees that
+        /// all logging happens either on behalf of the constructor or on behalf
+        /// of the invocation of run().
+        util::Logger* logger = nullptr;
+
+        /// Use ports 80 and 443 by default instead of 7800 and 7801
+        /// respectively. Ideally, these default ports should have been made
+        /// available via a different URI scheme instead (http/https or ws/wss).
+        bool enable_default_port_hack = true;
+
+        /// For testing purposes only.
+        ReconnectMode reconnect_mode = ReconnectMode::normal;
+
+        /// Create a separate connection for each session. For testing purposes
+        /// only.
+        ///
+        /// FIXME: This setting needs to be true for now, due to limitations in
+        /// the load balancer.
+        bool one_connection_per_session = true;
+
+        /// Do not access the local file system. Sessions will act as if
+        /// initiated on behalf of an empty (or nonexisting) local Realm
+        /// file. Received DOWNLOAD messages will be accepted, but otherwise
+        /// ignored. No UPLOAD messages will be generated. For testing purposes
+        /// only.
+        ///
+        /// Many operations, such as serialized transactions, are not suppored
+        /// in this mode.
+        bool dry_run = false;
+
+        /// The default changeset cooker to be used by new sessions. Can be
+        /// overridden by Session::Config::changeset_cooker.
+        ///
+        /// \sa make_client_history(), TrivialChangesetCooker.
+        std::shared_ptr<ClientHistory::ChangesetCooker> changeset_cooker;
+
+        /// The maximum number of milliseconds to allow for a connection to
+        /// become fully established. This includes the time to resolve the
+        /// network address, the TCP connect operation, the SSL handshake, and
+        /// the WebSocket handshake.
+        milliseconds_type connect_timeout = default_connect_timeout;
+
+        /// The number of milliseconds to keep a connection open after all
+        /// sessions have been abandoned (or suspended by errors).
+        ///
+        /// The purpose of this linger time is to avoid close/reopen cycles
+        /// during short periods of time where there are no sessions interested
+        /// in using the connection.
+        ///
+        /// If the connection gets closed due to an error before the linger time
+        /// expires, the connection will be kept closed until there are sessions
+        /// willing to use it again.
+        milliseconds_type connection_linger_time = default_connection_linger_time;
+
+        /// The client will send PING messages periodically to allow the server
+        /// to detect dead connections (heartbeat). This parameter specifies the
+        /// time, in milliseconds, between these PING messages. When scheduling
+        /// the next PING message, the client will deduct a small random amount
+        /// from the specified value to help spread the load on the server from
+        /// many clients.
+        milliseconds_type ping_keepalive_period = default_ping_keepalive_period;
+
+        /// Whenever the server receives a PING message, it is supposed to
+        /// respond with a PONG messsage to allow the client to detect dead
+        /// connections (heartbeat). This parameter specifies the time, in
+        /// milliseconds, that the client will wait for the PONG response
+        /// message before it assumes that the connection is dead, and
+        /// terminates it.
+        milliseconds_type pong_keepalive_timeout = default_pong_keepalive_timeout;
+
+        /// The maximum amount of time, in milliseconds, since the loss of a
+        /// prior connection, for a new connection to be considered a *fast
+        /// reconnect*.
+        ///
+        /// In general, when a client establishes a connection to the server,
+        /// the uploading process remains suspended until the initial
+        /// downloading process completes (as if by invocation of
+        /// Session::async_wait_for_download_completion()). However, to avoid
+        /// unnecessary latency in change propagation during ongoing
+        /// application-level activity, if the new connection is established
+        /// less than a certain amount of time (`fast_reconnect_limit`) since
+        /// the client was previously connected to the server, then the
+        /// uploading process will be activated immediately.
+        ///
+        /// For now, the purpose of the general delaying of the activation of
+        /// the uploading process, is to increase the chance of multiple initial
+        /// transactions on the client-side, to be uploaded to, and processed by
+        /// the server as a single unit. In the longer run, the intention is
+        /// that the client should upload transformed (from reciprocal history),
+        /// rather than original changesets when applicable to reduce the need
+        /// for changeset to be transformed on both sides. The delaying of the
+        /// upload process will increase the number of cases where this is
+        /// possible.
+        ///
+        /// FIXME: Currently, the time between connections is not tracked across
+        /// sessions, so if the application closes its session, and opens a new
+        /// one immediately afterwards, the activation of the upload process
+        /// will be delayed unconditionally.
+        milliseconds_type fast_reconnect_limit = default_fast_reconnect_limit;
+
+        /// Set to true to completely disable delaying of the upload process. In
+        /// this mode, the upload process will be activated immediately, and the
+        /// value of `fast_reconnect_limit` is ignored.
+        ///
+        /// For testing purposes only.
+        bool disable_upload_activation_delay = false;
+
+        /// If `disable_upload_compaction` is true, every changeset will be
+        /// compacted before it is uploaded to the server. Compaction will
+        /// reduce the size of a changeset if the same field is set multiple
+        /// times or if newly created objects are deleted within the same
+        /// transaction. Log compaction increeses CPU usage and memory
+        /// consumption.
+        bool disable_upload_compaction = false;
+
+        /// Set the `TCP_NODELAY` option on all TCP/IP sockets. This disables
+        /// the Nagle algorithm. Disabling it, can in some cases be used to
+        /// decrease latencies, but possibly at the expense of scalability. Be
+        /// sure to research the subject before you enable this option.
+        bool tcp_no_delay = false;
+
+        /// The specified function will be called whenever a PONG message is
+        /// received on any connection. The round-trip time in milliseconds will
+        /// be pased to the function. The specified function will always be
+        /// called by the client's event loop thread, i.e., the thread that
+        /// calls `Client::run()`. This feature is mainly for testing purposes.
+        std::function<RoundtripTimeHandler> roundtrip_time_handler;
+
+        /// Disable sync to disk (fsync(), msync()) for all realm files managed
+        /// by this client.
+        ///
+        /// Testing/debugging feature. Should never be enabled in production.
+        bool disable_sync_to_disk = false;
+    };
+
+    /// \throw util::EventLoop::Implementation::NotAvailable if no event loop
+    /// implementation was specified, and
+    /// util::EventLoop::Implementation::get_default() throws it.
+    Client(Config = {});
+    Client(Client&&) noexcept;
+    ~Client() noexcept;
+
+    /// Run the internal event-loop of the client. At most one thread may
+    /// execute run() at any given time. The call will not return until somebody
+    /// calls stop().
+    void run();
+
+    /// See run().
+    ///
+    /// Thread-safe.
+    void stop() noexcept;
+
+    /// \brief Cancel current or next reconnect delay for all servers.
+    ///
+    /// This corresponds to calling Session::cancel_reconnect_delay() on all
+    /// bound sessions, but will also cancel reconnect delays applying to
+    /// servers for which there are currently no bound sessions.
+    ///
+    /// Thread-safe.
+    void cancel_reconnect_delay();
+
+    /// \brief Wait for session termination to complete.
+    ///
+    /// Wait for termination of all sessions whose termination was initiated
+    /// prior this call (the completion condition), or until the client's event
+    /// loop thread exits from Client::run(), whichever happens
+    /// first. Termination of a session can be initiated implicitly (e.g., via
+    /// destruction of the session object), or explicitly by Session::detach().
+    ///
+    /// Note: After session termination (when this function returns true) no
+    /// session specific callback function can be called or continue to execute,
+    /// and the client is guaranteed to no longer have a Realm file open on
+    /// behalf of the terminated session.
+    ///
+    /// CAUTION: If run() returns while a wait operation is in progress, this
+    /// waiting function will return immediately, even if the completion
+    /// condition is not yet satisfied. The completion condition is guaranteed
+    /// to be satisfied only when these functions return true. If it returns
+    /// false, session specific callback functions may still be executing or get
+    /// called, and the associated Realm files may still not have been closed.
+    ///
+    /// If a new wait operation is initiated while another wait operation is in
+    /// progress by another thread, the waiting period of fist operation may, or
+    /// may not get extended. The application must not assume either.
+    ///
+    /// Note: Session termination does not imply that the client has received an
+    /// UNBOUND message from the server (see the protocol specification). This
+    /// may happen later.
+    ///
+    /// \return True only if the completion condition was satisfied. False if
+    /// the client's event loop thread exited from Client::run() in which case
+    /// the completion condition may, or may not have been satisfied.
+    ///
+    /// Note: These functions are fully thread-safe. That is, they may be called
+    /// by any thread, and by multiple threads concurrently.
+    bool wait_for_session_terminations_or_client_stopped();
+
+    /// Returns false if the specified URL is invalid.
+    bool decompose_server_url(const std::string& url, ProtocolEnvelope& protocol,
+                              std::string& address, port_type& port, std::string& path) const;
+
+private:
+    class Impl;
+    std::unique_ptr<Impl> m_impl;
+    friend class Session;
+};
+
+
+class BadServerUrl; // Exception
+
+
+/// \brief Client-side representation of a Realm file synchronization session.
+///
+/// A synchronization session deals with precisely one local Realm file. To
+/// synchronize multiple local Realm files, you need multiple sessions.
+///
+/// A session object is always associated with a particular client object (\ref
+/// Client). The application must ensure that the destruction of the associated
+/// client object never happens before the destruction of the session
+/// object. The consequences of a violation are unspecified.
+///
+/// A session object is always associated with a particular local Realm file,
+/// however, a session object does not represent a session until it is bound to
+/// a server side Realm, i.e., until bind() is called. From the point of view of
+/// the thread that calls bind(), the session starts precisely when the
+/// execution of bind() starts, i.e., before bind() returns.
+///
+/// At most one session is allowed to exist for a particular local Realm file
+/// (file system inode) at any point in time. Multiple session objects may
+/// coexists for a single file, as long as bind() has been called on at most one
+/// of them. Additionally, two bound session objects for the same file are
+/// allowed to exist at different times, if they have no overlap in time (in
+/// their bound state), as long as they are associated with the same client
+/// object, or with two different client objects that do not overlap in
+/// time. This means, in particular, that it is an error to create two bound
+/// session objects for the same local Realm file, it they are associated with
+/// two different client objects that overlap in time, even if the session
+/// objects do not overlap in time (in their bound state). It is the
+/// responsibility of the application to ensure that these rules are adhered
+/// to. The consequences of a violation are unspecified.
+///
+/// Thread-safety: It is safe for multiple threads to construct, use (with some
+/// exceptions), and destroy session objects concurrently, regardless of whether
+/// those session objects are associated with the same, or with different Client
+/// objects. Please note that some of the public member functions are fully
+/// thread-safe, while others are not.
+///
+/// Callback semantics: All session specific callback functions will be executed
+/// by the event loop thread, i.e., the thread that calls Client::run(). No
+/// callback function will be called before Session::bind() is called. Callback
+/// functions that are specified prior to calling bind() (e.g., any passed to
+/// set_progress_handler()) may start to execute before bind() returns, as long
+/// as some thread is executing Client::run(). Likewise, completion handlers,
+/// such as those passed to async_wait_for_sync_completion() may start to
+/// execute before the submitting function returns. All session specific
+/// callback functions (including completion handlers) are guaranteed to no
+/// longer be executing when session termination completes, and they are
+/// guaranteed to not be called after session termination completes. Termination
+/// is an event that completes asynchronously with respect to the application,
+/// but is initiated by calling detach(), or implicitely by destroying a session
+/// object. After having initiated one or more session terminations, the
+/// application can wait for those terminations to complete by calling
+/// Client::wait_for_session_terminations_or_client_stopped(). Since callback
+/// functinos are always executed by the event loop thread, they are also
+/// guaranteed to not be executing after Client::run() has returned.
+class Session {
+public:
+    using port_type = util::network::Endpoint::port_type;
+    using SyncTransactCallback = void(VersionID old_version, VersionID new_version);
+    using ProgressHandler = void(std::uint_fast64_t downloaded_bytes,
+                                 std::uint_fast64_t downloadable_bytes,
+                                 std::uint_fast64_t uploaded_bytes,
+                                 std::uint_fast64_t uploadable_bytes,
+                                 std::uint_fast64_t progress_version,
+                                 std::uint_fast64_t snapshot_version);
+    using WaitOperCompletionHandler = std::function<void(std::error_code)>;
+    using SerialTransactChangeset = util::Buffer<char>;
+    using SerialTransactInitiationHandler = std::function<void(std::error_code)>;
+    using SerialTransactCompletionHandler = std::function<void(std::error_code, bool accepted)>;
+    using SSLVerifyCallback = bool(const std::string& server_address,
+                                   port_type server_port,
+                                   const char* pem_data,
+                                   size_t pem_size,
+                                   int preverify_ok,
+                                   int depth);
+
+    class Config {
+    public:
+        Config() {}
+
+        /// server_address is the fully qualified host name, or IP address of
+        /// the server.
+        std::string server_address = "localhost";
+
+        /// server_port is the port at which the server listens. If server_port
+        /// is zero, the default port for the specified protocol is used. See
+        /// ProtocolEnvelope for information on default ports.
+        port_type server_port = 0;
+
+        /// server_path is  the virtual path by which the server identifies the
+        /// Realm. This path must always be an absolute path, and must therefore
+        /// always contain a leading slash (`/`). Further more, each segment of the
+        /// virtual path must consist of one or more characters that are either
+        /// alpha-numeric or in (`_`, `-`, `.`), and each segment is not allowed to
+        /// equal `.` or `..`, and must not end with `.realm`, `.realm.lock`, or
+        /// `.realm.management`. These rules are necessary because the server
+        /// currently reserves the right to use the specified path as part of the
+        /// file system path of a Realm file. It is expected that these rules will
+        /// be significantly relaxed in the future by completely decoupling the
+        /// virtual paths from actual file system paths.
+        std::string server_path = "/";
+
+        /// The protocol used for communicating with the server. See
+        /// ProtocolEnvelope.
+        ProtocolEnvelope protocol_envelope = ProtocolEnvelope::realm;
+
+        /// url_prefix is a prefix that is prepended to the server_path
+        /// in the HTTP GET request that initiates a sync connection. The value
+        /// specified here must match with the server's expectation. Changing
+        /// the value of url_prefix should be matched with a corresponding
+        /// change of the server side proxy.
+        std::string url_prefix = "/realm-sync";
+
+        /// authorization_header_name is the name of the HTTP header containing
+        /// the Realm access token. The value of the HTTP header is
+        /// "Realm-Access-Token version=1 token=....".
+        /// authorization_header_name does not participate in session
+        /// multiplexing partitioning.
+        std::string authorization_header_name = "Authorization";
+
+        /// custom_http_headers is a map of custom HTTP headers. The keys of the map
+        /// are HTTP header names, and the values are the corresponding HTTP
+        /// header values.
+        /// If "Authorization" is used as a custom header name,
+        /// authorization_header_name must be set to anther value.
+        std::map<std::string, std::string> custom_http_headers;
+
+        /// Sessions can be multiplexed over the same TCP/SSL connection.
+        /// Sessions might share connection if they have identical server_address,
+        /// server_port, and protocol. multiplex_ident is a parameter that allows
+        /// finer control over session multiplexing. If two sessions have distinct
+        /// multiplex_ident, they will never share connection. The typical use of
+        /// multilex_ident is to give sessions with incompatible SSL requirements
+        /// distinct multiplex_idents.
+        /// multiplex_ident can be any string and the value has no meaning except
+        /// for partitioning the sessions.
+        std::string multiplex_ident;
+
+        /// Controls whether the server certificate is verified for SSL
+        /// connections. It should generally be true in production.
+        bool verify_servers_ssl_certificate = true;
+
+        /// ssl_trust_certificate_path is the path of a trust/anchor
+        /// certificate used by the client to verify the server certificate.
+        /// ssl_trust_certificate_path is only used if the protocol is ssl and
+        /// verify_servers_ssl_certificate is true.
+        ///
+        /// A server certificate is verified by first checking that the
+        /// certificate has a valid signature chain back to a trust/anchor
+        /// certificate, and secondly checking that the server_address matches
+        /// a host name contained in the certificate. The host name of the
+        /// certificate is stored in either Common Name or the Alternative
+        /// Subject Name (DNS section).
+        ///
+        /// If ssl_trust_certificate_path is None (default), ssl_verify_callback
+        /// (see below) is used if set, and the default device trust/anchor
+        /// store is used otherwise.
+        util::Optional<std::string> ssl_trust_certificate_path;
+
+        /// If Client::Config::ssl_verify_callback is set, that function is called
+        /// to verify the certificate, unless verify_servers_ssl_certificate is
+        /// false.
+
+        /// ssl_verify_callback is used to implement custom SSL certificate
+        /// verification. it is only used if the protocol is SSL,
+        /// verify_servers_ssl_certificate is true and ssl_trust_certificate_path
+        /// is None.
+        ///
+        /// The signature of ssl_verify_callback is
+        ///
+        /// bool(const std::string& server_address,
+        ///      port_type server_port,
+        ///      const char* pem_data,
+        ///      size_t pem_size,
+        ///      int preverify_ok,
+        ///      int depth);
+        ///
+        /// server address and server_port is the address and port of the server
+        /// that a SSL connection is being established to. They are identical to
+        /// the server_address and server_port set in this config file and are
+        /// passed for convenience.
+        /// pem_data is the certificate of length pem_size in
+        /// the PEM format. preverify_ok is OpenSSL's preverification of the
+        /// certificate. preverify_ok is either 0, or 1. If preverify_ok is 1,
+        /// OpenSSL has accepted the certificate and it will generally be safe
+        /// to trust that certificate. depth represents the position of the
+        /// certificate in the certificate chain sent by the server. depth = 0
+        /// represents the actual server certificate that should contain the
+        /// host name(server address) of the server. The highest depth is the
+        /// root certificate.
+        /// The callback function will receive the certificates starting from
+        /// the root certificate and moving down the chain until it reaches the
+        /// server's own certificate with a host name. The depth of the last
+        /// certificate is 0. The depth of the first certificate is chain
+        /// length - 1.
+        ///
+        /// The return value of the callback function decides whether the
+        /// client accepts the certificate. If the return value is false, the
+        /// processing of the certificate chain is interrupted and the SSL
+        /// connection is rejected. If the return value is true, the verification
+        /// process continues. If the callback function returns true for all
+        /// presented certificates including the depth == 0 certificate, the
+        /// SSL connection is accepted.
+        ///
+        /// A recommended way of using the callback function is to return true
+        /// if preverify_ok = 1 and depth > 0,
+        /// always check the host name if depth = 0,
+        /// and use an independent verification step if preverify_ok = 0.
+        ///
+        /// Another possible way of using the callback is to collect all the
+        /// certificates until depth = 0, and present the entire chain for
+        /// independent verification.
+        std::function<SSLVerifyCallback> ssl_verify_callback;
+
+        /// signed_user_token is a cryptographically signed token describing the
+        /// identity and access rights of the current user.
+        std::string signed_user_token;
+
+        /// If not null, overrides whatever is specified by
+        /// Client::Config::changeset_cooker.
+        ///
+        /// The shared ownership over the cooker will be relinquished shortly
+        /// after the destruction of the session object as long as the event
+        /// loop of the client is being executed (Client::run()).
+        ///
+        /// CAUTION: ChangesetCooker::cook_changeset() of the specified cooker
+        /// may get called before the call to bind() returns, and it may get
+        /// called (or continue to execute) after the session object is
+        /// destroyed. Please see "Callback semantics" section under Client for
+        /// more on this.
+        ///
+        /// \sa make_client_history(), TrivialChangesetCooker.
+        std::shared_ptr<ClientHistory::ChangesetCooker> changeset_cooker;
+
+        /// The encryption key the SharedGroup will be opened with.
+        util::Optional<std::array<char, 64>> encryption_key;
+
+        /// ClientReset is used for both async open and client reset. If
+        /// client_reset is not util::none, the sync client will perform
+        /// async open for this session if the local Realm does not exist, and
+        /// client reset if the local Realm exists. If client_reset is
+        /// util::none, an ordinary sync session will take place.
+        ///
+        /// A session will perform async open by downloading a state Realm, and
+        /// some metadata, from the server, patching up the metadata part of
+        /// the Realm and finally move the downloaded Realm into the path of
+        /// the local Realm. After completion of async open, the application
+        /// can open and use the Realm.
+        ///
+        /// A session will perform client reset by downloading a state Realm, and
+        /// some metadata, from the server. After download, the state Realm will
+        /// be integrated into the local Realm in a write transaction. The
+        /// application is free to use the local realm during the entire client
+        /// reset. Like a DOWNLOAD message, the application will not be able
+        /// to perform a write transaction at the same time as the sync client
+        /// performs its own write transaction. Client reset is not more
+        /// disturbing for the application than any DOWNLOAD message. The
+        /// application can listen to change notifications from the client
+        /// reset exactly as in a DOWNLOAD message.
+        ///
+        /// The client reset will recover non-uploaded changes in the local
+        /// Realm if and only if 'recover_local_changes' is true. In case,
+        /// 'recover_local_changes' is false, the local Realm state will hence
+        /// be set to the server's state (server wins).
+        ///
+        /// Async open and client reset require a private directory for
+        /// metadata. This directory must be specified in the option
+        /// 'metadata_dir'. The metadata_dir must not be touched during async
+        /// open or client reset. The metadata_dir can safely be removed at
+        /// times where async open or client reset do not take place. The sync
+        /// client attempts to clean up metadata_dir. The metadata_dir can be
+        /// reused across app restarts to resume an interrupted download. It is
+        /// recommended to leave the metadata_dir unchanged except when it is
+        /// known that async open or client reset is done.
+        ///
+        /// The recommended usage of async open is to use it for the initial
+        /// bootstrap if Realm usage is not needed until after the server state
+        /// has been downloaded.
+        ///
+        /// The recommended usage of client reset is after a previous session
+        /// encountered an error that implies the need for a client reset. It
+        /// is not recommended to persist the need for a client reset. The
+        /// application should just attempt to synchronize in the usual fashion
+        /// and only after hitting an error, start a new session with a client
+        /// reset. In other words, if the application crashes during a client reset,
+        /// the application should attempt to perform ordinary synchronization
+        /// after restart and switch to client reset if needed.
+        ///
+        /// Error codes that imply the need for a client reset are the session
+        /// level error codes:
+        ///
+        /// bad_client_file_ident        = 208, // Bad client file identifier (IDENT)
+        /// bad_server_version           = 209, // Bad server version (IDENT, UPLOAD)
+        /// bad_client_version           = 210, // Bad client version (IDENT, UPLOAD)
+        /// diverging_histories          = 211, // Diverging histories (IDENT)
+        ///
+        /// However, other errors such as bad changeset (UPLOAD) could also be resolved
+        /// with a client reset. Client reset can even be used without any prior error
+        /// if so desired.
+        ///
+        /// After completion of async open and client reset, the sync client
+        /// will continue synchronizing with the server in the usual fashion.
+        ///
+        /// The progress of async open and client reset can be tracked with the
+        /// standard progress handler.
+        ///
+        /// Async open and client reset are done when the progress handler
+        /// arguments satisfy "progress_version > 0". However, if the
+        /// application wants to ensure that it has all data present on the
+        /// server, it should wait for download completion using either
+        /// void async_wait_for_download_completion(WaitOperCompletionHandler)
+        /// or
+        /// bool wait_for_download_complete_or_client_stopped().
+        ///
+        /// The option 'require_recent_state_realm' is used for async open to
+        /// request a recent state Realm. A recent state Realm is never empty
+        /// (unless there is no data), and is recent in the sense that it was
+        /// produced by the current incarnation of the server. Recent does not
+        /// mean the absolutely newest possible state Realm, since that might
+        /// lead to too excessive work on the server. Setting
+        /// 'require_recent_state_realm' to true might lead to more work
+        /// performed by the server but it ensures that more data is downloaded
+        /// using async open instead of ordinary synchronization. It is
+        /// recommended to set 'require_recent_state_realm' to true. Client
+        /// reset always downloads a recent state Realm.
+        struct ClientReset {
+            std::string metadata_dir;
+            bool recover_local_changes = true;
+            bool require_recent_state_realm = true;
+        };
+        util::Optional<ClientReset> client_reset_config;
+
+        struct ProxyConfig {
+            enum class Type { HTTP, HTTPS } type;
+            std::string address;
+            port_type port;
+        };
+        util::Optional<ProxyConfig> proxy_config;
+
+        /// Set to true to disable the upload process for this session. This
+        /// includes the sending of empty UPLOAD messages.
+        ///
+        /// This feature exists exclusively for testing purposes at this time.
+        bool disable_upload = false;
+
+        /// Set to true to disable sending of empty UPLOAD messages for this
+        /// session.
+        ///
+        /// This feature exists exclusively for testing purposes at this time.
+        bool disable_empty_upload = false;
+
+        /// Set to true to cause the integration of the first received changeset
+        /// (in a DOWNLOAD message) to fail.
+        ///
+        /// This feature exists exclusively for testing purposes at this time.
+        bool simulate_integration_error = false;
+    };
+
+    /// \brief Start a new session for the specified client-side Realm.
+    ///
+    /// Note that the session is not fully activated until you call bind().
+    /// Also note that if you call set_sync_transact_callback(), it must be
+    /// done before calling bind().
+    ///
+    /// \param realm_path The file-system path of a local client-side Realm
+    /// file.
+    Session(Client&, std::string realm_path, Config = {});
+
+    /// This leaves the right-hand side session object detached. See "Thread
+    /// safety" section under detach().
+    Session(Session&&) noexcept;
+
+    /// Create a detached session object (see detach()).
+    Session() noexcept;
+
+    /// Implies detachment. See "Thread safety" section under detach().
+    ~Session() noexcept;
+
+    /// Detach the object on the left-hand side, then "steal" the session from
+    /// the object on the right-hand side, if there is one. This leaves the
+    /// object on the right-hand side detached. See "Thread safety" section
+    /// under detach().
+    Session& operator=(Session&&) noexcept;
+
+    /// Detach this sesion object from the client object (Client). If the
+    /// session object is already detached, this function has no effect
+    /// (idempotency).
+    ///
+    /// Detachment initiates session termination, which is an event that takes
+    /// place shortly therafter in the context of the client's event loop
+    /// thread.
+    ///
+    /// A detached session object may be destroyed, move-assigned to, and moved
+    /// from. Apart from that, it is an error to call any function other than
+    /// detach() on a detached session object.
+    ///
+    /// Thread safety: Detachment is not a thread-safe operation. This means
+    /// that detach() may not be executed by two threads concurrently, and may
+    /// not execute concurrently with object destruction. Additionally,
+    /// detachment must not execute concurrently with a moving operation
+    /// involving the session object on the left or right-hand side. See move
+    /// constructor and assigment operator.
+    void detach() noexcept;
+
+    /// \brief Set a function to be called when the local Realm has changed due
+    /// to integration of a downloaded changeset.
+    ///
+    /// Specify the callback function that will be called when one or more
+    /// transactions are performed to integrate downloaded changesets into the
+    /// client-side Realm, that is associated with this session.
+    ///
+    /// The callback function will always be called by the thread that executes
+    /// the event loop (Client::run()), but not until bind() is called. If the
+    /// callback function throws an exception, that exception will "travel" out
+    /// through Client::run().
+    ///
+    /// Note: Any call to this function must have returned before bind() is
+    /// called. If this function is called multiple times, each call overrides
+    /// the previous setting.
+    ///
+    /// Note: This function is **not thread-safe**. That is, it is an error if
+    /// it is called while another thread is executing any member function on
+    /// the same Session object.
+    ///
+    /// CAUTION: The specified callback function may get called before the call
+    /// to bind() returns, and it may get called (or continue to execute) after
+    /// the session object is destroyed. Please see "Callback semantics" section
+    /// under Session for more on this.
+    void set_sync_transact_callback(std::function<SyncTransactCallback>);
+
+    /// \brief Set a handler to monitor the state of download and upload
+    /// progress.
+    ///
+    /// The handler must have signature
+    ///
+    ///     void(uint_fast64_t downloaded_bytes, uint_fast64_t downloadable_bytes,
+    ///          uint_fast64_t uploaded_bytes, uint_fast64_t uploadable_bytes,
+    ///          uint_fast64_t progress_version);
+    ///
+    /// downloaded_bytes is the size in bytes of all downloaded changesets.
+    /// downloadable_bytes is equal to downloaded_bytes plus an estimate of
+    /// the size of the remaining server history.
+    ///
+    /// uploaded_bytes is the size in bytes of all locally produced changesets
+    /// that have been received and acknowledged by the server.
+    /// uploadable_bytes is the size in bytes of all locally produced changesets.
+    ///
+    /// Due to the nature of the merge rules, it is possible that the size of an
+    /// uploaded changeset uploaded from one client is not equal to the size of
+    /// the changesets that other clients will download.
+    ///
+    /// Typical uses of this function:
+    ///
+    /// Upload completion can be checked by
+    ///
+    ///    bool upload_complete = (uploaded_bytes == uploadable_bytes);
+    ///
+    /// Download completion could be checked by
+    ///
+    ///     bool download_complete = (downloaded_bytes == downloadable_bytes);
+    ///
+    /// However, download completion might never be reached because the server
+    /// can receive new changesets from other clients. downloadable_bytes can
+    /// decrease for two reasons: server side compaction and changesets of
+    /// local origin. Code using downloadable_bytes must not assume that it
+    /// is increasing.
+    ///
+    /// Upload progress can be calculated by caching an initial value of
+    /// uploaded_bytes from the last, or next, callback. Then
+    ///
+    ///     double upload_progress =
+    ///        (uploaded_bytes - initial_uploaded_bytes)
+    ///       -------------------------------------------
+    ///       (uploadable_bytes - initial_uploaded_bytes)
+    ///
+    /// Download progress can be calculates similarly:
+    ///
+    ///     double download_progress =
+    ///        (downloaded_bytes - initial_downloaded_bytes)
+    ///       -----------------------------------------------
+    ///       (downloadable_bytes - initial_downloaded_bytes)
+    ///
+    /// progress_version is 0 at the start of a session. When at least one
+    /// DOWNLOAD message has been received from the server, progress_version is
+    /// positive. progress_version can be used to ensure that the reported
+    /// progress contains information obtained from the server in the current
+    /// session. The server will send a message as soon as possible, and the
+    /// progress handler will eventually be called with a positive progress_version
+    /// unless the session is interrupted before a message from the server has
+    /// been received.
+    ///
+    /// The handler is called on the event loop thread.The handler after bind(),
+    /// after each DOWNLOAD message, and after each local transaction
+    /// (nonsync_transact_notify).
+    ///
+    /// set_progress_handler() is not thread safe and it must be called before
+    /// bind() is called. Subsequent calls to set_progress_handler() overwrite
+    /// the previous calls. Typically, this function is called once per session.
+    ///
+    /// CAUTION: The specified callback function may get called before the call
+    /// to bind() returns, and it may get called (or continue to execute) after
+    /// the session object is destroyed. Please see "Callback semantics" section
+    /// under Session for more on this.
+    void set_progress_handler(std::function<ProgressHandler>);
+
+    enum class ConnectionState { disconnected, connecting, connected };
+
+    /// \brief Information about an error causing a session to be temporarily
+    /// disconnected from the server.
+    ///
+    /// In general, the connection will be automatically reestablished
+    /// later. Whether this happens quickly, generally depends on \ref
+    /// is_fatal. If \ref is_fatal is true, it means that the error is deemed to
+    /// be of a kind that is likely to persist, and cause all future reconnect
+    /// attempts to fail. In that case, if another attempt is made at
+    /// reconnecting, the delay will be substantial (at least an hour).
+    ///
+    /// \ref error_code specifies the error that caused the connection to be
+    /// closed. For the list of errors reported by the server, see \ref
+    /// ProtocolError (or `protocol.md`). For the list of errors corresponding
+    /// to protocol violations that are detected by the client, see
+    /// Client::Error. The error may also be a system level error, or an error
+    /// from one of the potential intermediate protocol layers (SSL or
+    /// WebSocket).
+    ///
+    /// \ref detailed_message is the most detailed message available to describe
+    /// the error. It is generally equal to `error_code.message()`, but may also
+    /// be a more specific message (one that provides extra context). The
+    /// purpose of this message is mostly to aid in debugging. For non-debugging
+    /// purposes, `error_code.message()` should generally be considered
+    /// sufficient.
+    ///
+    /// \sa set_connection_state_change_listener().
+    struct ErrorInfo {
+        std::error_code error_code;
+        bool is_fatal;
+        const std::string& detailed_message;
+    };
+
+    using ConnectionStateChangeListener = void(ConnectionState, const ErrorInfo*);
+
+    /// \brief Install a connection state change listener.
+    ///
+    /// Sets a function to be called whenever the state of the underlying
+    /// network connection changes between "disconnected", "connecting", and
+    /// "connected". The initial state is always "disconnected". The next state
+    /// after "disconnected" is always "connecting". The next state after
+    /// "connecting" is either "connected" or "disconnected". The next state
+    /// after "connected" is always "disconnected". A switch to the
+    /// "disconnected" state only happens when an error occurs.
+    ///
+    /// Whenever the installed function is called, an ErrorInfo object is passed
+    /// when, and only when the passed state is ConnectionState::disconnected.
+    ///
+    /// When multiple sessions share a single connection, the state changes will
+    /// be reported for each session in turn.
+    ///
+    /// The callback function will always be called by the thread that executes
+    /// the event loop (Client::run()), but not until bind() is called. If the
+    /// callback function throws an exception, that exception will "travel" out
+    /// through Client::run().
+    ///
+    /// Note: Any call to this function must have returned before bind() is
+    /// called. If this function is called multiple times, each call overrides
+    /// the previous setting.
+    ///
+    /// Note: This function is **not thread-safe**. That is, it is an error if
+    /// it is called while another thread is executing any member function on
+    /// the same Session object.
+    ///
+    /// CAUTION: The specified callback function may get called before the call
+    /// to bind() returns, and it may get called (or continue to execute) after
+    /// the session object is destroyed. Please see "Callback semantics" section
+    /// under Session for more on this.
+    void set_connection_state_change_listener(std::function<ConnectionStateChangeListener>);
+
+    //@{
+    /// Deprecated! Use set_connection_state_change_listener() instead.
+    using ErrorHandler = void(std::error_code, bool is_fatal, const std::string& detailed_message);
+    void set_error_handler(std::function<ErrorHandler>);
+    //@}
+
+    /// @{ \brief Bind this session to the specified server side Realm.
+    ///
+    /// No communication takes place on behalf of this session before the
+    /// session is bound, but as soon as the session becomes bound, the server
+    /// will start to push changes to the client, and vice versa.
+    ///
+    /// If a callback function was set using set_sync_transact_callback(), then
+    /// that callback function will start to be called as changesets are
+    /// downloaded and integrated locally. It is important to understand that
+    /// callback functions are executed by the event loop thread (Client::run())
+    /// and the callback function may therefore be called before bind() returns.
+    ///
+    /// Note: It is an error if this function is called more than once per
+    /// Session object.
+    ///
+    /// Note: This function is **not thread-safe**. That is, it is an error if
+    /// it is called while another thread is executing any member function on
+    /// the same Session object.
+    ///
+    /// bind() binds this session to the specified server side Realm using the
+    /// parameters specified in the Session::Config object.
+    ///
+    /// The two other forms of bind() are convenience functions.
+    /// void bind(std::string server_address, std::string server_path,
+    ///           std::string signed_user_token, port_type server_port = 0,
+    ///           ProtocolEnvelope protocol = ProtocolEnvelope::realm);
+    /// replaces the corresponding parameters from the Session::Config object
+    /// before the session is bound.
+    /// void bind(std::string server_url, std::string signed_user_token) parses
+    /// the \param server_url and replaces the parameters in the Session::Config object
+    /// before the session is bound.
+    ///
+    /// \param server_url For example "realm://sync.realm.io/test". See
+    /// server_address, server_path, and server_port in Session::Config for
+    /// information about the individual components of the URL. See
+    /// ProtocolEnvelope for the list of available URL schemes and the
+    /// associated default ports.
+    ///
+    /// \throw BadServerUrl if the specified server URL is malformed.
+    void bind();
+    void bind(std::string server_url, std::string signed_user_token);
+    void bind(std::string server_address, std::string server_path,
+              std::string signed_user_token, port_type server_port = 0,
+              ProtocolEnvelope protocol = ProtocolEnvelope::realm);
+    /// @}
+
+    /// \brief Refresh the access token associated with this session.
+    ///
+    /// This causes the REFRESH protocol message to be sent to the server. See
+    /// ProtocolEnvelope. It is an error to pass a token with a different user
+    /// identity than the token used to initiate the session.
+    ///
+    /// In an on-going session the application may expect the access token to
+    /// expire at a certain time and schedule acquisition of a fresh access
+    /// token (using a refresh token or by other means) in due time to provide a
+    /// better user experience, and seamless connectivity to the server.
+    ///
+    /// If the application does not proactively refresh an expiring token, the
+    /// session will eventually be disconnected. The application can detect this
+    /// by monitoring the connection state
+    /// (set_connection_state_change_listener()), and check whether the error
+    /// code is `ProtocolError::token_expired`. Such a session can then be
+    /// revived by calling refresh() with a newly acquired access token.
+    ///
+    /// Due to protocol techicalities, a race condition exists that can cause a
+    /// session to become, and remain disconnected after a new access token has
+    /// been passed to refresh(). The application can work around this race
+    /// condition by detecting the `ProtocolError::token_expired` error, and
+    /// always initiate a token renewal in this case.
+    ///
+    /// It is an error to call this function before calling `Client::bind()`.
+    ///
+    /// Note: This function is thread-safe.
+    ///
+    /// \param signed_user_token A cryptographically signed token describing the
+    /// identity and access rights of the current user. See ProtocolEnvelope.
+    void refresh(std::string signed_user_token);
+
+    /// \brief Inform the synchronization agent about changes of local origin.
+    ///
+    /// This function must be called by the application after a transaction
+    /// performed on its behalf, that is, after a transaction that is not
+    /// performed to integrate a changeset that was downloaded from the server.
+    ///
+    /// It is an error to call this function before bind() has been called, and
+    /// has returned.
+    ///
+    /// Note: This function is fully thread-safe. That is, it may be called by
+    /// any thread, and by multiple threads concurrently.
+    void nonsync_transact_notify(version_type new_version);
+
+    /// @{ \brief Wait for upload, download, or upload+download completion.
+    ///
+    /// async_wait_for_upload_completion() initiates an asynchronous wait for
+    /// upload to complete, async_wait_for_download_completion() initiates an
+    /// asynchronous wait for download to complete, and
+    /// async_wait_for_sync_completion() initiates an asynchronous wait for
+    /// upload and download to complete.
+    ///
+    /// Upload is considered complete when all non-empty changesets of local
+    /// origin have been uploaded to the server, and the server has acknowledged
+    /// reception of them. Changesets of local origin introduced after the
+    /// initiation of the session (after bind() is called) will generally not be
+    /// considered for upload unless they are announced to this client through
+    /// nonsync_transact_notify() prior to the initiation of the wait operation,
+    /// i.e., prior to the invocation of async_wait_for_upload_completion() or
+    /// async_wait_for_sync_completion(). Unannounced changesets may get picked
+    /// up, but there is no guarantee that they will be, however, if a certain
+    /// changeset is announced, then all previous changesets are implicitly
+    /// announced. Also all preexisting changesets are implicitly announced
+    /// when the session is initiated.
+    ///
+    /// Download is considered complete when all non-empty changesets of remote
+    /// origin have been downloaded from the server, and integrated into the
+    /// local Realm state. To know what is currently outstanding on the server,
+    /// the client always sends a special "marker" message to the server, and
+    /// waits until it has downloaded all outstanding changesets that were
+    /// present on the server at the time when the server received that marker
+    /// message. Each call to async_wait_for_download_completion() and
+    /// async_wait_for_sync_completion() therefore requires a full client <->
+    /// server round-trip.
+    ///
+    /// If a new wait operation is initiated while another wait operation is in
+    /// progress by another thread, the waiting period of first operation may,
+    /// or may not get extended. The application must not assume either. The
+    /// application may assume, however, that async_wait_for_upload_completion()
+    /// will not affect the waiting period of
+    /// async_wait_for_download_completion(), and vice versa.
+    ///
+    /// It is an error to call these functions before bind() has been called,
+    /// and has returned.
+    ///
+    /// The specified completion handlers will always be executed by the thread
+    /// that executes the event loop (the thread that calls Client::run()). If
+    /// the handler throws an exception, that exception will "travel" out
+    /// through Client::run().
+    ///
+    /// If incomplete wait operations exist when the session is terminated,
+    /// those wait operations will be canceled. Session termination is an event
+    /// that happens in the context of the client's event loop thread shortly
+    /// after the destruction of the session object. The std::error_code
+    /// argument passed to the completion handler of a canceled wait operation
+    /// will be `util::error::operation_aborted`. For uncanceled wait operations
+    /// it will be `std::error_code{}`. Note that as long as the client's event
+    /// loop thread is running, all completion handlers will be called
+    /// regardless of whether the operations get canceled or not.
+    ///
+    /// CAUTION: The specified completion handlers may get called before the
+    /// call to the waiting function returns, and it may get called (or continue
+    /// to execute) after the session object is destroyed. Please see "Callback
+    /// semantics" section under Session for more on this.
+    ///
+    /// Note: These functions are fully thread-safe. That is, they may be called
+    /// by any thread, and by multiple threads concurrently.
+    void async_wait_for_sync_completion(WaitOperCompletionHandler);
+    void async_wait_for_upload_completion(WaitOperCompletionHandler);
+    void async_wait_for_download_completion(WaitOperCompletionHandler);
+    /// @}
+
+    /// @{ \brief Synchronous wait for upload or download completion.
+    ///
+    /// These functions are synchronous equivalents of
+    /// async_wait_for_upload_completion() and
+    /// async_wait_for_download_completion() respectively. This means that they
+    /// block the caller until the completion condition is satisfied, or the
+    /// client's event loop thread exits from Client::run(), whichever happens
+    /// first.
+    ///
+    /// It is an error to call these functions before bind() has been called,
+    /// and has returned.
+    ///
+    /// CAUTION: If Client::run() returns while a wait operation is in progress,
+    /// these waiting functions return immediately, even if the completion
+    /// condition is not yet satisfied. The completion condition is guaranteed
+    /// to be satisfied only when these functions return true.
+    ///
+    /// \return True only if the completion condition was satisfied. False if
+    /// the client's event loop thread exited from Client::run() in which case
+    /// the completion condition may, or may not have been satisfied.
+    ///
+    /// Note: These functions are fully thread-safe. That is, they may be called
+    /// by any thread, and by multiple threads concurrently.
+    bool wait_for_upload_complete_or_client_stopped();
+    bool wait_for_download_complete_or_client_stopped();
+    /// @}
+
+    /// \brief Cancel the current or next reconnect delay for the server
+    /// associated with this session.
+    ///
+    /// When the network connection is severed, or an attempt to establish
+    /// connection fails, a certain delay will take effect before the client
+    /// will attempt to reestablish the connection. This delay will generally
+    /// grow with the number of unsuccessful reconnect attempts, and can grow to
+    /// over a minute. In some cases however, the application will know when it
+    /// is a good time to stop waiting and retry immediately. One example is
+    /// when a device has been offline for a while, and the operating system
+    /// then tells the application that network connectivity has been restored.
+    ///
+    /// Clearly, this function should not be called too often and over extended
+    /// periods of time, as that would effectively disable the built-in "server
+    /// hammering" protection.
+    ///
+    /// It is an error to call this function before bind() has been called, and
+    /// has returned.
+    ///
+    /// This function is fully thread-safe. That is, it may be called by any
+    /// thread, and by multiple threads concurrently.
+    void cancel_reconnect_delay();
+
+    /// \brief Change address of server for this session.
+    void override_server(std::string address, port_type);
+
+    /// \brief Initiate a serialized transaction.
+    ///
+    /// Asynchronously waits for completion of any serialized transactions, that
+    /// are already in progress via the same session object, then waits for
+    /// the download process to complete (async_wait_for_download_completion()),
+    /// then pauses the upload process. The upload process will be resumed when
+    /// async_try_complete_serial_transact() or abort_serial_transact() is
+    /// called.
+    ///
+    /// Changesets produced by local transactions, that are committed after the
+    /// completion of the initiation of a serialized transaction, are guaranteed
+    /// to not be uploaded until after (or during) the completion of that
+    /// serialized transaction (async_try_complete_serial_transact()).
+    ///
+    /// If the initiation of a serialized transaction is successfully completed,
+    /// that is, if the specified handler gets called with an std::error_code
+    /// argument that evaluates to false in a boolean context, then the
+    /// application is required to eventually call
+    /// async_try_complete_serial_transact() to complete the transaction, or
+    /// abort_serial_transact() to abort it. If
+    /// async_try_complete_serial_transact() fails (throws), the application is
+    /// required to follow up with a call to abort_serial_transact().
+    ///
+    /// If the session object is destroyed before initiation process completes,
+    /// the specified handler will be called with error
+    /// `util::error::operation_aborted`. Currently, this is the only possible
+    /// error that can be reported through this handler.
+    ///
+    /// This feature is only available when the server supports version 28, or
+    /// later, of the synchronization protocol. See
+    /// get_current_protocol_version().
+    ///
+    /// This feature is not currently supported with Partial Synchronization,
+    /// and in a server cluster, it is currently only supported on the root
+    /// node.
+    void async_initiate_serial_transact(SerialTransactInitiationHandler);
+
+    /// \brief Complete a serialized transaction.
+    ///
+    /// Initiate the completion of the serialized transaction. This involves
+    /// sending the specified changeset to the server, and waiting for the
+    /// servers response.
+    ///
+    /// If the session object is destroyed before completion process completes,
+    /// the specified handler will be called with error
+    /// `util::error::operation_aborted`.
+    ///
+    /// Otherwise, if the server does not support serialized transactions, the
+    /// specified handler will be called with error
+    /// `util::MiscExtErrors::operation_not_supported`. This happens if the
+    /// negotiated protocol version is too old, if serialized transactions are
+    /// disallowed by the server, or if it is not allowed for the Realm file in
+    /// question (partial synchronization).
+    ///
+    /// Otherwise, the specified handler will be called with an error code
+    /// argument that evaluates to false in a boolean context, and the
+    /// `accepted` argument will be true if, and only if the transaction was
+    /// accepted by the server.
+    ///
+    /// \param upload_anchor The upload cursor associated with the snapshot on
+    /// which the specified changeset is based. Use
+    /// sync::ClientHistory::get_upload_anchor_of_current_transact() to obtain
+    /// it. Note that
+    /// sync::ClientHistory::get_upload_anchor_of_current_transact() needs to be
+    /// called during the transaction that is used to produce the changeset of
+    /// the serialized transaction.
+    ///
+    /// \param changeset A changeset obtained from an aborted transaction on the
+    /// Realm file associated with this session. Use
+    /// sync::ClientHistory::get_sync_changeset() to obtain it. The transaction,
+    /// which is used to produce teh changeset, needs to be rolled back rather
+    /// than committed, because the decision of whether to accept the changes
+    /// need to be delegated to the server. Note that
+    /// sync::ClientHistory::get_sync_Changeset_of_current_transact() needs to
+    /// be called at the end of the transaction, that is used to produce the
+    /// changeset, but before the rollback operation.
+    void async_try_complete_serial_transact(UploadCursor upload_anchor,
+                                            SerialTransactChangeset changeset,
+                                            SerialTransactCompletionHandler);
+
+    /// \brief Abort a serialized transaction.
+    ///
+    /// Must be called if async_try_complete_serial_transact() fails, i.e., if
+    /// it throws, or if async_try_complete_serial_transact() is not called at
+    /// all. Must not be called if async_try_complete_serial_transact()
+    /// succeeds, i.e., if it does not throw.
+    ///
+    /// Will resume upload process.
+    void abort_serial_transact() noexcept;
+
+private:
+    class Impl;
+    Impl* m_impl = nullptr;
+
+    void abandon() noexcept;
+    void async_wait_for(bool upload_completion, bool download_completion,
+                        WaitOperCompletionHandler);
+};
+
+
+/// \brief Protocol errors discovered by the client.
+///
+/// These errors will terminate the network connection (disconnect all sessions
+/// associated with the affected connection), and the error will be reported to
+/// the application via the connection state change listeners of the affected
+/// sessions.
+enum class Client::Error {
+    connection_closed           = 100, ///< Connection closed (no error)
+    unknown_message             = 101, ///< Unknown type of input message
+    bad_syntax                  = 102, ///< Bad syntax in input message head
+    limits_exceeded             = 103, ///< Limits exceeded in input message
+    bad_session_ident           = 104, ///< Bad session identifier in input message
+    bad_message_order           = 105, ///< Bad input message order
+    bad_client_file_ident       = 106, ///< Bad client file identifier (IDENT)
+    bad_progress                = 107, ///< Bad progress information (DOWNLOAD)
+    bad_changeset_header_syntax = 108, ///< Bad syntax in changeset header (DOWNLOAD)
+    bad_changeset_size          = 109, ///< Bad changeset size in changeset header (DOWNLOAD)
+    bad_origin_file_ident       = 110, ///< Bad origin file identifier in changeset header (DOWNLOAD)
+    bad_server_version          = 111, ///< Bad server version in changeset header (DOWNLOAD)
+    bad_changeset               = 112, ///< Bad changeset (DOWNLOAD)
+    bad_request_ident           = 113, ///< Bad request identifier (MARK)
+    bad_error_code              = 114, ///< Bad error code (ERROR),
+    bad_compression             = 115, ///< Bad compression (DOWNLOAD)
+    bad_client_version          = 116, ///< Bad last integrated client version in changeset header (DOWNLOAD)
+    ssl_server_cert_rejected    = 117, ///< SSL server certificate rejected
+    pong_timeout                = 118, ///< Timeout on reception of PONG respone message
+    bad_client_file_ident_salt  = 119, ///< Bad client file identifier salt (IDENT)
+    bad_file_ident              = 120, ///< Bad file identifier (ALLOC)
+    connect_timeout             = 121, ///< Sync connection was not fully established in time
+    bad_timestamp               = 122, ///< Bad timestamp (PONG)
+    bad_protocol_from_server    = 123, ///< Bad or missing protocol version information from server
+    client_too_old_for_server   = 124, ///< Protocol version negotiation failed: Client is too old for server
+    client_too_new_for_server   = 125, ///< Protocol version negotiation failed: Client is too new for server
+    protocol_mismatch           = 126, ///< Protocol version negotiation failed: No version supported by both client and server
+    bad_state_message           = 127, ///< Bad values in state message (STATE)
+    missing_protocol_feature    = 128, ///< Requested feature missing in negotiated protocol version
+    bad_serial_transact_status  = 129, ///< Bad status of serialized transaction (TRANSACT)
+    bad_object_id_substitutions = 130, ///< Bad encoded object identifier substitutions (TRANSACT)
+    http_tunnel_failed          = 131, ///< Failed to establish HTTP tunnel with configured proxy
+};
+
+const std::error_category& client_error_category() noexcept;
+
+std::error_code make_error_code(Client::Error) noexcept;
+
+std::ostream& operator<<(std::ostream& os, Session::Config::ProxyConfig::Type);
+
+} // namespace sync
+} // namespace realm
+
+namespace std {
+
+template<> struct is_error_code_enum<realm::sync::Client::Error> {
+    static const bool value = true;
+};
+
+} // namespace std
+
+namespace realm {
+namespace sync {
+
+
+
+// Implementation
+
+class BadServerUrl: public std::exception {
+public:
+    const char* what() const noexcept override
+    {
+        return "Bad server URL";
+    }
+};
+
+inline Session::Session(Session&& sess) noexcept:
+    m_impl{sess.m_impl}
+{
+    sess.m_impl = nullptr;
+}
+
+inline Session::Session() noexcept
+{
+}
+
+inline Session::~Session() noexcept
+{
+    if (m_impl)
+        abandon();
+}
+
+inline Session& Session::operator=(Session&& sess) noexcept
+{
+    if (m_impl)
+        abandon();
+    m_impl = sess.m_impl;
+    sess.m_impl = nullptr;
+    return *this;
+}
+
+inline void Session::detach() noexcept
+{
+    if (m_impl)
+        abandon();
+    m_impl = nullptr;
+}
+
+inline void Session::set_error_handler(std::function<ErrorHandler> handler)
+{
+    auto handler_2 = [handler=std::move(handler)](ConnectionState state,
+                                                  const ErrorInfo* error_info) {
+        if (state != ConnectionState::disconnected)
+            return;
+        REALM_ASSERT(error_info);
+        std::error_code ec = error_info->error_code;
+        bool is_fatal = error_info->is_fatal;
+        const std::string& detailed_message = error_info->detailed_message;
+        handler(ec, is_fatal, detailed_message); // Throws
+    };
+    set_connection_state_change_listener(std::move(handler_2)); // Throws
+}
+
+inline void Session::async_wait_for_sync_completion(WaitOperCompletionHandler handler)
+{
+    bool upload_completion = true, download_completion = true;
+    async_wait_for(upload_completion, download_completion, std::move(handler)); // Throws
+}
+
+inline void Session::async_wait_for_upload_completion(WaitOperCompletionHandler handler)
+{
+    bool upload_completion = true, download_completion = false;
+    async_wait_for(upload_completion, download_completion, std::move(handler)); // Throws
+}
+
+inline void Session::async_wait_for_download_completion(WaitOperCompletionHandler handler)
+{
+    bool upload_completion = false, download_completion = true;
+    async_wait_for(upload_completion, download_completion, std::move(handler)); // Throws
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_CLIENT_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/crypto.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/crypto.hpp
new file mode 100644
index 0000000..40ade0e
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/crypto.hpp
@@ -0,0 +1,51 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_CRYPTO_HPP
+#define REALM_SYNC_CRYPTO_HPP
+
+#include <memory>
+#include <stdexcept>
+
+#include <realm/binary_data.hpp>
+#include <realm/util/buffer.hpp>
+
+namespace realm {
+namespace sync {
+namespace crypto {
+
+/// The digest functions calculate the message digest of the input in \param
+/// in_buffer of size \param in_buffer_size. The digest is placed in \param
+/// out_buffer. The caller must guarantee that the output buffer is large
+/// enough to contain the digest.
+///
+/// The functions throw if the underlying platform dependent implementations
+/// throw. Typically, exceptions are "out of memory" errors.
+///
+/// sha1() calculates the SHA-1 hash value of output size 20.
+/// sha256() calculates the SHA-256 hash value of output size 32.
+void sha1(const char* in_buffer, size_t in_buffer_size, unsigned char* out_buffer);
+void sha256(const char* in_buffer, size_t in_buffer_size, unsigned char* out_buffer);
+
+} // namespace crypto
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_CRYPTO_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/crypto_server.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/crypto_server.hpp
new file mode 100644
index 0000000..c241a71
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/crypto_server.hpp
@@ -0,0 +1,91 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_CRYPTO_SERVER_HPP
+#define REALM_SYNC_CRYPTO_SERVER_HPP
+
+#include <memory>
+#include <stdexcept>
+
+#include <realm/binary_data.hpp>
+#include <realm/util/buffer.hpp>
+
+namespace realm {
+namespace sync {
+
+struct CryptoError: std::runtime_error {
+    CryptoError(std::string message) : std::runtime_error(std::move(message)) {}
+};
+
+/// This class represents a public/private keypair, or more commonly a single public
+/// key used for verifying signatures.
+///
+/// Only RSA keys are supported for now.
+///
+/// Its methods correspond roughly to the EVP_PKEY_* set of functionality found in
+/// the OpenSSL library.
+class PKey {
+public:
+    PKey(PKey&&);
+    PKey& operator=(PKey&&);
+    ~PKey();
+
+    /// Load RSA public key from \a pemfile.
+    static PKey load_public(const std::string& pemfile);
+    /// Load RSA public key from a PEM buffer
+    static PKey load_public(BinaryData pem_buffer);
+
+    /// Load RSA public/private keypair from \a pemfile.
+    static PKey load_private(const std::string& pemfile);
+    /// Load RSA public/private keypair from a PEM buffer
+    static PKey load_private(BinaryData pem_buffer);
+
+    /// Whether or not the key can be used for signing.
+    ///
+    /// True if the private part is loaded.
+    bool can_sign() const noexcept;
+
+    /// Whether or not the key can be used for verifying.
+    ///
+    /// Always true for RSA keys.
+    bool can_verify() const noexcept;
+
+    /// Sign \a message with the loaded key, if the private part is
+    /// loaded. Store the signed message as binary data in \a signature.
+    ///
+    /// If a private key is not loaded, throws an exception of type CryptoError.
+    void sign(BinaryData message, util::Buffer<unsigned char>& signature) const;
+
+    /// Verify that \a signature is a valid digest of \a message.
+    ///
+    /// Returns true if the signature is valid, otherwise false. If an error occurs while
+    /// attempting verification, an exception of type CryptoError is thrown.
+    bool verify(BinaryData message, BinaryData signature) const;
+
+private:
+    PKey();
+    struct Impl;
+    std::unique_ptr<Impl> m_impl;
+};
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_CRYPTO_SERVER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/feature_token.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/feature_token.hpp
new file mode 100644
index 0000000..86db015
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/feature_token.hpp
@@ -0,0 +1,69 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2012] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_SYNC_FEATURE_TOKEN_HPP
+#define REALM_SYNC_FEATURE_TOKEN_HPP
+
+#include <realm/util/features.h>
+
+#if !REALM_MOBILE && !defined(REALM_EXCLUDE_FEATURE_TOKENS)
+#define REALM_HAVE_FEATURE_TOKENS 1
+#else
+#define REALM_HAVE_FEATURE_TOKENS 0
+#endif
+
+#if REALM_HAVE_FEATURE_TOKENS
+
+#include <memory>
+
+#include <realm/string_data.hpp>
+
+namespace realm {
+namespace sync {
+
+class FeatureGate {
+public:
+
+    // The constructor takes a JWT token as argument.
+    // The constructor throws a std::runtime_error if
+    // the token is invalid. An invalid token is a token
+    // that has bad syntax, is not signed by Realm, or is 
+    // expired.
+    FeatureGate(StringData token);
+
+    // Constructs a feature gate without any features.
+    FeatureGate();
+    ~FeatureGate();
+
+    FeatureGate(FeatureGate&&);
+    FeatureGate& operator=(FeatureGate&&);
+
+    bool has_feature(StringData feature_name);
+
+private:
+    struct Impl;
+    std::unique_ptr<Impl> m_impl;
+};
+
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_HAVE_FEATURE_TOKENS
+#endif // REALM_SYNC_FEATURE_TOKEN_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/fingerprint.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/fingerprint.hpp
new file mode 100644
index 0000000..13b54ab
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/fingerprint.hpp
@@ -0,0 +1,53 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_ENCRYPT_FINGERPRINT_HPP
+#define REALM_ENCRYPT_FINGERPRINT_HPP
+
+#include <string>
+#include <array>
+
+#include <realm/util/optional.hpp>
+
+namespace realm {
+namespace encrypt {
+
+// calculate_fingerprint() calculates, and returns, a fingerprint of an
+// encryption key. The input key can be util::none in order to calculate a
+// fingerprint even in the case of unencrypted Realms.
+//
+// An intruder cannot recover an unknown encryption_key from the fingerprint,
+// and it is safe to save the fingerprint in a file together with the encrypted
+// Realms.
+//
+// calculate_fingerprint() can be considered opaque, but currently the
+// fingerprint is a colon separated hex representation of the SHA-256 hash of
+// the encryption key.
+std::string calculate_fingerprint(const util::Optional<std::array<char, 64>> encryption_key);
+
+// verify_fingerprint() returns true if `fingerprint` was obtained previously
+// from calculate_fingerprint() with `encryption_key` as argument.  Otherwise,
+// verify_fingerprint() returns false with extremely high probability.
+bool verify_fingerprint(const std::string& fingerprint,
+                        const util::Optional<std::array<char, 64>> encryption_key);
+
+} // namespace encrypt
+} // namespace realm
+
+#endif // REALM_ENCRYPT_FINGERPRINT_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/history.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/history.hpp
new file mode 100644
index 0000000..5fc571f
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/history.hpp
@@ -0,0 +1,613 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#include <cstdint>
+#include <memory>
+#include <chrono>
+#include <string>
+
+#include <realm/util/string_view.hpp>
+#include <realm/impl/cont_transact_hist.hpp>
+#include <realm/sync/instruction_replication.hpp>
+#include <realm/sync/protocol.hpp>
+#include <realm/sync/transform.hpp>
+#include <realm/sync/object_id.hpp>
+#include <realm/sync/instructions.hpp>
+
+#ifndef REALM_SYNC_HISTORY_HPP
+#define REALM_SYNC_HISTORY_HPP
+
+
+namespace realm {
+namespace _impl {
+
+struct ObjectIDHistoryState;
+
+} // namespace _impl
+} // namespace realm
+
+
+namespace realm {
+namespace sync {
+
+struct VersionInfo {
+    /// Realm snapshot version.
+    version_type realm_version = 0;
+
+    /// The synchronization version corresponding to `realm_version`.
+    ///
+    /// In the context of the client-side history type `sync_version.version`
+    /// will currently always be equal to `realm_version` and
+    /// `sync_version.salt` will always be zero.
+    SaltedVersion sync_version = {0, 0};
+};
+
+
+struct SerialTransactSubstitutions {
+    struct Class {
+        InternString name;
+        std::size_t substitutions_end;
+    };
+    std::vector<Class> classes;
+    std::vector<std::pair<ObjectID, ObjectID>> substitutions;
+};
+
+
+timestamp_type generate_changeset_timestamp() noexcept;
+
+// FIXME: in C++17, switch to using std::timespec in place of last two
+// arguments.
+void map_changeset_timestamp(timestamp_type, std::time_t& seconds_since_epoch,
+                             long& nanoseconds) noexcept;
+
+
+/// Thrown if changeset cooking is not either consistently on or consistently
+/// off during synchronization (ClientHistory::set_sync_progress() and
+/// ClientHistory::integrate_server_changesets()).
+class InconsistentUseOfCookedHistory;
+
+/// Thrown if a bad server version is passed to
+/// ClientHistory::get_cooked_status().
+class BadCookedServerVersion;
+
+
+class ClientHistoryBase :
+        public InstructionReplication {
+public:
+    using SyncTransactCallback = void(VersionID old_version, VersionID new_version);
+
+    /// Get the version of the latest snapshot of the associated Realm, as well
+    /// as the client file identifier and the synchronization progress as they
+    /// are stored in that snapshot.
+    ///
+    /// The returned current client version is the version produced by the last
+    /// changeset in the history. The type of version returned here, is the one
+    /// that identifies an entry in the sync history. Whether this is the same
+    /// as the snapshot number of the Realm file depends on the history
+    /// implementation.
+    ///
+    /// The returned client file identifier is the one that was last stored by
+    /// set_client_file_ident(), or `SaltedFileIdent{0, 0}` if
+    /// set_client_file_ident() has never been called.
+    ///
+    /// The returned SyncProgress is the one that was last stored by
+    /// set_sync_progress(), or `SyncProgress{}` if set_sync_progress() has
+    /// never been called.
+    virtual void get_status(version_type& current_client_version,
+                            SaltedFileIdent& client_file_ident,
+                            SyncProgress& progress) const = 0;
+
+    /// Stores the server assigned client file identifier in the associated
+    /// Realm file, such that it is available via get_status() during future
+    /// synchronization sessions. It is an error to set this identifier more
+    /// than once per Realm file.
+    ///
+    /// \param client_file_ident The server assigned client-side file
+    /// identifier. A client-side file identifier is a non-zero positive integer
+    /// strictly less than 2**64. The server guarantees that all client-side
+    /// file identifiers generated on behalf of a particular server Realm are
+    /// unique with respect to each other. The server is free to generate
+    /// identical identifiers for two client files if they are associated with
+    /// different server Realms.
+    ///
+    /// \param fix_up_object_ids The object ids that depend on client file ident
+    /// will be fixed in both state and history if this parameter is true. If
+    /// it is known that there are no objects to fix, it can be set to false to
+    /// achieve higher performance.
+    ///
+    /// The client is required to obtain the file identifier before engaging in
+    /// synchronization proper, and it must store the identifier and use it to
+    /// reestablish the connection between the client file and the server file
+    /// when engaging in future synchronization sessions.
+    virtual void set_client_file_ident(SaltedFileIdent client_file_ident,
+                                       bool fix_up_object_ids) = 0;
+
+    /// Stores the synchronization progress in the associated Realm file in a
+    /// way that makes it available via get_status() during future
+    /// synchronization sessions. Progress is reported by the server in the
+    /// DOWNLOAD message.
+    ///
+    /// See struct SyncProgress for a description of \a progress.
+    ///
+    /// \param downloadable_bytes If specified, and if the implementation cares
+    /// about byte-level progress, this function updates the persistent record
+    /// of the estimate of the number of remaining bytes to be downloaded.
+    ///
+    /// \throw InconsistentUseOfCookedHistory If a changeset cooker has been
+    /// attached to this history object, and the Realm file does not have a
+    /// cooked history, and a cooked history can no longer be added because some
+    /// synchronization has already happened. Or if no changeset cooker has been
+    /// attached, and the Realm file does have a cooked history.
+    virtual void set_sync_progress(const SyncProgress& progress,
+                                   const std::uint_fast64_t* downloadable_bytes, VersionInfo&) = 0;
+
+    struct UploadChangeset {
+        timestamp_type origin_timestamp;
+        file_ident_type origin_file_ident;
+        UploadCursor progress;
+        ChunkedBinaryData changeset;
+        std::unique_ptr<char[]> buffer;
+    };
+
+    /// \brief Scan through the history for changesets to be uploaded.
+    ///
+    /// This function scans the history for changesets to be uploaded, i.e., for
+    /// changesets that are not empty, and were not produced by integration of
+    /// changesets recieved from the server. The scan begins at the position
+    /// specified by the initial value of \a upload_progress.client_version, and
+    /// ends no later than at the position specified by \a end_version.
+    ///
+    /// The implementation is allowed to end the scan before \a end_version,
+    /// such as to limit the combined size of returned changesets. However, if
+    /// the specified range contains any changesets that are supposed to be
+    /// uploaded, this function must return at least one.
+    ///
+    /// Upon return, \a upload_progress will have been updated to point to the
+    /// position from which the next scan should resume. This must be a position
+    /// after the last returned changeset, and before any remaining changesets
+    /// that are supposed to be uploaded, although never a position that
+    /// succeeds \a end_version.
+    ///
+    /// The value passed as \a upload_progress by the caller, must either be one
+    /// that was produced by an earlier invocation of
+    /// find_uploadable_changesets(), one that was returned by get_status(), or
+    /// one that was received by the client in a DOWNLOAD message from the
+    /// server. When the value comes from a DOWNLOAD message, it is supposed to
+    /// reflect a value of UploadChangeset::progress produced by an earlier
+    /// invocation of find_uploadable_changesets().
+    ///
+    /// Found changesets are added to \a uploadable_changesets.
+    ///
+    /// \param locked_server_version will be set to the value that should be
+    /// used as `<locked server version>` in a DOWNLOAD message.
+    ///
+    /// For changesets of local origin, UploadChangeset::origin_file_ident will
+    /// be zero.
+    virtual void find_uploadable_changesets(UploadCursor& upload_progress, version_type end_version,
+                                            std::vector<UploadChangeset>& uploadable_changesets,
+                                            version_type& locked_server_version) const = 0;
+
+    using RemoteChangeset = Transformer::RemoteChangeset;
+
+    // FIXME: Apparently, this feature is expected by object store, but why?
+    // What is it ultimately used for? (@tgoyne)
+    class SyncTransactReporter {
+    public:
+        virtual void report_sync_transact(VersionID old_version, VersionID new_version) = 0;
+    protected:
+        ~SyncTransactReporter() {}
+    };
+
+    enum class IntegrationError {
+        bad_origin_file_ident,
+        bad_changeset
+    };
+
+    /// \brief Integrate a sequence of changesets received from the server using
+    /// a single Realm transaction.
+    ///
+    /// Each changeset will be transformed as if by a call to
+    /// Transformer::transform_remote_changeset(), and then applied to the
+    /// associated Realm.
+    ///
+    /// As a final step, each changeset will be added to the local history (list
+    /// of applied changesets).
+    ///
+    /// This function checks whether the specified changesets specify valid
+    /// remote origin file identifiers and whether the changesets contain valid
+    /// sequences of instructions. The caller must already have ensured that the
+    /// origin file identifiers are strictly positive and not equal to the file
+    /// identifier assigned to this client by the server.
+    ///
+    /// If any of the changesets are invalid, this function returns false and
+    /// sets `integration_error` to the appropriate value. If they are all
+    /// deemed valid, this function updates \a version_info to reflect the new
+    /// version produced by the transaction.
+    ///
+    /// \param progress The synchronization progress is what was received in the
+    /// DOWNLOAD message along with the specified changesets. The progress will
+    /// be persisted along with the changesets.
+    ///
+    /// \param downloadable_bytes If specified, and if the implementation cares
+    /// about byte-level progress, this function updates the persistent record
+    /// of the estimate of the number of remaining bytes to be downloaded.
+    ///
+    /// \param num_changesets The number of passed changesets. Must be non-zero.
+    ///
+    /// \param transact_reporter An optional callback which will be called with the
+    /// version immediately processing the sync transaction and that of the sync
+    /// transaction.
+    ///
+    /// \throw InconsistentUseOfCookedHistory If a changeset cooker has been
+    /// attached to this history object, and the Realm file does not have a
+    /// cooked history, and a cooked history can no longer be added because some
+    /// synchronization has already happened. Or if no changeset cooker has been
+    /// attached, and the Realm file does have a cooked history.
+    virtual bool integrate_server_changesets(const SyncProgress& progress,
+                                             const std::uint_fast64_t* downloadable_bytes,
+                                             const RemoteChangeset* changesets,
+                                             std::size_t num_changesets, VersionInfo& new_version,
+                                             IntegrationError& integration_error, util::Logger&,
+                                             SyncTransactReporter* transact_reporter = nullptr,
+                                             const SerialTransactSubstitutions* = nullptr) = 0;
+
+protected:
+    ClientHistoryBase(const std::string& realm_path);
+};
+
+
+
+class ClientHistory : public ClientHistoryBase {
+public:
+    class ChangesetCooker;
+    class Config;
+
+    /// Get the persisted upload/download progress in bytes.
+    virtual void get_upload_download_bytes(std::uint_fast64_t& downloaded_bytes,
+                                           std::uint_fast64_t& downloadable_bytes,
+                                           std::uint_fast64_t& uploaded_bytes,
+                                           std::uint_fast64_t& uploadable_bytes,
+                                           std::uint_fast64_t& snapshot_version) = 0;
+
+    /// See set_cooked_progress().
+    struct CookedProgress {
+        std::int_fast64_t changeset_index = 0;
+        std::int_fast64_t intrachangeset_progress = 0;
+    };
+
+    /// Get information about the current state of the cooked history including
+    /// the point of progress of its consumption.
+    ///
+    /// \param server_version The server version associated with the last cooked
+    /// changeset that should be skipped. See `/doc/cooked_history.md` for an
+    /// explanation of the rationale behind this. Specifying zero means that no
+    /// changesets should be skipped. It is an error to specify a nonzero server
+    /// version that is not the server version associated with any of of the
+    /// cooked changesets, or to specify a nonzero server version that precedes
+    /// the one, that is associated with the last cooked changeset that was
+    /// marked as consumed. Doing so, will cause BadCookedServerVersion to be
+    /// thrown.
+    ///
+    /// \param num_changesets Set to the total number of produced cooked
+    /// changesets over the lifetime of the Realm file to which this history
+    /// accessor object is attached. This is the number of previously consumed
+    /// changesets plus the number of unconsumed changesets remaining in the
+    /// Realm file.
+    ///
+    /// \param progress The point of progress of the consumption of the cooked
+    /// history. Initially, and until explicitly modified by
+    /// set_cooked_progress(), both `CookedProgress::changeset_index` and
+    /// `CookedProgress::intrachangeset_progress` are zero. If a nonzero value
+    /// was passed for \a server_version, \a progress will be transparently
+    /// adjusted to account for the skipped changesets. See also \a
+    /// num_skipped_changesets. If one or more changesets are skipped,
+    /// `CookedProgress::intrachangeset_progress` will be set to zero.
+    ///
+    /// \param num_skipped_changesets The number of skipped changesets. See also
+    /// \a server_version.
+    ///
+    /// \throw BadCookedServerVersion See \a server_version.
+    virtual void get_cooked_status(version_type server_version, std::int_fast64_t& num_changesets,
+                                   CookedProgress& progress,
+                                   std::int_fast64_t& num_skipped_changesets) const = 0;
+
+    /// Fetch the cooked changeset at the specified index.
+    ///
+    /// Cooked changesets are made available in the order they are produced by
+    /// the changeset cooker (ChangesetCooker).
+    ///
+    /// Behaviour is undefined if the specified index is less than the index
+    /// (CookedProgress::changeset_index) returned by get_cooked_progress(), or
+    /// if it is greater than, or equal to the total number of cooked changesets
+    /// (as returned by get_num_cooked_changesets()).
+    ///
+    /// The callee must append the bytes of the located cooked changeset to the
+    /// specified buffer, which does not have to be empty initially.
+    ///
+    /// \param server_version Will be set to the version produced on the server
+    /// by an earlier form of the retreived changeset. If the cooked changeset
+    /// was produced (as output of cooker) before migration of the client-side
+    /// history compartment to schema version 2, then \a server_version will be
+    /// set to zero instead, because the real value is unkown. Zero is not a
+    /// possible value in any other case.
+    virtual void get_cooked_changeset(std::int_fast64_t index,
+                                      util::AppendBuffer<char>&,
+                                      version_type& server_version) const = 0;
+
+    /// Persistently stores the point of progress of the consumer of cooked
+    /// changesets.
+    ///
+    /// The changeset index (CookedProgress::changeset_index) is the index (as
+    /// passed to get_cooked_changeset()) of the first unconsumed cooked
+    /// changset. Changesets at lower indexes will no longer be available.
+    ///
+    /// The intrachangeset progress field
+    /// (CookedProgress::intrachangeset_progress) will be faithfully persisted,
+    /// but will otherwise be treated as an opaque object by the history
+    /// internals.
+    ///
+    /// As well as allowing for later retrieval, the specification of the point
+    /// of progress of the consumer of cooked changesets also has the effect of
+    /// trimming obsolete cooked changesets from the Realm file (i.e., removal
+    /// of all changesets at indexes lower than
+    /// CookedProgress::intrachangeset_progress).  Indeed, if this function is
+    /// never called, but cooked changesets are continually being produced, then
+    /// the Realm file will grow without bounds.
+    ///
+    /// It is an error if the specified index (CookedProgress::changeset_index)
+    /// is lower than the index returned by get_cooked_progress(), and if it is
+    /// higher that the value returned by get_num_cooked_changesets().
+    ///
+    /// \return The snapshot number produced by the transaction performed
+    /// internally in set_cooked_progress(). This is also the client-side sync
+    /// version, and it should be passed to
+    /// sync::Session::nonsync_transact_notify() if a synchronization session is
+    /// in progress for the same file while set_cooked_progress() is
+    /// called. Doing so, ensures that the server will be notified about the
+    /// released server versions as soon as possible.
+    ///
+    /// \throw InconsistentUseOfCookedHistory If this file does not have a
+    /// cooked history and one can no longer be added because changesets of
+    /// remote origin has already been integrated.
+    virtual version_type set_cooked_progress(CookedProgress) = 0;
+
+    /// \brief Get the number of cooked changesets so far produced for this
+    /// Realm.
+    ///
+    /// This is the same thing as is returned via \a num_changesets by
+    /// get_cooked_status().
+    std::int_fast64_t get_num_cooked_changesets() const noexcept;
+
+    /// \brief Returns the persisted progress that was last stored by
+    /// set_cooked_progress().
+    ///
+    /// This is the same thing as is returned via \a progress by
+    /// get_cooked_status() when invoked with a server version of zero.
+    CookedProgress get_cooked_progress() const noexcept;
+
+    /// Same as get_cooked_changeset(std::int_fast64_t,
+    /// util::AppendBuffer<char>&, version_type&) but does not retreived the
+    /// server version.
+    void get_cooked_changeset(std::int_fast64_t index, util::AppendBuffer<char>&) const;
+
+    /// Return an upload cursor as it would be when the uploading process
+    /// reaches the snapshot to which the current transaction is bound.
+    ///
+    /// **CAUTION:** Must be called only while a transaction (read or write) is
+    /// in progress via the SharedGroup object associated with this history
+    /// object.
+    virtual UploadCursor get_upload_anchor_of_current_transact() const = 0;
+
+    /// Return the synchronization changeset of the current transaction as it
+    /// would be if that transaction was committed at this time.
+    ///
+    /// The returned memory reference may be invalidated by subsequent
+    /// operations on the Realm state.
+    ///
+    /// **CAUTION:** Must be called only while a write transaction is in
+    /// progress via the SharedGroup object associated with this history object.
+    virtual util::StringView get_sync_changeset_of_current_transact() const noexcept = 0;
+
+protected:
+    ClientHistory(const std::string& realm_path);
+};
+
+
+/// \brief Abstract interface for changeset cookers.
+///
+/// Note, it is completely up to the application to decide what a cooked
+/// changeset is. History objects (instances of ClientHistory) are required to
+/// treat cooked changesets as opaque entities. For an example of a concrete
+/// changeset cooker, see TrivialChangesetCooker which defines the cooked
+/// changesets to be identical copies of the raw changesets.
+class ClientHistory::ChangesetCooker {
+public:
+    virtual ~ChangesetCooker() {}
+
+    /// \brief An opportunity to produce a cooked changeset.
+    ///
+    /// When the implementation chooses to produce a cooked changeset, it must
+    /// write the cooked changeset to the specified buffer, and return
+    /// true. When the implementation chooses not to produce a cooked changeset,
+    /// it must return false. The implementation is allowed to write to the
+    /// buffer, and return false, and in that case, the written data will be
+    /// ignored.
+    ///
+    /// \param prior_state The state of the local Realm on which the specified
+    /// raw changeset is based.
+    ///
+    /// \param changeset, changeset_size The raw changeset.
+    ///
+    /// \param buffer The buffer to which the cooked changeset must be written.
+    ///
+    /// \return True if a cooked changeset was produced. Otherwise false.
+    virtual bool cook_changeset(const Group& prior_state,
+                                const char* changeset, std::size_t changeset_size,
+                                util::AppendBuffer<char>& buffer) = 0;
+};
+
+
+class ClientHistory::Config {
+public:
+    Config() {}
+
+    /// Must be set to true if, and only if the created history object
+    /// represents (is owned by) the sync agent of the specified Realm file. At
+    /// most one such instance is allowed to participate in a Realm file access
+    /// session at any point in time. Ordinarily the sync agent is encapsulated
+    /// by the sync::Client class, and the history instance representing the
+    /// agent is created transparently by sync::Client (one history instance per
+    /// sync::Session object).
+    bool owner_is_sync_agent = false;
+
+    /// If a changeset cooker is specified, then the created history object will
+    /// allow for a cooked changeset to be produced for each changeset of remote
+    /// origin; that is, for each changeset that is integrated during the
+    /// execution of ClientHistory::integrate_remote_changesets(). If no
+    /// changeset cooker is specified, then no cooked changesets will be
+    /// produced on behalf of the created history object.
+    ///
+    /// ClientHistory::integrate_remote_changesets() will pass each incoming
+    /// changeset to the cooker after operational transformation; that is, when
+    /// the chageset is ready to be applied to the local Realm state.
+    std::shared_ptr<ChangesetCooker> changeset_cooker;
+};
+
+/// \brief Create a "sync history" implementation of the realm::Replication
+/// interface.
+///
+/// The intended role for such an object is as a plugin for new
+/// realm::SharedGroup objects.
+std::unique_ptr<ClientHistory> make_client_history(const std::string& realm_path,
+                                                   ClientHistory::Config = {});
+
+
+
+// Implementation
+
+inline timestamp_type generate_changeset_timestamp() noexcept
+{
+    namespace chrono = std::chrono;
+    // Unfortunately, C++11 does not specify what the epoch is for
+    // `chrono::system_clock` (or for any other clock). It is believed, however,
+    // that there is a de-facto standard, that the Epoch for
+    // `chrono::system_clock` is the Unix epoch, i.e., 1970-01-01T00:00:00Z. See
+    // http://stackoverflow.com/a/29800557/1698548. Additionally, it is assumed
+    // that leap seconds are not included in the value returned by
+    // time_since_epoch(), i.e., that it conforms to POSIX time. This is known
+    // to be true on Linux.
+    //
+    // FIXME: Investigate under which conditions OS X agrees with POSIX about
+    // not including leap seconds in the value returned by time_since_epoch().
+    //
+    // FIXME: Investigate whether Microsoft Windows agrees with POSIX about
+    // about not including leap seconds in the value returned by
+    // time_since_epoch().
+    auto time_since_epoch = chrono::system_clock::now().time_since_epoch();
+    std::uint_fast64_t millis_since_epoch =
+        chrono::duration_cast<chrono::milliseconds>(time_since_epoch).count();
+    // `offset_in_millis` is the number of milliseconds between
+    // 1970-01-01T00:00:00Z and 2015-01-01T00:00:00Z not counting leap seconds.
+    std::uint_fast64_t offset_in_millis = 1420070400000ULL;
+    return timestamp_type(millis_since_epoch - offset_in_millis);
+}
+
+inline void map_changeset_timestamp(timestamp_type timestamp, std::time_t& seconds_since_epoch,
+                                    long& nanoseconds) noexcept
+{
+    std::uint_fast64_t offset_in_millis = 1420070400000ULL;
+    std::uint_fast64_t millis_since_epoch = std::uint_fast64_t(offset_in_millis + timestamp);
+    seconds_since_epoch = std::time_t(millis_since_epoch / 1000);
+    nanoseconds = long(millis_since_epoch % 1000 * 1000000L);
+}
+
+class InconsistentUseOfCookedHistory : public std::exception {
+public:
+    InconsistentUseOfCookedHistory(const char* message) noexcept :
+        m_message{message}
+    {
+    }
+    const char* what() const noexcept override final
+    {
+        return m_message;
+    }
+private:
+    const char* m_message;
+};
+
+class BadCookedServerVersion : public std::exception {
+public:
+    BadCookedServerVersion(const char* message) noexcept :
+        m_message{message}
+    {
+    }
+    const char* what() const noexcept override final
+    {
+        return m_message;
+    }
+private:
+    const char* m_message;
+};
+
+inline ClientHistoryBase::ClientHistoryBase(const std::string& realm_path) :
+    InstructionReplication{realm_path} // Throws
+{
+}
+
+inline ClientHistory::ClientHistory(const std::string& realm_path) :
+    ClientHistoryBase{realm_path} // Throws
+{
+}
+
+inline std::int_fast64_t ClientHistory::get_num_cooked_changesets() const noexcept
+{
+    version_type server_version = 0; // Skip nothing
+    std::int_fast64_t num_changesets = 0;
+    ClientHistory::CookedProgress progress;
+    std::int_fast64_t num_skipped_changesets = 0;
+    get_cooked_status(server_version, num_changesets, progress, num_skipped_changesets);
+    REALM_ASSERT(progress.changeset_index <= num_changesets);
+    REALM_ASSERT(num_skipped_changesets == 0);
+    return num_changesets;
+}
+
+inline auto ClientHistory::get_cooked_progress() const noexcept -> CookedProgress
+{
+    version_type server_version = 0; // Skip nothing
+    std::int_fast64_t num_changesets = 0;
+    ClientHistory::CookedProgress progress;
+    std::int_fast64_t num_skipped_changesets = 0;
+    get_cooked_status(server_version, num_changesets, progress, num_skipped_changesets);
+    REALM_ASSERT(progress.changeset_index <= num_changesets);
+    REALM_ASSERT(num_skipped_changesets == 0);
+    return progress;
+}
+
+inline void ClientHistory::get_cooked_changeset(std::int_fast64_t index,
+                                                util::AppendBuffer<char>& buffer) const
+{
+    version_type server_version; // Dummy
+    get_cooked_changeset(index, buffer, server_version); // Throws
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_HISTORY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/instruction_applier.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/instruction_applier.hpp
new file mode 100644
index 0000000..92bb573
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/instruction_applier.hpp
@@ -0,0 +1,147 @@
+/*************************************************************************
+ *
+ * Copyright 2017 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_IMPL_INSTRUCTION_APPLIER_HPP
+#define REALM_SYNC_IMPL_INSTRUCTION_APPLIER_HPP
+
+#include <realm/sync/instructions.hpp>
+#include <realm/sync/changeset.hpp>
+#include <realm/sync/object.hpp>
+#include <realm/util/logger.hpp>
+
+
+namespace realm {
+namespace sync {
+
+struct Changeset;
+
+struct InstructionApplier {
+    explicit InstructionApplier(Group&, TableInfoCache&) noexcept;
+
+    /// Throws BadChangesetError if application fails due to a problem with the
+    /// changeset.
+    ///
+    /// FIXME: Consider using std::error_code instead of throwing
+    /// BadChangesetError.
+    void apply(const Changeset&, util::Logger*);
+
+    void begin_apply(const Changeset&, util::Logger*) noexcept;
+    void end_apply() noexcept;
+
+protected:
+    StringData get_string(InternString) const;
+    StringData get_string(StringBufferRange) const;
+#define REALM_DECLARE_INSTRUCTION_HANDLER(X) void operator()(const Instruction::X&);
+    REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_DECLARE_INSTRUCTION_HANDLER)
+#undef REALM_DECLARE_INSTRUCTION_HANDLER
+    friend struct Instruction; // to allow visitor
+
+    template<class A> static void apply(A& applier, const Changeset&, util::Logger*);
+
+    // Allows for in-place modification of changeset while applying it
+    template<class A> static void apply(A& applier, Changeset&, util::Logger*);
+
+    TableRef table_for_class_name(StringData) const; // Throws
+    REALM_NORETURN void bad_transaction_log(const char*) const;
+
+    Group& m_group;
+    TableInfoCache& m_table_info_cache;
+    LinkViewRef m_selected_link_list;
+    TableRef m_selected_table;
+    TableRef m_selected_array;
+    TableRef m_link_target_table;
+
+    template <class... Args>
+    void log(const char* fmt, Args&&... args)
+    {
+        if (m_logger) {
+            m_logger->trace(fmt, std::forward<Args>(args)...); // Throws
+        }
+    }
+
+private:
+    const Changeset* m_log = nullptr;
+    util::Logger* m_logger = nullptr;
+};
+
+
+
+
+// Implementation
+
+inline InstructionApplier::InstructionApplier(Group& group, TableInfoCache& table_info_cache) noexcept:
+    m_group(group),
+    m_table_info_cache(table_info_cache)
+{
+}
+
+inline void InstructionApplier::begin_apply(const Changeset& log, util::Logger* logger) noexcept
+{
+    m_log = &log;
+    m_logger = logger;
+}
+
+inline void InstructionApplier::end_apply() noexcept
+{
+    m_log = nullptr;
+    m_logger = nullptr;
+    m_selected_table = TableRef{};
+    m_selected_array = TableRef{};
+    m_selected_link_list = LinkViewRef{};
+    m_link_target_table = TableRef{};
+}
+
+template<class A>
+inline void InstructionApplier::apply(A& applier, const Changeset& changeset, util::Logger* logger)
+{
+    applier.begin_apply(changeset, logger);
+    for (auto instr : changeset) {
+        if (!instr)
+            continue;
+        instr->visit(applier); // Throws
+#if REALM_DEBUG
+        applier.m_table_info_cache.verify();
+#endif
+    }
+    applier.end_apply();
+}
+
+template<class A>
+inline void InstructionApplier::apply(A& applier, Changeset& changeset, util::Logger* logger)
+{
+    applier.begin_apply(changeset, logger);
+    for (auto instr : changeset) {
+        if (!instr)
+            continue;
+        instr->visit(applier); // Throws
+#if REALM_DEBUG
+        applier.m_table_info_cache.verify();
+#endif
+    }
+    applier.end_apply();
+}
+
+inline void InstructionApplier::apply(const Changeset& log, util::Logger* logger)
+{
+    apply(*this, log, logger); // Throws
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_IMPL_INSTRUCTION_APPLIER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/instruction_replication.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/instruction_replication.hpp
new file mode 100644
index 0000000..b66e332
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/instruction_replication.hpp
@@ -0,0 +1,238 @@
+/*************************************************************************
+ *
+ * Copyright 2017 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_IMPL_INSTRUCTION_REPLICATION_HPP
+#define REALM_SYNC_IMPL_INSTRUCTION_REPLICATION_HPP
+
+#include <realm/replication.hpp>
+#include <realm/sync/instructions.hpp>
+#include <realm/sync/object.hpp>
+#include <realm/sync/changeset_encoder.hpp>
+
+namespace realm {
+namespace sync {
+
+
+class InstructionReplication: public TrivialReplication, public ObjectIDProvider {
+public:
+    enum class TableBehavior {
+        Class,
+        Array,
+        Ignore
+    };
+
+    explicit InstructionReplication(const std::string& realm_path);
+    void set_short_circuit(bool) noexcept;
+    bool is_short_circuited() const noexcept;
+
+    // reset() resets the encoder, the selected tables and the cache. It is
+    // called by do_initiate_transact(), but can be called at the other times
+    // as well.
+    virtual void reset();
+
+    ChangesetEncoder& get_instruction_encoder() noexcept;
+    const ChangesetEncoder& get_instruction_encoder() const noexcept;
+
+    //@{
+    /// Generate instructions for Object Store tables. These must be called
+    /// prior to calling the equivalent functions in Core's API. When creating a
+    /// class-like table, `add_class()` must be called prior to
+    /// `Group::insert_group_level_table()`. Similarly, `create_object()` or
+    /// `create_object_with_primary_key()` must be called prior to
+    /// `Table::insert_empty_row()` and/or `Table::set_int_unique()` or
+    /// `Table::set_string_unique()` or `Table::set_null_unique()`.
+    ///
+    /// If a class-like table is added, or an object-like row is inserted,
+    /// without calling these methods first, an exception will be thrown.
+    ///
+    /// A "class-like table" is defined as a table whose name begins with
+    /// "class_" (this is the convention used by Object Store). Non-class-like
+    /// tables can be created and modified using Core's API without calling
+    /// these functions, because they do not result in instructions being
+    /// emitted.
+    void add_class(StringData table_name);
+    void add_class_with_primary_key(StringData table_name, DataType pk_type, StringData pk_field, bool nullable);
+    void create_object(const Table*, ObjectID);
+    void create_object_with_primary_key(const Table*, ObjectID, StringData);
+    void create_object_with_primary_key(const Table*, ObjectID, int_fast64_t);
+    void create_object_with_primary_key(const Table*, ObjectID, realm::util::None);
+    void prepare_erase_table(StringData table_name);
+    //@}
+
+    // TrivialReplication interface:
+    void initialize(SharedGroup&) override;
+
+    // TransactLogConvenientEncoder interface:
+    void insert_group_level_table(size_t table_ndx, size_t num_tables, StringData name) override;
+    void erase_group_level_table(size_t table_ndx, size_t num_tables) override;
+    void rename_group_level_table(size_t table_ndx, StringData new_name) override;
+    void insert_column(const Descriptor&, size_t col_ndx, DataType type, StringData name, LinkTargetInfo& link,
+                               bool nullable = false) override;
+    void erase_column(const Descriptor&, size_t col_ndx) override;
+    void rename_column(const Descriptor&, size_t col_ndx, StringData name) override;
+
+    void set_int(const Table*, size_t col_ndx, size_t ndx, int_fast64_t value, _impl::Instruction variant) override;
+    void add_int(const Table*, size_t col_ndx, size_t ndx, int_fast64_t value) override;
+    void set_bool(const Table*, size_t col_ndx, size_t ndx, bool value, _impl::Instruction variant) override;
+    void set_float(const Table*, size_t col_ndx, size_t ndx, float value, _impl::Instruction variant) override;
+    void set_double(const Table*, size_t col_ndx, size_t ndx, double value, _impl::Instruction variant) override;
+    void set_string(const Table*, size_t col_ndx, size_t ndx, StringData value, _impl::Instruction variant) override;
+    void set_binary(const Table*, size_t col_ndx, size_t ndx, BinaryData value, _impl::Instruction variant) override;
+    void set_olddatetime(const Table*, size_t col_ndx, size_t ndx, OldDateTime value,
+                                 _impl::Instruction variant) override;
+    void set_timestamp(const Table*, size_t col_ndx, size_t ndx, Timestamp value, _impl::Instruction variant) override;
+    void set_table(const Table*, size_t col_ndx, size_t ndx, _impl::Instruction variant) override;
+    void set_mixed(const Table*, size_t col_ndx, size_t ndx, const Mixed& value, _impl::Instruction variant) override;
+    void set_link(const Table*, size_t col_ndx, size_t ndx, size_t value, _impl::Instruction variant) override;
+    void set_null(const Table*, size_t col_ndx, size_t ndx, _impl::Instruction variant) override;
+    void set_link_list(const LinkView&, const IntegerColumn& values) override;
+    void insert_substring(const Table*, size_t col_ndx, size_t row_ndx, size_t pos, StringData) override;
+    void erase_substring(const Table*, size_t col_ndx, size_t row_ndx, size_t pos, size_t size) override;
+    void insert_empty_rows(const Table*, size_t row_ndx, size_t num_rows_to_insert, size_t prior_num_rows) override;
+    void add_row_with_key(const Table*, size_t row_ndx, size_t prior_num_rows, size_t key_col_ndx, int64_t key) override;
+    void erase_rows(const Table*, size_t row_ndx, size_t num_rows_to_erase, size_t prior_num_rowsp,
+                            bool is_move_last_over) override;
+    void swap_rows(const Table*, size_t row_ndx_1, size_t row_ndx_2) override;
+    void move_row(const Table*, size_t row_ndx_1, size_t row_ndx_2) override;
+    void merge_rows(const Table*, size_t row_ndx, size_t new_row_ndx) override;
+    void add_search_index(const Descriptor&, size_t col_ndx) override;
+    void remove_search_index(const Descriptor&, size_t col_ndx) override;
+    void set_link_type(const Table*, size_t col_ndx, LinkType) override;
+    void clear_table(const Table*, size_t prior_num_rows) override;
+    void optimize_table(const Table*) override;
+    void link_list_set(const LinkView&, size_t ndx, size_t value) override;
+    void link_list_insert(const LinkView&, size_t ndx, size_t value) override;
+    void link_list_move(const LinkView&, size_t from_ndx, size_t to_ndx) override;
+    void link_list_swap(const LinkView&, size_t ndx_1, size_t ndx_2) override;
+    void link_list_erase(const LinkView&, size_t ndx) override;
+    void link_list_clear(const LinkView&) override;
+    void nullify_link(const Table*, size_t col_ndx, size_t ndx) override;
+    void link_list_nullify(const LinkView&, size_t ndx) override;
+
+    template <class T>
+    void emit(T instruction);
+
+    TableBehavior select_table(const Table*);
+    const Table* selected_table() const noexcept;
+
+protected:
+    // Replication interface:
+    void do_initiate_transact(TransactionType, version_type current_version) override;
+private:
+    bool m_short_circuit = false;
+
+    ChangesetEncoder m_encoder;
+    SharedGroup* m_sg = nullptr;
+    std::unique_ptr<TableInfoCache> m_cache;
+
+
+    // FIXME: The base class already caches this.
+    ConstTableRef m_selected_table;
+    TableBehavior m_selected_table_behavior; // cache
+    ConstLinkViewRef m_selected_link_list = nullptr;
+
+    // Consistency checks:
+    std::string m_table_being_created;
+    std::string m_table_being_created_primary_key;
+    std::string m_table_being_erased;
+    util::Optional<ObjectID> m_object_being_created;
+
+    REALM_NORETURN void unsupported_instruction(); // Throws TransformError
+    TableBehavior select_table(const Descriptor&);
+    TableBehavior select_table_inner(const Table* table);
+    bool select_link_list(const LinkView&); // returns true if table behavior != ignored
+
+    TableBehavior get_table_behavior(const Table*) const;
+
+    template <class T>
+    void set(const Table*, size_t row_ndx, size_t col_ndx, T payload,
+             _impl::Instruction variant);
+    template <class T>
+    void set_pk(const Table*, size_t row_ndx, size_t col_ndx, T payload,
+                _impl::Instruction variant);
+    template <class T>
+    auto as_payload(T value);
+};
+
+inline void InstructionReplication::set_short_circuit(bool b) noexcept
+{
+    m_short_circuit = b;
+}
+
+inline bool InstructionReplication::is_short_circuited() const noexcept
+{
+    return m_short_circuit;
+}
+
+inline ChangesetEncoder& InstructionReplication::get_instruction_encoder() noexcept
+{
+    return m_encoder;
+}
+
+inline const ChangesetEncoder& InstructionReplication::get_instruction_encoder() const noexcept
+{
+    return m_encoder;
+}
+
+template <class T>
+inline void InstructionReplication::emit(T instruction)
+{
+    REALM_ASSERT(!m_short_circuit);
+    m_encoder(instruction);
+}
+
+inline auto InstructionReplication::select_table(const Table* table) -> TableBehavior
+{
+    if (m_selected_table == table) {
+        return m_selected_table_behavior;
+    }
+    return select_table_inner(table);
+}
+
+inline const Table* InstructionReplication::selected_table() const noexcept
+{
+    return m_selected_table.get();
+}
+
+// Temporarily short-circuit replication
+class TempShortCircuitReplication {
+public:
+    TempShortCircuitReplication(InstructionReplication& bridge): m_bridge(bridge)
+    {
+        m_was_short_circuited = bridge.is_short_circuited();
+        bridge.set_short_circuit(true);
+    }
+
+    ~TempShortCircuitReplication()
+    {
+        m_bridge.set_short_circuit(m_was_short_circuited);
+    }
+
+    bool was_short_circuited() const noexcept
+    {
+        return m_was_short_circuited;
+    }
+private:
+    InstructionReplication& m_bridge;
+    bool m_was_short_circuited;
+};
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_IMPL_INSTRUCTION_REPLICATION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/instructions.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/instructions.hpp
new file mode 100644
index 0000000..4c8051a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/instructions.hpp
@@ -0,0 +1,421 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_IMPL_INSTRUCTIONS_HPP
+#define REALM_IMPL_INSTRUCTIONS_HPP
+
+#include <vector>
+#include <unordered_map>
+#include <iosfwd> // string conversion, debug prints
+#include <memory> // shared_ptr
+#include <type_traits>
+
+#include <realm/util/string_buffer.hpp>
+#include <realm/string_data.hpp>
+#include <realm/binary_data.hpp>
+#include <realm/data_type.hpp>
+#include <realm/timestamp.hpp>
+#include <realm/sync/object_id.hpp>
+#include <realm/impl/input_stream.hpp>
+#include <realm/table_ref.hpp>
+#include <realm/link_view_fwd.hpp>
+
+namespace realm {
+namespace sync {
+
+// CAUTION: Any change to the order or number of instructions is a
+// protocol-breaking change!
+#define REALM_FOR_EACH_INSTRUCTION_TYPE(X) \
+    X(SelectTable) \
+    X(SelectField) \
+    X(AddTable) \
+    X(EraseTable) \
+    X(CreateObject) \
+    X(EraseObject) \
+    X(Set) \
+    X(AddInteger) \
+    X(InsertSubstring) \
+    X(EraseSubstring) \
+    X(ClearTable) \
+    X(AddColumn) \
+    X(EraseColumn) \
+    X(ArraySet) \
+    X(ArrayInsert) \
+    X(ArrayMove) \
+    X(ArraySwap) \
+    X(ArrayErase) \
+    X(ArrayClear) \
+
+
+enum class ContainerType {
+    None = 0,
+    Reserved0 = 1,
+    Array = 2,
+    Set = 3,
+    Dictionary = 4,
+};
+
+struct Instruction {
+    // Base classes for instructions with common fields. They enable the merge
+    // algorithm to reuse some code without resorting to templates, and can be
+    // combined to allow optimal memory layout of instructions (size <= 64).
+    struct PayloadInstructionBase;
+    struct ObjectInstructionBase;
+    struct FieldInstructionBase;
+
+#define REALM_DECLARE_INSTRUCTION_STRUCT(X) struct X;
+    REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_DECLARE_INSTRUCTION_STRUCT)
+#undef REALM_DECLARE_INSTRUCTION_STRUCT
+
+    enum class Type: uint8_t {
+#define REALM_DEFINE_INSTRUCTION_TYPE(X) X,
+    REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_DEFINE_INSTRUCTION_TYPE)
+#undef REALM_DEFINE_INSTRUCTION_TYPE
+    };
+
+    struct Payload;
+    template <Type t> struct GetType;
+    template <class T> struct GetInstructionType;
+
+    Instruction() {}
+    template<class T> Instruction(T instr);
+
+    static const size_t max_instruction_size = 64;
+    std::aligned_storage_t<max_instruction_size> m_storage;
+    Type type;
+
+    template<class F> auto visit(F&& lambda);
+    template<class F> auto visit(F&& lambda) const;
+
+    template<class T> T& get_as()
+    {
+        REALM_ASSERT(type == GetInstructionType<T>::value);
+        return *reinterpret_cast<T*>(&m_storage);
+    }
+
+    template<class T> const T& get_as() const
+    {
+        return const_cast<Instruction*>(this)->template get_as<T>();
+    }
+
+    bool operator==(const Instruction& other) const noexcept;
+
+    bool operator!=(const Instruction& other) const noexcept
+    {
+        return !(*this == other);
+    }
+};
+
+// 0x3f is the largest value that fits in a single byte in the variable-length
+// encoded integer instruction format.
+static constexpr uint8_t InstrTypeInternString = 0x3f;
+
+// This instruction code is only ever used internally by the Changeset class
+// to allow insertion/removal while keeping iterators stable. Should never
+// make it onto the wire.
+static constexpr uint8_t InstrTypeMultiInstruction = 0xff;
+
+struct StringBufferRange {
+    uint32_t offset, size;
+};
+
+struct InternString {
+    static const InternString npos;
+    explicit constexpr InternString(uint32_t v = uint32_t(-1)) noexcept : value(v) {}
+
+    uint32_t value;
+
+    bool operator==(const InternString& other) const noexcept { return value == other.value; }
+    bool operator<(const InternString& other) const noexcept { return value < other.value; }
+
+    explicit operator bool() const noexcept { return (value != npos.value); }
+};
+
+struct Instruction::Payload {
+    struct Link {
+        sync::ObjectID target; // can be nothing = null
+        InternString target_table;
+    };
+
+    union Data {
+        bool boolean;
+        int64_t integer;
+        float fnum;
+        double dnum;
+        StringBufferRange str;
+        Timestamp timestamp;
+        Link link;
+
+        Data() noexcept {}
+        Data(const Data&) noexcept = default;
+        Data& operator=(const Data&) noexcept = default;
+    };
+    Data data;
+    int8_t type; // -1 = null, -2 = implicit_nullify
+
+    Payload(): Payload(realm::util::none) {}
+    explicit Payload(bool value)      noexcept: type(type_Bool) { data.boolean = value; }
+    explicit Payload(int64_t value)   noexcept: type(type_Int) { data.integer = value; }
+    explicit Payload(float value)     noexcept: type(type_Float) { data.fnum = value; }
+    explicit Payload(double value)    noexcept: type(type_Double) { data.dnum = value; }
+    explicit Payload(Link value)      noexcept: type(type_Link) { data.link = value; }
+    explicit Payload(StringBufferRange value) noexcept: type(type_String) { data.str = value; }
+    explicit Payload(realm::util::None, bool implicit_null = false) noexcept {
+        type = (implicit_null ? -2 : -1);
+    }
+    explicit Payload(Timestamp value) noexcept: type(value.is_null() ? -1 : type_Timestamp)
+    {
+        data.timestamp = value;
+    }
+
+    Payload(const Payload&) noexcept = default;
+    Payload& operator=(const Payload&) noexcept = default;
+
+    bool is_null() const;
+    bool is_implicit_null() const;
+};
+
+struct Instruction::ObjectInstructionBase {
+    sync::ObjectID object;
+};
+
+struct Instruction::FieldInstructionBase
+    : Instruction::ObjectInstructionBase
+{
+    InternString field;
+};
+
+struct Instruction::PayloadInstructionBase {
+    Payload payload;
+};
+
+
+struct Instruction::SelectTable {
+    InternString table;
+};
+
+struct Instruction::SelectField
+    : Instruction::FieldInstructionBase
+{
+    InternString link_target_table;
+};
+
+struct Instruction::AddTable {
+    InternString table;
+    InternString primary_key_field;
+    DataType primary_key_type;
+    bool has_primary_key;
+    bool primary_key_nullable;
+};
+
+struct Instruction::EraseTable {
+    InternString table;
+};
+
+struct Instruction::CreateObject
+    : Instruction::PayloadInstructionBase
+    , Instruction::ObjectInstructionBase
+{
+    bool has_primary_key;
+};
+
+struct Instruction::EraseObject
+    : Instruction::ObjectInstructionBase
+{};
+
+struct Instruction::Set
+    : Instruction::PayloadInstructionBase
+    , Instruction::FieldInstructionBase
+{
+    bool is_default;
+};
+
+struct Instruction::AddInteger
+    : Instruction::FieldInstructionBase
+{
+    int64_t value;
+};
+
+struct Instruction::InsertSubstring
+    : Instruction::FieldInstructionBase
+{
+    StringBufferRange value;
+    uint32_t pos;
+};
+
+struct Instruction::EraseSubstring
+    : Instruction::FieldInstructionBase
+{
+    uint32_t pos;
+    uint32_t size;
+};
+
+struct Instruction::ClearTable {
+};
+
+struct Instruction::ArraySet {
+    Instruction::Payload payload;
+    uint32_t ndx;
+    uint32_t prior_size;
+};
+
+struct Instruction::ArrayInsert {
+    // payload carries the value in case of LinkList
+    // payload is empty in case of Array, Dict or any other container type
+    Instruction::Payload payload;
+    uint32_t ndx;
+    uint32_t prior_size;
+};
+
+struct Instruction::ArrayMove {
+    uint32_t ndx_1;
+    uint32_t ndx_2;
+};
+
+struct Instruction::ArrayErase {
+    uint32_t ndx;
+    uint32_t prior_size;
+    bool implicit_nullify;
+};
+
+struct Instruction::ArraySwap {
+    uint32_t ndx_1;
+    uint32_t ndx_2;
+};
+
+struct Instruction::ArrayClear {
+    uint32_t prior_size;
+};
+
+
+// If container_type != ContainerType::none, creates a subtable:
+// +---+---+-------+
+// | a | b |   c   |
+// +---+---+-------+
+// |   |   | +---+ |
+// |   |   | | v | |
+// |   |   | +---+ |
+// | 1 | 2 | | 3 | |
+// |   |   | | 4 | |
+// |   |   | | 5 | |
+// |   |   | +---+ |
+// +---+---+-------+
+struct Instruction::AddColumn {
+    InternString field;
+    InternString link_target_table;
+    DataType type;
+    ContainerType container_type;
+    bool nullable;
+};
+
+struct Instruction::EraseColumn {
+    InternString field;
+};
+
+struct InstructionHandler {
+    /// Notify the handler that an InternString meta-instruction was found.
+    virtual void set_intern_string(uint32_t index, StringBufferRange) = 0;
+
+    /// Notify the handler of the string value. The handler guarantees that the
+    /// returned string range is valid at least until the next invocation of
+    /// add_string_range().
+    ///
+    /// Instances of `StringBufferRange` passed to operator() after invoking
+    /// this function are assumed to refer to ranges in this buffer.
+    virtual StringBufferRange add_string_range(StringData) = 0;
+
+    /// Handle an instruction.
+    virtual void operator()(const Instruction&) = 0;
+};
+
+
+/// Implementation:
+
+#define REALM_DEFINE_INSTRUCTION_GET_TYPE(X) \
+    template <> struct Instruction::GetType<Instruction::Type::X> { using Type = Instruction::X; }; \
+    template <> struct Instruction::GetInstructionType<Instruction::X> { static const Instruction::Type value = Instruction::Type::X; };
+    REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_DEFINE_INSTRUCTION_GET_TYPE)
+#undef REALM_DEFINE_INSTRUCTION_GET_TYPE
+
+template <class T>
+Instruction::Instruction(T instr) : type(GetInstructionType<T>::value)
+{
+    new(&m_storage) T(std::move(instr));
+}
+
+template <class F>
+inline auto Instruction::visit(F&& lambda)
+{
+    switch (type) {
+#define REALM_VISIT_INSTRUCTION(X) \
+        case Type::X: \
+            return lambda(get_as<Instruction::X>());
+        REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_VISIT_INSTRUCTION)
+#undef REALM_VISIT_INSTRUCTION
+    }
+    REALM_UNREACHABLE();
+}
+
+template <class F>
+inline auto Instruction::visit(F&& lambda) const
+{
+    switch (type) {
+#define REALM_VISIT_INSTRUCTION(X) \
+        case Type::X: \
+            return lambda(get_as<Instruction::X>());
+        REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_VISIT_INSTRUCTION)
+#undef REALM_VISIT_INSTRUCTION
+    }
+    REALM_UNREACHABLE();
+}
+
+inline bool Instruction::operator==(const Instruction& other) const noexcept
+{
+    if (type != other.type)
+        return false;
+    size_t valid_size;
+    switch (type) {
+#define REALM_COMPARE_INSTRUCTION(X) \
+        case Type::X: valid_size = sizeof(Instruction::X); break;
+        REALM_FOR_EACH_INSTRUCTION_TYPE(REALM_COMPARE_INSTRUCTION)
+#undef REALM_COMPARE_INSTRUCTION
+        default: REALM_UNREACHABLE();
+    }
+
+    // This relies on all instruction types being PODs to work.
+    return std::memcmp(&m_storage, &other.m_storage, valid_size) == 0;
+}
+
+inline bool Instruction::Payload::is_null() const
+{
+    return type < 0;
+}
+
+inline bool Instruction::Payload::is_implicit_null() const
+{
+    return type == -2;
+}
+
+std::ostream& operator<<(std::ostream&, Instruction::Type);
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_IMPL_INSTRUCTIONS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/object.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/object.hpp
new file mode 100644
index 0000000..8529fa0
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/object.hpp
@@ -0,0 +1,262 @@
+/*************************************************************************
+ *
+ * Copyright 2017 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_OBJECT_HPP
+#define REALM_SYNC_OBJECT_HPP
+
+#include <realm/util/logger.hpp>
+#include <realm/table_ref.hpp>
+#include <realm/string_data.hpp>
+#include <realm/group.hpp>
+
+#include <realm/sync/object_id.hpp>
+
+#include <vector>
+
+/// This file presents a convenience API for making changes to a Realm file that
+/// adhere to the conventions of assigning stable IDs to every object.
+
+namespace realm {
+
+class Group;
+class ReadTransaction;
+class WriteTransaction;
+
+namespace sync {
+
+class SyncHistory;
+
+extern const char object_id_column_name[]; // "!OID"
+extern const char array_value_column_name[]; // "!ARRAY_VALUE"
+
+struct TableInfoCache;
+
+/// Determine whether the Group has a sync-type history, and therefore whether
+/// it supports globally stable object IDs.
+///
+/// The Group does not need to be in a transaction.
+bool has_object_ids(const Group&);
+
+/// Determine whether object IDs for objects without primary keys are globally
+/// stable. This is true if and only if the Group has been in touch with the
+/// server (or is the server), and will remain true forever thereafter.
+///
+/// It is an error to call this function for groups that do not have object IDs
+/// (i.e. where `has_object_ids()` returns false).
+///
+/// The Group is assumed to be in a read transaction.
+bool is_object_id_stability_achieved(const Group&);
+
+/// Create a table with an object ID column.
+///
+/// It is an error to add tables to Groups with a sync history type directly.
+/// This function or related functions must be used instead.
+///
+/// The resulting table will be born with 1 column, which is a column used
+/// in the maintenance of object IDs.
+///
+/// NOTE: The table name must begin with the prefix "class_" in accordance with
+/// Object Store conventions.
+///
+/// The Group must be in a write transaction.
+TableRef create_table(Group&, StringData name);
+
+/// Create a table with an object ID column and a primary key column.
+///
+/// It is an error to add tables to Groups with a sync history type directly.
+/// This function or related functions must be used instead.
+///
+/// The resulting table will be born with 2 columns, which is a column used
+/// in the maintenance of object IDs and the requested primary key column.
+/// The primary key column must have either integer or string type, and it
+/// will be given the name provided in the argument \a pk_column_name.
+///
+/// The 'pk' metadata table is updated with information about the primary key
+/// column. If the 'pk' table does not yet exist, it is created.
+///
+/// Please note: The 'pk' metadata table will not be synchronized directly,
+/// so subsequent updates to it will be lost (as they constitute schema-breaking
+/// changes).
+///
+/// NOTE: The table name must begin with the prefix "class_" in accordance with
+/// Object Store conventions.
+///
+/// The Group must be in a write transaction.
+TableRef create_table_with_primary_key(Group&, StringData name, DataType pk_type,
+                                       StringData pk_column_name, bool nullable = false);
+
+
+//@{
+/// Erase table and update metadata.
+///
+/// It is an error to erase tables via the Group API, because it does not
+/// correctly update metadata tables (such as the `pk` table).
+void erase_table(Group& g, TableInfoCache& table_info_cache, StringData name);
+void erase_table(Group& g, TableInfoCache& table_info_cache, TableRef);
+//@}
+
+/// Create an array column with the specified element type.
+///
+/// The result will be a column of type type_Table with one subcolumn named
+/// "!ARRAY_VALUE" of the specified element type and nullability.
+///
+/// Return the column index of the inserted array column.
+size_t add_array_column(Table&, DataType element_type, StringData column_name, bool is_nullable = false);
+
+
+//@{
+/// Calculate the object ID from the argument, where the argument is a primary
+/// key value.
+ObjectID object_id_for_primary_key(StringData);
+ObjectID object_id_for_primary_key(util::Optional<int64_t>);
+//@}
+
+/// Determine whether it is safe to call `object_id_for_row()` on tables without
+/// primary keys. If the table has a primary key, always returns true.
+bool has_globally_stable_object_ids(const Table&);
+
+bool table_has_primary_key(const TableInfoCache&, const Table&);
+
+/// Get the globally unique object ID for the row.
+///
+/// If the table has a primary key, this is guaranteed to succeed. Otherwise, if
+/// the server has not been contacted yet (`has_globally_stable_object_ids()`
+/// returns false), an exception is thrown.
+ObjectID object_id_for_row(const TableInfoCache&, const Table&, size_t);
+
+/// Get the index of the row with the object ID.
+///
+/// \returns realm::npos if the object does not exist in the table.
+size_t row_for_object_id(const TableInfoCache&, const Table&, ObjectID);
+
+//@{
+/// Add a row to the table and populate the object ID with an appropriate value.
+///
+/// In the variant which takes an ObjectID parameter, a check is performed to see
+/// if the object already exists. If it does, the row index of the existing object
+/// is returned.
+///
+/// If the table has a primary key column, an exception is thrown.
+///
+/// \returns the row index of the object.
+size_t create_object(const TableInfoCache&, Table&);
+size_t create_object(const TableInfoCache&, Table&, ObjectID);
+//@}
+
+//@{
+/// Create an object with a primary key value and populate the object ID with an
+/// appropriate value.
+///
+/// If the table does not have a primary key column (as indicated by the Object
+/// Store's metadata in the special "pk" table), or the type of the primary key
+/// column does not match the argument provided, an exception is thrown.
+///
+/// The primary key column's value is populated with the appropriate
+/// `set_int_unique()`, `set_string_unique()`, or `set_null_unique()` method
+/// called on \a table.
+///
+/// If an object with the given primary key value already exists, its row number
+/// is returned without creating any new objects.
+///
+/// These are convenience functions, equivalent to the following:
+///   - Add an empty row to the table.
+///   - Obtain an `ObjectID` with `object_id_for_primary_key()`.
+///   - Obtain a local object ID with `global_to_local_object_id()`.
+///   - Store the local object ID in the object ID column.
+///   - Call `set_int_unique()`,`set_string_unique()`, or `set_null_unique()`
+///     to set the primary key value.
+///
+/// \returns the row index of the created object.
+size_t create_object_with_primary_key(const TableInfoCache&, Table&, util::Optional<int64_t> primary_key);
+size_t create_object_with_primary_key(const TableInfoCache&, Table&, StringData primary_key);
+//@}
+
+struct TableInfoCache {
+    const Group& m_group;
+
+    explicit TableInfoCache(const ReadTransaction&);
+    explicit TableInfoCache(const WriteTransaction&);
+
+    // Implicit conversion deliberately allowed for the purpose of calling the above
+    // functions without constructing a cache manually.
+    TableInfoCache(const Group&);
+    TableInfoCache(TableInfoCache&&) noexcept = default;
+
+    struct TableInfo {
+        struct VTable;
+
+        StringData name;
+        const VTable* vtable;
+        size_t object_id_index = size_t(-1);
+        size_t primary_key_index;
+        DataType primary_key_type = DataType(-1);
+        bool primary_key_nullable = false;
+        mutable size_t last_row_index = size_t(-1);
+        mutable ObjectID last_object_id;
+
+        void clear_last_object() const
+        {
+            last_row_index = size_t(-1);
+            last_object_id = {};
+        }
+    };
+
+    mutable std::vector<util::Optional<TableInfo>> m_table_info;
+
+    const TableInfo& get_table_info(const Table&) const;
+    const TableInfo& get_table_info(size_t table_index) const;
+    void clear();
+    void clear_last_object(const Table&);
+    void verify();
+};
+
+
+/// Migrate a server-side Realm file whose history type is
+/// `Replication::hist_SyncServer` and whose history schema version is 0 (i.e.,
+/// Realm files without stable identifiers).
+void import_from_legacy_format(const Group& old_group, Group& new_group, util::Logger&);
+
+using TableNameBuffer = std::array<char, Group::max_table_name_length>;
+StringData table_name_to_class_name(StringData);
+StringData class_name_to_table_name(StringData, TableNameBuffer&);
+
+
+// Implementation:
+
+inline StringData table_name_to_class_name(StringData table_name)
+{
+    REALM_ASSERT(table_name.begins_with("class_"));
+    return table_name.substr(6);
+}
+
+
+inline StringData class_name_to_table_name(StringData class_name, TableNameBuffer& buffer)
+{
+    constexpr const char class_prefix[] = "class_";
+    constexpr size_t class_prefix_len = sizeof(class_prefix) - 1;
+    char* p = std::copy_n(class_prefix, class_prefix_len, buffer.data());
+    size_t len = std::min(class_name.size(), buffer.size() - class_prefix_len);
+    std::copy_n(class_name.data(), len, p);
+    return StringData(buffer.data(), class_prefix_len + len);
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_OBJECT_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/object_id.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/object_id.hpp
new file mode 100644
index 0000000..e3e96e0
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/object_id.hpp
@@ -0,0 +1,312 @@
+/*************************************************************************
+ *
+ * Copyright 2017 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_OBJECT_ID_HPP
+#define REALM_SYNC_OBJECT_ID_HPP
+
+#include <functional> // std::hash
+#include <string>
+#include <iosfwd> // operator<<
+#include <map>
+#include <set>
+
+#include <stdint.h>
+
+#include <realm/util/optional.hpp>
+#include <realm/string_data.hpp>
+#include <realm/data_type.hpp>
+#include <realm/util/metered/map.hpp>
+#include <realm/util/metered/set.hpp>
+#include <realm/util/metered/string.hpp>
+
+// Only set this to one when testing the code paths that exercise object ID
+// hash collisions. It artificially limits the "optimistic" local ID to use
+// only the lower 15 bits of the ID rather than the lower 63 bits, making it
+// feasible to generate collisions within reasonable time.
+#define REALM_EXERCISE_OBJECT_ID_COLLISION 0
+
+namespace realm {
+
+class Group;
+
+namespace sync {
+
+/// ObjectIDs are globally unique for a given class (table), and up to 128 bits
+/// wide. They are represented as two 64-bit integers, each of which may
+/// frequently be small, for best on-wire compressibility.
+struct ObjectID {
+    constexpr ObjectID(uint64_t hi, uint64_t lo);
+    static ObjectID from_string(StringData);
+    static bool from_string(StringData, ObjectID&) noexcept;
+
+    // FIXME: Remove "empty" ObjectIDs, wrap in Optional instead.
+    constexpr ObjectID(realm::util::None = realm::util::none);
+    constexpr ObjectID(const ObjectID&) noexcept = default;
+    ObjectID& operator=(const ObjectID&) noexcept = default;
+
+    constexpr uint64_t lo() const { return m_lo; }
+    constexpr uint64_t hi() const { return m_hi; }
+
+    std::string to_string() const;
+
+    constexpr bool operator<(const ObjectID& other) const;
+    constexpr bool operator==(const ObjectID& other) const;
+    constexpr bool operator!=(const ObjectID& other) const;
+
+    explicit constexpr operator bool() const noexcept;
+
+private:
+    uint64_t m_lo;
+    uint64_t m_hi;
+};
+
+/// Implementors of this interface should define a way to map from 128-bit
+/// on-write ObjectIDs to local 64-bit object IDs.
+///
+/// The three object ID types are:
+/// a. Object IDs for objects in tables without primary keys.
+/// b. Object IDs for objects in tables with integer primary keys.
+/// c. Object IDs for objects in tables with other primary key types.
+///
+/// For integer primary keys (b), the Object ID is just the integer value.
+///
+/// For objects without primary keys (a), a "squeezed" tuple of the
+/// client_file_ident and a peer-local sequence number is used as the local
+/// Object ID. The on-write Object ID is the "unsqueezed" format. The methods on
+/// this interface ending in "_squeezed" aid in the creation and conversion of
+/// these IDs.
+///
+/// For objects with other types of primary keys (c), the ObjectID
+/// is a 128-bit hash of the primary key value. However, the local object ID
+/// must be a 64-bit integer, because that is the maximum size integer that
+/// Realm is able to store. The solution is to optimistically use the lower 63
+/// bits of the on-wire Object ID, and use a local ID with the upper 64th bit
+/// set when there is a collision in the lower 63 bits between two different
+/// hash values.
+class ObjectIDProvider {
+public:
+    using LocalObjectID = int_fast64_t;
+
+    /// Calculate optimistic local ID that may collide with others. It is up to
+    /// the caller to ensure that collisions are detected and that
+    /// allocate_local_id_after_collision() is called to obtain a non-colliding
+    /// ID.
+    static LocalObjectID get_optimistic_local_id_hashed(ObjectID global_id);
+
+    /// Find the local 64-bit object ID for the provided global 128-bit ID.
+    virtual LocalObjectID global_to_local_object_id_hashed(size_t table_ndx, ObjectID global_id) const = 0;
+
+    /// After a local ID collision has been detected, this function may be
+    /// called to obtain a non-colliding local ID in such a way that subsequence
+    /// calls to global_to_local_object_id() will return the correct local ID
+    /// for both \a incoming_id and \a colliding_id.
+    virtual LocalObjectID allocate_local_id_after_hash_collision(size_t table_ndx,
+                                                                 ObjectID incoming_id,
+                                                                 ObjectID colliding_id,
+                                                                 LocalObjectID colliding_local_id) = 0;
+    static LocalObjectID make_tagged_local_id_after_hash_collision(uint64_t sequence_number);
+    virtual void free_local_id_after_hash_collision(size_t table_ndx, ObjectID object_id) = 0;
+
+    /// Some Object IDs are generated as a tuple of the client_file_ident and a
+    /// local sequence number. This function takes the next number in the
+    /// sequence for the given table and returns an appropriate globally unique
+    /// ObjectID.
+    virtual ObjectID allocate_object_id_squeezed(size_t table_ndx) = 0;
+    static LocalObjectID global_to_local_object_id_squeezed(ObjectID);
+    static ObjectID local_to_global_object_id_squeezed(LocalObjectID);
+
+    virtual void table_erased(size_t table_ndx) = 0;
+
+    virtual int_fast64_t get_client_file_ident() const = 0;
+};
+
+// ObjectIDSet is a set of (table name, object id)
+class ObjectIDSet {
+public:
+
+    void insert(StringData table, ObjectID object_id);
+    void erase(StringData table, ObjectID object_id);
+    bool contains(StringData table, ObjectID object_id) const noexcept;
+    bool empty() const noexcept;
+
+    // A map from table name to a set of object ids.
+    util::metered::map<std::string, util::metered::set<ObjectID>> m_objects;
+};
+
+// FieldSet is a set of fields in tables. A field is defined by a
+// table name, a column in the table and an object id for the row.
+class FieldSet {
+public:
+
+    void insert(StringData table, StringData column, ObjectID object_id);
+    void erase(StringData table, StringData column, ObjectID object_id);
+    bool contains(StringData table, ObjectID object_id) const noexcept;
+    bool contains(StringData table, StringData column, ObjectID object_id) const noexcept;
+    bool empty() const noexcept;
+
+    // A map from table name to a map from column name to a set of
+    // object ids.
+    util::metered::map<
+        std::string,
+        util::metered::map<std::string, util::metered::set<ObjectID>>
+    >  m_fields;
+};
+
+struct GlobalID {
+    StringData table_name;
+    ObjectID object_id;
+
+    bool operator==(const GlobalID& other) const;
+    bool operator!=(const GlobalID& other) const;
+    bool operator<(const GlobalID& other) const;
+};
+
+
+
+
+/// Implementation
+
+constexpr ObjectID::ObjectID(uint64_t hi, uint64_t lo) : m_lo(lo), m_hi(hi)
+{
+}
+
+constexpr ObjectID::ObjectID(realm::util::None) : m_lo(-1), m_hi(-1)
+{
+}
+
+constexpr bool ObjectID::operator<(const ObjectID& other) const
+{
+    return (m_hi == other.m_hi) ? (m_lo < other.m_lo) : (m_hi < other.m_hi);
+}
+
+constexpr bool ObjectID::operator==(const ObjectID& other) const
+{
+    return m_hi == other.m_hi && m_lo == other.m_lo;
+}
+
+constexpr bool ObjectID::operator!=(const ObjectID& other) const
+{
+    return !(*this == other);
+}
+
+constexpr ObjectID::operator bool() const noexcept
+{
+    return (*this != ObjectID{});
+}
+
+inline bool GlobalID::operator==(const GlobalID& other) const
+{
+    return object_id == other.object_id && table_name == other.table_name;
+}
+
+inline bool GlobalID::operator!=(const GlobalID& other) const
+{
+    return !(*this == other);
+}
+
+inline bool GlobalID::operator<(const GlobalID& other) const
+{
+    if (table_name == other.table_name)
+        return object_id < other.object_id;
+    return table_name < other.table_name;
+}
+
+
+std::ostream& operator<<(std::ostream&, const realm::sync::ObjectID&);
+std::istream& operator>>(std::istream&, realm::sync::ObjectID&);
+
+inline ObjectIDProvider::LocalObjectID
+ObjectIDProvider::get_optimistic_local_id_hashed(ObjectID global_id)
+{
+#if REALM_EXERCISE_OBJECT_ID_COLLISION
+    const uint64_t optimistic_mask = 0xff;
+#else
+    const uint64_t optimistic_mask = 0x7fffffffffffffff;
+#endif
+    static_assert(optimistic_mask < 0x8000000000000000, "optimistic Object ID mask must leave the 64th bit zero");
+    return global_id.lo() & optimistic_mask;
+}
+
+inline ObjectIDProvider::LocalObjectID
+ObjectIDProvider::make_tagged_local_id_after_hash_collision(uint64_t sequence_number)
+{
+    REALM_ASSERT(sequence_number < 0x8000000000000000);
+    return 0x8000000000000000 | sequence_number;
+}
+
+inline ObjectIDProvider::LocalObjectID
+ObjectIDProvider::global_to_local_object_id_squeezed(ObjectID object_id)
+{
+    REALM_ASSERT(object_id.hi() <= std::numeric_limits<uint32_t>::max());
+    REALM_ASSERT(object_id.lo() <= std::numeric_limits<uint32_t>::max());
+
+    uint64_t a =  object_id.lo() & 0xff;
+    uint64_t b = (object_id.hi() & 0xff) << 8;
+    uint64_t c = (object_id.lo() & 0xffffff00) << 8;
+    uint64_t d = (object_id.hi() & 0xffffff00) << 32;
+    union {
+        uint64_t u;
+        int64_t  s;
+    } bitcast;
+    bitcast.u = a | b | c | d;
+    return bitcast.s;
+}
+
+inline ObjectID
+ObjectIDProvider::local_to_global_object_id_squeezed(LocalObjectID squeezed)
+{
+    union {
+        uint64_t u;
+        int64_t  s;
+    } bitcast;
+    bitcast.s = squeezed;
+
+    uint64_t u = bitcast.u;
+
+    uint64_t lo = (u & 0xff) | ((u & 0xffffff0000) >> 8);
+    uint64_t hi = ((u & 0xff00) >> 8) | ((u & 0xffffff0000000000) >> 32);
+    return ObjectID{hi, lo};
+}
+
+inline bool ObjectIDSet::empty() const noexcept
+{
+    return m_objects.empty();
+}
+
+inline bool FieldSet::empty() const noexcept
+{
+    return m_fields.empty();
+}
+
+} // namespace sync
+} // namespace realm
+
+namespace std {
+
+template <>
+struct hash<realm::sync::ObjectID> {
+    size_t operator()(realm::sync::ObjectID oid) const
+    {
+        return std::hash<uint64_t>{}(oid.lo()) ^ std::hash<uint64_t>{}(oid.hi());
+    }
+};
+
+} // namespace std
+
+#endif // REALM_SYNC_OBJECT_ID_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/permissions.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/permissions.hpp
new file mode 100644
index 0000000..073f2d6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/permissions.hpp
@@ -0,0 +1,446 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_PERMISSIONS_HPP
+#define REALM_SYNC_PERMISSIONS_HPP
+
+#include <iosfwd>
+
+#include <realm/sync/instruction_applier.hpp>
+#include <realm/sync/object_id.hpp>
+#include <realm/sync/object.hpp>
+#include <realm/util/metered/map.hpp>
+#include <realm/util/metered/set.hpp>
+#include <realm/util/metered/string.hpp>
+
+#include <realm/table_view.hpp>
+
+namespace realm {
+namespace sync {
+
+/// Permissions Schema:
+///
+/// class___Role:
+///     string name PRIMARY_KEY;
+///     User[] members;
+///
+/// class___Permission:
+///     __Role role;
+///     bool canRead;
+///     bool canUpdate;
+///     bool canDelete;
+///     bool canSetPermissions;
+///     bool canQuery;
+///     bool canCreate;
+///     bool canModifySchema;
+///
+/// class___Realm:
+///     int id PRIMARY_KEY = 0; // singleton object
+///     __Permission[] permissions;
+///
+/// class___User:
+///     string id PRIMARY_KEY;
+///     __Role role;
+///
+/// class___Class:
+///     string name PRIMARY_KEY;
+///     __Permission[] permissions;
+///
+/// class_<ANYTHING>:
+///     __Permission[] <user-chosen name>;
+///     __Role <resource-role>;
+///
+
+static constexpr char g_roles_table_name[] = "class___Role";
+static constexpr char g_permissions_table_name[] = "class___Permission";
+static constexpr char g_users_table_name[] = "class___User";
+static constexpr char g_classes_table_name[] = "class___Class";
+static constexpr char g_realms_table_name[] = "class___Realm";
+
+
+/// Create the permissions schema if it doesn't already exist.
+void create_permissions_schema(Group&);
+
+/// Set up the basic "everyone" role and default permissions. The default is to
+/// set up some very permissive defaults, where "everyone" can do everything.
+void set_up_basic_permissions(Group& group, TableInfoCache& table_info_cache, bool permissive = true);
+// Convenience function that creates a new TableInfoCache.
+void set_up_basic_permissions(Group& group, bool permissive = true);
+
+/// Set up some basic permissions for the class. The default is to set up some
+/// very permissive default, where "everyone" can do everything in the class.
+void set_up_basic_permissions_for_class(Group&, StringData class_name, bool permissive = true);
+// void set_up_basic_default_permissions_for_class(Group&, TableRef klass, bool permissive = true);
+
+/// Return the index of the ACL in the class, if one exists. If no ACL column is
+/// defined in the class, returns `npos`.
+size_t find_permissions_column(const Group&, ConstTableRef);
+
+//@{
+/// Convenience functions to check permisions data
+/// The functions must be called inside a read (or write) transaction.
+bool permissions_schema_exist(const Group&);
+
+bool user_exist(const Group&, StringData user_id);
+//@}
+
+
+/// Perform a query as user \a user_id, returning only the results that the
+/// user has access to read. If the user is an admin, there is no need to call
+/// this function, since admins can always read everything.
+///
+/// If the target table of the query does not have object-level permissions,
+/// the query results will be returned without any additional filtering.
+///
+/// If the target table of the query has object-level permissions, but the
+/// permissions schema of this Realm is invalid, an exception of type
+/// `InvalidPermissionsSchema` is thrown.
+///
+/// LIMIT and DISTINCT will be applied *after* permission filters.
+///
+/// The resulting TableView can be used like any other query result.
+///
+/// Note: Class-level and Realm-level permissions are not taken into account in
+/// the resulting TableView, since there is no way to represent this in the
+/// query engine.
+ConstTableView query_with_permissions(Query query, StringData user_id,
+                                      const DescriptorOrdering* ordering = nullptr);
+
+struct InvalidPermissionsSchema : util::runtime_error {
+    using util::runtime_error::runtime_error;
+};
+
+//@{
+/// Convenience function to modify permission data.
+///
+/// When a role or user has not already been defined in the Realm, these
+/// functions create them on-demand.
+void set_realm_permissions_for_role(Group&, StringData role_name,
+                                    uint_least32_t privileges);
+void set_class_permissions_for_role(Group&, StringData class_name,
+                                    StringData role_name, uint_least32_t privileges);
+// void set_default_object_permissions_for_role(Group&, StringData class_name,
+//                                              StringData role_name,
+//                                              uint_least32_t privileges);
+void set_object_permissions_for_role(Group&, TableRef table, size_t row_ndx,
+                                     StringData role_name, uint_least32_t privileges);
+
+void add_user_to_role(Group&, StringData user_id, StringData role_name);
+//@}
+
+/// The Privilege enum is intended to be used in a bitfield.
+enum class Privilege : uint_least32_t {
+    None = 0,
+
+    /// The user can read the object (i.e. it can participate in the user's
+    /// subscription.
+    ///
+    /// NOTE: On objects, it is a prerequisite that the object's class is also
+    /// readable by the user.
+    ///
+    /// FIXME: Until we get asynchronous links, any object that is reachable
+    /// through links from another readable/queryable object is also readable,
+    /// regardless of whether the user specifically does not have read access.
+    Read = 1,
+
+    /// The user can modify the fields of the object.
+    ///
+    /// NOTE: On objects, it is a prerequisite that the object's class is also
+    /// updatable by the user. When applied to a Class object, it does not
+    /// imply that the user can modify the schema of the class, only the
+    /// objects of that class.
+    ///
+    /// NOTE: This does not imply the SetPermissions privilege.
+    Update = 2,
+
+    /// The user can delete the object.
+    ///
+    /// NOTE: When applied to a Class object, it has no effect on whether
+    /// objects of that class can be deleted by the user.
+    ///
+    /// NOTE: This implies the ability to implicitly nullify links pointing
+    /// to the object from other objects, even if the user does not have
+    /// permission to modify those objects in the normal way.
+    Delete = 4,
+
+    //@{
+    /// The user can modify the object's permissions.
+    ///
+    /// NOTE: The user will only be allowed to assign permissions at or below
+    /// their own privilege level.
+    SetPermissions = 8,
+    Share = SetPermissions,
+    //@}
+
+    /// When applied to a Class object, the user can query objects in that
+    /// class.
+    ///
+    /// Has no effect when applied to objects other than Class.
+    Query = 16,
+
+    /// When applied to a Class object, the user may create objects in that
+    /// class.
+    ///
+    /// NOTE: The user implicitly has Update and SetPermissions
+    /// (but not necessarily Delete permission) within the same
+    /// transaction as the object was created.
+    ///
+    /// NOTE: Even when a user has CreateObject rights, a CreateObject
+    /// operation may still be rejected by the server, if the object has a
+    /// primary key and the object already exists, but is not accessible by the
+    /// user.
+    Create = 32,
+
+    /// When applied as a "Realm" privilege, the user can add classes and add
+    /// columns to classes.
+    ///
+    /// NOTE: When applied to a class or object, this has no effect.
+    ModifySchema = 64,
+
+    ///
+    /// Aggregate permissions for compatibility:
+    ///
+    Download = Read | Query,
+    Upload = Update | Delete | Create,
+    DeleteRealm = Upload, // FIXME: This seems overly permissive
+};
+
+inline constexpr uint_least32_t operator|(Privilege a, Privilege b)
+{
+    return static_cast<uint_least32_t>(a) | static_cast<uint_least32_t>(b);
+}
+
+inline constexpr uint_least32_t operator|(uint_least32_t a, Privilege b)
+{
+    return a | static_cast<uint_least32_t>(b);
+}
+
+inline constexpr uint_least32_t operator&(Privilege a, Privilege b)
+{
+    return static_cast<uint_least32_t>(a) & static_cast<uint_least32_t>(b);
+}
+
+inline constexpr uint_least32_t operator&(uint_least32_t a, Privilege b)
+{
+    return a & static_cast<uint_least32_t>(b);
+}
+
+inline uint_least32_t& operator|=(uint_least32_t& a, Privilege b)
+{
+    return a |= static_cast<uint_least32_t>(b);
+}
+
+inline constexpr uint_least32_t operator~(Privilege p)
+{
+    return ~static_cast<uint_least32_t>(p);
+}
+
+struct PermissionsCache {
+    /// Each element is the index of a row in the `class___Roles` table.
+    using RoleList = std::vector<std::size_t>;
+
+    PermissionsCache(const Group& g, TableInfoCache& table_info_cache,
+                     StringData user_identity, bool is_admin = false);
+
+    bool is_admin() const noexcept;
+
+    /// Leaves out any role that has no permission objects linking to it.
+    RoleList get_users_list_of_roles();
+
+    /// Get Realm-level privileges for the current user.
+    ///
+    /// The user must have Read access at the Realm level to be able to see
+    /// anything in the file.
+    ///
+    /// The user must have Update access at the Realm level to be able to make
+    /// any changes at all in the Realm file.
+    ///
+    /// If no Realm-level permissions are defined, no access is granted for any
+    /// user.
+    uint_least32_t get_realm_privileges();
+
+    /// Get class-level privileges for the current user and the given class.
+    ///
+    /// If the class does not have any class-level privileges defined, no access
+    /// is granted to the class.
+    ///
+    /// Calling this function is equivalent to calling `get_object_privileges()`
+    /// with an object of the type `__Class`.
+    ///
+    /// NOTE: This function only considers class-level permissions. It does not
+    /// mask the returned value by the Realm-level permissions. See `can()`.
+    uint_least32_t get_class_privileges(StringData class_name);
+
+    /// Get object-level privileges for the current user and the given object.
+    ///
+    /// If the object's class has an ACL property (a linklist to the
+    /// `__Permission` class), and it isn't empty, the user's privileges is the
+    /// OR'ed privileges for the intersection of roles that have a defined
+    /// permission on the object and the roles of which the user is a member.
+    ///
+    /// If the object's ACL property is empty (but the column exists), no access
+    /// is granted to anyone.
+    ///
+    /// If the object does not exist in the table, the returned value is
+    /// equivalent to that of an object with an empty ACL property, i.e. no
+    /// privileges are granted. Note that the existence of the column is checked
+    /// first, so an absent ACL property (granting all privileges) takes
+    /// precedence over an absent object (granting no privileges) in terms of
+    /// calculating permissions.
+    ///
+    /// NOTE: This function only considers object-level permissions (per-object
+    /// ACLs or default object permissions). It does not mask the returned value
+    /// by the object's class-level permissions, or by the Realm-level
+    /// permissions. See `can()`.
+    uint_least32_t get_object_privileges(GlobalID);
+
+    /// Get object-level privileges without adding it to the cache.
+    uint_least32_t get_object_privileges_nocache(GlobalID);
+
+    //@{
+    /// Check permissions for the object, taking all levels of permission into
+    /// account.
+    ///
+    /// This method only returns `true` if the user has Realm-level access to
+    /// the object, class-level access to the object, and object-level access to
+    /// the object.
+    ///
+    /// In the version where the first argument is a mask of privileges, the
+    /// method only returns `true` when all privileges are satisfied.
+    bool can(Privilege privilege, GlobalID object_id);
+    bool can(uint_least32_t privileges, GlobalID object_id);
+    //@}
+
+    /// Invalidate all cache entries pertaining to the object.
+    ///
+    /// The object may be an instance of `__Class`.
+    void object_permissions_modified(GlobalID);
+
+    /// Register the object as created in this transaction, meaning that the
+    /// user gets full privileges until the end of the transaction.
+    void object_created(GlobalID);
+
+    /// Invalidate all cache entries pertaining to the class.
+    // void default_object_permissions_modified(StringData class_name);
+
+    /// Invalidate all cached permissions.
+    void clear();
+
+    /// Check that all cache permissions correspond to the current permission
+    /// state in the database.
+    void verify();
+
+private:
+    const Group& group;
+    TableInfoCache& m_table_info_cache;
+    std::string user_id;
+    bool m_is_admin;
+    util::Optional<uint_least32_t> realm_privileges;
+    util::metered::map<GlobalID, uint_least32_t> object_privileges;
+    ObjectIDSet created_objects;
+
+    // uint_least32_t get_default_object_privileges(ConstTableRef);
+    uint_least32_t get_privileges_for_permissions(ConstLinkViewRef);
+    friend struct InstructionApplierWithPermissionCheck;
+};
+
+inline bool PermissionsCache::is_admin() const noexcept
+{
+    return m_is_admin;
+}
+
+/// PermissionCorrections is a struct that describes some changes that must be
+/// sent to the client because the client tried to perform changes to a database
+/// that it wasn't allowed to make.
+struct PermissionCorrections {
+    using TableColumnSet = util::metered::map<std::string, util::metered::set<std::string>>;
+    using TableSet = util::metered::set<std::string>;
+
+    // Objects that a client tried to delete without being allowed.
+    ObjectIDSet recreate_objects;
+
+    // Objects that a client tried to create without being allowed.
+    ObjectIDSet erase_objects;
+
+    // Fields that were illegally modified by the client and must be reset.
+    //
+    // Objects mentioned in `recreate_objects` and `erase_objects` are not
+    // mentioned here.
+    FieldSet reset_fields;
+
+    // Columns that were illegally added by the client.
+    TableColumnSet erase_columns;
+
+    // Columns that were illegally removed by the client.
+    TableColumnSet recreate_columns;
+
+    // Tables that were illegally added by the client.
+    // std::set<StringData> erase_tables;
+    TableSet erase_tables;
+
+    // Tables that were illegally removed by the client.
+    TableSet recreate_tables;
+
+    bool empty() const noexcept;
+};
+
+// Function for printing out a permission correction object. Useful for debugging purposes.
+std::ostream& operator<<(std::ostream&, const PermissionCorrections&);
+
+
+
+/// InstructionApplierWithPermissionCheck conditionally applies each
+/// instruction, and builds a `PermissionCorrections` struct based on the
+/// illicit changes. The member `m_corrections` can be used to synthesize a
+/// changeset that can be sent to the client to revert the illicit changes that
+/// were detected by the applier.
+struct InstructionApplierWithPermissionCheck {
+    explicit InstructionApplierWithPermissionCheck(Group& reference_realm,
+                                                   bool is_admin,
+                                                   StringData user_identity);
+    ~InstructionApplierWithPermissionCheck();
+
+    /// Apply \a incoming_changeset, checking permissions in the process.
+    /// Populates `m_corrections`.
+    void apply(const Changeset& incoming_changeset, util::Logger*);
+
+    PermissionCorrections m_corrections;
+
+private:
+    struct Impl;
+    std::unique_ptr<Impl> m_impl;
+};
+
+
+// Implementation:
+
+inline bool PermissionCorrections::empty() const noexcept
+{
+    return recreate_objects.empty() && erase_objects.empty()
+        && reset_fields.empty() && erase_columns.empty()
+        && recreate_columns.empty() && erase_tables.empty()
+        && recreate_tables.empty();
+}
+
+} // namespace sync
+} // namespace realm
+
+
+#endif // REALM_SYNC_PERMISSIONS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/protocol.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/protocol.hpp
new file mode 100644
index 0000000..1178218
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/protocol.hpp
@@ -0,0 +1,439 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_SYNC_PROTOCOL_HPP
+#define REALM_SYNC_PROTOCOL_HPP
+
+#include <cstdint>
+#include <system_error>
+
+#include <realm/replication.hpp>
+
+
+
+// NOTE: The protocol specification is in `/doc/protocol.md`
+
+
+namespace realm {
+namespace sync {
+
+// Protocol versions:
+//
+//   1 Initial version.
+//
+//   2 Introduces the UNBOUND message (sent from server to client in
+//     response to a BIND message).
+//
+//   3 Introduces the ERROR message (sent from server to client before the
+//     server closes a connection). Introduces MARK message from client to
+//     server, and MARK response message from server to client as a way for the
+//     client to wait for download to complete.
+//
+//   4 User token and signature are now passed as a single string (see
+//     /doc/protocol.md for details). Also, `application_ident` parameter
+//     removed from IDENT message.
+//
+//   5 IDENT message renamed to CLIENT, and ALLOC message (client->server)
+//     renamed to IDENT. Also, <client info> parameter added to CLIENT
+//     message. Also, the protocol has been changed to make the clients
+//     acquisition of a server allocated file identifier pair be part of a
+//     session from the servers point of view. File identifier and version
+//     parameters moved from the BIND message to a new IDENT message sent by
+//     client when it has obtained the file identifier pair. Both the new IDENT
+//     message and the ALLOC message sent by the server are now properly
+//     associated with a session.
+//
+//   6 Server session IDs have been added to the IDENT, DOWNLOAD, and PROGRESS
+//     messages, and the "Divergent history" error code was added as an
+//     indication that a server version / session ID pair does not match the
+//     server's history.
+//
+//   7 FIXME: Who introduced version 7? Please describe what changed.
+//
+//   8 Error code (`bad_authentication`) moved from 200-range to 300-range
+//     because it is now session specific. Other error codes were renumbered.
+//
+//   9 New format of the DOWNLOAD message to support progress reporting on the
+//     client
+//
+//  10 Error codes reordered (now categorized as either connection or session
+//     level errors).
+//
+//  11 Bugfixes in Link List and ChangeLinkTargets merge rules, that
+//     make previous versions incompatible.
+//
+//  12 FIXME What was 12?
+//
+//  13 Bugfixes in Link List and ChangeLinkTargets merge rules, that
+//     make previous versions incompatible.
+//
+//  14 Further bugfixes related to primary keys and link lists. Add support for
+//     LinkListSwap.
+//
+//  15 Deleting an object with a primary key deletes all objects on other
+//     with the same primary key.
+//
+//  16 Downloadable bytes added to DOWNLOAD message. It is used for download progress
+//     by the client
+//
+//  17 Added PING and PONG messages. It is used for rtt monitoring and dead
+//     connection detection by both the client and the server.
+//
+//  18 Enhanced the session_ident to accept values of size up to at least 63 bits.
+//
+//  19 New instruction log format with stable object IDs and arrays of
+//     primitives (Generalized LinkList* commands to Container* commands)
+//     Message format is identical to version 18.
+//
+//  20 Added support for log compaction in DOWNLOAD message.
+//
+//  21 Removed "class_" prefix in instructions referencing tables.
+//
+//  22 Fixed a bug in the merge rule of MOVE vs SWAP.
+//
+//  23 Introduced full support for session specific ERROR messages. Removed the
+//     obsolete concept of a "server file identifier". Added support for relayed
+//     subtier client file identifier allocation. For this purpose, the message
+//     that was formerly known as ALLOC was renamed to IDENT, and a new ALLOC
+//     message was added in both directions. Added the ability for an UPLOAD
+//     message to carry a per-changeset origin client file identifier. Added
+//     `<upload server version>` parameter to DOWNLOAD message. Added new error
+//     codes 215 "Unsupported session-level feature" and 216 "Bad origin client
+//     file identifier (UPLOAD)".
+//
+//  24 Support schema-breaking instructions. Official support for partial sync.
+//
+//  25 Include "last server version" in the UPLOAD message for history trimming
+//     on the server.
+//
+//  26 Four new protocol error codes, 217, 218, 219, and 220.
+//
+//     The downloadable_bytes field in the DOWNLOAD message denotes the byte
+//     size of the changesets following those in the DOWNLOAD
+//     message. Previously, downloadable_bytes denoted the total byte size of
+//     the entire history.
+//
+//     Introduction of protocol version flexibility on client side (strictly
+//     speaking, this is a change that transcends the sync protocol).
+//
+//  27 STATE_REQUEST, STATE, CLIENT_VERSION_REQUEST and CLIENT_VERSION messages
+//     introduced. These messages are used for client reset and async open.
+//
+//  28 Introduction of TRANSACT message (serialized transactions). New session
+//     level error code 221 "Serialized transaction before upload completion".
+//
+//     Also added new parameters `<min file format version>`, `<max file format
+//     version>`, `<min history schema version>`, and `<max history schema
+//     version>` to STATE_REQUEST message.
+//
+//  29 Addition of `<progress client version>` and `<progress server version>`
+//     to the UPLOAD message. Together, these constitute an upload cursor that
+//     marks the reached position in the client-side history of the uploading
+//     process.
+//
+//     Removal of `<last server version>`, and addition of `<locked server
+//     version>`. `<last server version>` was replaced in part by `<progress
+//     server version>` as described above, and in part by the new `<locked
+//     server version>`. The purpose of `<locked server version>` is to allow
+//     the client to lock parts of the server-side history that precede
+//     `<progress server version>`. It is intended to be used in the future in
+//     conjunction with the cooked history.
+//
+//  30 New error code, 222 "Client file has expired", was added. New parameter
+//     `<is subserver>` added to BIND message.
+//
+constexpr int get_current_protocol_version() noexcept
+{
+    return 30;
+}
+
+
+/// Supported protocol envelopes:
+///
+///                                                             Alternative (*)
+///      Name     Envelope          URL scheme   Default port   default port
+///     ------------------------------------------------------------------------
+///      realm    WebSocket         realm:       7800           80
+///      realms   WebSocket + SSL   realms:      7801           443
+///      ws       WebSocket         ws:          80
+///      wss      WebSocket + SSL   wss:         443
+///
+///       *) When Client::Config::enable_default_port_hack is true
+///
+enum class ProtocolEnvelope { realm, realms, ws, wss };
+
+inline bool is_ssl(ProtocolEnvelope protocol) noexcept
+{
+    switch (protocol) {
+        case ProtocolEnvelope::realm:
+        case ProtocolEnvelope::ws:
+            break;
+        case ProtocolEnvelope::realms:
+        case ProtocolEnvelope::wss:
+            return true;
+    }
+    return false;
+}
+
+
+// These integer types are selected so that they accomodate the requirements of
+// the protocol specification (`/doc/protocol.md`).
+using file_ident_type    = std::uint_fast64_t;
+using version_type       = Replication::version_type;
+using salt_type          = std::int_fast64_t;
+using timestamp_type     = std::uint_fast64_t;
+using session_ident_type = std::uint_fast64_t;
+using request_ident_type = std::uint_fast64_t;
+using milliseconds_type  = std::int_fast64_t;
+
+constexpr file_ident_type get_max_file_ident()
+{
+    return 0x0'7FFF'FFFF'FFFF'FFFF;
+}
+
+
+struct SaltedFileIdent {
+    file_ident_type ident;
+    /// History divergence and identity spoofing protection.
+    salt_type salt;
+};
+
+struct SaltedVersion {
+    version_type version;
+    /// History divergence protection.
+    salt_type salt;
+};
+
+
+/// \brief A client's reference to a position in the server-side history.
+///
+/// A download cursor refers to a position in the server-side history. If
+/// `server_version` is zero, the position is at the beginning of the history,
+/// otherwise the position is after the entry whose changeset produced that
+/// version. In general, positions are to be understood as places between two
+/// adjacent history entries.
+///
+/// `last_integrated_client_version` is the version produced on the client by
+/// the last changeset that was sent to the server and integrated into the
+/// server-side Realm state at the time indicated by the history position
+/// specified by `server_version`, or zero if no changesets from the client were
+/// integrated by the server at that point in time.
+struct DownloadCursor {
+    version_type server_version;
+    version_type last_integrated_client_version;
+};
+
+/// Checks that `dc.last_integrated_client_version` is zero if
+/// `dc.server_version` is zero.
+bool is_consistent(DownloadCursor dc) noexcept;
+
+/// Checks that `a.last_integrated_client_version` and
+/// `b.last_integrated_client_version` are equal, if `a.server_version` and
+/// `b.server_version` are equal. Otherwise checks that
+/// `a.last_integrated_client_version` is less than, or equal to
+/// `b.last_integrated_client_version`, if `a.server_version` is less than
+/// `b.server_version`. Otherwise checks that `a.last_integrated_client_version`
+/// is greater than, or equal to `b.last_integrated_client_version`.
+bool are_mutually_consistent(DownloadCursor a, DownloadCursor b) noexcept;
+
+
+/// \brief The server's reference to a position in the client-side history.
+///
+/// An upload cursor refers to a position in the client-side history. If
+/// `client_version` is zero, the position is at the beginning of the history,
+/// otherwise the position is after the entry whose changeset produced that
+/// version. In general, positions are to be understood as places between two
+/// adjacent history entries.
+///
+/// `last_integrated_server_version` is the version produced on the server by
+/// the last changeset that was sent to the client and integrated into the
+/// client-side Realm state at the time indicated by the history position
+/// specified by `client_version`, or zero if no changesets from the server were
+/// integrated by the client at that point in time.
+struct UploadCursor {
+    version_type client_version;
+    version_type last_integrated_server_version;
+};
+
+/// Checks that `uc.last_integrated_server_version` is zero if
+/// `uc.client_version` is zero.
+bool is_consistent(UploadCursor uc) noexcept;
+
+/// Checks that `a.last_integrated_server_version` and
+/// `b.last_integrated_server_version` are equal, if `a.client_version` and
+/// `b.client_version` are equal. Otherwise checks that
+/// `a.last_integrated_server_version` is less than, or equal to
+/// `b.last_integrated_server_version`, if `a.client_version` is less than
+/// `b.client_version`. Otherwise checks that `a.last_integrated_server_version`
+/// is greater than, or equal to `b.last_integrated_server_version`.
+bool are_mutually_consistent(UploadCursor a, UploadCursor b) noexcept;
+
+
+/// A client's record of the current point of progress of the synchronization
+/// process. The client must store this persistently in the local Realm file.
+struct SyncProgress {
+    /// The last server version that the client has heard about.
+    SaltedVersion latest_server_version = {0, 0};
+
+    /// The last server version integrated, or about to be integrated by the
+    /// client.
+    DownloadCursor download = {0, 0};
+
+    /// The last client version integrated by the server.
+    UploadCursor upload = {0, 0};
+};
+
+
+/// An indication of the final status of an attempt at performing a serialized
+/// transaction.
+enum class SerialTransactStatus {
+    /// The transaction was accepted and successful.
+    accepted = 1,
+
+    /// The transaction was rejected because the servers history contained
+    /// causally unrelated changes. I.e., the requesting client lost a race to
+    /// be served first. The client should try again.
+    rejected = 2,
+
+    /// The server did not support serialized transactions at all, or did not
+    /// support it on the targeted Realm in particular.
+    not_supported = 3,
+};
+
+
+
+/// \brief Protocol errors discovered by the server, and reported to the client
+/// by way of ERROR messages.
+///
+/// These errors will be reported to the client-side application via the error
+/// handlers of the affected sessions.
+///
+/// ATTENTION: Please remember to update is_session_level_error() when
+/// adding/removing error codes.
+enum class ProtocolError {
+    // Connection level and protocol errors
+    connection_closed            = 100, // Connection closed (no error)
+    other_error                  = 101, // Other connection level error
+    unknown_message              = 102, // Unknown type of input message
+    bad_syntax                   = 103, // Bad syntax in input message head
+    limits_exceeded              = 104, // Limits exceeded in input message
+    wrong_protocol_version       = 105, // Wrong protocol version (CLIENT) (obsolete)
+    bad_session_ident            = 106, // Bad session identifier in input message
+    reuse_of_session_ident       = 107, // Overlapping reuse of session identifier (BIND)
+    bound_in_other_session       = 108, // Client file bound in other session (IDENT)
+    bad_message_order            = 109, // Bad input message order
+    bad_decompression            = 110, // Error in decompression (UPLOAD)
+    bad_changeset_header_syntax  = 111, // Bad syntax in a changeset header (UPLOAD)
+    bad_changeset_size           = 112, // Bad size specified in changeset header (UPLOAD)
+    bad_changesets               = 113, // Bad changesets (UPLOAD)
+
+    // Session level errors
+    session_closed               = 200, // Session closed (no error)
+    other_session_error          = 201, // Other session level error
+    token_expired                = 202, // Access token expired
+    bad_authentication           = 203, // Bad user authentication (BIND, REFRESH)
+    illegal_realm_path           = 204, // Illegal Realm path (BIND)
+    no_such_realm                = 205, // No such Realm (BIND)
+    permission_denied            = 206, // Permission denied (STATE_REQUEST, BIND, REFRESH)
+    bad_server_file_ident        = 207, // Bad server file identifier (IDENT) (obsolete!)
+    bad_client_file_ident        = 208, // Bad client file identifier (IDENT)
+    bad_server_version           = 209, // Bad server version (IDENT, UPLOAD, TRANSACT)
+    bad_client_version           = 210, // Bad client version (IDENT, UPLOAD)
+    diverging_histories          = 211, // Diverging histories (IDENT)
+    bad_changeset                = 212, // Bad changeset (UPLOAD)
+    superseded                   = 213, // Superseded by new session for same client-side file (deprecated)
+    disabled_session             = 213, // Alias for `superseded` (deprecated)
+    partial_sync_disabled        = 214, // Partial sync disabled (BIND, STATE_REQUEST)
+    unsupported_session_feature  = 215, // Unsupported session-level feature
+    bad_origin_file_ident        = 216, // Bad origin file identifier (UPLOAD)
+    bad_client_file              = 217, // Synchronization no longer possible for client-side file
+    server_file_deleted          = 218, // Server file was deleted while session was bound to it
+    client_file_blacklisted      = 219, // Client file has been blacklisted (IDENT)
+    user_blacklisted             = 220, // User has been blacklisted (BIND)
+    transact_before_upload       = 221, // Serialized transaction before upload completion
+    client_file_expired          = 222, // Client file has expired
+};
+
+constexpr bool is_session_level_error(ProtocolError);
+
+/// Returns null if the specified protocol error code is not defined by
+/// ProtocolError.
+const char* get_protocol_error_message(int error_code) noexcept;
+
+const std::error_category& protocol_error_category() noexcept;
+
+std::error_code make_error_code(ProtocolError) noexcept;
+
+} // namespace sync
+} // namespace realm
+
+namespace std {
+
+template<> struct is_error_code_enum<realm::sync::ProtocolError> {
+    static const bool value = true;
+};
+
+} // namespace std
+
+namespace realm {
+namespace sync {
+
+
+
+
+
+// Implementation
+
+inline bool is_consistent(DownloadCursor dc) noexcept
+{
+    return (dc.server_version != 0 || dc.last_integrated_client_version == 0);
+}
+
+inline bool are_mutually_consistent(DownloadCursor a, DownloadCursor b) noexcept
+{
+    if (a.server_version < b.server_version)
+        return (a.last_integrated_client_version <= b.last_integrated_client_version);
+    if (a.server_version > b.server_version)
+        return (a.last_integrated_client_version >= b.last_integrated_client_version);
+    return (a.last_integrated_client_version == b.last_integrated_client_version);
+}
+
+inline bool is_consistent(UploadCursor uc) noexcept
+{
+    return (uc.client_version != 0 || uc.last_integrated_server_version == 0);
+}
+
+inline bool are_mutually_consistent(UploadCursor a, UploadCursor b) noexcept
+{
+    if (a.client_version < b.client_version)
+        return (a.last_integrated_server_version <= b.last_integrated_server_version);
+    if (a.client_version > b.client_version)
+        return (a.last_integrated_server_version >= b.last_integrated_server_version);
+    return (a.last_integrated_server_version == b.last_integrated_server_version);
+}
+
+constexpr bool is_session_level_error(ProtocolError error)
+{
+    return int(error) >= 200 && int(error) <= 299;
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_PROTOCOL_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/transform.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/transform.hpp
new file mode 100644
index 0000000..1f74fa6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/transform.hpp
@@ -0,0 +1,293 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SYNC_TRANSFORM_HPP
+#define REALM_SYNC_TRANSFORM_HPP
+
+#include <stddef.h>
+
+#include <realm/util/buffer.hpp>
+#include <realm/impl/cont_transact_hist.hpp>
+#include <realm/group_shared.hpp>
+#include <realm/chunked_binary.hpp>
+#include <realm/sync/protocol.hpp>
+
+namespace realm {
+namespace sync {
+
+struct Changeset;
+
+/// Represents an entry in the history of changes in a sync-enabled Realm
+/// file. Server and client use different history formats, but this class is
+/// used both on the server and the client side. Each history entry corresponds
+/// to a version of the Realm state. For server and client-side histories, these
+/// versions are referred to as *server versions* and *client versions*
+/// respectively. These versions may, or may not correspond to Realm snapshot
+/// numbers (on the server-side they currently do not).
+///
+/// FIXME: Move this class into a separate header
+/// (`<realm/sync/history_entry.hpp>`).
+class HistoryEntry {
+public:
+    /// The time of origination of the changes referenced by this history entry,
+    /// meassured as the number of milliseconds since 2015-01-01T00:00:00Z, not
+    /// including leap seconds. For changes of local origin, this is the local
+    /// time at the point when the local transaction was committed. For changes
+    /// of remote origin, it is the remote time of origin at the peer (client or
+    /// server) identified by `origin_file_ident`.
+    timestamp_type origin_timestamp;
+
+    /// The identifier of the file in the context of which the initial
+    /// untransformed changeset originated, or zero if the changeset originated
+    /// on the local peer (client or server).
+    ///
+    /// For example, when a changeset "travels" from a file with identifier 2 on
+    /// client A, through a file with identifier 1 on the server, to a file with
+    /// identifier 3 on client B, then `origin_file_ident` will be 0 on client
+    /// A, 2 on the server, and 2 on client B. On the other hand, if the server
+    /// was the originator of the changeset, then `origin_file_ident` would be
+    /// zero on the server, and 1 on both clients.
+    file_ident_type origin_file_ident;
+
+    /// For changes of local origin on the client side, this is the last server
+    /// version integrated locally prior to this history entry. In other words,
+    /// it is a copy of `remote_version` of the last preceding history entry
+    /// that carries changes of remote origin, or zero if there is no such
+    /// preceding history entry.
+    ///
+    /// For changes of local origin on the server-side, this is always zero.
+    ///
+    /// For changes of remote origin, this is the version produced within the
+    /// remote-side Realm file by the change that gave rise to this history
+    /// entry. The remote-side Realm file is not always the same Realm file from
+    /// which the change originated. On the client side, the remote side is
+    /// always the server side, and `remote_version` is always a server version
+    /// (since clients do not speak directly to each other). On the server side,
+    /// the remote side is always a client side, and `remote_version` is always
+    /// a client version.
+    version_type remote_version;
+
+    /// Referenced memory is not owned by this class.
+    ChunkedBinaryData changeset;
+};
+
+
+
+/// The interface between the sync history and the operational transformer
+/// (Transformer) for the purpose of transforming changesets received from a
+/// particular *remote peer*.
+class TransformHistory {
+public:
+    /// Get the first history entry where the produced version is greater than
+    /// `begin_version` and less than or equal to `end_version`, and whose
+    /// changeset is neither empty, nor produced by integration of a changeset
+    /// received from the remote peer associated with this history.
+    ///
+    /// If \a buffer is non-null, memory will be allocated and transferred to
+    /// \a buffer. The changeset will be copied into the newly allocated memory.
+    ///
+    /// If \a buffer is null, the changeset is not copied out of the Realm,
+    /// and entry.changeset.data() does not point to the changeset.
+    /// The changeset in the Realm could be chunked, hence it is not possible
+    /// to point to it with BinaryData. entry.changeset.size() always gives the
+    /// size of the changeset.
+    ///
+    /// \param begin_version, end_version The range of versions to consider. If
+    /// `begin_version` is equal to `end_version`, it is the empty range. If
+    /// `begin_version` is zero, it means that everything preceeding
+    /// `end_version` is to be considered, which is again the empty range if
+    /// `end_version` is also zero. Zero is a special value in that no changeset
+    /// produces that version. It is an error if `end_version` precedes
+    /// `begin_version`, or if `end_version` is zero and `begin_version` is not.
+    ///
+    /// \return The version produced by the changeset of the located history
+    /// entry, or zero if no history entry exists matching the specified and
+    /// implied criteria.
+    virtual version_type find_history_entry(version_type begin_version, version_type end_version,
+                                            HistoryEntry& entry) const noexcept = 0;
+
+    /// Get the specified reciprocal changeset. The targeted history entry is
+    /// the one whose untransformed changeset produced the specified version.
+    virtual ChunkedBinaryData get_reciprocal_transform(version_type version) const = 0;
+
+    /// Replace the specified reciprocally transformed changeset. The targeted
+    /// history entry is the one whose untransformed changeset produced the
+    /// specified version.
+    ///
+    /// \param encoded_changeset The new reciprocally transformed changeset.
+    virtual void set_reciprocal_transform(version_type version, BinaryData encoded_changeset) = 0;
+
+    virtual ~TransformHistory() noexcept {}
+};
+
+
+
+class TransformError; // Exception
+
+class Transformer {
+public:
+    class RemoteChangeset;
+    class Reporter;
+
+    /// Produce operationally transformed versions of the specified changesets,
+    /// which are assumed to be received from a particular remote peer, P,
+    /// represented by the specified transform history. Note that P is not
+    /// necessarily the peer on which the changes originated.
+    ///
+    /// Operational transformation is carried out between the specified
+    /// changesets and all causally unrelated changesets in the local history. A
+    /// changeset in the local history is causally unrelated if, and only if it
+    /// occurs after the local changeset that produced
+    /// `remote_changeset.last_integrated_local_version` and is not a produced
+    /// by integration of a changeset received from P. This assumes that
+    /// `remote_changeset.last_integrated_local_version` is set to the local
+    /// version produced by the last local changeset, that was integrated by P
+    /// before P produced the specified changeset.
+    ///
+    /// The operational transformation is reciprocal (two-way), so it also
+    /// transforms the causally unrelated local changesets. This process does
+    /// not modify the history itself (the changesets available through
+    /// TransformHistory::get_history_entry()), instead the reciprocally
+    /// transformed changesets are stored separately, and individually for each
+    /// remote peer, such that they can participate in transformation of the
+    /// next incoming changeset from P.
+    ///
+    /// In general, if A and B are two causally unrelated (alternative)
+    /// changesets based on the same version V, then the operational
+    /// transformation between A and B produces changesets A' and B' such that
+    /// both of the concatenated changesets A + B' and B + A' produce the same
+    /// final state when applied to V. Operational transformation is meaningful
+    /// only when carried out between alternative changesets based on the same
+    /// version.
+    ///
+    /// \param local_file_ident The identifier of the local Realm file. The
+    /// transformer uses this as the actual origin file identifier for
+    /// changesets where HistoryEntry::origin_file_ident is zero, i.e., when the
+    /// changeset is of local origin. The specified identifier must never be
+    /// zero.
+    ///
+    /// \return The size of the transformed version of the specified
+    /// changesets. Upon return, the transformed changesets are concatenated
+    /// and placed in \a output_buffer.
+    ///
+    /// \throw TransformError Thrown if operational transformation fails due to
+    /// a problem with the specified changeset.
+    ///
+    /// FIXME: Consider using std::error_code instead of throwing
+    /// TransformError.
+    virtual void transform_remote_changesets(TransformHistory&,
+                                             file_ident_type local_file_ident,
+                                             version_type current_local_version,
+                                             Changeset* changesets,
+                                             std::size_t num_changesets,
+                                             Reporter* = nullptr,
+                                             util::Logger* = nullptr) = 0;
+
+    virtual ~Transformer() noexcept {}
+};
+
+std::unique_ptr<Transformer> make_transformer();
+
+
+
+class Transformer::RemoteChangeset {
+public:
+    /// The version produced on the remote peer by this changeset.
+    ///
+    /// On the server, the remote peer is the client from which the changeset
+    /// originated, and `remote_version` is the client version produced by the
+    /// changeset on that client.
+    ///
+    /// On a client, the remote peer is the server, and `remote_version` is the
+    /// server version produced by this changeset on the server. Since the
+    /// server is never the originator of changes, this changeset must in turn
+    /// have been produced on the server by integration of a changeset uploaded
+    /// by some other client.
+    version_type remote_version = 0;
+
+    /// The last local version that has been integrated into `remote_version`.
+    ///
+    /// A local version, L, has been integrated into a remote version, R, when,
+    /// and only when L is the latest local version such that all preceeding
+    /// changesets in the local history have been integrated by the remote peer
+    /// prior to R.
+    ///
+    /// On the server, this is the last server version integrated into the
+    /// client version `remote_version`. On a client, it is the last client
+    /// version integrated into the server version `remote_version`.
+    version_type last_integrated_local_version = 0;
+
+    /// The changeset itself.
+    ChunkedBinaryData data;
+
+    /// Same meaning as `HistoryEntry::origin_timestamp`.
+    timestamp_type origin_timestamp = 0;
+
+    /// Same meaning as `HistoryEntry::origin_file_ident`.
+    file_ident_type origin_file_ident = 0;
+
+    /// If the changeset was compacted during download, the size of the original
+    /// changeset.
+    std::size_t original_changeset_size = 0;
+
+    RemoteChangeset() {}
+    RemoteChangeset(version_type rv, version_type lv, ChunkedBinaryData d, timestamp_type ot,
+                    file_ident_type fi);
+};
+
+
+
+class Transformer::Reporter {
+public:
+    virtual void on_changesets_merged(long num_merges) = 0;
+};
+
+
+
+void parse_remote_changeset(const Transformer::RemoteChangeset&, Changeset&);
+
+
+
+
+// Implementation
+
+class TransformError: public std::runtime_error {
+public:
+    TransformError(const std::string& message):
+        std::runtime_error(message)
+    {
+    }
+};
+
+inline Transformer::RemoteChangeset::RemoteChangeset(version_type rv, version_type lv,
+                                                     ChunkedBinaryData d, timestamp_type ot,
+                                                     file_ident_type fi):
+    remote_version(rv),
+    last_integrated_local_version(lv),
+    data(d),
+    origin_timestamp(ot),
+    origin_file_ident(fi)
+{
+}
+
+} // namespace sync
+} // namespace realm
+
+#endif // REALM_SYNC_TRANSFORM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/sync/version.hpp b/node_modules/realm/vendor/realm-ios/include/realm/sync/version.hpp
new file mode 100644
index 0000000..65e09ca
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/sync/version.hpp
@@ -0,0 +1,34 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2013] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_SYNC_VERSION_HPP
+#define REALM_SYNC_VERSION_HPP
+
+#include <realm/util/features.h>
+
+#define REALM_SYNC_VER_MAJOR 4
+#define REALM_SYNC_VER_MINOR 9
+#define REALM_SYNC_VER_PATCH 1
+#define REALM_SYNC_PRODUCT_NAME "realm-sync"
+
+#define REALM_SYNC_VER_STRING REALM_QUOTE(REALM_SYNC_VER_MAJOR) "." \
+    REALM_QUOTE(REALM_SYNC_VER_MINOR) "." REALM_QUOTE(REALM_SYNC_VER_PATCH)
+#define REALM_SYNC_VER_CHUNK "[" REALM_SYNC_PRODUCT_NAME "-" REALM_SYNC_VER_STRING "]"
+
+#endif // REALM_SYNC_VERSION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/table.hpp b/node_modules/realm/vendor/realm-ios/include/realm/table.hpp
new file mode 100644
index 0000000..1535b57
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/table.hpp
@@ -0,0 +1,2807 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_TABLE_HPP
+#define REALM_TABLE_HPP
+
+#include <algorithm>
+#include <map>
+#include <utility>
+#include <typeinfo>
+#include <memory>
+#include <mutex>
+
+#include <realm/util/features.h>
+#include <realm/util/thread.hpp>
+#include <realm/table_ref.hpp>
+#include <realm/link_view_fwd.hpp>
+#include <realm/row.hpp>
+#include <realm/descriptor_fwd.hpp>
+#include <realm/spec.hpp>
+#include <realm/mixed.hpp>
+#include <realm/query.hpp>
+#include <realm/column.hpp>
+#include <realm/column_binary.hpp>
+
+namespace realm {
+
+class BacklinkColumn;
+template <class>
+class BacklinkCount;
+class BinaryColumy;
+class ConstTableView;
+class Group;
+class LinkColumn;
+class LinkColumnBase;
+class LinkListColumn;
+class LinkView;
+class SortDescriptor;
+class StringIndex;
+class TableView;
+class TableViewBase;
+class TimestampColumn;
+template <class>
+class Columns;
+template <class>
+class SubQuery;
+struct LinkTargetInfo;
+
+struct SubTable {
+};
+struct Link {
+};
+typedef Link LinkList;
+typedef Link BackLink;
+
+namespace _impl {
+class TableFriend;
+}
+namespace metrics {
+class QueryInfo;
+}
+
+class Replication;
+
+
+/// FIXME: Table assignment (from any group to any group) could be made aliasing
+/// safe as follows: Start by cloning source table into target allocator. On
+/// success, assign, and then deallocate any previous structure at the target.
+///
+/// FIXME: It might be desirable to have a 'table move' feature between two
+/// places inside the same group (say from a subtable or a mixed column to group
+/// level). This could be done in a very efficient manner.
+///
+/// FIXME: When compiling in debug mode, all public non-static table functions
+/// should REALM_ASSERT(is_attached()).
+class Table {
+public:
+    /// Construct a new freestanding top-level table with static
+    /// lifetime.
+    ///
+    /// This constructor should be used only when placing a table
+    /// instance on the stack, and it is then the responsibility of
+    /// the application that there are no objects of type TableRef or
+    /// ConstTableRef that refer to it, or to any of its subtables,
+    /// when it goes out of scope. To create a top-level table with
+    /// dynamic lifetime, use Table::create() instead.
+    Table(Allocator& = Allocator::get_default());
+
+    /// Construct a copy of the specified table as a new freestanding
+    /// top-level table with static lifetime.
+    ///
+    /// This constructor should be used only when placing a table
+    /// instance on the stack, and it is then the responsibility of
+    /// the application that there are no objects of type TableRef or
+    /// ConstTableRef that refer to it, or to any of its subtables,
+    /// when it goes out of scope. To create a top-level table with
+    /// dynamic lifetime, use Table::copy() instead.
+    Table(const Table&, Allocator& = Allocator::get_default());
+
+    ~Table() noexcept;
+
+    Allocator& get_alloc() const;
+
+    /// Construct a new freestanding top-level table with dynamic lifetime.
+    static TableRef create(Allocator& = Allocator::get_default());
+
+    /// Construct a copy of the specified table as a new freestanding top-level
+    /// table with dynamic lifetime.
+    TableRef copy(Allocator& = Allocator::get_default()) const;
+
+    /// Returns true if, and only if this accessor is currently attached to an
+    /// underlying table.
+    ///
+    /// A table accessor may get detached from the underlying row for various
+    /// reasons (see below). When it does, it no longer refers to anything, and
+    /// can no longer be used, except for calling is_attached(). The
+    /// consequences of calling other non-static functions on a detached table
+    /// accessor are unspecified. Table accessors obtained by calling functions in
+    /// the Realm API are always in the 'attached' state immediately upon
+    /// return from those functions.
+    ///
+    /// A table accessor of a free-standing table never becomes detached (except
+    /// during its eventual destruction). A group-level table accessor becomes
+    /// detached if the underlying table is removed from the group, or when the
+    /// group accessor is destroyed. A subtable accessor becomes detached if the
+    /// underlying subtable is removed, or if the parent table accessor is
+    /// detached. A table accessor does not become detached for any other reason
+    /// than those mentioned here.
+    ///
+    /// FIXME: High level language bindings will probably want to be able to
+    /// explicitely detach a group and all tables of that group if any modifying
+    /// operation fails (e.g. memory allocation failure) (and something similar
+    /// for freestanding tables) since that leaves the group in state where any
+    /// further access is disallowed. This way they will be able to reliably
+    /// intercept any attempt at accessing such a failed group.
+    ///
+    /// FIXME: The C++ documentation must state that if any modifying operation
+    /// on a group (incl. tables, subtables, and specs) or on a free standing
+    /// table (incl. subtables and specs) fails, then any further access to that
+    /// group (except ~Group()) or freestanding table (except ~Table()) has
+    /// undefined behaviour and is considered an error on behalf of the
+    /// application. Note that even Table::is_attached() is disallowed in this
+    /// case.
+    bool is_attached() const noexcept;
+
+    /// Get the name of this table, if it has one. Only group-level tables have
+    /// names. For a table of any other kind, this function returns the empty
+    /// string.
+    StringData get_name() const noexcept;
+
+    // Whether or not elements can be null.
+    bool is_nullable(size_t col_ndx) const;
+
+    // Returns the link type for the given column.
+    // Throws an LogicError if target column is not a link column.
+    LinkType get_link_type(size_t col_ndx) const;
+
+    //@{
+    /// Conventience functions for inspecting the dynamic table type.
+    ///
+    /// These functions behave as if they were called on the descriptor returned
+    /// by get_descriptor().
+    size_t get_column_count() const noexcept;
+    DataType get_column_type(size_t column_ndx) const noexcept;
+    StringData get_column_name(size_t column_ndx) const noexcept;
+    size_t get_column_index(StringData name) const noexcept;
+    typedef util::Optional<std::pair<ConstTableRef, size_t>> BacklinkOrigin;
+    BacklinkOrigin find_backlink_origin(StringData origin_table_name, StringData origin_col_name) const noexcept;
+    //@}
+
+    //@{
+    /// Convenience functions for manipulating the dynamic table type.
+    ///
+    /// These function must be called only for tables with independent dynamic
+    /// type. A table has independent dynamic type if the function
+    /// has_shared_type() returns false. A table that is a direct member of a
+    /// group has independent dynamic type. So does a free-standing table, and a
+    /// subtable in a column of type 'mixed'. All other tables have shared
+    /// dynamic type. The consequences of calling any of these functions for a
+    /// table with shared dynamic type are undefined.
+    ///
+    /// Apart from that, these functions behave as if they were called on the
+    /// descriptor returned by get_descriptor(). Note especially that the
+    /// `_link` suffixed functions must be used when inserting link-type
+    /// columns.
+    ///
+    /// If you need to change the shared dynamic type of the subtables in a
+    /// subtable column, consider using the API offered by the Descriptor class.
+    ///
+    /// \sa has_shared_type()
+    /// \sa get_descriptor()
+
+    size_t add_column(DataType type, StringData name, bool nullable = false, DescriptorRef* subdesc = nullptr);
+    void insert_column(size_t column_ndx, DataType type, StringData name, bool nullable = false,
+                       DescriptorRef* subdesc = nullptr);
+
+    // Todo, these prototypes only exist for backwards compatibility. We should remove them because they are error
+    // prone (optional arguments and implicit bool to null-ptr conversion)
+    size_t add_column(DataType type, StringData name, DescriptorRef* subdesc)
+    {
+        return add_column(type, name, false, subdesc);
+    }
+    void insert_column(size_t column_ndx, DataType type, StringData name, DescriptorRef* subdesc)
+    {
+        insert_column(column_ndx, type, name, false, subdesc);
+    }
+
+    size_t add_column_link(DataType type, StringData name, Table& target, LinkType link_type = link_Weak);
+    void insert_column_link(size_t column_ndx, DataType type, StringData name, Table& target,
+                            LinkType link_type = link_Weak);
+    void remove_column(size_t column_ndx);
+    void rename_column(size_t column_ndx, StringData new_name);
+    //@}
+    //@{
+
+    /// has_search_index() returns true if, and only if a search index has been
+    /// added to the specified column. Rather than throwing, it returns false if
+    /// the table accessor is detached or the specified index is out of range.
+    ///
+    /// add_search_index() adds a search index to the specified column of the
+    /// table. It has no effect if a search index has already been added to the
+    /// specified column (idempotency).
+    ///
+    /// remove_search_index() removes the search index from the specified column
+    /// of the table. It has no effect if the specified column has no search
+    /// index. The search index cannot be removed from the primary key of a
+    /// table.
+    ///
+    /// This table must be a root table; that is, it must have an independent
+    /// descriptor. Freestanding tables, group-level tables, and subtables in a
+    /// column of type 'mixed' are all examples of root tables. See add_column()
+    /// for more on this. If you want to manipulate subtable indexes, you must use
+    /// the Descriptor interface.
+    ///
+    /// \param column_ndx The index of a column of the table.
+
+    bool has_search_index(size_t column_ndx) const noexcept;
+    void add_search_index(size_t column_ndx);
+    void remove_search_index(size_t column_ndx);
+
+    //@}
+
+    //@{
+    /// Get the dynamic type descriptor for this table.
+    ///
+    /// Every table has an associated descriptor that specifies its dynamic
+    /// type. For simple tables, that is, tables without subtable columns, the
+    /// dynamic type can be inspected and modified directly using member
+    /// functions such as get_column_count() and add_column(). For more complex
+    /// tables, the type is best managed through the associated descriptor
+    /// object which is returned by this function.
+    ///
+    /// \sa has_shared_type()
+    DescriptorRef get_descriptor();
+    ConstDescriptorRef get_descriptor() const;
+    //@}
+
+    //@{
+    /// Get the dynamic type descriptor for the column with the
+    /// specified index. That column must have type 'table'.
+    ///
+    /// This is merely a shorthand for calling `get_subdescriptor(column_ndx)`
+    /// on the descriptor returned by `get_descriptor()`.
+    DescriptorRef get_subdescriptor(size_t column_ndx);
+    ConstDescriptorRef get_subdescriptor(size_t column_ndx) const;
+    //@}
+
+    //@{
+    /// Get access to an arbitrarily nested dynamic type descriptor.
+    ///
+    /// The returned descriptor is the one you would get by calling
+    /// Descriptor::get_subdescriptor() once for each entry in the specified
+    /// path, starting with the descriptor returned by get_descriptor(). The
+    /// path is allowed to be empty.
+    typedef std::vector<size_t> path_vec;
+    DescriptorRef get_subdescriptor(const path_vec& path);
+    ConstDescriptorRef get_subdescriptor(const path_vec& path) const;
+    //@}
+
+    //@{
+    /// Convenience functions for manipulating nested table types.
+    ///
+    /// These functions behave as if they were called on the descriptor returned
+    /// by `get_subdescriptor(path)`. These function must be called only on
+    /// tables with independent dynamic type.
+    ///
+    /// \return The value returned by add_subcolumn(), is the index of
+    /// the added column within the descriptor referenced by the
+    /// specified path.
+    ///
+    /// \sa Descriptor::add_column()
+    /// \sa has_shared_type()
+    size_t add_subcolumn(const path_vec& path, DataType type, StringData name);
+    void insert_subcolumn(const path_vec& path, size_t column_ndx, DataType type, StringData name);
+    void remove_subcolumn(const path_vec& path, size_t column_ndx);
+    void rename_subcolumn(const path_vec& path, size_t column_ndx, StringData new_name);
+    //@}
+
+    /// Does this table share its type with other tables?
+    ///
+    /// Tables that are direct members of groups have independent
+    /// dynamic types. The same is true for free-standing tables and
+    /// subtables in coulmns of type 'mixed'. For such tables, this
+    /// function returns false.
+    ///
+    /// When a table has a column of type 'table', the cells in that
+    /// column contain subtables. All those subtables have the same
+    /// dynamic type, and they share a single type descriptor. For all
+    /// such subtables, this function returns true. See
+    /// Descriptor::is_root() for more on this.
+    ///
+    /// Please note that Table functions that modify the dynamic type
+    /// directly, such as add_column(), are only allowed to be used on
+    /// tables with non-shared type. If you need to modify a shared
+    /// type, you will have to do that through the descriptor returned
+    /// by get_descriptor(), but note that it will then affect all the
+    /// tables sharing that descriptor.
+    ///
+    /// \sa get_descriptor()
+    /// \sa Descriptor::is_root()
+    bool has_shared_type() const noexcept;
+
+
+    template <class T>
+    Columns<T> column(size_t column); // FIXME: Should this one have been declared noexcept?
+    template <class T>
+    Columns<T> column(const Table& origin, size_t origin_column_ndx);
+    // BacklinkCount is a total count per row and therefore not attached to a specific column
+    template <class T>
+    BacklinkCount<T> get_backlink_count();
+
+    template <class T>
+    SubQuery<T> column(size_t column, Query subquery);
+    template <class T>
+    SubQuery<T> column(const Table& origin, size_t origin_column_ndx, Query subquery);
+
+    // Table size and deletion
+    bool is_empty() const noexcept;
+    size_t size() const noexcept;
+
+    typedef BasicRowExpr<Table> RowExpr;
+    typedef BasicRowExpr<const Table> ConstRowExpr;
+
+    RowExpr get(size_t row_ndx) noexcept;
+    ConstRowExpr get(size_t row_ndx) const noexcept;
+
+    RowExpr front() noexcept;
+    ConstRowExpr front() const noexcept;
+
+    RowExpr back() noexcept;
+    ConstRowExpr back() const noexcept;
+
+    RowExpr operator[](size_t row_ndx) noexcept;
+    ConstRowExpr operator[](size_t row_ndx) const noexcept;
+
+
+    //@{
+
+    /// Row handling.
+    ///
+    /// remove() removes the specified row from the table and shifts all rows at
+    /// higher index to fill the vacated slot. This operation assumes that the
+    /// table is ordered, and it is therefore allowed only on tables **without**
+    /// link columns, as link columns are only allowed in unordered tables.
+    ///
+    /// move_last_over() removes the specified row from the table, and if it is
+    /// not the last row in the table, it then moves the last row into the
+    /// vacated slot. This operation assumes that the table is unordered, and it
+    /// may therfore be used on tables with link columns.
+    ///
+    /// remove_recursive() will delete linked rows if the removed link was the
+    /// last one holding on to the row in question. This will be done recursively.
+    ///
+    /// The removal of a row from an unordered table (move_last_over()) may
+    /// cause other linked rows to be cascade-removed. The clearing of a table
+    /// may also cause linked rows to be cascade-removed, but in this respect,
+    /// the effect is exactly as if each row had been removed individually. See
+    /// Descriptor::set_link_type() for details.
+
+    size_t add_empty_row(size_t num_rows = 1);
+    void insert_empty_row(size_t row_ndx, size_t num_rows = 1);
+    size_t add_row_with_key(size_t col_ndx, util::Optional<int64_t> key);
+    size_t add_row_with_keys(size_t col_1_ndx, int64_t key1, size_t col_2_ndx, StringData key2);
+    void remove(size_t row_ndx);
+    void remove_recursive(size_t row_ndx);
+    void remove_last();
+    void move_last_over(size_t row_ndx);
+    void clear();
+    void swap_rows(size_t row_ndx_1, size_t row_ndx_2);
+    void move_row(size_t from_ndx, size_t to_ndx);
+    //@}
+
+    /// Replaces all links to \a row_ndx with links to \a new_row_ndx.
+    ///
+    /// This operation is usually followed by Table::move_last_over()
+    /// as part of Table::set_int_unique() or Table::set_string_unique()
+    /// or Table::set_null_unique() detecting a collision.
+    ///
+    /// \sa Table::move_last_over()
+    /// \sa Table::set_int_unique()
+    /// \sa Table::set_string_unique()
+    /// \sa Table::set_null_unique()
+    void merge_rows(size_t row_ndx, size_t new_row_ndx);
+
+    //@{
+
+    /// Get cell values.
+    /// Will assert if the requested type does not match the column type.
+    ///
+    /// When fetching from a nullable column and the value is null, a default
+    /// value will be returned, except for object like types (StringData,
+    /// BinaryData, Timestamp) which have support for storing nulls. In that
+    /// case, call the `is_null()` method on the returned object to check
+    /// whether the stored value was null. If nullability matters and returning
+    /// a default value is unacceptable, check Table::is_null() before getting a
+    /// cell value.
+    ///
+    /// \sa Table::is_nullable(size_t col_ndx)
+    /// \sa Table::is_null(size_t col_ndx, size_t row_ndx)
+    /// \sa StringData::is_null()
+    int64_t get_int(size_t column_ndx, size_t row_ndx) const noexcept;
+    bool get_bool(size_t column_ndx, size_t row_ndx) const noexcept;
+    OldDateTime get_olddatetime(size_t column_ndx, size_t row_ndx) const noexcept;
+    float get_float(size_t column_ndx, size_t row_ndx) const noexcept;
+    double get_double(size_t column_ndx, size_t row_ndx) const noexcept;
+    StringData get_string(size_t column_ndx, size_t row_ndx) const noexcept;
+    BinaryData get_binary(size_t column_ndx, size_t row_ndx) const noexcept;
+    BinaryIterator get_binary_iterator(size_t column_ndx, size_t row_ndx) const noexcept;
+    Mixed get_mixed(size_t column_ndx, size_t row_ndx) const noexcept;
+    DataType get_mixed_type(size_t column_ndx, size_t row_ndx) const noexcept;
+    Timestamp get_timestamp(size_t column_ndx, size_t row_ndx) const noexcept;
+
+    //@}
+
+    /// Return data from position 'pos' and onwards. If the blob is distributed
+    /// across multiple arrays, you will only get data from one array. 'pos'
+    /// will be updated to be an index to next available data. It will be 0
+    /// if no more data.
+    BinaryData get_binary_at(size_t col_ndx, size_t ndx, size_t& pos) const noexcept;
+
+    template <class T>
+    T get(size_t c, size_t r) const noexcept;
+
+    size_t get_link(size_t column_ndx, size_t row_ndx) const noexcept;
+    bool is_null_link(size_t column_ndx, size_t row_ndx) const noexcept;
+    LinkViewRef get_linklist(size_t column_ndx, size_t row_ndx);
+    ConstLinkViewRef get_linklist(size_t column_ndx, size_t row_ndx) const;
+    size_t get_link_count(size_t column_ndx, size_t row_ndx) const noexcept;
+    bool linklist_is_empty(size_t column_ndx, size_t row_ndx) const noexcept;
+    bool is_null(size_t column_ndx, size_t row_ndx) const noexcept;
+
+    TableRef get_link_target(size_t column_ndx) noexcept;
+    ConstTableRef get_link_target(size_t column_ndx) const noexcept;
+
+    //@{
+
+    /// Set cell values.
+    ///
+    /// It is an error to specify a column index, row index, or string position
+    /// that is out of range.
+    ///
+    /// The number of bytes in a string value must not exceed `max_string_size`,
+    /// and the number of bytes in a binary data value must not exceed
+    /// `max_binary_size`. String must also contain valid UTF-8 encodings. These
+    /// requirements also apply when modifying a string with insert_substring()
+    /// and remove_substring(), and for strings in a mixed columnt. Passing, or
+    /// producing an oversized string or binary data value will cause an
+    /// exception to be thrown.
+    ///
+    /// The "unique" variants (set_int_unique(), set_string_unique(), set_null_unique())
+    /// are intended to be used in the implementation of primary key support. They
+    /// check if the given column already contains one or more values that are
+    /// equal to \a value, and if there are conflicts, it calls
+    /// Table::merge_rows() for the row_ndx to be replaced by the
+    /// existing row, followed by a Table::move_last_over() of row_ndx. The
+    /// return value is always a row index of a row that contains \a value in
+    /// the specified column, possibly different from \a row_ndx if a conflict
+    /// occurred.  Users intending to implement primary keys must therefore
+    /// manually check for duplicates if they want to raise an error instead.
+    ///
+    /// NOTE:  It is an error to call either function after adding elements to a
+    /// linklist in the object. In general, calling set_int_unique() or
+    /// set_string_unique() or set_null_unique() should be the first thing that
+    /// happens after creating a row. These limitations are imposed by limitations
+    /// in the Realm Object Server and may be relaxed in the future. A violation of
+    /// these rules results in a LogicError being thrown.
+    ///
+    /// add_int() adds a 64-bit signed integer to the current value of the
+    /// cell.  If the addition would cause signed integer overflow or
+    /// underflow, the addition "wraps around" with semantics similar to
+    /// unsigned integer arithmetic, such that Table::max_integer + 1 ==
+    /// Table::min_integer and Table::min_integer - 1 == Table::max_integer.
+    /// Note that the wrapping is platform-independent (all platforms wrap in
+    /// the same way regardless of integer representation). If the existing
+    /// value in the cell is null, a LogicError exception is thrown.
+    ///
+    /// insert_substring() inserts the specified string into the currently
+    /// stored string at the specified position. The position must be less than
+    /// or equal to the size of the currently stored string.
+    ///
+    /// remove_substring() removes the specified byte range from the currently
+    /// stored string. The beginning of the range (\a pos) must be less than or
+    /// equal to the size of the currently stored string. If the specified range
+    /// extends beyond the end of the currently stored string, it will be
+    /// silently clamped.
+    ///
+    /// String level modifications performed via insert_substring() and
+    /// remove_substring() are mergable and subject to operational
+    /// transformation. That is, the effect of two causally unrelated
+    /// modifications will in general both be retained during synchronization.
+
+    static const size_t max_string_size = 0xFFFFF8 - Array::header_size - 1;
+    static const size_t max_binary_size = 0xFFFFF8 - Array::header_size;
+
+    // FIXME: These limits should be chosen independently of the underlying
+    // platform's choice to define int64_t and independent of the integer
+    // representation. The current values only work for 2's complement, which is
+    // not guaranteed by the standard.
+    static constexpr int_fast64_t max_integer = std::numeric_limits<int64_t>::max();
+    static constexpr int_fast64_t min_integer = std::numeric_limits<int64_t>::min();
+
+    template <class T>
+    void set(size_t c, size_t r, T value, bool is_default = false);
+
+    template <class T>
+    size_t set_unique(size_t c, size_t r, T value);
+
+    void set_int(size_t column_ndx, size_t row_ndx, int_fast64_t value, bool is_default = false);
+    size_t set_int_unique(size_t column_ndx, size_t row_ndx, int_fast64_t value);
+    void set_bool(size_t column_ndx, size_t row_ndx, bool value, bool is_default = false);
+    void set_olddatetime(size_t column_ndx, size_t row_ndx, OldDateTime value, bool is_default = false);
+    void set_timestamp(size_t column_ndx, size_t row_ndx, Timestamp value, bool is_default = false);
+    template <class E>
+    void set_enum(size_t column_ndx, size_t row_ndx, E value);
+    void set_float(size_t column_ndx, size_t row_ndx, float value, bool is_default = false);
+    void set_double(size_t column_ndx, size_t row_ndx, double value, bool is_default = false);
+    void set_string(size_t column_ndx, size_t row_ndx, StringData value, bool is_default = false);
+    size_t set_string_unique(size_t column_ndx, size_t row_ndx, StringData value);
+    void set_binary(size_t column_ndx, size_t row_ndx, BinaryData value, bool is_default = false);
+    void set_mixed(size_t column_ndx, size_t row_ndx, Mixed value, bool is_default = false);
+    void set_link(size_t column_ndx, size_t row_ndx, size_t target_row_ndx, bool is_default = false);
+    void nullify_link(size_t column_ndx, size_t row_ndx);
+    void set_null(size_t column_ndx, size_t row_ndx, bool is_default = false);
+    void set_null_unique(size_t col_ndx, size_t row_ndx);
+
+    // Sync needs to store blobs bigger than 16 M. This function can be used for that. Data should be read
+    // out again using the get_binary_at() function. Should not be used for user data as normal get_binary()
+    // will just return null if the data is bigger than the limit.
+    void set_binary_big(size_t column_ndx, size_t row_ndx, BinaryData value, bool is_default = false);
+
+    void add_int(size_t column_ndx, size_t row_ndx, int_fast64_t value);
+
+    void insert_substring(size_t col_ndx, size_t row_ndx, size_t pos, StringData);
+    void remove_substring(size_t col_ndx, size_t row_ndx, size_t pos, size_t substring_size = realm::npos);
+
+    //@}
+
+    /// Assumes that the specified column is a subtable column (in
+    /// particular, not a mixed column) and that the specified table
+    /// has a spec that is compatible with that column, that is, the
+    /// number of columns must be the same, and corresponding columns
+    /// must have identical data types (as returned by
+    /// get_column_type()).
+    void set_subtable(size_t col_ndx, size_t row_ndx, const Table*);
+    void set_mixed_subtable(size_t col_ndx, size_t row_ndx, const Table*);
+
+
+    // Sub-tables (works on columns whose type is either 'subtable' or
+    // 'mixed', for a value in a mixed column that is not a subtable,
+    // get_subtable() returns null, get_subtable_size() returns zero,
+    // and clear_subtable() replaces the value with an empty table.)
+    // Currently, subtables of subtables are not supported.
+    TableRef get_subtable(size_t column_ndx, size_t row_ndx);
+    ConstTableRef get_subtable(size_t column_ndx, size_t row_ndx) const;
+    size_t get_subtable_size(size_t column_ndx, size_t row_ndx) const noexcept;
+    void clear_subtable(size_t column_ndx, size_t row_ndx);
+
+    // Backlinks
+    size_t get_backlink_count(size_t row_ndx, bool only_strong_links = false) const noexcept;
+    size_t get_backlink_count(size_t row_ndx, const Table& origin, size_t origin_col_ndx) const noexcept;
+    size_t get_backlink(size_t row_ndx, const Table& origin, size_t origin_col_ndx, size_t backlink_ndx) const
+        noexcept;
+
+
+    //@{
+
+    /// If this accessor is attached to a subtable, then that subtable has a
+    /// parent table, and the subtable either resides in a column of type
+    /// `table` or of type `mixed` in that parent. In that case
+    /// get_parent_table() returns a reference to the accessor associated with
+    /// the parent, and get_parent_row_index() returns the index of the row in
+    /// which the subtable resides. In all other cases (free-standing and
+    /// group-level tables), get_parent_table() returns null and
+    /// get_parent_row_index() returns realm::npos.
+    ///
+    /// If this accessor is attached to a subtable, and \a column_ndx_out is
+    /// specified, then `*column_ndx_out` is set to the index of the column of
+    /// the parent table in which the subtable resides. If this accessor is not
+    /// attached to a subtable, then `*column_ndx_out` will retain its original
+    /// value upon return.
+
+    TableRef get_parent_table(size_t* column_ndx_out = nullptr) noexcept;
+    ConstTableRef get_parent_table(size_t* column_ndx_out = nullptr) const noexcept;
+    size_t get_parent_row_index() const noexcept;
+
+    //@}
+
+
+    /// Only group-level unordered tables can be used as origins or targets of
+    /// links.
+    bool is_group_level() const noexcept;
+
+    /// If this table is a group-level table, then this function returns the
+    /// index of this table within the group. Otherwise it returns realm::npos.
+    size_t get_index_in_group() const noexcept;
+
+    // Aggregate functions
+    size_t count_int(size_t column_ndx, int64_t value) const;
+    size_t count_string(size_t column_ndx, StringData value) const;
+    size_t count_float(size_t column_ndx, float value) const;
+    size_t count_double(size_t column_ndx, double value) const;
+
+    int64_t sum_int(size_t column_ndx) const;
+    double sum_float(size_t column_ndx) const;
+    double sum_double(size_t column_ndx) const;
+    int64_t maximum_int(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    float maximum_float(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double maximum_double(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    OldDateTime maximum_olddatetime(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    Timestamp maximum_timestamp(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    int64_t minimum_int(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    float minimum_float(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double minimum_double(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    OldDateTime minimum_olddatetime(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    Timestamp minimum_timestamp(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double average_int(size_t column_ndx, size_t* value_count = nullptr) const;
+    double average_float(size_t column_ndx, size_t* value_count = nullptr) const;
+    double average_double(size_t column_ndx, size_t* value_count = nullptr) const;
+
+    // Searching
+    template <class T>
+    size_t find_first(size_t column_ndx, T value) const;
+
+    size_t find_first_link(size_t target_row_index) const;
+    size_t find_first_int(size_t column_ndx, int64_t value) const;
+    size_t find_first_bool(size_t column_ndx, bool value) const;
+    size_t find_first_olddatetime(size_t column_ndx, OldDateTime value) const;
+    size_t find_first_timestamp(size_t column_ndx, Timestamp value) const;
+    size_t find_first_float(size_t column_ndx, float value) const;
+    size_t find_first_double(size_t column_ndx, double value) const;
+    size_t find_first_string(size_t column_ndx, StringData value) const;
+    size_t find_first_binary(size_t column_ndx, BinaryData value) const;
+    size_t find_first_null(size_t column_ndx) const;
+
+    TableView find_all_link(size_t target_row_index);
+    ConstTableView find_all_link(size_t target_row_index) const;
+    TableView find_all_int(size_t column_ndx, int64_t value);
+    ConstTableView find_all_int(size_t column_ndx, int64_t value) const;
+    TableView find_all_bool(size_t column_ndx, bool value);
+    ConstTableView find_all_bool(size_t column_ndx, bool value) const;
+    TableView find_all_olddatetime(size_t column_ndx, OldDateTime value);
+    ConstTableView find_all_olddatetime(size_t column_ndx, OldDateTime value) const;
+    TableView find_all_float(size_t column_ndx, float value);
+    ConstTableView find_all_float(size_t column_ndx, float value) const;
+    TableView find_all_double(size_t column_ndx, double value);
+    ConstTableView find_all_double(size_t column_ndx, double value) const;
+    TableView find_all_string(size_t column_ndx, StringData value);
+    ConstTableView find_all_string(size_t column_ndx, StringData value) const;
+    TableView find_all_binary(size_t column_ndx, BinaryData value);
+    ConstTableView find_all_binary(size_t column_ndx, BinaryData value) const;
+    TableView find_all_null(size_t column_ndx);
+    ConstTableView find_all_null(size_t column_ndx) const;
+
+    /// The following column types are supported: String, Integer, OldDateTime, Bool
+    TableView get_distinct_view(size_t column_ndx);
+    ConstTableView get_distinct_view(size_t column_ndx) const;
+
+    TableView get_sorted_view(size_t column_ndx, bool ascending = true);
+    ConstTableView get_sorted_view(size_t column_ndx, bool ascending = true) const;
+
+    TableView get_sorted_view(SortDescriptor order);
+    ConstTableView get_sorted_view(SortDescriptor order) const;
+
+    TableView get_range_view(size_t begin, size_t end);
+    ConstTableView get_range_view(size_t begin, size_t end) const;
+
+    TableView get_backlink_view(size_t row_ndx, Table* src_table, size_t src_col_ndx);
+
+
+    // Pivot / aggregate operation types. Experimental! Please do not document method publicly.
+    enum AggrType {
+        aggr_count,
+        aggr_sum,
+        aggr_avg,
+        aggr_min,
+        aggr_max,
+    };
+
+    // Simple pivot aggregate method. Experimental! Please do not document method publicly.
+    void aggregate(size_t group_by_column, size_t aggr_column, AggrType op, Table& result,
+                   const IntegerColumn* viewrefs = nullptr) const;
+
+    /// Report the current versioning counter for the table. The versioning counter is guaranteed to
+    /// change when the contents of the table changes after advance_read() or promote_to_write(), or
+    /// immediately after calls to methods which change the table. The term "change" means "change of
+    /// value": The storage layout of the table may change, for example due to optimization, but this
+    /// is not considered a change of a value. This means that you *cannot* use a non-changing version
+    /// count to indicate that object addresses (e.g. strings, binary data) remain the same.
+    /// The versioning counter *may* change (but is not required to do so) when another table linked
+    /// from this table, or linking to this table, is changed. The version counter *may* also change
+    /// without any apparent reason.
+    uint_fast64_t get_version_counter() const noexcept;
+
+private:
+    template <class T>
+    TableView find_all(size_t column_ndx, T value);
+
+public:
+    //@{
+    /// Find the lower/upper bound according to a column that is
+    /// already sorted in ascending order.
+    ///
+    /// For an integer column at index 0, and an integer value '`v`',
+    /// lower_bound_int(0,v) returns the index '`l`' of the first row
+    /// such that `get_int(0,l) &ge; v`, and upper_bound_int(0,v)
+    /// returns the index '`u`' of the first row such that
+    /// `get_int(0,u) &gt; v`. In both cases, if no such row is found,
+    /// the returned value is the number of rows in the table.
+    ///
+    ///     3 3 3 4 4 4 5 6 7 9 9 9
+    ///     ^     ^     ^     ^     ^
+    ///     |     |     |     |     |
+    ///     |     |     |     |      -- Lower and upper bound of 15
+    ///     |     |     |     |
+    ///     |     |     |      -- Lower and upper bound of 8
+    ///     |     |     |
+    ///     |     |      -- Upper bound of 4
+    ///     |     |
+    ///     |      -- Lower bound of 4
+    ///     |
+    ///      -- Lower and upper bound of 1
+    ///
+    /// These functions are similar to std::lower_bound() and
+    /// std::upper_bound().
+    ///
+    /// The string versions assume that the column is sorted according
+    /// to StringData::operator<().
+    size_t lower_bound_int(size_t column_ndx, int64_t value) const noexcept;
+    size_t upper_bound_int(size_t column_ndx, int64_t value) const noexcept;
+    size_t lower_bound_bool(size_t column_ndx, bool value) const noexcept;
+    size_t upper_bound_bool(size_t column_ndx, bool value) const noexcept;
+    size_t lower_bound_float(size_t column_ndx, float value) const noexcept;
+    size_t upper_bound_float(size_t column_ndx, float value) const noexcept;
+    size_t lower_bound_double(size_t column_ndx, double value) const noexcept;
+    size_t upper_bound_double(size_t column_ndx, double value) const noexcept;
+    size_t lower_bound_string(size_t column_ndx, StringData value) const noexcept;
+    size_t upper_bound_string(size_t column_ndx, StringData value) const noexcept;
+    //@}
+
+    // Queries
+    // Using where(tv) is the new method to perform queries on TableView. The 'tv' can have any order; it does not
+    // need to be sorted, and, resulting view retains its order.
+    Query where(TableViewBase* tv = nullptr)
+    {
+        return Query(*this, tv);
+    }
+
+    // FIXME: We need a ConstQuery class or runtime check against modifications in read transaction.
+    Query where(TableViewBase* tv = nullptr) const
+    {
+        return Query(*this, tv);
+    }
+
+    // Perform queries on a LinkView. The returned Query holds a reference to lv.
+    Query where(const LinkViewRef& lv)
+    {
+        return Query(*this, lv);
+    }
+
+    //@{
+    /// WARNING: The link() and backlink() methods will alter a state on the Table object and return a reference to itself.
+    /// Be aware if assigning the return value of link() to a variable; this might be an error!
+
+    /// This is an error:
+
+    /// Table& cats = owners->link(1);
+    /// auto& dogs = owners->link(2);
+
+    /// Query q = person_table->where()
+    /// .and_query(cats.column<String>(5).equal("Fido"))
+    /// .Or()
+    /// .and_query(dogs.column<String>(6).equal("Meowth"));
+
+    /// Instead, do this:
+
+    /// Query q = owners->where()
+    /// .and_query(person_table->link(1).column<String>(5).equal("Fido"))
+    /// .Or()
+    /// .and_query(person_table->link(2).column<String>(6).equal("Meowth"));
+
+    /// The two calls to link() in the errorneous example will append the two values 0 and 1 to an internal vector in the
+    /// owners table, and we end up with three references to that same table: owners, cats and dogs. They are all the same
+    /// table, its vector has the values {0, 1}, so a query would not make any sense.
+    Table& link(size_t link_column);    
+    Table& backlink(const Table& origin, size_t origin_col_ndx);
+    //@}
+
+    // Optimizing. enforce == true will enforce enumeration of all string columns;
+    // enforce == false will auto-evaluate if they should be enumerated or not
+    void optimize(bool enforce = false);
+
+    /// Write this table (or a slice of this table) to the specified
+    /// output stream.
+    ///
+    /// The output will have the same format as any other Realm
+    /// database file, such as those produced by Group::write(). In
+    /// this case, however, the resulting database file will contain
+    /// exactly one table, and that table will contain only the
+    /// specified slice of the source table (this table).
+    ///
+    /// The new table will always have the same dynamic type (see
+    /// Descriptor) as the source table (this table), and unless it is
+    /// overridden (\a override_table_name), the new table will have
+    /// the same name as the source table (see get_name()). Indexes
+    /// (see add_search_index()) will not be carried over to the new
+    /// table.
+    ///
+    /// \param out The destination output stream buffer.
+    ///
+    /// \param offset Index of first row to include (if `slice_size >
+    /// 0`). Must be less than, or equal to size().
+    ///
+    /// \param slice_size Number of rows to include. May be zero. If
+    /// `slice_size > size() - offset`, then the effective size of
+    /// the written slice will be `size() - offset`.
+    ///
+    /// \param override_table_name Custom name to write out instead of
+    /// the actual table name.
+    ///
+    /// \throw std::out_of_range If `offset > size()`.
+    ///
+    /// FIXME: While this function does provided a maximally efficient
+    /// way of serializing part of a table, it offers little in terms
+    /// of general utility. This is unfortunate, because it pulls
+    /// quite a large amount of code into the core library to support
+    /// it.
+    void write(std::ostream& out, size_t offset = 0, size_t slice_size = npos,
+               StringData override_table_name = StringData()) const;
+
+    // Conversion
+    void to_json(std::ostream& out, size_t link_depth = 0,
+                 std::map<std::string, std::string>* renames = nullptr) const;
+    void to_string(std::ostream& out, size_t limit = 500) const;
+    void row_to_string(size_t row_ndx, std::ostream& out) const;
+
+    // Get a reference to this table
+    TableRef get_table_ref()
+    {
+        return TableRef(this);
+    }
+    ConstTableRef get_table_ref() const
+    {
+        return ConstTableRef(this);
+    }
+
+    /// \brief Compare two tables for equality.
+    ///
+    /// Two tables are equal if they have equal descriptors
+    /// (`Descriptor::operator==()`) and equal contents. Equal descriptors imply
+    /// that the two tables have the same columns in the same order. Equal
+    /// contents means that the two tables must have the same number of rows,
+    /// and that for each row index, the two rows must have the same values in
+    /// each column.
+    ///
+    /// In mixed columns, both the value types and the values are required to be
+    /// equal.
+    ///
+    /// For a particular row and column, if the two values are themselves tables
+    /// (subtable and mixed columns) value equality implies a recursive
+    /// invocation of `Table::operator==()`.
+    bool operator==(const Table&) const;
+
+    /// \brief Compare two tables for inequality.
+    ///
+    /// See operator==().
+    bool operator!=(const Table& t) const;
+
+    /// A subtable in a column of type 'table' (which shares descriptor with
+    /// other subtables in the same column) is initially in a degenerate state
+    /// where it takes up a minimal amout of space. This function returns true
+    /// if, and only if the table accessor is attached to such a subtable. This
+    /// function is mainly intended for debugging purposes.
+    bool is_degenerate() const;
+
+    /// Compute the sum of the sizes in number of bytes of all the array nodes
+    /// that currently make up this table. See also
+    /// Group::compute_aggregate_byte_size().
+    ///
+    /// If this table accessor is the detached state, this function returns
+    /// zero.
+    size_t compute_aggregated_byte_size() const noexcept;
+
+    // Debug
+    void verify() const;
+#ifdef REALM_DEBUG
+    void to_dot(std::ostream&, StringData title = StringData()) const;
+    void print() const;
+    MemStats stats() const;
+    void dump_node_structure() const; // To std::cerr (for GDB)
+    void dump_node_structure(std::ostream&, int level) const;
+#endif
+
+    class Parent;
+    using HandoverPatch = TableHandoverPatch;
+    static void generate_patch(const Table* ref, std::unique_ptr<HandoverPatch>& patch);
+    static TableRef create_from_and_consume_patch(std::unique_ptr<HandoverPatch>& patch, Group& group);
+
+protected:
+    /// Get a pointer to the accessor of the specified subtable. The
+    /// accessor will be created if it does not already exist.
+    ///
+    /// The returned table pointer must **always** end up being
+    /// wrapped in some instantiation of BasicTableRef<>.
+    TableRef get_subtable_tableref(size_t col_ndx, size_t row_ndx);
+
+    /// See non-const get_subtable_tableref().
+    ConstTableRef get_subtable_tableref(size_t col_ndx, size_t row_ndx) const;
+
+    /// Compare the rows of two tables under the assumption that the two tables
+    /// have the same number of columns, and the same data type at each column
+    /// index (as expressed through the DataType enum).
+    bool compare_rows(const Table&) const;
+
+    void set_into_mixed(Table* parent, size_t col_ndx, size_t row_ndx) const;
+
+    void check_lists_are_empty(size_t row_ndx) const;
+
+private:
+    class SliceWriter;
+
+    // Number of rows in this table
+    size_t m_size;
+
+    // Underlying array structure. `m_top` is in use only for root tables; that
+    // is, for tables with independent descriptor. `m_columns` contains a ref
+    // for each column and search index in order of the columns. A search index
+    // ref always occurs immediately after the ref of the column to which the
+    // search index belongs.
+    //
+    // A subtable column (a column of type `type_table`) is essentially just a
+    // column of 'refs' pointing to the root node of each subtable.
+    //
+    // To save space in the database file, a subtable in such a column always
+    // starts out in a degenerate form where nothing is allocated on its behalf,
+    // and a null 'ref' is stored in the corresponding slot of the column. A
+    // subtable remains in this degenerate state until the first row is added to
+    // the subtable.
+    //
+    // For this scheme to work, it must be (and is) possible to create a table
+    // accessor that refers to a degenerate subtable. A table accessor (instance
+    // of `Table`) refers to a degenerate subtable if, and only if `m_columns`
+    // is unattached.
+    //
+    // FIXME: The fact that `m_columns` may be detached means that many
+    // functions (even non-modifying functions) need to check for that before
+    // accessing the contents of the table. This incurs a runtime
+    // overhead. Consider whether this overhead can be eliminated by having
+    // `Table::m_columns` always attached to something, and then detect the
+    // degenerate state in a different way.
+    Array m_top;
+    Array m_columns; // 2nd slot in m_top (for root tables)
+
+    // Management class for the spec object. Only if the table has an independent
+    // spec, the spec object should be deleted when the table object is deleted.
+    // If the table has a shared spec, the spec object is managed by the spec object
+    // of the containing table.
+    class SpecPtr {
+    public:
+        ~SpecPtr()
+         {
+            optionally_delete();
+         }
+        void manage(Spec* ptr)
+        {
+            optionally_delete();
+            m_p = ptr;
+            m_is_managed = true;
+        }
+        void detach()
+        {
+            if (m_is_managed) {
+                m_p->detach();
+            }
+        }
+        SpecPtr& operator=(Spec* ptr)
+        {
+            optionally_delete();
+            m_p = ptr;
+            m_is_managed = false;
+            return *this;
+        }
+        Spec* operator->() const
+        {
+            return m_p;
+        }
+        Spec* get() const
+        {
+            return m_p;
+        }
+        Spec& operator*() const
+        {
+            return *m_p;
+        }
+        operator bool() const
+        {
+            return m_p != nullptr;
+        }
+        bool is_managed() const
+        {
+            return m_is_managed;
+        }
+
+    private:
+        Spec* m_p = nullptr;
+        bool m_is_managed = false;
+
+        void optionally_delete()
+        {
+            if (m_is_managed) {
+                delete m_p;
+            }
+        }
+    };
+
+    SpecPtr m_spec; // 1st slot in m_top (for root tables)
+
+    // Is guaranteed to be empty for a detached accessor. Otherwise it is empty
+    // when the table accessor is attached to a degenerate subtable (unattached
+    // `m_columns`), otherwise it contains precisely one column accessor for
+    // each column in the table, in order.
+    //
+    // In some cases an entry may be null. This is currently possible only in
+    // connection with Group::advance_transact(), but it means that several
+    // member functions must be prepared to handle these null entries; in
+    // particular, detach(), ~Table(), functions called on behalf of detach()
+    // and ~Table(), and functiones called on behalf of
+    // Group::advance_transact().
+    typedef std::vector<ColumnBase*> column_accessors;
+    column_accessors m_cols;
+
+    mutable std::atomic<size_t> m_ref_count;
+
+    // If this table is a root table (has independent descriptor),
+    // then Table::m_descriptor refers to the accessor of its
+    // descriptor when, and only when the descriptor accessor
+    // exists. This is used to ensure that at most one descriptor
+    // accessor exists for each underlying descriptor at any given
+    // point in time. Subdescriptors are kept unique by means of a
+    // registry in the parent descriptor. Table::m_descriptor is
+    // always null for tables with shared descriptor.
+    mutable std::weak_ptr<Descriptor> m_descriptor;
+
+    // Table view instances
+    // Access needs to be protected by m_accessor_mutex
+    typedef std::vector<TableViewBase*> views;
+    mutable views m_views;
+
+    // Points to first bound row accessor, or is null if there are none.
+    mutable RowBase* m_row_accessors = nullptr;
+
+    // Mutex which must be locked any time the row accessor chain or m_views is used
+    mutable util::Mutex m_accessor_mutex;
+
+    // Used for queries: Items are added with link() method during buildup of query
+    mutable std::vector<size_t> m_link_chain;
+
+    /// Used only in connection with Group::advance_transact() and
+    /// Table::refresh_accessor_tree().
+    mutable bool m_mark;
+
+    mutable uint_fast64_t m_version;
+
+    void erase_row(size_t row_ndx, bool is_move_last_over);
+    void batch_erase_rows(const IntegerColumn& row_indexes, bool is_move_last_over);
+    void do_remove(size_t row_ndx, bool broken_reciprocal_backlinks);
+    void do_move_last_over(size_t row_ndx, bool broken_reciprocal_backlinks);
+    void do_swap_rows(size_t row_ndx_1, size_t row_ndx_2);
+    void do_move_row(size_t from_ndx, size_t to_ndx);
+    void do_merge_rows(size_t row_ndx, size_t new_row_ndx);
+    void do_clear(bool broken_reciprocal_backlinks);
+    size_t do_set_link(size_t col_ndx, size_t row_ndx, size_t target_row_ndx);
+    template <class ColType, class T>
+    size_t do_find_unique(ColType& col, size_t ndx, T&& value, bool& conflict);
+    template <class ColType>
+    size_t do_set_unique_null(ColType& col, size_t ndx, bool& conflict);
+    template <class ColType, class T>
+    size_t do_set_unique(ColType& column, size_t row_ndx, T&& value, bool& conflict);
+
+    void _add_search_index(size_t column_ndx);
+    void _remove_search_index(size_t column_ndx);
+
+    void rebuild_search_index(size_t current_file_format_version);
+
+    // Upgrades OldDateTime columns to Timestamp columns
+    void upgrade_olddatetime();
+
+    // Indicate that the current global state version has been "observed". Until this
+    // happens, bumping of the global version counter can be bypassed, as any query
+    // checking for a version change will see the older version change anyways.
+    // Also returns the table-local version.
+    uint64_t observe_version() const noexcept;
+
+    /// Update the version of this table and all tables which have links to it.
+    /// This causes all views referring to those tables to go out of sync, so that
+    /// calls to sync_if_needed() will bring the view up to date by reexecuting the
+    /// query.
+    ///
+    /// \param bump_global chooses whether the global versioning counter must be
+    /// bumped first as part of the update. This is the normal mode of operation,
+    /// when a change is made to the table. When calling recursively (following links
+    /// or going to the parent table), the parameter should be set to false to correctly
+    /// prune traversal.
+    void bump_version(bool bump_global = true) const noexcept;
+
+    /// Disable copying assignment.
+    ///
+    /// It could easily be implemented by calling assign(), but the
+    /// non-checking nature of the low-level dynamically typed API
+    /// makes it too risky to offer this feature as an
+    /// operator.
+    ///
+    /// FIXME: assign() has not yet been implemented, but the
+    /// intention is that it will copy the rows of the argument table
+    /// into this table after clearing the original contents, and for
+    /// target tables without a shared spec, it would also copy the
+    /// spec. For target tables with shared spec, it would be an error
+    /// to pass an argument table with an incompatible spec, but
+    /// assign() would not check for spec compatibility. This would
+    /// make it ideal as a basis for implementing operator=() for
+    /// typed tables.
+    Table& operator=(const Table&) = delete;
+
+    /// Used when constructing an accessor whose lifetime is going to be managed
+    /// by reference counting. The lifetime of accessors of free-standing tables
+    /// allocated on the stack by the application is not managed by reference
+    /// counting, so that is a case where this tag must **not** be specified.
+    class ref_count_tag {
+    };
+
+    /// Create an uninitialized accessor whose lifetime is managed by reference
+    /// counting.
+    Table(ref_count_tag, Allocator&);
+
+    void init(ref_type top_ref, ArrayParent*, size_t ndx_in_parent, bool skip_create_column_accessors = false);
+    void init(Spec* shared_spec, ArrayParent* parent_column, size_t parent_row_ndx);
+
+    static void do_insert_column(Descriptor&, size_t col_ndx, DataType type, StringData name,
+                                 LinkTargetInfo& link_target_info, bool nullable = false);
+    static void do_insert_column_unless_exists(Descriptor&, size_t col_ndx, DataType type, StringData name,
+                                               LinkTargetInfo& link, bool nullable = false,
+                                               bool* was_inserted = nullptr);
+    static void do_erase_column(Descriptor&, size_t col_ndx);
+    static void do_rename_column(Descriptor&, size_t col_ndx, StringData name);
+
+    static void do_add_search_index(Descriptor&, size_t col_ndx);
+    static void do_remove_search_index(Descriptor&, size_t col_ndx);
+
+    struct InsertSubtableColumns;
+    struct EraseSubtableColumns;
+    struct RenameSubtableColumns;
+
+    void insert_root_column(size_t col_ndx, DataType type, StringData name, LinkTargetInfo& link_target,
+                            bool nullable = false);
+    void erase_root_column(size_t col_ndx);
+    void do_insert_root_column(size_t col_ndx, ColumnType, StringData name, bool nullable = false);
+    void do_erase_root_column(size_t col_ndx);
+    void do_set_link_type(size_t col_ndx, LinkType);
+    void insert_backlink_column(size_t origin_table_ndx, size_t origin_col_ndx, size_t backlink_col_ndx);
+    void erase_backlink_column(size_t origin_table_ndx, size_t origin_col_ndx);
+    void update_link_target_tables(size_t old_col_ndx_begin, size_t new_col_ndx_begin);
+    void update_link_target_tables_after_column_move(size_t moved_from, size_t moved_to);
+
+    struct SubtableUpdater {
+        virtual void update(const SubtableColumn&, Array& subcolumns) = 0;
+        virtual void update_accessor(Table&) = 0;
+        virtual ~SubtableUpdater()
+        {
+        }
+    };
+    static void update_subtables(Descriptor&, SubtableUpdater*);
+    void update_subtables(const size_t* col_path_begin, const size_t* col_path_end, SubtableUpdater*);
+
+    struct AccessorUpdater {
+        virtual void update(Table&) = 0;
+        virtual void update_parent(Table&) = 0;
+        virtual ~AccessorUpdater()
+        {
+        }
+    };
+    void update_accessors(const size_t* col_path_begin, const size_t* col_path_end, AccessorUpdater&);
+
+    void create_degen_subtab_columns();
+    ColumnBase* create_column_accessor(ColumnType, size_t col_ndx, size_t ndx_in_parent);
+    void destroy_column_accessors() noexcept;
+
+    /// Called in the context of Group::commit() to ensure that
+    /// attached table accessors stay valid across a commit. Please
+    /// note that this works only for non-transactional commits. Table
+    /// accessors obtained during a transaction are always detached
+    /// when the transaction ends.
+    void update_from_parent(size_t old_baseline) noexcept;
+
+    // Support function for conversions
+    void to_string_header(std::ostream& out, std::vector<size_t>& widths) const;
+    void to_string_row(size_t row_ndx, std::ostream& out, const std::vector<size_t>& widths) const;
+
+    // recursive methods called by to_json, to follow links
+    void to_json(std::ostream& out, size_t link_depth, std::map<std::string, std::string>& renames,
+                 std::vector<ref_type>& followed) const;
+    void to_json_row(size_t row_ndx, std::ostream& out, size_t link_depth,
+                     std::map<std::string, std::string>& renames, std::vector<ref_type>& followed) const;
+    void to_json_row(size_t row_ndx, std::ostream& out, size_t link_depth = 0,
+                     std::map<std::string, std::string>* renames = nullptr) const;
+
+    // Detach accessor from underlying table. Caller must ensure that
+    // a reference count exists upon return, for example by obtaining
+    // an extra reference count before the call.
+    //
+    // This function puts this table accessor into the detached
+    // state. This detaches it from the underlying structure of array
+    // nodes. It also recursively detaches accessors for subtables,
+    // and the type descriptor accessor. When this function returns,
+    // is_attached() will return false.
+    //
+    // This function may be called for a table accessor that is
+    // already in the detached state (idempotency).
+    //
+    // It is also valid to call this function for a table accessor
+    // that has not yet been detached, but whose underlying structure
+    // of arrays have changed in an unpredictable/unknown way. This
+    // kind of change generally happens when a modifying table
+    // operation fails, and also when one transaction is ended and a
+    // new one is started.
+    void detach() noexcept;
+
+    /// Detach and remove all attached row, link list, and subtable
+    /// accessors. This function does not discard the descriptor accessor, if
+    /// any, and it does not discard column accessors either.
+    void discard_child_accessors() noexcept;
+
+    void discard_row_accessors() noexcept;
+
+    // Detach the type descriptor accessor if it exists.
+    void discard_desc_accessor() noexcept;
+
+    void bind_ptr() const noexcept;
+    void unbind_ptr() const noexcept;
+    bool has_references() const noexcept;
+
+    void register_view(const TableViewBase* view);
+    void unregister_view(const TableViewBase* view) noexcept;
+    void move_registered_view(const TableViewBase* old_addr, const TableViewBase* new_addr) noexcept;
+    void discard_views() noexcept;
+
+    void register_row_accessor(RowBase*) const noexcept;
+    void unregister_row_accessor(RowBase*) const noexcept;
+    void do_unregister_row_accessor(RowBase*) const noexcept;
+
+    class UnbindGuard;
+
+    ColumnType get_real_column_type(size_t column_ndx) const noexcept;
+
+    /// If this table is a group-level table, the parent group is returned,
+    /// otherwise null is returned.
+    Group* get_parent_group() const noexcept;
+
+    const ColumnBase& get_column_base(size_t column_ndx) const noexcept;
+    ColumnBase& get_column_base(size_t column_ndx);
+
+    const ColumnBaseWithIndex& get_column_base_indexed(size_t ndx) const noexcept;
+    ColumnBaseWithIndex& get_column_base_indexed(size_t ndx);
+
+    template <class T, ColumnType col_type>
+    T& get_column(size_t ndx);
+
+    template <class T, ColumnType col_type>
+    const T& get_column(size_t ndx) const noexcept;
+
+    IntegerColumn& get_column(size_t column_ndx);
+    const IntegerColumn& get_column(size_t column_ndx) const noexcept;
+    IntNullColumn& get_column_int_null(size_t column_ndx);
+    const IntNullColumn& get_column_int_null(size_t column_ndx) const noexcept;
+    FloatColumn& get_column_float(size_t column_ndx);
+    const FloatColumn& get_column_float(size_t column_ndx) const noexcept;
+    DoubleColumn& get_column_double(size_t column_ndx);
+    const DoubleColumn& get_column_double(size_t column_ndx) const noexcept;
+    StringColumn& get_column_string(size_t column_ndx);
+    const StringColumn& get_column_string(size_t column_ndx) const noexcept;
+    BinaryColumn& get_column_binary(size_t column_ndx);
+    const BinaryColumn& get_column_binary(size_t column_ndx) const noexcept;
+    StringEnumColumn& get_column_string_enum(size_t column_ndx);
+    const StringEnumColumn& get_column_string_enum(size_t column_ndx) const noexcept;
+    SubtableColumn& get_column_table(size_t column_ndx);
+    const SubtableColumn& get_column_table(size_t column_ndx) const noexcept;
+    MixedColumn& get_column_mixed(size_t column_ndx);
+    const MixedColumn& get_column_mixed(size_t column_ndx) const noexcept;
+    TimestampColumn& get_column_timestamp(size_t column_ndx);
+    const TimestampColumn& get_column_timestamp(size_t column_ndx) const noexcept;
+    const LinkColumnBase& get_column_link_base(size_t ndx) const noexcept;
+    LinkColumnBase& get_column_link_base(size_t ndx);
+    const LinkColumn& get_column_link(size_t ndx) const noexcept;
+    LinkColumn& get_column_link(size_t ndx);
+    const LinkListColumn& get_column_link_list(size_t ndx) const noexcept;
+    LinkListColumn& get_column_link_list(size_t ndx);
+    const BacklinkColumn& get_column_backlink(size_t ndx) const noexcept;
+    BacklinkColumn& get_column_backlink(size_t ndx);
+
+    void verify_column(size_t col_ndx, const ColumnBase* col) const;
+
+    void instantiate_before_change();
+    void validate_column_type(const ColumnBase& col, ColumnType expected_type, size_t ndx) const;
+
+    static size_t get_size_from_ref(ref_type top_ref, Allocator&) noexcept;
+    static size_t get_size_from_ref(ref_type spec_ref, ref_type columns_ref, Allocator&) noexcept;
+
+    const Table* get_parent_table_ptr(size_t* column_ndx_out = nullptr) const noexcept;
+    Table* get_parent_table_ptr(size_t* column_ndx_out = nullptr) noexcept;
+
+    /// Create an empty table with independent spec and return just
+    /// the reference to the underlying memory.
+    static ref_type create_empty_table(Allocator&);
+
+    /// Create a column of the specified type, fill it with the
+    /// specified number of default values, and return just the
+    /// reference to the underlying memory.
+    static ref_type create_column(ColumnType column_type, size_t num_default_values, bool nullable, Allocator&);
+
+    /// Construct a copy of the columns array of this table using the
+    /// specified allocator and return just the ref to that array.
+    ///
+    /// In the clone, no string column will be of the enumeration
+    /// type.
+    ref_type clone_columns(Allocator&) const;
+
+    /// Construct a complete copy of this table (including its spec)
+    /// using the specified allocator and return just the ref to the
+    /// new top array.
+    ref_type clone(Allocator&) const;
+
+    /// True for `col_type_Link` and `col_type_LinkList`.
+    static bool is_link_type(ColumnType) noexcept;
+
+    void connect_opposite_link_columns(size_t link_col_ndx, Table& target_table, size_t backlink_col_ndx) noexcept;
+
+    //@{
+
+    /// Cascading removal of strong links.
+    ///
+    /// cascade_break_backlinks_to() removes all backlinks pointing to the row
+    /// at \a row_ndx. Additionally, if this causes the number of **strong**
+    /// backlinks originating from a particular opposite row (target row of
+    /// corresponding forward link) to drop to zero, and that row is not already
+    /// in \a state.rows, then that row is added to \a state.rows, and
+    /// cascade_break_backlinks_to() is called recursively for it. This
+    /// operation is the first half of the cascading row removal operation. The
+    /// second half is performed by passing the resulting contents of \a
+    /// state.rows to remove_backlink_broken_rows().
+    ///
+    /// Operations that trigger cascading row removal due to explicit removal of
+    /// one or more rows (the *initiating rows*), should add those rows to \a
+    /// rows initially, and then call cascade_break_backlinks_to() once for each
+    /// of them in turn. This is opposed to carrying out the explicit row
+    /// removals independently, which is also possible, but does require that
+    /// any initiating rows, that end up in \a state.rows due to link cycles,
+    /// are removed before passing \a state.rows to
+    /// remove_backlink_broken_rows(). In the case of clear(), where all rows of
+    /// a table are explicitly removed, it is better to use
+    /// cascade_break_backlinks_to_all_rows(), and then carry out the table
+    /// clearing as an independent step. For operations that trigger cascading
+    /// row removal for other reasons than explicit row removal, \a state.rows
+    /// must be empty initially, but cascade_break_backlinks_to() must still be
+    /// called for each of the initiating rows.
+    ///
+    /// When the last non-recursive invocation of cascade_break_backlinks_to()
+    /// returns, all forward links originating from a row in \a state.rows have
+    /// had their reciprocal backlinks removed, so remove_backlink_broken_rows()
+    /// does not perform reciprocal backlink removal at all. Additionally, all
+    /// remaining backlinks originating from rows in \a state.rows are
+    /// guaranteed to point to rows that are **not** in \a state.rows. This is
+    /// true because any backlink that was pointing to a row in \a state.rows
+    /// has been removed by one of the invocations of
+    /// cascade_break_backlinks_to(). The set of forward links, that correspond
+    /// to these remaining backlinks, is precisely the set of forward links that
+    /// need to be removed/nullified by remove_backlink_broken_rows(), which it
+    /// does by way of reciprocal forward link removal. Note also, that while
+    /// all the rows in \a state.rows can have remaining **weak** backlinks
+    /// originating from them, only the initiating rows in \a state.rows can
+    /// have remaining **strong** backlinks originating from them. This is true
+    /// because a non-initiating row is added to \a state.rows only when the
+    /// last backlink originating from it is lost.
+    ///
+    /// Each row removal is replicated individually (as opposed to one
+    /// replication instruction for the entire cascading operation). This is
+    /// done because it provides an easy way for Group::advance_transact() to
+    /// know which tables are affected by the cascade. Note that this has
+    /// several important consequences: First of all, the replication log
+    /// receiver must execute the row removal instructions in a non-cascading
+    /// fashion, meaning that there will be an asymmetry between the two sides
+    /// in how the effect of the cascade is brought about. While this is fine
+    /// for simple 1-to-1 replication, it may end up interfering badly with
+    /// *transaction merging*, when that feature is introduced. Imagine for
+    /// example that the cascade initiating operation gets canceled during
+    /// conflict resolution, but some, or all of the induced row removals get to
+    /// stay. That would break causal consistency. It is important, however, for
+    /// transaction merging that the cascaded row removals are explicitly
+    /// mentioned in the replication log, such that they can be used to adjust
+    /// row indexes during the *operational transform*.
+    ///
+    /// cascade_break_backlinks_to_all_rows() has the same affect as calling
+    /// cascade_break_backlinks_to() once for each row in the table. When
+    /// calling this function, \a state.stop_on_table must be set to the origin
+    /// table (origin table of corresponding forward links), and \a
+    /// state.stop_on_link_list_column must be null.
+    ///
+    /// It is immaterial which table remove_backlink_broken_rows() is called on,
+    /// as long it that table is in the same group as the removed rows.
+
+    void cascade_break_backlinks_to(size_t row_ndx, CascadeState& state);
+    void cascade_break_backlinks_to_all_rows(CascadeState& state);
+    void remove_backlink_broken_rows(const CascadeState&);
+
+    //@}
+
+    /// Used by query. Follows chain of link columns and returns final target table
+    const Table* get_link_chain_target(const std::vector<size_t>& link_chain) const;
+
+    /// Remove the specified row by the 'move last over' method.
+    void do_move_last_over(size_t row_ndx);
+
+    // Precondition: 1 <= end - begin
+    size_t* record_subtable_path(size_t* begin, size_t* end) const noexcept;
+
+    /// Check if an accessor exists for the specified subtable. If it does,
+    /// return a pointer to it, otherwise return null. This function assumes
+    /// that the specified column index in a valid index into `m_cols` but does
+    /// not otherwise assume more than minimal accessor consistency (see
+    /// AccessorConsistencyLevels.)
+    TableRef get_subtable_accessor(size_t col_ndx, size_t row_ndx) noexcept;
+
+    /// Unless the column accessor is missing, this function returns the
+    /// accessor for the target table of the specified link-type column. The
+    /// column accessor is said to be missing if `m_cols[col_ndx]` is null, and
+    /// this can happen only during certain operations such as the updating of
+    /// the accessor tree when a read transaction is advanced. Note that for
+    /// link type columns, the target table accessor exists when, and only when
+    /// the origin table accessor exists. This function assumes that the
+    /// specified column index in a valid index into `m_cols` and that the
+    /// column is a link-type column. Beyond that, it assume nothing more than
+    /// minimal accessor consistency (see AccessorConsistencyLevels.)
+    Table* get_link_target_table_accessor(size_t col_ndx) noexcept;
+
+    void discard_subtable_accessor(size_t col_ndx, size_t row_ndx) noexcept;
+
+    void adj_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept;
+    void adj_acc_erase_row(size_t row_ndx) noexcept;
+    void adj_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept;
+    void adj_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept;
+    void adj_acc_merge_rows(size_t old_row_ndx, size_t new_row_ndx) noexcept;
+
+    /// Adjust this table accessor and its subordinates after move_last_over()
+    /// (or its inverse).
+    ///
+    /// First, any row, subtable, or link list accessors registered as being at
+    /// \a to_row_ndx will be detached, as that row is assumed to have been
+    /// replaced. Next, any row, subtable, or link list accessors registered as
+    /// being at \a from_row_ndx, will be reregistered as being at \a
+    /// to_row_ndx, as the row at \a from_row_ndx is assumed to have been moved
+    /// to \a to_row_ndx.
+    ///
+    /// Crucially, if \a to_row_ndx is equal to \a from_row_ndx, then row,
+    /// subtable, or link list accessors at that row are **still detached**.
+    ///
+    /// Additionally, this function causes all link-adjacent tables to be marked
+    /// (dirty). Two tables are link-adjacent if one is the target table of a
+    /// link column of the other table. Note that this marking follows these
+    /// relations in both directions, but only to a depth of one.
+    ///
+    /// When this function is used in connection with move_last_over(), set \a
+    /// to_row_ndx to the index of the row to be removed, and set \a
+    /// from_row_ndx to the index of the last row in the table. As mentioned
+    /// earlier, this function can also be used in connection with the **inverse
+    /// of** move_last_over(), which is an operation that vacates a row by
+    /// moving its contents into a new last row of the table. In that case, set
+    /// \a to_row_ndx to one plus the index of the last row in the table, and
+    /// set \a from_row_ndx to the index of the row to be vacated.
+    ///
+    /// This function is used as part of Table::refresh_accessor_tree() to
+    /// promote the state of the accessors from Minimal Consistency into
+    /// Structural Correspondence, so it must be able to execute without
+    /// accessing the underlying array nodes.
+    void adj_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+
+    void adj_acc_clear_root_table() noexcept;
+    void adj_acc_clear_nonroot_table() noexcept;
+    void adj_row_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept;
+    void adj_row_acc_erase_row(size_t row_ndx) noexcept;
+    void adj_row_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept;
+    void adj_row_acc_move_row(size_t from_ndx, size_t to_ndx) noexcept;
+    void adj_row_acc_merge_rows(size_t old_row_ndx, size_t new_row_ndx) noexcept;
+
+    /// Called by adj_acc_move_over() to adjust row accessors.
+    void adj_row_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+
+    void adj_insert_column(size_t col_ndx);
+    void adj_erase_column(size_t col_ndx) noexcept;
+
+    bool is_marked() const noexcept;
+    void mark() noexcept;
+    void unmark() noexcept;
+    void recursive_mark() noexcept;
+    void mark_link_target_tables(size_t col_ndx_begin) noexcept;
+    void mark_opposite_link_tables() noexcept;
+
+    Replication* get_repl() noexcept;
+
+    void set_ndx_in_parent(size_t ndx_in_parent) noexcept;
+
+    /// Refresh the part of the accessor tree that is rooted at this
+    /// table. Subtable accessors will be refreshed only if they are marked
+    /// (Table::m_mark), and this applies recursively to subtables of
+    /// subtables. All refreshed table accessors (including this one) will be
+    /// unmarked upon return.
+    ///
+    /// The following conditions are necessary and sufficient for the proper
+    /// operation of this function:
+    ///
+    ///  - This table must be a group-level table, or a subtable. It must not be
+    ///    a free-standing table (because a free-standing table has no parent).
+    ///
+    ///  - The `index in parent` property is correct. The `index in parent`
+    ///    property of the table is the `index in parent` property of
+    ///    `m_columns` for subtables with shared descriptor, and the `index in
+    ///    parent` property of `m_top` for all other tables.
+    ///
+    ///  - If this table has shared descriptor, then the `index in parent`
+    ///    property of the contained spec accessor is correct.
+    ///
+    ///  - The parent accessor is in a valid state (already refreshed). If the
+    ///    parent is a group, then the group accessor (excluding its table
+    ///    accessors) must be in a valid state. If the parent is a table, then
+    ///    the table accessor (excluding its subtable accessors) must be in a
+    ///    valid state.
+    ///
+    ///  - Every descendant subtable accessor is marked if it needs to be
+    ///    refreshed, or if it has a descendant accessor that needs to be
+    ///    refreshed.
+    ///
+    ///  - This table accessor, as well as all its descendant accessors, are in
+    ///    structural correspondence with the underlying node hierarchy whose
+    ///    root ref is stored in the parent (see AccessorConsistencyLevels).
+    void refresh_accessor_tree();
+
+    void refresh_spec_accessor();
+
+    void refresh_column_accessors(size_t col_ndx_begin = 0);
+
+    // Look for link columns starting from col_ndx_begin.
+    // If a link column is found, follow the link and update it's
+    // backlink column accessor if it is in different table.
+    void refresh_link_target_accessors(size_t col_ndx_begin = 0);
+
+    bool is_cross_table_link_target() const noexcept;
+    std::recursive_mutex* get_parent_accessor_management_lock() const;
+#ifdef REALM_DEBUG
+    void to_dot_internal(std::ostream&) const;
+#endif
+
+    friend class SubtableNode;
+    friend class _impl::TableFriend;
+    friend class Query;
+    friend class metrics::QueryInfo;
+    template <class>
+    friend class util::bind_ptr;
+    template <class>
+    friend class SimpleQuerySupport;
+    friend class LangBindHelper;
+    friend class TableViewBase;
+    template <class T>
+    friend class Columns;
+    friend class Columns<StringData>;
+    friend class ParentNode;
+    template <class>
+    friend class SequentialGetter;
+    friend struct util::serializer::SerialisationState;
+    friend class RowBase;
+    friend class LinksToNode;
+    friend class LinkMap;
+    friend class LinkView;
+    friend class Group;
+};
+
+class Table::Parent : public ArrayParent {
+public:
+    ~Parent() noexcept override
+    {
+    }
+
+protected:
+    virtual StringData get_child_name(size_t child_ndx) const noexcept;
+
+    /// If children are group-level tables, then this function returns the
+    /// group. Otherwise it returns null.
+    virtual Group* get_parent_group() noexcept;
+
+    /// If children are subtables, then this function returns the
+    /// parent table. Otherwise it returns null.
+    ///
+    /// If \a column_ndx_out is not null, this function must assign the index of
+    /// the column within the parent table to `*column_ndx_out` when , and only
+    /// when this table parent is a column in a parent table.
+    virtual Table* get_parent_table(size_t* column_ndx_out = nullptr) noexcept;
+
+    virtual Spec* get_subtable_spec() noexcept;
+
+    /// Must be called whenever a child table accessor is about to be destroyed.
+    ///
+    /// Note that the argument is a pointer to the child Table rather than its
+    /// `ndx_in_parent` property. This is because only minimal accessor
+    /// consistency can be assumed by this function.
+    virtual void child_accessor_destroyed(Table* child) noexcept = 0;
+
+
+    virtual size_t* record_subtable_path(size_t* begin, size_t* end) noexcept;
+    virtual std::recursive_mutex* get_accessor_management_lock() noexcept = 0;
+
+    friend class Table;
+};
+
+
+// Implementation:
+
+
+inline uint_fast64_t Table::get_version_counter() const noexcept
+{
+    return observe_version();
+}
+
+inline uint64_t Table::observe_version() const noexcept
+{
+    m_top.get_alloc().observe_version();
+    return m_version;
+}
+
+inline void Table::bump_version(bool bump_global) const noexcept
+{
+    if (bump_global) {
+        // This is only set on initial entry through an operation on the same
+        // table.  recursive calls (via parent or via backlinks) must be done
+        // with bump_global=false.
+        m_top.get_alloc().bump_global_version();
+    }
+    if (m_top.get_alloc().should_propagate_version(m_version)) {
+        if (const Table* parent = get_parent_table_ptr())
+            parent->bump_version(false);
+        // Recurse through linked tables, use m_mark to avoid infinite recursion
+        for (auto& column_ptr : m_cols) {
+            // We may meet a null pointer in place of a backlink column, pending
+            // replacement with a new one. This can happen ONLY when creation of
+            // the corresponding forward link column in the origin table is
+            // pending as well. In this case it is ok to just ignore the zeroed
+            // backlink column, because the origin table is guaranteed to also
+            // be refreshed/marked dirty and hence have it's version bumped.
+            if (column_ptr != nullptr)
+                column_ptr->bump_link_origin_table_version();
+        }
+    }
+}
+
+inline void Table::remove(size_t row_ndx)
+{
+    bool is_move_last_over = false;
+    erase_row(row_ndx, is_move_last_over); // Throws
+}
+
+inline void Table::move_last_over(size_t row_ndx)
+{
+    bool is_move_last_over = true;
+    erase_row(row_ndx, is_move_last_over); // Throws
+}
+
+inline void Table::remove_last()
+{
+    if (!is_empty())
+        remove(size() - 1);
+}
+
+// A good place to start if you want to understand the memory ordering
+// chosen for the operations below is http://preshing.com/20130922/acquire-and-release-fences/
+inline void Table::bind_ptr() const noexcept
+{
+    m_ref_count.fetch_add(1, std::memory_order_relaxed);
+}
+
+inline void Table::unbind_ptr() const noexcept
+{
+    // The delete operation runs the destructor, and the destructor
+    // must always see all changes to the object being deleted.
+    // Within each thread, we know that unbind_ptr will always happen after
+    // any changes, so it is a convenient place to do a release.
+    // The release will then be observed by the acquire fence in
+    // the case where delete is actually called (the count reaches 0)
+    if (m_ref_count.fetch_sub(1, std::memory_order_release) != 1) {
+        return;
+    }
+
+    std::atomic_thread_fence(std::memory_order_acquire);
+
+    std::recursive_mutex* lock = get_parent_accessor_management_lock();
+    if (lock) {
+        std::lock_guard<std::recursive_mutex> lg(*lock);
+        if (m_ref_count == 0)
+            delete this;
+    }
+    else {
+        delete this;
+    }
+}
+
+inline bool Table::has_references() const noexcept
+{
+    return m_ref_count.load() > 0;
+}
+
+inline void Table::register_view(const TableViewBase* view)
+{
+    util::LockGuard lock(m_accessor_mutex);
+    // Casting away constness here - operations done on tableviews
+    // through m_views are all internal and preserving "some" kind
+    // of logical constness.
+    m_views.push_back(const_cast<TableViewBase*>(view));
+}
+
+inline bool Table::is_attached() const noexcept
+{
+    // Note that it is not possible to tie the state of attachment of a table to
+    // the state of attachment of m_top, because tables with shared spec do not
+    // have a 'top' array. Neither is it possible to tie it to the state of
+    // attachment of m_columns, because subtables with shared spec start out in
+    // a degenerate form where they do not have a 'columns' array. For these
+    // reasons, it is neccessary to define the notion of attachment for a table
+    // as follows: A table is attached if, and ony if m_column stores a non-null
+    // parent pointer. This works because even for degenerate subtables,
+    // m_columns is initialized with the correct parent pointer.
+    return m_columns.has_parent();
+}
+
+inline StringData Table::get_name() const noexcept
+{
+    REALM_ASSERT(is_attached());
+    const Array& real_top = m_top.is_attached() ? m_top : m_columns;
+    ArrayParent* parent = real_top.get_parent();
+    if (!parent)
+        return StringData("");
+    size_t index_in_parent = real_top.get_ndx_in_parent();
+    REALM_ASSERT(dynamic_cast<Parent*>(parent));
+    return static_cast<Parent*>(parent)->get_child_name(index_in_parent);
+}
+
+inline size_t Table::get_column_count() const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_public_column_count();
+}
+
+inline StringData Table::get_column_name(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, get_column_count());
+    return m_spec->get_column_name(ndx);
+}
+
+inline size_t Table::get_column_index(StringData name) const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return m_spec->get_column_index(name);
+}
+
+inline ColumnType Table::get_real_column_type(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_spec->get_column_count());
+    return m_spec->get_column_type(ndx);
+}
+
+inline DataType Table::get_column_type(size_t ndx) const noexcept
+{
+    REALM_ASSERT_3(ndx, <, m_spec->get_column_count());
+    return m_spec->get_public_column_type(ndx);
+}
+
+template <class Col, ColumnType col_type>
+inline Col& Table::get_column(size_t ndx)
+{
+    ColumnBase& col = get_column_base(ndx);
+#ifdef REALM_DEBUG
+    validate_column_type(col, col_type, ndx);
+#endif
+    REALM_ASSERT(typeid(Col) == typeid(col));
+    return static_cast<Col&>(col);
+}
+
+template <class Col, ColumnType col_type>
+inline const Col& Table::get_column(size_t ndx) const noexcept
+{
+    const ColumnBase& col = get_column_base(ndx);
+#ifdef REALM_DEBUG
+    validate_column_type(col, col_type, ndx);
+#endif
+    REALM_ASSERT(typeid(Col) == typeid(col));
+    return static_cast<const Col&>(col);
+}
+
+inline bool Table::has_shared_type() const noexcept
+{
+    REALM_ASSERT(is_attached());
+    return !m_top.is_attached();
+}
+
+inline void Table::verify_column(size_t col_ndx, const ColumnBase* col) const
+{
+    // Check if the column exists at the expected location
+    if (REALM_LIKELY(col_ndx < m_cols.size() && m_cols[col_ndx] == col))
+        return;
+    // The column might be elsewhere in the list
+    for (auto c : m_cols) {
+        if (c == col)
+            return;
+    }
+    throw LogicError(LogicError::column_does_not_exist);
+}
+
+class Table::UnbindGuard {
+public:
+    UnbindGuard(Table* table) noexcept
+        : m_table(table)
+    {
+    }
+
+    ~UnbindGuard() noexcept
+    {
+        if (m_table)
+            m_table->unbind_ptr();
+    }
+
+    Table& operator*() const noexcept
+    {
+        return *m_table;
+    }
+
+    Table* operator->() const noexcept
+    {
+        return m_table;
+    }
+
+    Table* get() const noexcept
+    {
+        return m_table;
+    }
+
+    Table* release() noexcept
+    {
+        Table* table = m_table;
+        m_table = nullptr;
+        return table;
+    }
+
+private:
+    Table* m_table;
+};
+
+
+inline Table::Table(Allocator& alloc)
+    : m_top(alloc)
+    , m_columns(alloc)
+{
+    m_ref_count = 1; // Explicitly managed lifetime
+
+    ref_type ref = create_empty_table(alloc); // Throws
+    Parent* parent = nullptr;
+    size_t ndx_in_parent = 0;
+    init(ref, parent, ndx_in_parent);
+}
+
+inline Table::Table(const Table& t, Allocator& alloc)
+    : m_top(alloc)
+    , m_columns(alloc)
+{
+    m_ref_count = 1; // Explicitly managed lifetime
+
+    ref_type ref = t.clone(alloc); // Throws
+    Parent* parent = nullptr;
+    size_t ndx_in_parent = 0;
+    init(ref, parent, ndx_in_parent);
+}
+
+inline Table::Table(ref_count_tag, Allocator& alloc)
+    : m_top(alloc)
+    , m_columns(alloc)
+{
+    m_ref_count = 0; // Lifetime managed by reference counting
+}
+
+inline Allocator& Table::get_alloc() const
+{
+    return m_top.get_alloc();
+}
+
+inline TableRef Table::create(Allocator& alloc)
+{
+    std::unique_ptr<Table> table(new Table(ref_count_tag(), alloc)); // Throws
+    ref_type ref = create_empty_table(alloc);                        // Throws
+    Parent* parent = nullptr;
+    size_t ndx_in_parent = 0;
+    table->init(ref, parent, ndx_in_parent); // Throws
+    return table.release()->get_table_ref();
+}
+
+inline TableRef Table::copy(Allocator& alloc) const
+{
+    std::unique_ptr<Table> table(new Table(ref_count_tag(), alloc)); // Throws
+    ref_type ref = clone(alloc);                                     // Throws
+    Parent* parent = nullptr;
+    size_t ndx_in_parent = 0;
+    table->init(ref, parent, ndx_in_parent); // Throws
+    return table.release()->get_table_ref();
+}
+
+// For use by queries
+template <class T>
+inline Columns<T> Table::column(size_t column_ndx)
+{
+    std::vector<size_t> link_chain = std::move(m_link_chain);
+    m_link_chain.clear();
+
+    // Check if user-given template type equals Realm type. Todo, we should clean up and reuse all our
+    // type traits (all the is_same() cases below).
+    const Table* table = get_link_chain_target(link_chain);
+
+    realm::DataType ct = table->get_column_type(column_ndx);
+    if (std::is_same<T, int64_t>::value && ct != type_Int)
+        throw LogicError(LogicError::type_mismatch);
+    else if (std::is_same<T, bool>::value && ct != type_Bool)
+        throw LogicError(LogicError::type_mismatch);
+    else if (std::is_same<T, realm::OldDateTime>::value && ct != type_OldDateTime)
+        throw LogicError(LogicError::type_mismatch);
+    else if (std::is_same<T, float>::value && ct != type_Float)
+        throw LogicError(LogicError::type_mismatch);
+    else if (std::is_same<T, double>::value && ct != type_Double)
+        throw LogicError(LogicError::type_mismatch);
+
+    if (std::is_same<T, Link>::value || std::is_same<T, LinkList>::value || std::is_same<T, BackLink>::value) {
+        link_chain.push_back(column_ndx);
+    }
+
+    return Columns<T>(column_ndx, this, std::move(link_chain));
+}
+
+template <class T>
+inline Columns<T> Table::column(const Table& origin, size_t origin_col_ndx)
+{
+    static_assert(std::is_same<T, BackLink>::value, "");
+
+    size_t origin_table_ndx = origin.get_index_in_group();
+    const Table& current_target_table = *get_link_chain_target(m_link_chain);
+    size_t backlink_col_ndx = current_target_table.m_spec->find_backlink_column(origin_table_ndx, origin_col_ndx);
+
+    std::vector<size_t> link_chain = std::move(m_link_chain);
+    m_link_chain.clear();
+    link_chain.push_back(backlink_col_ndx);
+
+    return Columns<T>(backlink_col_ndx, this, std::move(link_chain));
+}
+
+template <class T>
+inline BacklinkCount<T> Table::get_backlink_count()
+{
+    std::vector<size_t> link_chain = std::move(m_link_chain);
+    m_link_chain.clear();
+    return BacklinkCount<T>(this, std::move(link_chain));
+}
+
+template <class T>
+SubQuery<T> Table::column(size_t column_ndx, Query subquery)
+{
+    static_assert(std::is_same<T, LinkList>::value, "A subquery must involve a link list or backlink column");
+    return SubQuery<T>(column<T>(column_ndx), std::move(subquery));
+}
+
+template <class T>
+SubQuery<T> Table::column(const Table& origin, size_t origin_col_ndx, Query subquery)
+{
+    static_assert(std::is_same<T, BackLink>::value, "A subquery must involve a link list or backlink column");
+    return SubQuery<T>(column<T>(origin, origin_col_ndx), std::move(subquery));
+}
+
+inline Table& Table::link(size_t link_column)
+{
+    m_link_chain.push_back(link_column);
+    return *this;
+}
+
+inline Table& Table::backlink(const Table& origin, size_t origin_col_ndx)
+{
+    size_t origin_table_ndx = origin.get_index_in_group();
+    const Table& current_target_table = *get_link_chain_target(m_link_chain);
+    size_t backlink_col_ndx = current_target_table.m_spec->find_backlink_column(origin_table_ndx, origin_col_ndx);
+    return link(backlink_col_ndx);
+}
+
+inline bool Table::is_empty() const noexcept
+{
+    return m_size == 0;
+}
+
+inline size_t Table::size() const noexcept
+{
+    return m_size;
+}
+
+inline Table::RowExpr Table::get(size_t row_ndx) noexcept
+{
+    REALM_ASSERT_3(row_ndx, <, size());
+    return RowExpr(this, row_ndx);
+}
+
+inline Table::ConstRowExpr Table::get(size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_3(row_ndx, <, size());
+    return ConstRowExpr(this, row_ndx);
+}
+
+inline Table::RowExpr Table::front() noexcept
+{
+    return get(0);
+}
+
+inline Table::ConstRowExpr Table::front() const noexcept
+{
+    return get(0);
+}
+
+inline Table::RowExpr Table::back() noexcept
+{
+    return get(m_size - 1);
+}
+
+inline Table::ConstRowExpr Table::back() const noexcept
+{
+    return get(m_size - 1);
+}
+
+inline Table::RowExpr Table::operator[](size_t row_ndx) noexcept
+{
+    return get(row_ndx);
+}
+
+inline Table::ConstRowExpr Table::operator[](size_t row_ndx) const noexcept
+{
+    return get(row_ndx);
+}
+
+inline size_t Table::add_empty_row(size_t num_rows)
+{
+    size_t row_ndx = m_size;
+    insert_empty_row(row_ndx, num_rows); // Throws
+    return row_ndx;                      // Return index of first new row
+}
+
+inline ConstTableRef Table::get_subtable_tableref(size_t col_ndx, size_t row_ndx) const
+{
+    return const_cast<Table*>(this)->get_subtable_tableref(col_ndx, row_ndx); // Throws
+}
+
+inline bool Table::is_null_link(size_t col_ndx, size_t row_ndx) const noexcept
+{
+    return get_link(col_ndx, row_ndx) == realm::npos;
+}
+
+inline ConstTableRef Table::get_link_target(size_t col_ndx) const noexcept
+{
+    return const_cast<Table*>(this)->get_link_target(col_ndx);
+}
+
+template <class E>
+inline void Table::set_enum(size_t column_ndx, size_t row_ndx, E value)
+{
+    set_int(column_ndx, row_ndx, value);
+}
+
+inline void Table::nullify_link(size_t col_ndx, size_t row_ndx)
+{
+    set_link(col_ndx, row_ndx, realm::npos);
+}
+
+inline TableRef Table::get_subtable(size_t column_ndx, size_t row_ndx)
+{
+    return get_subtable_tableref(column_ndx, row_ndx);
+}
+
+inline ConstTableRef Table::get_subtable(size_t column_ndx, size_t row_ndx) const
+{
+    return get_subtable_tableref(column_ndx, row_ndx);
+}
+
+inline ConstTableRef Table::get_parent_table(size_t* column_ndx_out) const noexcept
+{
+    return ConstTableRef(get_parent_table_ptr(column_ndx_out));
+}
+
+inline TableRef Table::get_parent_table(size_t* column_ndx_out) noexcept
+{
+    return TableRef(get_parent_table_ptr(column_ndx_out));
+}
+
+inline bool Table::is_group_level() const noexcept
+{
+    return bool(get_parent_group());
+}
+
+inline bool Table::operator==(const Table& t) const
+{
+    return *m_spec == *t.m_spec && compare_rows(t); // Throws
+}
+
+inline bool Table::operator!=(const Table& t) const
+{
+    return !(*this == t); // Throws
+}
+
+inline bool Table::is_degenerate() const
+{
+    if (!is_attached()) {
+        throw LogicError{LogicError::detached_accessor};
+    }
+
+    return !m_columns.is_attached();
+}
+
+inline void Table::set_into_mixed(Table* parent, size_t col_ndx, size_t row_ndx) const
+{
+    parent->set_mixed_subtable(col_ndx, row_ndx, this);
+}
+
+inline size_t Table::get_size_from_ref(ref_type top_ref, Allocator& alloc) noexcept
+{
+    const char* top_header = alloc.translate(top_ref);
+    std::pair<int_least64_t, int_least64_t> p = Array::get_two(top_header, 0);
+    ref_type spec_ref = to_ref(p.first), columns_ref = to_ref(p.second);
+    return get_size_from_ref(spec_ref, columns_ref, alloc);
+}
+
+inline Table* Table::get_parent_table_ptr(size_t* column_ndx_out) noexcept
+{
+    const Table* parent = const_cast<const Table*>(this)->get_parent_table_ptr(column_ndx_out);
+    return const_cast<Table*>(parent);
+}
+
+inline bool Table::is_link_type(ColumnType col_type) noexcept
+{
+    return col_type == col_type_Link || col_type == col_type_LinkList;
+}
+
+inline size_t* Table::record_subtable_path(size_t* begin, size_t* end) const noexcept
+{
+    const Array& real_top = m_top.is_attached() ? m_top : m_columns;
+    size_t index_in_parent = real_top.get_ndx_in_parent();
+    REALM_ASSERT_3(begin, <, end);
+    *begin++ = index_in_parent;
+    ArrayParent* parent = real_top.get_parent();
+    REALM_ASSERT(parent);
+    REALM_ASSERT(dynamic_cast<Parent*>(parent));
+    return static_cast<Parent*>(parent)->record_subtable_path(begin, end);
+}
+
+inline size_t* Table::Parent::record_subtable_path(size_t* begin, size_t*) noexcept
+{
+    return begin;
+}
+
+inline bool Table::is_marked() const noexcept
+{
+    return m_mark;
+}
+
+inline void Table::mark() noexcept
+{
+    m_mark = true;
+}
+
+inline void Table::unmark() noexcept
+{
+    m_mark = false;
+}
+
+inline Replication* Table::get_repl() noexcept
+{
+    return m_top.get_alloc().get_replication();
+}
+
+inline void Table::set_ndx_in_parent(size_t ndx_in_parent) noexcept
+{
+    if (m_top.is_attached()) {
+        // Root table (independent descriptor)
+        m_top.set_ndx_in_parent(ndx_in_parent);
+    }
+    else {
+        // Subtable with shared descriptor
+        m_columns.set_ndx_in_parent(ndx_in_parent);
+    }
+}
+
+// Declare our explicit specializations so that the inline wrappers don't try
+// to instantiate them
+template<> int64_t Table::get<int64_t>(size_t, size_t) const noexcept;
+template<> util::Optional<int64_t> Table::get<util::Optional<int64_t>>(size_t, size_t) const noexcept;
+template<> bool Table::get<bool>(size_t, size_t) const noexcept;
+template<> Optional<bool> Table::get<Optional<bool>>(size_t, size_t) const noexcept;
+template<> float Table::get<float>(size_t, size_t) const noexcept;
+template<> util::Optional<float> Table::get<util::Optional<float>>(size_t, size_t) const noexcept;
+template<> double Table::get<double>(size_t, size_t) const noexcept;
+template<> util::Optional<double> Table::get<util::Optional<double>>(size_t, size_t) const noexcept;
+template<> OldDateTime Table::get<OldDateTime>(size_t, size_t) const noexcept;
+template<> Timestamp Table::get<Timestamp>(size_t, size_t) const noexcept;
+template<> StringData Table::get<StringData>(size_t, size_t) const noexcept;
+template<> BinaryData Table::get<BinaryData>(size_t, size_t) const noexcept;
+template<> BinaryIterator Table::get<BinaryIterator>(size_t, size_t) const noexcept;
+template<> Mixed Table::get<Mixed>(size_t, size_t) const noexcept;
+
+template<> void Table::set<int64_t>(size_t, size_t, int64_t, bool);
+template<> void Table::set<bool>(size_t, size_t, bool, bool);
+template<> void Table::set<float>(size_t, size_t, float, bool);
+template<> void Table::set<double>(size_t, size_t, double, bool);
+template<> void Table::set<OldDateTime>(size_t, size_t, OldDateTime, bool);
+template<> void Table::set<Timestamp>(size_t, size_t, Timestamp, bool);
+template<> void Table::set<StringData>(size_t, size_t, StringData, bool);
+template<> void Table::set<BinaryData>(size_t, size_t, BinaryData, bool);
+template<> void Table::set<Mixed>(size_t, size_t, Mixed, bool);
+template<> void Table::set<null>(size_t, size_t, null, bool);
+
+template<> size_t Table::set_unique<int64_t>(size_t, size_t, int64_t);
+template<> size_t Table::set_unique<StringData>(size_t, size_t, StringData);
+template<> size_t Table::set_unique<null>(size_t, size_t, null);
+
+
+inline int64_t Table::get_int(size_t col_ndx, size_t ndx) const noexcept
+{
+    if (is_nullable(col_ndx))
+        return get<util::Optional<int64_t>>(col_ndx, ndx).value_or(0);
+    else
+        return get<int64_t>(col_ndx, ndx);
+}
+
+inline size_t Table::set_int_unique(size_t col_ndx, size_t ndx, int_fast64_t value)
+{
+    return set_unique(col_ndx, ndx, value);
+}
+
+inline void Table::set_int(size_t col_ndx, size_t ndx, int_fast64_t value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline Timestamp Table::get_timestamp(size_t col_ndx, size_t ndx) const noexcept
+{
+    return get<Timestamp>(col_ndx, ndx);
+}
+
+inline void Table::set_timestamp(size_t col_ndx, size_t ndx, Timestamp value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline bool Table::get_bool(size_t col_ndx, size_t ndx) const noexcept
+{
+    if (is_nullable(col_ndx))
+        return get<util::Optional<bool>>(col_ndx, ndx).value_or(false);
+    else
+        return get<bool>(col_ndx, ndx);
+}
+
+inline void Table::set_bool(size_t col_ndx, size_t ndx, bool value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline OldDateTime Table::get_olddatetime(size_t col_ndx, size_t ndx) const noexcept
+{
+    return get<OldDateTime>(col_ndx, ndx);
+}
+
+inline void Table::set_olddatetime(size_t col_ndx, size_t ndx, OldDateTime value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline float Table::get_float(size_t col_ndx, size_t ndx) const noexcept
+{
+    float f = get<float>(col_ndx, ndx);
+    return null::is_null_float(f) ? 0.0f : f;
+}
+
+inline void Table::set_float(size_t col_ndx, size_t ndx, float value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline double Table::get_double(size_t col_ndx, size_t ndx) const noexcept
+{
+    double d = get<double>(col_ndx, ndx);
+    return null::is_null_float(d) ? 0.0 : d;
+}
+
+inline void Table::set_double(size_t col_ndx, size_t ndx, double value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline StringData Table::get_string(size_t col_ndx, size_t ndx) const noexcept
+{
+    return get<StringData>(col_ndx, ndx);
+}
+
+inline void Table::set_string(size_t col_ndx, size_t ndx, StringData value, bool is_default)
+{
+    return set(col_ndx, ndx, value, is_default);
+}
+
+inline size_t Table::set_string_unique(size_t col_ndx, size_t ndx, StringData value)
+{
+    return set_unique(col_ndx, ndx, value);
+}
+
+inline BinaryData Table::get_binary(size_t col_ndx, size_t ndx) const noexcept
+{
+    return get<BinaryData>(col_ndx, ndx);
+}
+
+inline BinaryIterator Table::get_binary_iterator(size_t col_ndx, size_t ndx) const noexcept
+{
+    return get<BinaryIterator>(col_ndx, ndx);
+}
+
+inline void Table::set_binary(size_t col_ndx, size_t ndx, BinaryData value, bool is_default)
+{
+    set(col_ndx, ndx, value, is_default);
+}
+
+inline Mixed Table::get_mixed(size_t col_ndx, size_t ndx) const noexcept
+{
+    return get<Mixed>(col_ndx, ndx);
+}
+
+inline void Table::set_mixed(size_t col_ndx, size_t ndx, Mixed value, bool is_default)
+{
+    set(col_ndx, ndx, value, is_default);
+}
+
+inline void Table::set_null(size_t col_ndx, size_t ndx, bool is_default)
+{
+    set(col_ndx, ndx, null(), is_default);
+}
+
+inline void Table::set_null_unique(size_t col_ndx, size_t ndx)
+{
+    set_unique(col_ndx, ndx, null());
+}
+
+
+// This class groups together information about the target of a link column
+// This is not a valid link if the target table == nullptr
+struct LinkTargetInfo {
+    LinkTargetInfo(Table* target = nullptr, size_t backlink_ndx = realm::npos)
+        : m_target_table(target)
+        , m_backlink_col_ndx(backlink_ndx)
+    {
+    }
+    bool is_valid() const
+    {
+        return (m_target_table != nullptr);
+    }
+    Table* m_target_table;
+    size_t m_backlink_col_ndx; // a value of npos indicates the backlink should be appended
+};
+
+// The purpose of this class is to give internal access to some, but
+// not all of the non-public parts of the Table class.
+class _impl::TableFriend {
+public:
+    typedef Table::UnbindGuard UnbindGuard;
+
+    static ref_type create_empty_table(Allocator& alloc)
+    {
+        return Table::create_empty_table(alloc); // Throws
+    }
+
+    static ref_type clone(const Table& table, Allocator& alloc)
+    {
+        return table.clone(alloc); // Throws
+    }
+
+    static ref_type clone_columns(const Table& table, Allocator& alloc)
+    {
+        return table.clone_columns(alloc); // Throws
+    }
+
+    static Table* create_accessor(Allocator& alloc, ref_type top_ref, Table::Parent* parent, size_t ndx_in_parent)
+    {
+        std::unique_ptr<Table> table(new Table(Table::ref_count_tag(), alloc)); // Throws
+        table->init(top_ref, parent, ndx_in_parent);                            // Throws
+        return table.release();
+    }
+
+    static Table* create_accessor(Spec* shared_spec, Table::Parent* parent_column, size_t parent_row_ndx)
+    {
+        Allocator& alloc = shared_spec->get_alloc();
+        std::unique_ptr<Table> table(new Table(Table::ref_count_tag(), alloc)); // Throws
+        table->init(shared_spec, parent_column, parent_row_ndx);                // Throws
+        return table.release();
+    }
+
+    // Intended to be used only by Group::create_table_accessor()
+    static Table* create_incomplete_accessor(Allocator& alloc, ref_type top_ref, Table::Parent* parent,
+                                             size_t ndx_in_parent)
+    {
+        std::unique_ptr<Table> table(new Table(Table::ref_count_tag(), alloc)); // Throws
+        bool skip_create_column_accessors = true;
+        table->init(top_ref, parent, ndx_in_parent, skip_create_column_accessors); // Throws
+        return table.release();
+    }
+
+    // Intended to be used only by Group::create_table_accessor()
+    static void complete_accessor(Table& table)
+    {
+        table.refresh_column_accessors(); // Throws
+    }
+
+    static void set_top_parent(Table& table, ArrayParent* parent, size_t ndx_in_parent) noexcept
+    {
+        table.m_top.set_parent(parent, ndx_in_parent);
+    }
+
+    static void update_from_parent(Table& table, size_t old_baseline) noexcept
+    {
+        table.update_from_parent(old_baseline);
+    }
+
+    static void detach(Table& table) noexcept
+    {
+        table.detach();
+    }
+
+    static void discard_row_accessors(Table& table) noexcept
+    {
+        table.discard_row_accessors();
+    }
+
+    static void discard_child_accessors(Table& table) noexcept
+    {
+        table.discard_child_accessors();
+    }
+
+    static void discard_subtable_accessor(Table& table, size_t col_ndx, size_t row_ndx) noexcept
+    {
+        table.discard_subtable_accessor(col_ndx, row_ndx);
+    }
+
+    static void bind_ptr(Table& table) noexcept
+    {
+        table.bind_ptr();
+    }
+
+    static void unbind_ptr(Table& table) noexcept
+    {
+        table.unbind_ptr();
+    }
+
+    static bool compare_rows(const Table& a, const Table& b)
+    {
+        return a.compare_rows(b); // Throws
+    }
+
+    static size_t get_size_from_ref(ref_type ref, Allocator& alloc) noexcept
+    {
+        return Table::get_size_from_ref(ref, alloc);
+    }
+
+    static size_t get_size_from_ref(ref_type spec_ref, ref_type columns_ref, Allocator& alloc) noexcept
+    {
+        return Table::get_size_from_ref(spec_ref, columns_ref, alloc);
+    }
+
+    static Spec& get_spec(Table& table) noexcept
+    {
+        return *table.m_spec;
+    }
+
+    static const Spec& get_spec(const Table& table) noexcept
+    {
+        return *table.m_spec;
+    }
+
+    static ColumnBase& get_column(const Table& table, size_t col_ndx)
+    {
+        return *table.m_cols[col_ndx];
+    }
+
+    static void do_remove(Table& table, size_t row_ndx)
+    {
+        bool broken_reciprocal_backlinks = false;
+        table.do_remove(row_ndx, broken_reciprocal_backlinks); // Throws
+    }
+
+    static void do_move_last_over(Table& table, size_t row_ndx)
+    {
+        bool broken_reciprocal_backlinks = false;
+        table.do_move_last_over(row_ndx, broken_reciprocal_backlinks); // Throws
+    }
+
+    static void do_swap_rows(Table& table, size_t row_ndx_1, size_t row_ndx_2)
+    {
+        table.do_swap_rows(row_ndx_1, row_ndx_2); // Throws
+    }
+
+    static void do_move_row(Table& table, size_t from_ndx, size_t to_ndx)
+    {
+        table.do_move_row(from_ndx, to_ndx); // Throws
+    }
+
+    static void do_merge_rows(Table& table, size_t row_ndx, size_t new_row_ndx)
+    {
+        table.do_merge_rows(row_ndx, new_row_ndx); // Throws
+    }
+
+    static void do_clear(Table& table)
+    {
+        bool broken_reciprocal_backlinks = false;
+        table.do_clear(broken_reciprocal_backlinks); // Throws
+    }
+
+    static void do_set_link(Table& table, size_t col_ndx, size_t row_ndx, size_t target_row_ndx)
+    {
+        table.do_set_link(col_ndx, row_ndx, target_row_ndx); // Throws
+    }
+
+    static size_t get_backlink_count(const Table& table, size_t row_ndx, bool only_strong_links) noexcept
+    {
+        return table.get_backlink_count(row_ndx, only_strong_links);
+    }
+
+    static void cascade_break_backlinks_to(Table& table, size_t row_ndx, CascadeState& state)
+    {
+        table.cascade_break_backlinks_to(row_ndx, state); // Throws
+    }
+
+    static void remove_backlink_broken_rows(Table& table, const CascadeState& rows)
+    {
+        table.remove_backlink_broken_rows(rows); // Throws
+    }
+
+    static size_t* record_subtable_path(const Table& table, size_t* begin, size_t* end) noexcept
+    {
+        return table.record_subtable_path(begin, end);
+    }
+
+    static void insert_column(Descriptor& desc, size_t column_ndx, DataType type, StringData name,
+                              LinkTargetInfo& link, bool nullable = false)
+    {
+        Table::do_insert_column(desc, column_ndx, type, name, link, nullable); // Throws
+    }
+
+    static void insert_column_unless_exists(Descriptor& desc, size_t column_ndx, DataType type, StringData name,
+                                            LinkTargetInfo link, bool nullable = false, bool* was_inserted = nullptr)
+    {
+        Table::do_insert_column_unless_exists(desc, column_ndx, type, name, link, nullable, was_inserted); // Throws
+    }
+
+    static void erase_column(Descriptor& desc, size_t column_ndx)
+    {
+        Table::do_erase_column(desc, column_ndx); // Throws
+    }
+
+    static void rename_column(Descriptor& desc, size_t column_ndx, StringData name)
+    {
+        Table::do_rename_column(desc, column_ndx, name); // Throws
+    }
+
+    static void add_search_index(Descriptor& desc, size_t column_ndx)
+    {
+        Table::do_add_search_index(desc, column_ndx); // Throws
+    }
+
+    static void remove_search_index(Descriptor& desc, size_t column_ndx)
+    {
+        Table::do_remove_search_index(desc, column_ndx); // Throws
+    }
+
+    static void set_link_type(Table& table, size_t column_ndx, LinkType link_type)
+    {
+        table.do_set_link_type(column_ndx, link_type); // Throws
+    }
+
+    static void erase_row(Table& table, size_t row_ndx, bool is_move_last_over)
+    {
+        table.erase_row(row_ndx, is_move_last_over); // Throws
+    }
+
+    static void batch_erase_rows(Table& table, const IntegerColumn& row_indexes, bool is_move_last_over)
+    {
+        table.batch_erase_rows(row_indexes, is_move_last_over); // Throws
+    }
+
+    static TableRef get_subtable_accessor(Table& table, size_t col_ndx, size_t row_ndx) noexcept
+    {
+        return table.get_subtable_accessor(col_ndx, row_ndx);
+    }
+
+    static const Table* get_link_target_table_accessor(const Table& table, size_t col_ndx) noexcept
+    {
+        return const_cast<Table&>(table).get_link_target_table_accessor(col_ndx);
+    }
+
+    static Table* get_link_target_table_accessor(Table& table, size_t col_ndx) noexcept
+    {
+        return table.get_link_target_table_accessor(col_ndx);
+    }
+
+    static void adj_acc_insert_rows(Table& table, size_t row_ndx, size_t num_rows) noexcept
+    {
+        table.adj_acc_insert_rows(row_ndx, num_rows);
+    }
+
+    static void adj_acc_erase_row(Table& table, size_t row_ndx) noexcept
+    {
+        table.adj_acc_erase_row(row_ndx);
+    }
+
+    static void adj_acc_swap_rows(Table& table, size_t row_ndx_1, size_t row_ndx_2) noexcept
+    {
+        table.adj_acc_swap_rows(row_ndx_1, row_ndx_2);
+    }
+
+    static void adj_acc_move_row(Table& table, size_t from_ndx, size_t to_ndx) noexcept
+    {
+        table.adj_acc_move_row(from_ndx, to_ndx);
+    }
+
+    static void adj_acc_merge_rows(Table& table, size_t row_ndx_1, size_t row_ndx_2) noexcept
+    {
+        table.adj_acc_merge_rows(row_ndx_1, row_ndx_2);
+    }
+
+    static void adj_acc_move_over(Table& table, size_t from_row_ndx, size_t to_row_ndx) noexcept
+    {
+        table.adj_acc_move_over(from_row_ndx, to_row_ndx);
+    }
+
+    static void adj_acc_clear_root_table(Table& table) noexcept
+    {
+        table.adj_acc_clear_root_table();
+    }
+
+    static void adj_acc_clear_nonroot_table(Table& table) noexcept
+    {
+        table.adj_acc_clear_nonroot_table();
+    }
+
+    static void adj_insert_column(Table& table, size_t col_ndx)
+    {
+        table.adj_insert_column(col_ndx); // Throws
+    }
+
+    static void adj_add_column(Table& table)
+    {
+        size_t num_cols = table.m_cols.size();
+        table.adj_insert_column(num_cols); // Throws
+    }
+
+    static void adj_erase_column(Table& table, size_t col_ndx) noexcept
+    {
+        table.adj_erase_column(col_ndx);
+    }
+
+    static bool is_marked(const Table& table) noexcept
+    {
+        return table.is_marked();
+    }
+
+    static void mark(Table& table) noexcept
+    {
+        table.mark();
+    }
+
+    static void unmark(Table& table) noexcept
+    {
+        table.unmark();
+    }
+
+    static void recursive_mark(Table& table) noexcept
+    {
+        table.recursive_mark();
+    }
+
+    static void mark_link_target_tables(Table& table, size_t col_ndx_begin) noexcept
+    {
+        table.mark_link_target_tables(col_ndx_begin);
+    }
+
+    static void mark_opposite_link_tables(Table& table) noexcept
+    {
+        table.mark_opposite_link_tables();
+    }
+
+    static DescriptorRef get_root_table_desc_accessor(Table& root_table) noexcept
+    {
+        return root_table.m_descriptor.lock();
+    }
+
+    typedef Table::AccessorUpdater AccessorUpdater;
+    static void update_accessors(Table& table, const size_t* col_path_begin, const size_t* col_path_end,
+                                 AccessorUpdater& updater)
+    {
+        table.update_accessors(col_path_begin, col_path_end, updater); // Throws
+    }
+
+    static void refresh_accessor_tree(Table& table)
+    {
+        table.refresh_accessor_tree(); // Throws
+    }
+
+    static void refresh_spec_accessor(Table& table)
+    {
+        table.refresh_spec_accessor(); // Throws
+    }
+
+    static void set_ndx_in_parent(Table& table, size_t ndx_in_parent) noexcept
+    {
+        table.set_ndx_in_parent(ndx_in_parent);
+    }
+
+    static bool is_link_type(ColumnType type) noexcept
+    {
+        return Table::is_link_type(type);
+    }
+
+    static void bump_version(Table& table, bool bump_global = true) noexcept
+    {
+        table.bump_version(bump_global);
+    }
+
+    static bool is_cross_table_link_target(const Table& table)
+    {
+        return table.is_cross_table_link_target();
+    }
+
+    static Group* get_parent_group(const Table& table) noexcept
+    {
+        return table.get_parent_group();
+    }
+
+    static Replication* get_repl(Table& table) noexcept
+    {
+        return table.get_repl();
+    }
+
+    static void register_view(Table& table, const TableViewBase* view)
+    {
+        table.register_view(view); // Throws
+    }
+
+    static void unregister_view(Table& table, const TableViewBase* view) noexcept
+    {
+        table.unregister_view(view);
+    }
+
+    static bool has_references(const Table& table) noexcept
+    {
+        return table.has_references();
+    }
+};
+
+
+} // namespace realm
+
+#endif // REALM_TABLE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/table_ref.hpp b/node_modules/realm/vendor/realm-ios/include/realm/table_ref.hpp
new file mode 100644
index 0000000..6e5c02b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/table_ref.hpp
@@ -0,0 +1,481 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_TABLE_REF_HPP
+#define REALM_TABLE_REF_HPP
+
+#include <cstddef>
+#include <algorithm>
+
+#include <realm/util/bind_ptr.hpp>
+
+namespace realm {
+
+
+class Table;
+
+
+/// A reference-counting "smart pointer" for referring to table
+/// accessors.
+///
+/// The purpose of this smart pointer is to keep the referenced table
+/// accessor alive for as long as anybody is referring to it, however,
+/// for stack allocated table accessors, the lifetime is necessarily
+/// determined by scope (see below).
+///
+/// Please take note of the distinction between a "table" and a "table
+/// accessor" here. A table accessor is an instance of `Table`,
+/// and it may, or may not be attached to an
+/// actual table at any specific point in time, but this state of
+/// attachment of the accessor has nothing to do with the function of
+/// the smart pointer. Also, in the rest of the documentation of this
+/// class, whenever you see `Table::%foo`, you are supposed to read it
+/// as, `Table::%foo`.
+///
+///
+/// Table accessors are either created directly by an application via
+/// a call to one of the public table constructors, or they are
+/// created internally by the Realm library, such as when the
+/// application calls Group::get_table(), Table::get_subtable(), or
+/// Table::create().
+///
+/// Applications can safely assume that all table accessors, created
+/// internally by the Realm library, have a lifetime that is managed
+/// by reference counting. This means that the application can prolong
+/// the lifetime of *such* table accessors indefinitely by holding on
+/// to at least one smart pointer, but note that the guarantee of the
+/// continued existence of the accessor, does not imply that the
+/// accessor remains attached to the underlying table (see
+/// Table::is_attached() for details). Accessors whose lifetime are
+/// controlled by reference counting are destroyed exactly when the
+/// reference count drops to zero.
+///
+/// When an application creates a new table accessor by a direct call
+/// to one of the public constructors, the lifetime of that table
+/// accessor is *not*, and cannot be managed by reference
+/// counting. This is true regardless of the way the accessor is
+/// created (i.e., regardless of whether it is an automatic variable
+/// on the stack, or created on the heap using `new`). However, for
+/// convenience, but with one important caveat, it is still possible
+/// to use smart pointers to refer to such accessors. The caveat is
+/// that no smart pointers are allowed to refer to the accessor at the
+/// point in time when its destructor is called. It is entirely the
+/// responsibility of the application to ensure that this requirement
+/// is met. Failing to do so, will result in undefined
+/// behavior. Finally, please note that an application is always free
+/// to use Table::create() as an alternative to creating free-standing
+/// top-level tables on the stack, and that this is indeed neccessary
+/// when fully reference counted lifetimes are required.
+///
+/// So, at any time, and for any table accessor, an application can
+/// call Table::get_table_ref() to obtain a smart pointer that refers
+/// to that table, however, while that is always possible and safe, it
+/// is not always possible to extend the lifetime of an accessor by
+/// holding on to a smart pointer. The question of whether that is
+/// possible, depends directly on the way the accessor was created.
+///
+///
+/// Apart from keeping track of the number of references, these smart
+/// pointers behaves almost exactly like regular pointers. In
+/// particular, it is possible to dereference a TableRef and get a
+/// `Table&` out of it, however, if you are not careful, this can
+/// easily lead to dangling references:
+///
+/// \code{.cpp}
+///
+///   Table& sub_1 = *(table.get_subtable(0,0));
+///   sub_1.add_empty_row(); // Oops, sub_1 may be dangling!
+///
+/// \endcode
+///
+/// Whether `sub_1` is actually dangling in the example above will
+/// depend on whether other references to the same subtable accessor
+/// already exist, but it is never wise to rely in this. Here is a
+/// safe and proper alternative:
+///
+/// \code{.cpp}
+///
+///   TableRef sub_2 = table.get_subtable(0,0);
+///   sub_2.add_empty_row(); // Safe!
+///
+///   void do_something(Table&);
+///   do_something(*(table.get_subtable(0,0))); // Also safe!
+///
+/// \endcode
+///
+///
+/// \sa Table
+/// \sa TableRef
+template <class T>
+class BasicTableRef : util::bind_ptr<T> {
+public:
+    constexpr BasicTableRef() noexcept
+    {
+    }
+    ~BasicTableRef() noexcept
+    {
+    }
+
+    // Copy construct
+    BasicTableRef(const BasicTableRef& r) noexcept
+        : util::bind_ptr<T>(r)
+    {
+    }
+    template <class U>
+    BasicTableRef(const BasicTableRef<U>& r) noexcept
+        : util::bind_ptr<T>(r)
+    {
+    }
+
+    // Copy assign
+    BasicTableRef& operator=(const BasicTableRef&) noexcept;
+    template <class U>
+    BasicTableRef& operator=(const BasicTableRef<U>&) noexcept;
+
+    // Move construct
+    BasicTableRef(BasicTableRef&& r) noexcept
+        : util::bind_ptr<T>(std::move(r))
+    {
+    }
+    template <class U>
+    BasicTableRef(BasicTableRef<U>&& r) noexcept
+        : util::bind_ptr<T>(std::move(r))
+    {
+    }
+
+    // Move assign
+    BasicTableRef& operator=(BasicTableRef&&) noexcept;
+    template <class U>
+    BasicTableRef& operator=(BasicTableRef<U>&&) noexcept;
+
+    //@{
+    /// Comparison
+    template <class U>
+    bool operator==(const BasicTableRef<U>&) const noexcept;
+
+    template <class U>
+    bool operator==(U*) const noexcept;
+
+    template <class U>
+    bool operator!=(const BasicTableRef<U>&) const noexcept;
+
+    template <class U>
+    bool operator!=(U*) const noexcept;
+
+    template <class U>
+    bool operator<(const BasicTableRef<U>&) const noexcept;
+
+    template <class U>
+    bool operator<(U*) const noexcept;
+
+    template <class U>
+    bool operator>(const BasicTableRef<U>&) const noexcept;
+
+    template <class U>
+    bool operator>(U*) const noexcept;
+
+    template <class U>
+    bool operator<=(const BasicTableRef<U>&) const noexcept;
+
+    template <class U>
+    bool operator<=(U*) const noexcept;
+
+    template <class U>
+    bool operator>=(const BasicTableRef<U>&) const noexcept;
+
+    template <class U>
+    bool operator>=(U*) const noexcept;
+//@}
+
+// Dereference
+#ifdef __clang__
+    // Clang has a bug that causes it to effectively ignore the 'using' declaration.
+    T& operator*() const noexcept
+    {
+        return util::bind_ptr<T>::operator*();
+    }
+#else
+    using util::bind_ptr<T>::operator*;
+#endif
+    using util::bind_ptr<T>::operator->;
+
+    using util::bind_ptr<T>::operator bool;
+
+    T* get() const noexcept
+    {
+        return util::bind_ptr<T>::get();
+    }
+    void reset() noexcept
+    {
+        util::bind_ptr<T>::reset();
+    }
+    void reset(T* t) noexcept
+    {
+        util::bind_ptr<T>::reset(t);
+    }
+
+    void swap(BasicTableRef& r) noexcept
+    {
+        this->util::bind_ptr<T>::swap(r);
+    }
+    friend void swap(BasicTableRef& a, BasicTableRef& b) noexcept
+    {
+        a.swap(b);
+    }
+
+    template <class U>
+    friend BasicTableRef<U> unchecked_cast(BasicTableRef<Table>) noexcept;
+
+    template <class U>
+    friend BasicTableRef<const U> unchecked_cast(BasicTableRef<const Table>) noexcept;
+
+private:
+    template <class>
+    struct GetRowAccType {
+        typedef void type;
+    };
+
+    typedef typename GetRowAccType<T>::type RowAccessor;
+
+public:
+    /// Same as 'table[i]' where 'table' is the referenced table.
+    RowAccessor operator[](size_t i) const noexcept
+    {
+        return (*this->get())[i];
+    }
+
+    explicit BasicTableRef(T* t) noexcept
+        : util::bind_ptr<T>(t)
+    {
+    }
+
+    T* release() { return util::bind_ptr<T>::release(); }
+private:
+    friend class SubtableColumnBase;
+    friend class Table;
+    friend class Group;
+
+    template <class>
+    friend class BasicTableRef;
+
+    typedef typename util::bind_ptr<T>::casting_move_tag casting_move_tag;
+    template <class U>
+    BasicTableRef(BasicTableRef<U>* r, casting_move_tag) noexcept
+        : util::bind_ptr<T>(r, casting_move_tag())
+    {
+    }
+};
+
+
+typedef BasicTableRef<Table> TableRef;
+typedef BasicTableRef<const Table> ConstTableRef;
+
+
+template <class C, class T, class U>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, const BasicTableRef<U>& p)
+{
+    out << static_cast<const void*>(&*p);
+    return out;
+}
+
+template <class T>
+inline BasicTableRef<T> unchecked_cast(TableRef t) noexcept
+{
+    return BasicTableRef<T>(&t, typename BasicTableRef<T>::casting_move_tag());
+}
+
+template <class T>
+inline BasicTableRef<const T> unchecked_cast(ConstTableRef t) noexcept
+{
+    return BasicTableRef<const T>(&t, typename BasicTableRef<T>::casting_move_tag());
+}
+
+
+//@{
+/// Comparison
+template <class T, class U>
+bool operator==(T*, const BasicTableRef<U>&) noexcept;
+template <class T, class U>
+bool operator!=(T*, const BasicTableRef<U>&) noexcept;
+template <class T, class U>
+bool operator<(T*, const BasicTableRef<U>&) noexcept;
+template <class T, class U>
+bool operator>(T*, const BasicTableRef<U>&) noexcept;
+template <class T, class U>
+bool operator<=(T*, const BasicTableRef<U>&) noexcept;
+template <class T, class U>
+bool operator>=(T*, const BasicTableRef<U>&) noexcept;
+//@}
+
+
+// Implementation:
+
+template <class T>
+inline BasicTableRef<T>& BasicTableRef<T>::operator=(const BasicTableRef& r) noexcept
+{
+    this->util::bind_ptr<T>::operator=(r);
+    return *this;
+}
+
+template <class T>
+template <class U>
+inline BasicTableRef<T>& BasicTableRef<T>::operator=(const BasicTableRef<U>& r) noexcept
+{
+    this->util::bind_ptr<T>::operator=(r);
+    return *this;
+}
+
+template <class T>
+inline BasicTableRef<T>& BasicTableRef<T>::operator=(BasicTableRef&& r) noexcept
+{
+    this->util::bind_ptr<T>::operator=(std::move(r));
+    return *this;
+}
+
+template <class T>
+template <class U>
+inline BasicTableRef<T>& BasicTableRef<T>::operator=(BasicTableRef<U>&& r) noexcept
+{
+    this->util::bind_ptr<T>::operator=(std::move(r));
+    return *this;
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator==(const BasicTableRef<U>& p) const noexcept
+{
+    return get() == p.get();
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator==(U* p) const noexcept
+{
+    return get() == p;
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator!=(const BasicTableRef<U>& p) const noexcept
+{
+    return get() != p.get();
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator!=(U* p) const noexcept
+{
+    return get() != p;
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator<(const BasicTableRef<U>& p) const noexcept
+{
+    return get() < p.get();
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator<(U* p) const noexcept
+{
+    return get() < p;
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator>(const BasicTableRef<U>& p) const noexcept
+{
+    return get() > p.get();
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator>(U* p) const noexcept
+{
+    return get() > p;
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator<=(const BasicTableRef<U>& p) const noexcept
+{
+    return get() <= p.get();
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator<=(U* p) const noexcept
+{
+    return get() <= p;
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator>=(const BasicTableRef<U>& p) const noexcept
+{
+    return get() >= p.get();
+}
+
+template <class T>
+template <class U>
+bool BasicTableRef<T>::operator>=(U* p) const noexcept
+{
+    return get() >= p;
+}
+
+template <class T, class U>
+bool operator==(T* a, const BasicTableRef<U>& b) noexcept
+{
+    return b == a;
+}
+
+template <class T, class U>
+bool operator!=(T* a, const BasicTableRef<U>& b) noexcept
+{
+    return b != a;
+}
+
+template <class T, class U>
+bool operator<(T* a, const BasicTableRef<U>& b) noexcept
+{
+    return b > a;
+}
+
+template <class T, class U>
+bool operator>(T* a, const BasicTableRef<U>& b) noexcept
+{
+    return b < a;
+}
+
+template <class T, class U>
+bool operator<=(T* a, const BasicTableRef<U>& b) noexcept
+{
+    return b >= a;
+}
+
+template <class T, class U>
+bool operator>=(T* a, const BasicTableRef<U>& b) noexcept
+{
+    return b <= a;
+}
+
+
+} // namespace realm
+
+#endif // REALM_TABLE_REF_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/table_view.hpp b/node_modules/realm/vendor/realm-ios/include/realm/table_view.hpp
new file mode 100644
index 0000000..3989da0
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/table_view.hpp
@@ -0,0 +1,1614 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_TABLE_VIEW_HPP
+#define REALM_TABLE_VIEW_HPP
+
+#include <realm/column.hpp>
+#include <realm/link_view.hpp>
+#include <realm/table.hpp>
+#include <realm/util/features.h>
+#include <realm/views.hpp>
+
+namespace realm {
+
+// Views, tables and synchronization between them:
+//
+// Views are built through queries against either tables or another view.
+// Views may be restricted to only hold entries provided by another view.
+// this other view is called the "restricting view".
+// Views may be sorted in ascending or descending order of values in one ore more columns.
+//
+// Views remember the query from which it was originally built.
+// Views remember the table from which it was originally built.
+// Views remember a restricting view if one was used when it was originally built.
+// Views remember the sorting criteria (columns and direction)
+//
+// A view may be operated in one of two distinct modes: *reflective* and *imperative*.
+// Sometimes the term "reactive" is used instead of "reflective" with the same meaning.
+//
+// Reflective views:
+// - A reflective view *always* *reflect* the result of running the query.
+//   If the underlying tables or tableviews change, the reflective view changes as well.
+//   A reflective view may need to rerun the query it was generated from, a potentially
+//   costly operation which happens on demand.
+// - It does not matter whether changes are explicitly done within the transaction, or
+//   occur implicitly as part of advance_read() or promote_to_write().
+//
+// Imperative views:
+// - An imperative view only *initially* holds the result of the query. An imperative
+//   view *never* reruns the query. To force the view to match it's query (by rerunning it),
+//   the view must be operated in reflective mode.
+//   An imperative view can be modified explicitly. References can be added, removed or
+//   changed.
+//
+// - In imperative mode, the references in the view tracks movement of the referenced data:
+//   If you delete an entry which is referenced from a view, said reference is detached,
+//   not removed.
+// - It does not matter whether the delete is done in-line (as part of the current transaction),
+//   or if it is done implicitly as part of advance_read() or promote_to_write().
+//
+// The choice between reflective and imperative views might eventually be represented by a
+// switch on the tableview, but isn't yet. For now, clients (bindings) must call sync_if_needed()
+// to get reflective behavior.
+//
+// Use cases:
+//
+// 1. Presenting data
+// The first use case (and primary motivator behind the reflective view) is to just track
+// and present the state of the database. In this case, the view is operated in reflective
+// mode, it is not modified within the transaction, and it is not used to modify data in
+// other parts of the database.
+//
+// 2. Handover
+// The second use case is "handover." The implicit rerun of the query in our first use case
+// may be too costly to be acceptable on the main thread. Instead you want to run the query
+// on a worker thread, but display it on the main thread. To achieve this, you need two
+// SharedGroups locked on to the same version of the database. If you have that, you can
+// *handover* a view from one thread/SharedGroup to the other.
+//
+// Handover is a two-step procedure. First, the accessors are *exported* from one SharedGroup,
+// called the sourcing group, then it is *imported* into another SharedGroup, called the
+// receiving group. The thread associated with the sourcing SharedGroup will be
+// responsible for the export operation, while the thread associated with the receiving
+// SharedGroup will do the import operation.
+//
+// 3. Iterating a view and changing data
+// The third use case (and a motivator behind the imperative view) is when you want
+// to make changes to the database in accordance with a query result. Imagine you want to
+// find all employees with a salary below a limit and raise their salaries to the limit (pseudocode):
+//
+//    promote_to_write();
+//    view = table.where().less_than(salary_column,limit).find_all();
+//    for (size_t i = 0; i < view.size(); ++i) {
+//        view.set_int(salary_column, i, limit);
+//        // add this to get reflective mode: view.sync_if_needed();
+//    }
+//    commit_and_continue_as_read();
+//
+// This is idiomatic imperative code and it works if the view is operated in imperative mode.
+//
+// If the view is operated in reflective mode, the behaviour surprises most people: When the
+// first salary is changed, the entry no longer fullfills the query, so it is dropped from the
+// view implicitly. view[0] is removed, view[1] moves to view[0] and so forth. But the next
+// loop iteration has i=1 and refers to view[1], thus skipping view[0]. The end result is that
+// every other employee get a raise, while the others don't.
+//
+// 4. Iterating intermixed with implicit updates
+// This leads us to use case 4, which is similar to use case 3, but uses promote_to_write()
+// intermixed with iterating a view. This is actually quite important to some, who do not want
+// to end up with a large write transaction.
+//
+//    view = table.where().less_than(salary_column,limit).find_all();
+//    for (size_t i = 0; i < view.size(); ++i) {
+//        promote_to_write();
+//        view.set_int(salary_column, i, limit);
+//        commit_and_continue_as_write();
+//    }
+//
+// Anything can happen at the call to promote_to_write(). The key question then becomes: how
+// do we support a safe way of realising the original goal (raising salaries) ?
+//
+// using the imperative operating mode:
+//
+//    view = table.where().less_than(salary_column,limit).find_all();
+//    for (size_t i = 0; i < view.size(); ++i) {
+//        promote_to_write();
+//        // add r.sync_if_needed(); to get reflective mode
+//        if (r.is_row_attached(i)) {
+//            Row r = view[i];
+//            r.set_int(salary_column, limit);
+//        }
+//        commit_and_continue_as_write();
+//    }
+//
+// This is safe, and we just aim for providing low level safety: is_row_attached() can tell
+// if the reference is valid, and the references in the view continue to point to the
+// same object at all times, also following implicit updates. The rest is up to the
+// application logic.
+//
+// It is important to see, that there is no guarantee that all relevant employees get
+// their raise in cases whith concurrent updates. At every call to promote_to_write() new
+// employees may be added to the underlying table, but as the view is in imperative mode,
+// these new employees are not added to the view. Also at promote_to_write() an existing
+// employee could recieve a (different, larger) raise which would then be overwritten and lost.
+// However, these are problems that you should expect, since the activity is spread over multiple
+// transactions.
+
+
+/// Common base class for TableView and ConstTableView.
+class TableViewBase : public RowIndexes {
+public:
+    // - not in use / implemented yet:   ... explicit calls to sync_if_needed() must be used
+    //                                       to get 'reflective' mode.
+    //    enum mode { mode_Reflective, mode_Imperative };
+    //    void set_operating_mode(mode);
+    //    mode get_operating_mode();
+    bool is_empty() const noexcept;
+
+    // Tells if the table that this TableView points at still exists or has been deleted.
+    bool is_attached() const noexcept;
+
+    bool is_row_attached(size_t row_ndx) const noexcept;
+    size_t size() const noexcept;
+    size_t num_attached_rows() const noexcept;
+
+    // Get the query used to create this TableView
+    // The query will have a null source table if this tv was not created from
+    // a query
+    const Query& get_query() const noexcept;
+
+    // Column information
+    const ColumnBase& get_column_base(size_t index) const;
+
+    size_t get_column_count() const noexcept;
+    StringData get_column_name(size_t column_ndx) const noexcept;
+    size_t get_column_index(StringData name) const;
+    DataType get_column_type(size_t column_ndx) const noexcept;
+
+    // Getting values
+    int64_t get_int(size_t column_ndx, size_t row_ndx) const noexcept;
+    bool get_bool(size_t column_ndx, size_t row_ndx) const noexcept;
+    OldDateTime get_olddatetime(size_t column_ndx, size_t row_ndx) const noexcept;
+    Timestamp get_timestamp(size_t column_ndx, size_t row_ndx) const noexcept;
+    float get_float(size_t column_ndx, size_t row_ndx) const noexcept;
+    double get_double(size_t column_ndx, size_t row_ndx) const noexcept;
+    StringData get_string(size_t column_ndx, size_t row_ndx) const noexcept;
+    BinaryData get_binary(size_t column_ndx, size_t row_ndx) const noexcept;
+    Mixed get_mixed(size_t column_ndx, size_t row_ndx) const noexcept;
+    DataType get_mixed_type(size_t column_ndx, size_t row_ndx) const noexcept;
+    size_t get_link(size_t column_ndx, size_t row_ndx) const noexcept;
+
+    // Links
+    bool is_null_link(size_t column_ndx, size_t row_ndx) const noexcept;
+
+    // Subtables
+    size_t get_subtable_size(size_t column_ndx, size_t row_ndx) const noexcept;
+
+    // Searching
+    template<typename T>
+    size_t find_first(size_t column_ndx, T value) const;
+
+    size_t find_first_int(size_t column_ndx, int64_t value) const;
+    size_t find_first_bool(size_t column_ndx, bool value) const;
+    size_t find_first_olddatetime(size_t column_ndx, OldDateTime value) const;
+    size_t find_first_float(size_t column_ndx, float value) const;
+    size_t find_first_double(size_t column_ndx, double value) const;
+    size_t find_first_string(size_t column_ndx, StringData value) const;
+    size_t find_first_binary(size_t column_ndx, BinaryData value) const;
+    size_t find_first_timestamp(size_t column_ndx, Timestamp value) const;
+
+    // Aggregate functions. count_target is ignored by all <int
+    // function> except Count. Hack because of bug in optional
+    // arguments in clang and vs2010 (fixed in 2012)
+    template <int function, typename T, typename R, class ColType>
+    R aggregate(R (ColType::*aggregateMethod)(size_t, size_t, size_t, size_t*) const, size_t column_ndx,
+                T count_target, size_t* return_ndx = nullptr) const;
+
+    int64_t sum_int(size_t column_ndx) const;
+    int64_t maximum_int(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    int64_t minimum_int(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double average_int(size_t column_ndx, size_t* value_count = nullptr) const;
+    size_t count_int(size_t column_ndx, int64_t target) const;
+
+    double sum_float(size_t column_ndx) const;
+    float maximum_float(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    float minimum_float(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double average_float(size_t column_ndx, size_t* value_count = nullptr) const;
+    size_t count_float(size_t column_ndx, float target) const;
+
+    double sum_double(size_t column_ndx) const;
+    double maximum_double(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double minimum_double(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    double average_double(size_t column_ndx, size_t* value_count = nullptr) const;
+    size_t count_double(size_t column_ndx, double target) const;
+
+    OldDateTime maximum_olddatetime(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    OldDateTime minimum_olddatetime(size_t column_ndx, size_t* return_ndx = nullptr) const;
+
+    Timestamp minimum_timestamp(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    Timestamp maximum_timestamp(size_t column_ndx, size_t* return_ndx = nullptr) const;
+    size_t count_timestamp(size_t column_ndx, Timestamp target) const;
+
+    // Simple pivot aggregate method. Experimental! Please do not
+    // document method publicly.
+    void aggregate(size_t group_by_column, size_t aggr_column, Table::AggrType op, Table& result) const;
+
+    // Get row index in the source table this view is "looking" at.
+    size_t get_source_ndx(size_t row_ndx) const noexcept;
+
+    /// Search this view for the specified source table row (specified by its
+    /// index in the source table). If found, the index of that row within this
+    /// view is returned, otherwise `realm::not_found` is returned.
+    size_t find_by_source_ndx(size_t source_ndx) const noexcept;
+
+    // Conversion
+    void to_json(std::ostream&, size_t link_depth = 0, std::map<std::string, std::string>* renames = nullptr) const;
+    void to_string(std::ostream&, size_t limit = 500) const;
+    void row_to_string(size_t row_ndx, std::ostream&) const;
+
+    // Determine if the view is 'in sync' with the underlying table
+    // as well as other views used to generate the view. Note that updates
+    // through views maintains synchronization between view and table.
+    // It doesnt by itself maintain other views as well. So if a view
+    // is generated from another view (not a table), updates may cause
+    // that view to be outdated, AND as the generated view depends upon
+    // it, it too will become outdated.
+    bool is_in_sync() const;
+
+    // Tells if this TableView depends on a LinkList or row that has been deleted.
+    bool depends_on_deleted_object() const;
+
+    // Synchronize a view to match a table or tableview from which it
+    // has been derived. Synchronization is achieved by rerunning the
+    // query used to generate the view. If derived from another view, that
+    // view will be synchronized as well.
+    //
+    // "live" or "reactive" views are implemented by calling sync_if_needed
+    // before any of the other access-methods whenever the view may have become
+    // outdated.
+    //
+    // This will make the TableView empty and in sync with the highest possible table version
+    // if the TableView depends on an object (LinkView or row) that has been deleted.
+    uint_fast64_t sync_if_needed() const;
+
+    // Sort m_row_indexes according to one column
+    void sort(size_t column, bool ascending = true);
+
+    // Sort m_row_indexes according to multiple columns
+    void sort(SortDescriptor order);
+
+    // Remove rows that are duplicated with respect to the column set passed as argument.
+    // distinct() will preserve the original order of the row pointers, also if the order is a result of sort()
+    // If two rows are indentical (for the given set of distinct-columns), then the last row is removed.
+    // You can call sync_if_needed() to update the distinct view, just like you can for a sorted view.
+    // Each time you call distinct() it will compound on the previous calls
+    void distinct(size_t column);
+    void distinct(DistinctDescriptor columns);
+    void limit(LimitDescriptor limit);
+    void include(IncludeDescriptor include_paths);
+    IncludeDescriptor get_include_descriptors();
+
+    // Replace the order of sort and distinct operations, bypassing manually
+    // calling sort and distinct. This is a convenience method for bindings.
+    void apply_descriptor_ordering(DescriptorOrdering new_ordering);
+
+    // Gets a readable and parsable string which completely describes the sort and
+    // distinct operations applied to this view.
+    std::string get_descriptor_ordering_description() const;
+
+    // Returns whether the rows are guaranteed to be in table order.
+    // This is true only of unsorted TableViews created from either:
+    // - Table::find_all()
+    // - Query::find_all() when the query is not restricted to a view.
+    bool is_in_table_order() const;
+
+    virtual ~TableViewBase() noexcept;
+
+    virtual std::unique_ptr<TableViewBase> clone() const = 0;
+
+protected:
+    // This TableView can be "born" from 4 different sources:
+    // - LinkView
+    // - Query::find_all()
+    // - Table::get_distinct_view()
+    // - Table::get_backlink_view()
+    // Return the version of the source it was created from.
+    uint64_t outside_version() const;
+
+    void do_sync();
+
+    // Null if, and only if, the view is detached.
+    mutable TableRef m_table;
+
+    // The link column that this view contain backlinks for.
+    const BacklinkColumn* m_linked_column = nullptr;
+    // The target row that rows in this view link to.
+    ConstRow m_linked_row;
+
+    // If this TableView was created from a LinkView, then this reference points to it. Otherwise it's 0
+    mutable ConstLinkViewRef m_linkview_source;
+
+    // m_distinct_column_source != npos if this view was created from distinct values in a column of m_table.
+    size_t m_distinct_column_source = npos;
+
+    // Stores the ordering criteria of applied sort and distinct operations.
+    DescriptorOrdering m_descriptor_ordering;
+
+    // A valid query holds a reference to its table which must match our m_table.
+    // hence we can use a query with a null table reference to indicate that the view
+    // was NOT generated by a query, but follows a table directly.
+    Query m_query;
+    // parameters for findall, needed to rerun the query
+    size_t m_start;
+    size_t m_end;
+    size_t m_limit;
+
+    mutable util::Optional<uint_fast64_t> m_last_seen_version;
+
+    size_t m_num_detached_refs = 0;
+    /// Construct null view (no memory allocated).
+    TableViewBase();
+
+    /// Construct empty view, ready for addition of row indices.
+    TableViewBase(Table* parent);
+    TableViewBase(Table* parent, Query& query, size_t start, size_t end, size_t limit);
+    TableViewBase(Table* parent, size_t column, BasicRowExpr<const Table> row);
+    TableViewBase(Table* parent, ConstLinkViewRef link_view);
+
+    enum DistinctViewTag { DistinctView };
+    TableViewBase(DistinctViewTag, Table* parent, size_t column_ndx);
+
+    /// Copy constructor.
+    TableViewBase(const TableViewBase&);
+
+    /// Move constructor.
+    TableViewBase(TableViewBase&&) noexcept;
+
+    TableViewBase& operator=(const TableViewBase&);
+    TableViewBase& operator=(TableViewBase&&) noexcept;
+
+    template <class R, class V>
+    static R find_all_integer(V*, size_t, int64_t);
+
+    template <class R, class V>
+    static R find_all_float(V*, size_t, float);
+
+    template <class R, class V>
+    static R find_all_double(V*, size_t, double);
+
+    template <class R, class V>
+    static R find_all_string(V*, size_t, StringData);
+
+    using HandoverPatch = TableViewHandoverPatch;
+
+    // handover machinery entry points based on dynamic type. These methods:
+    // a) forward their calls to the static type entry points.
+    // b) new/delete patch data structures.
+    virtual std::unique_ptr<TableViewBase> clone_for_handover(std::unique_ptr<HandoverPatch>& patch,
+                                                              ConstSourcePayload mode) const = 0;
+
+    virtual std::unique_ptr<TableViewBase> clone_for_handover(std::unique_ptr<HandoverPatch>& patch,
+                                                              MutableSourcePayload mode) = 0;
+
+    void apply_and_consume_patch(std::unique_ptr<HandoverPatch>& patch, Group& group)
+    {
+        apply_patch(*patch, group);
+        patch.reset();
+    }
+    // handover machinery entry points based on static type
+    void apply_patch(HandoverPatch& patch, Group& group);
+    TableViewBase(const TableViewBase& source, HandoverPatch& patch, ConstSourcePayload mode);
+    TableViewBase(TableViewBase& source, HandoverPatch& patch, MutableSourcePayload mode);
+
+private:
+    void allocate_row_indexes();
+    void detach() const noexcept; // may have to remove const
+    size_t find_first_integer(size_t column_ndx, int64_t value) const;
+    template <class oper>
+    Timestamp minmax_timestamp(size_t column_ndx, size_t* return_ndx) const;
+
+    friend class Table;
+    friend class Query;
+    friend class SharedGroup;
+
+    // Called by table to adjust any row references:
+    void adj_row_acc_insert_rows(size_t row_ndx, size_t num_rows) noexcept;
+    void adj_row_acc_erase_row(size_t row_ndx) noexcept;
+    void adj_row_acc_move_over(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+    void adj_row_acc_swap_rows(size_t row_ndx_1, size_t row_ndx_2) noexcept;
+    void adj_row_acc_move_row(size_t from_row_ndx, size_t to_row_ndx) noexcept;
+    void adj_row_acc_clear() noexcept;
+};
+
+
+inline void TableViewBase::detach() const noexcept // may have to remove const
+{
+    m_table = TableRef();
+}
+
+
+class ConstTableView;
+
+
+enum class RemoveMode { ordered, unordered };
+
+
+/// A TableView gives read and write access to the parent table.
+///
+/// A 'const TableView' cannot be changed (e.g. sorted), nor can the
+/// parent table be modified through it.
+///
+/// A TableView is both copyable and movable.
+class TableView : public TableViewBase {
+public:
+    using TableViewBase::TableViewBase;
+
+    TableView() = default;
+
+    // Rows
+    typedef BasicRowExpr<Table> RowExpr;
+    typedef BasicRowExpr<const Table> ConstRowExpr;
+    RowExpr get(size_t row_ndx) noexcept;
+    ConstRowExpr get(size_t row_ndx) const noexcept;
+    RowExpr front() noexcept;
+    ConstRowExpr front() const noexcept;
+    RowExpr back() noexcept;
+    ConstRowExpr back() const noexcept;
+    RowExpr operator[](size_t row_ndx) noexcept;
+    ConstRowExpr operator[](size_t row_ndx) const noexcept;
+
+    // Setting values
+    void set_int(size_t column_ndx, size_t row_ndx, int64_t value);
+    void set_bool(size_t column_ndx, size_t row_ndx, bool value);
+    void set_olddatetime(size_t column_ndx, size_t row_ndx, OldDateTime value);
+    void set_timestamp(size_t column_ndx, size_t row_ndx, Timestamp value);
+    template <class E>
+    void set_enum(size_t column_ndx, size_t row_ndx, E value);
+    void set_float(size_t column_ndx, size_t row_ndx, float value);
+    void set_double(size_t column_ndx, size_t row_ndx, double value);
+    void set_string(size_t column_ndx, size_t row_ndx, StringData value);
+    void set_binary(size_t column_ndx, size_t row_ndx, BinaryData value);
+    void set_mixed(size_t column_ndx, size_t row_ndx, Mixed value);
+    void set_subtable(size_t column_ndx, size_t row_ndx, const Table* table);
+    void set_link(size_t column_ndx, size_t row_ndx, size_t target_row_ndx);
+
+    // Subtables
+    TableRef get_subtable(size_t column_ndx, size_t row_ndx);
+    ConstTableRef get_subtable(size_t column_ndx, size_t row_ndx) const;
+    void clear_subtable(size_t column_ndx, size_t row_ndx);
+
+    // Links
+    TableRef get_link_target(size_t column_ndx) noexcept;
+    ConstTableRef get_link_target(size_t column_ndx) const noexcept;
+    void nullify_link(size_t column_ndx, size_t row_ndx);
+
+    /// \defgroup table_view_removes
+    //@{
+    /// \brief Remove the specified row (or rows) from the underlying table.
+    ///
+    /// remove() removes the specified row from the underlying table,
+    /// remove_last() removes the last row in the table view from the underlying
+    /// table, and clear removes all the rows in the table view from the
+    /// underlying table.
+    ///
+    /// When rows are removed from the underlying table, they will by necessity
+    /// also be removed from the table view.
+    ///
+    /// The order of the remaining rows in the the table view will be maintained
+    /// regardless of the value passed for \a underlying_mode.
+    ///
+    /// \param row_ndx The index within this table view of the row to be
+    /// removed.
+    ///
+    /// \param underlying_mode If set to RemoveMode::ordered (the default), the
+    /// rows will be removed from the underlying table in a way that maintains
+    /// the order of the remaining rows in the underlying table. If set to
+    /// RemoveMode::unordered, the order of the remaining rows in the underlying
+    /// table will not in general be maintaind, but the operation will generally
+    /// be much faster. In any case, the order of remaining rows in the table
+    /// view will not be affected.
+    void remove(size_t row_ndx, RemoveMode underlying_mode = RemoveMode::ordered);
+    void remove_last(RemoveMode underlying_mode = RemoveMode::ordered);
+    void clear(RemoveMode underlying_mode = RemoveMode::ordered);
+    //@}
+
+    // Searching (Int and String)
+    TableView find_all_int(size_t column_ndx, int64_t value);
+    ConstTableView find_all_int(size_t column_ndx, int64_t value) const;
+    TableView find_all_bool(size_t column_ndx, bool value);
+    ConstTableView find_all_bool(size_t column_ndx, bool value) const;
+    TableView find_all_olddatetime(size_t column_ndx, OldDateTime value);
+    ConstTableView find_all_olddatetime(size_t column_ndx, OldDateTime value) const;
+    TableView find_all_float(size_t column_ndx, float value);
+    ConstTableView find_all_float(size_t column_ndx, float value) const;
+    TableView find_all_double(size_t column_ndx, double value);
+    ConstTableView find_all_double(size_t column_ndx, double value) const;
+    TableView find_all_string(size_t column_ndx, StringData value);
+    ConstTableView find_all_string(size_t column_ndx, StringData value) const;
+    // FIXME: Need: TableView find_all_binary(size_t column_ndx, BinaryData value);
+    // FIXME: Need: ConstTableView find_all_binary(size_t column_ndx, BinaryData value) const;
+
+    Table& get_parent() noexcept;
+    const Table& get_parent() const noexcept;
+
+    std::unique_ptr<TableViewBase> clone() const override
+    {
+        return std::unique_ptr<TableViewBase>(new TableView(*this));
+    }
+
+    std::unique_ptr<TableViewBase> clone_for_handover(std::unique_ptr<HandoverPatch>& patch,
+                                                      ConstSourcePayload mode) const override
+    {
+        patch.reset(new HandoverPatch);
+        std::unique_ptr<TableViewBase> retval(new TableView(*this, *patch, mode));
+        return retval;
+    }
+
+    std::unique_ptr<TableViewBase> clone_for_handover(std::unique_ptr<HandoverPatch>& patch,
+                                                      MutableSourcePayload mode) override
+    {
+        patch.reset(new HandoverPatch);
+        std::unique_ptr<TableViewBase> retval(new TableView(*this, *patch, mode));
+        return retval;
+    }
+
+private:
+    TableView(Table& parent);
+    TableView(Table& parent, Query& query, size_t start, size_t end, size_t limit);
+    TableView(Table& parent, ConstLinkViewRef);
+
+    TableView(DistinctViewTag, Table& parent, size_t column_ndx);
+
+    TableView find_all_integer(size_t column_ndx, int64_t value);
+    ConstTableView find_all_integer(size_t column_ndx, int64_t value) const;
+
+    friend class ConstTableView;
+    friend class Table;
+    friend class Query;
+    friend class TableViewBase;
+    friend class LinkView;
+};
+
+
+/// A ConstTableView gives read access to the parent table, but no
+/// write access. The view itself, though, can be changed, for
+/// example, it can be sorted.
+///
+/// Note that methods are declared 'const' if, and only if they leave
+/// the view unmodified, and this is irrespective of whether they
+/// modify the parent table.
+///
+/// A ConstTableView has both copy and move semantics. See TableView
+/// for more on this.
+class ConstTableView : public TableViewBase {
+public:
+    using TableViewBase::TableViewBase;
+
+    ConstTableView() = default;
+
+    ConstTableView(const TableView&);
+    ConstTableView(TableView&&);
+    ConstTableView& operator=(const TableView&);
+    ConstTableView& operator=(TableView&&);
+
+    // Rows
+    typedef BasicRowExpr<const Table> ConstRowExpr;
+    ConstRowExpr get(size_t row_ndx) const noexcept;
+    ConstRowExpr front() const noexcept;
+    ConstRowExpr back() const noexcept;
+    ConstRowExpr operator[](size_t row_ndx) const noexcept;
+
+    // Subtables
+    ConstTableRef get_subtable(size_t column_ndx, size_t row_ndx) const;
+
+    // Links
+    ConstTableRef get_link_target(size_t column_ndx) const noexcept;
+
+    // Searching (Int and String)
+    ConstTableView find_all_int(size_t column_ndx, int64_t value) const;
+    ConstTableView find_all_bool(size_t column_ndx, bool value) const;
+    ConstTableView find_all_olddatetime(size_t column_ndx, OldDateTime value) const;
+    ConstTableView find_all_float(size_t column_ndx, float value) const;
+    ConstTableView find_all_double(size_t column_ndx, double value) const;
+    ConstTableView find_all_string(size_t column_ndx, StringData value) const;
+
+    const Table& get_parent() const noexcept;
+
+    std::unique_ptr<TableViewBase> clone() const override
+    {
+        return std::unique_ptr<TableViewBase>(new ConstTableView(*this));
+    }
+
+    std::unique_ptr<TableViewBase> clone_for_handover(std::unique_ptr<HandoverPatch>& patch,
+                                                      ConstSourcePayload mode) const override
+    {
+        patch.reset(new HandoverPatch);
+        std::unique_ptr<TableViewBase> retval(new ConstTableView(*this, *patch, mode));
+        return retval;
+    }
+
+    std::unique_ptr<TableViewBase> clone_for_handover(std::unique_ptr<HandoverPatch>& patch,
+                                                      MutableSourcePayload mode) override
+    {
+        patch.reset(new HandoverPatch);
+        std::unique_ptr<TableViewBase> retval(new ConstTableView(*this, *patch, mode));
+        return retval;
+    }
+
+private:
+    ConstTableView(const Table& parent);
+
+    ConstTableView find_all_integer(size_t column_ndx, int64_t value) const;
+
+    friend class TableView;
+    friend class Table;
+    friend class Query;
+    friend class TableViewBase;
+};
+
+
+// ================================================================================================
+// TableViewBase Implementation:
+
+inline const Query& TableViewBase::get_query() const noexcept
+{
+    return m_query;
+}
+
+inline bool TableViewBase::is_empty() const noexcept
+{
+    return m_row_indexes.is_empty();
+}
+
+inline bool TableViewBase::is_attached() const noexcept
+{
+    return bool(m_table);
+}
+
+inline bool TableViewBase::is_row_attached(size_t row_ndx) const noexcept
+{
+    return m_row_indexes.get(row_ndx) != detached_ref;
+}
+
+inline size_t TableViewBase::size() const noexcept
+{
+    return m_row_indexes.size();
+}
+
+inline size_t TableViewBase::num_attached_rows() const noexcept
+{
+    return m_row_indexes.size() - m_num_detached_refs;
+}
+
+inline size_t TableViewBase::get_source_ndx(size_t row_ndx) const noexcept
+{
+    return to_size_t(m_row_indexes.get(row_ndx));
+}
+
+inline size_t TableViewBase::find_by_source_ndx(size_t source_ndx) const noexcept
+{
+    REALM_ASSERT(source_ndx < m_table->size());
+    return m_row_indexes.find_first(source_ndx);
+}
+
+inline void TableViewBase::allocate_row_indexes()
+{
+    // FIXME: This code is unreasonably complicated because it uses `IntegerColumn` as
+    // a free-standing container, and beause `IntegerColumn` does not conform to the
+    // RAII idiom (nor should it).
+    Allocator& alloc = m_row_indexes.get_alloc();
+    _impl::DeepArrayRefDestroyGuard ref_guard(alloc);
+    ref_guard.reset(IntegerColumn::create(alloc)); // Throws
+    m_table->register_view(this);                   // Throws
+    m_row_indexes.init_from_ref(alloc, ref_guard.release());
+}
+
+inline TableViewBase::TableViewBase()
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default()) // Throws
+{
+    ref_type ref = IntegerColumn::create(m_row_indexes.get_alloc()); // Throws
+    m_row_indexes.get_root_array()->init_from_ref(ref);
+}
+
+inline TableViewBase::TableViewBase(Table* parent)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default())
+    , m_table(parent->get_table_ref()) // Throws
+    , m_last_seen_version(m_table ? util::make_optional(m_table->m_version) : util::none)
+{
+    allocate_row_indexes();
+}
+
+inline TableViewBase::TableViewBase(Table* parent, Query& query, size_t start, size_t end, size_t lim)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default()) // Throws
+    , m_table(parent->get_table_ref())
+    , m_query(query)
+    , m_start(start)
+    , m_end(end)
+    , m_limit(lim)
+    , m_last_seen_version(outside_version())
+{
+    allocate_row_indexes();
+}
+
+inline TableViewBase::TableViewBase(Table* parent, size_t column, BasicRowExpr<const Table> row)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default())
+    , m_table(parent->get_table_ref()) // Throws
+    , m_linked_column(&parent->get_column_link_base(column).get_backlink_column())
+    , m_linked_row(row)
+    , m_last_seen_version(m_table ? util::make_optional(m_table->m_version) : util::none)
+{
+    allocate_row_indexes();
+}
+
+inline TableViewBase::TableViewBase(DistinctViewTag, Table* parent, size_t column_ndx)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default())
+    , m_table(parent->get_table_ref()) // Throws
+    , m_distinct_column_source(column_ndx)
+    , m_last_seen_version(m_table ? util::make_optional(m_table->m_version) : util::none)
+{
+    REALM_ASSERT(m_distinct_column_source != npos);
+
+    allocate_row_indexes();
+}
+
+inline TableViewBase::TableViewBase(Table* parent, ConstLinkViewRef link_view)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default())
+    , m_table(parent->get_table_ref()) // Throws
+    , m_linkview_source(std::move(link_view))
+    , m_last_seen_version(m_table ? util::make_optional(m_table->m_version) : util::none)
+{
+    REALM_ASSERT(m_linkview_source);
+
+    allocate_row_indexes();
+}
+
+inline TableViewBase::TableViewBase(const TableViewBase& tv)
+    : RowIndexes(IntegerColumn::unattached_root_tag(), Allocator::get_default())
+    , m_table(tv.m_table)
+    , m_linked_column(tv.m_linked_column)
+    , m_linked_row(tv.m_linked_row)
+    , m_linkview_source(tv.m_linkview_source)
+    , m_distinct_column_source(tv.m_distinct_column_source)
+    , m_descriptor_ordering(std::move(tv.m_descriptor_ordering))
+    , m_query(tv.m_query)
+    , m_start(tv.m_start)
+    , m_end(tv.m_end)
+    , m_limit(tv.m_limit)
+    , m_last_seen_version(tv.m_last_seen_version)
+    , m_num_detached_refs(tv.m_num_detached_refs)
+{
+    // FIXME: This code is unreasonably complicated because it uses `IntegerColumn` as
+    // a free-standing container, and because `IntegerColumn` does not conform to the
+    // RAII idiom (nor should it).
+    Allocator& alloc = m_row_indexes.get_alloc();
+    MemRef mem = tv.m_row_indexes.get_root_array()->clone_deep(alloc); // Throws
+    _impl::DeepArrayRefDestroyGuard ref_guard(mem.get_ref(), alloc);
+    if (m_table)
+        m_table->register_view(this); // Throws
+    m_row_indexes.init_from_mem(alloc, mem);
+    ref_guard.release();
+    RowIndexes::m_limit_count = tv.m_limit_count;
+}
+
+inline TableViewBase::TableViewBase(TableViewBase&& tv) noexcept
+    : RowIndexes(std::move(tv.m_row_indexes))
+    , m_table(std::move(tv.m_table))
+    , m_linked_column(tv.m_linked_column)
+    , m_linked_row(tv.m_linked_row)
+    , m_linkview_source(std::move(tv.m_linkview_source))
+    , m_distinct_column_source(tv.m_distinct_column_source)
+    , m_descriptor_ordering(std::move(tv.m_descriptor_ordering))
+    , m_query(std::move(tv.m_query))
+    , m_start(tv.m_start)
+    , m_end(tv.m_end)
+    , m_limit(tv.m_limit)
+    ,
+    // if we are created from a table view which is outdated, take care to use the outdated
+    // version number so that we can later trigger a sync if needed.
+    m_last_seen_version(tv.m_last_seen_version)
+    , m_num_detached_refs(tv.m_num_detached_refs)
+{
+    RowIndexes::m_limit_count = tv.m_limit_count;
+    if (m_table)
+        m_table->move_registered_view(&tv, this);
+}
+
+inline TableViewBase::~TableViewBase() noexcept
+{
+    if (m_table) {
+        m_table->unregister_view(this);
+        m_table = TableRef();
+    }
+    m_row_indexes.destroy(); // Shallow
+}
+
+inline TableViewBase& TableViewBase::operator=(TableViewBase&& tv) noexcept
+{
+    if (m_table)
+        m_table->unregister_view(this);
+    m_table = std::move(tv.m_table);
+    if (m_table)
+        m_table->move_registered_view(&tv, this);
+
+    m_row_indexes.move_assign(tv.m_row_indexes);
+    m_limit_count = tv.m_limit_count;
+    m_query = std::move(tv.m_query);
+    m_num_detached_refs = tv.m_num_detached_refs;
+    m_last_seen_version = tv.m_last_seen_version;
+    m_start = tv.m_start;
+    m_end = tv.m_end;
+    m_limit = tv.m_limit;
+    m_linked_column = tv.m_linked_column;
+    m_linked_row = tv.m_linked_row;
+    m_linkview_source = std::move(tv.m_linkview_source);
+    m_descriptor_ordering = std::move(tv.m_descriptor_ordering);
+    m_distinct_column_source = tv.m_distinct_column_source;
+
+    return *this;
+}
+
+inline TableViewBase& TableViewBase::operator=(const TableViewBase& tv)
+{
+    if (this == &tv)
+        return *this;
+
+    if (m_table != tv.m_table) {
+        if (m_table)
+            m_table->unregister_view(this);
+        m_table = tv.m_table;
+        if (m_table)
+            m_table->register_view(this);
+    }
+
+    Allocator& alloc = m_row_indexes.get_alloc();
+    MemRef mem = tv.m_row_indexes.get_root_array()->clone_deep(alloc); // Throws
+    _impl::DeepArrayRefDestroyGuard ref_guard(mem.get_ref(), alloc);
+    m_row_indexes.destroy();
+    m_row_indexes.get_root_array()->init_from_mem(mem);
+    ref_guard.release();
+    m_limit_count = tv.m_limit_count;
+
+    m_query = tv.m_query;
+    m_num_detached_refs = tv.m_num_detached_refs;
+    m_last_seen_version = tv.m_last_seen_version;
+    m_start = tv.m_start;
+    m_end = tv.m_end;
+    m_limit = tv.m_limit;
+    m_linked_column = tv.m_linked_column;
+    m_linked_row = tv.m_linked_row;
+    m_linkview_source = tv.m_linkview_source;
+    m_descriptor_ordering = tv.m_descriptor_ordering;
+    m_distinct_column_source = tv.m_distinct_column_source;
+
+    return *this;
+}
+
+#define REALM_ASSERT_COLUMN(column_ndx)                                                                              \
+    REALM_ASSERT(m_table);                                                                                           \
+    REALM_ASSERT(column_ndx < m_table->get_column_count())
+
+#define REALM_ASSERT_ROW(row_ndx)                                                                                    \
+    REALM_ASSERT(m_table);                                                                                           \
+    REALM_ASSERT(row_ndx < m_row_indexes.size())
+
+#define REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, column_type)                                                        \
+    REALM_ASSERT_COLUMN(column_ndx);                                                                                 \
+    REALM_DIAG_PUSH();                                                                                               \
+    REALM_DIAG_IGNORE_TAUTOLOGICAL_COMPARE();                                                                        \
+    REALM_ASSERT(m_table->get_column_type(column_ndx) == column_type ||                                              \
+                 (m_table->get_column_type(column_ndx) == type_OldDateTime && column_type == type_Int));             \
+    REALM_DIAG_POP()
+
+#define REALM_ASSERT_INDEX(column_ndx, row_ndx)                                                                      \
+    REALM_ASSERT_COLUMN(column_ndx);                                                                                 \
+    REALM_ASSERT(row_ndx < m_row_indexes.size())
+
+#define REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, column_type)                                                \
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, column_type);                                                           \
+    REALM_ASSERT(row_ndx < m_row_indexes.size())
+
+#define REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx)                                              \
+    REALM_ASSERT_COLUMN(column_ndx);                                                                                 \
+    REALM_DIAG_PUSH();                                                                                               \
+    REALM_DIAG_IGNORE_TAUTOLOGICAL_COMPARE();                                                                        \
+    REALM_ASSERT(m_table->get_column_type(column_ndx) == type_Table ||                                               \
+                 (m_table->get_column_type(column_ndx) == type_Mixed));                                              \
+    REALM_DIAG_POP();                                                                                                \
+    REALM_ASSERT(row_ndx < m_row_indexes.size())
+
+// Column information
+
+inline const ColumnBase& TableViewBase::get_column_base(size_t index) const
+{
+    return m_table->get_column_base(index);
+}
+
+inline size_t TableViewBase::get_column_count() const noexcept
+{
+    REALM_ASSERT(m_table);
+    return m_table->get_column_count();
+}
+
+inline StringData TableViewBase::get_column_name(size_t column_ndx) const noexcept
+{
+    REALM_ASSERT(m_table);
+    return m_table->get_column_name(column_ndx);
+}
+
+inline size_t TableViewBase::get_column_index(StringData name) const
+{
+    REALM_ASSERT(m_table);
+    return m_table->get_column_index(name);
+}
+
+inline DataType TableViewBase::get_column_type(size_t column_ndx) const noexcept
+{
+    REALM_ASSERT(m_table);
+    return m_table->get_column_type(column_ndx);
+}
+
+
+// Getters
+
+
+inline int64_t TableViewBase::get_int(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX(column_ndx, row_ndx);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_int(column_ndx, to_size_t(real_ndx));
+}
+
+inline bool TableViewBase::get_bool(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Bool);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_bool(column_ndx, to_size_t(real_ndx));
+}
+
+inline OldDateTime TableViewBase::get_olddatetime(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_OldDateTime);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_olddatetime(column_ndx, to_size_t(real_ndx));
+}
+
+inline Timestamp TableViewBase::get_timestamp(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Timestamp);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_timestamp(column_ndx, to_size_t(real_ndx));
+}
+
+inline float TableViewBase::get_float(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Float);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_float(column_ndx, to_size_t(real_ndx));
+}
+
+inline double TableViewBase::get_double(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Double);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_double(column_ndx, to_size_t(real_ndx));
+}
+
+inline StringData TableViewBase::get_string(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_String);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_string(column_ndx, to_size_t(real_ndx));
+}
+
+inline BinaryData TableViewBase::get_binary(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Binary);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_binary(column_ndx, to_size_t(real_ndx));
+}
+
+inline Mixed TableViewBase::get_mixed(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Mixed);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_mixed(column_ndx, to_size_t(real_ndx));
+}
+
+inline DataType TableViewBase::get_mixed_type(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Mixed);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_mixed_type(column_ndx, to_size_t(real_ndx));
+}
+
+inline size_t TableViewBase::get_subtable_size(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_subtable_size(column_ndx, to_size_t(real_ndx));
+}
+
+inline size_t TableViewBase::get_link(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Link);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_link(column_ndx, to_size_t(real_ndx));
+}
+
+inline TableRef TableView::get_link_target(size_t column_ndx) noexcept
+{
+    return m_table->get_link_target(column_ndx);
+}
+
+inline ConstTableRef TableView::get_link_target(size_t column_ndx) const noexcept
+{
+    return m_table->get_link_target(column_ndx);
+}
+
+inline ConstTableRef ConstTableView::get_link_target(size_t column_ndx) const noexcept
+{
+    return m_table->get_link_target(column_ndx);
+}
+
+inline bool TableViewBase::is_null_link(size_t column_ndx, size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Link);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->is_null_link(column_ndx, to_size_t(real_ndx));
+}
+
+
+// Searching
+
+
+inline size_t TableViewBase::find_first_int(size_t column_ndx, int64_t value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Int);
+    return find_first_integer(column_ndx, value);
+}
+
+inline size_t TableViewBase::find_first_bool(size_t column_ndx, bool value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Bool);
+    return find_first_integer(column_ndx, value ? 1 : 0);
+}
+
+inline size_t TableViewBase::find_first_olddatetime(size_t column_ndx, OldDateTime value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_OldDateTime);
+    return find_first_integer(column_ndx, int64_t(value.get_olddatetime()));
+}
+
+inline size_t TableViewBase::find_first_integer(size_t column_ndx, int64_t value) const
+{
+    return find_first<int64_t>(column_ndx, value);
+}
+
+inline size_t TableViewBase::find_first_float(size_t column_ndx, float value) const
+{
+    return find_first<float>(column_ndx, value);
+}
+
+inline size_t TableViewBase::find_first_double(size_t column_ndx, double value) const
+{
+    return find_first<double>(column_ndx, value);
+}
+
+inline size_t TableViewBase::find_first_string(size_t column_ndx, StringData value) const
+{
+    return find_first<StringData>(column_ndx, value);
+}
+
+inline size_t TableViewBase::find_first_binary(size_t column_ndx, BinaryData value) const
+{
+    return find_first<BinaryData>(column_ndx, value);
+}
+
+inline size_t TableViewBase::find_first_timestamp(size_t column_ndx, Timestamp value) const
+{
+    return find_first<Timestamp>(column_ndx, value);
+}
+
+
+template <class R, class V>
+R TableViewBase::find_all_integer(V* view, size_t column_ndx, int64_t value)
+{
+    typedef typename std::remove_const<V>::type TNonConst;
+    return view->m_table->where(const_cast<TNonConst*>(view)).equal(column_ndx, value).find_all();
+}
+
+template <class R, class V>
+R TableViewBase::find_all_float(V* view, size_t column_ndx, float value)
+{
+    typedef typename std::remove_const<V>::type TNonConst;
+    return view->m_table->where(const_cast<TNonConst*>(view)).equal(column_ndx, value).find_all();
+}
+
+template <class R, class V>
+R TableViewBase::find_all_double(V* view, size_t column_ndx, double value)
+{
+    typedef typename std::remove_const<V>::type TNonConst;
+    return view->m_table->where(const_cast<TNonConst*>(view)).equal(column_ndx, value).find_all();
+}
+
+template <class R, class V>
+R TableViewBase::find_all_string(V* view, size_t column_ndx, StringData value)
+{
+    typedef typename std::remove_const<V>::type TNonConst;
+    return view->m_table->where(const_cast<TNonConst*>(view)).equal(column_ndx, value).find_all();
+}
+
+
+//-------------------------- TableView, ConstTableView implementation:
+
+inline ConstTableView::ConstTableView(const TableView& tv)
+    : TableViewBase(tv)
+{
+}
+
+inline ConstTableView::ConstTableView(TableView&& tv)
+    : TableViewBase(std::move(tv))
+{
+}
+
+inline void TableView::remove_last(RemoveMode underlying_mode)
+{
+    if (!is_empty())
+        remove(size() - 1, underlying_mode);
+}
+
+inline Table& TableView::get_parent() noexcept
+{
+    return *m_table;
+}
+
+inline const Table& TableView::get_parent() const noexcept
+{
+    return *m_table;
+}
+
+inline const Table& ConstTableView::get_parent() const noexcept
+{
+    return *m_table;
+}
+
+inline TableView::TableView(Table& parent)
+    : TableViewBase(&parent)
+{
+}
+
+inline TableView::TableView(Table& parent, Query& query, size_t start, size_t end, size_t lim)
+    : TableViewBase(&parent, query, start, end, lim)
+{
+}
+
+inline TableView::TableView(Table& parent, ConstLinkViewRef link_view)
+: TableViewBase(&parent, std::move(link_view))
+{
+}
+
+inline TableView::TableView(TableViewBase::DistinctViewTag, Table& parent, size_t column_ndx)
+    : TableViewBase(TableViewBase::DistinctView, &parent, column_ndx)
+{
+}
+
+inline ConstTableView::ConstTableView(const Table& parent)
+    : TableViewBase(const_cast<Table*>(&parent))
+{
+}
+
+inline ConstTableView& ConstTableView::operator=(const TableView& tv)
+{
+    TableViewBase::operator=(tv);
+    return *this;
+}
+
+inline ConstTableView& ConstTableView::operator=(TableView&& tv)
+{
+    TableViewBase::operator=(std::move(tv));
+    return *this;
+}
+
+
+// - string
+inline TableView TableView::find_all_string(size_t column_ndx, StringData value)
+{
+    return TableViewBase::find_all_string<TableView>(this, column_ndx, value);
+}
+
+inline ConstTableView TableView::find_all_string(size_t column_ndx, StringData value) const
+{
+    return TableViewBase::find_all_string<ConstTableView>(this, column_ndx, value);
+}
+
+inline ConstTableView ConstTableView::find_all_string(size_t column_ndx, StringData value) const
+{
+    return TableViewBase::find_all_string<ConstTableView>(this, column_ndx, value);
+}
+
+// - float
+inline TableView TableView::find_all_float(size_t column_ndx, float value)
+{
+    return TableViewBase::find_all_float<TableView>(this, column_ndx, value);
+}
+
+inline ConstTableView TableView::find_all_float(size_t column_ndx, float value) const
+{
+    return TableViewBase::find_all_float<ConstTableView>(this, column_ndx, value);
+}
+
+inline ConstTableView ConstTableView::find_all_float(size_t column_ndx, float value) const
+{
+    return TableViewBase::find_all_float<ConstTableView>(this, column_ndx, value);
+}
+
+
+// - double
+inline TableView TableView::find_all_double(size_t column_ndx, double value)
+{
+    return TableViewBase::find_all_double<TableView>(this, column_ndx, value);
+}
+
+inline ConstTableView TableView::find_all_double(size_t column_ndx, double value) const
+{
+    return TableViewBase::find_all_double<ConstTableView>(this, column_ndx, value);
+}
+
+inline ConstTableView ConstTableView::find_all_double(size_t column_ndx, double value) const
+{
+    return TableViewBase::find_all_double<ConstTableView>(this, column_ndx, value);
+}
+
+
+// -- 3 variants of the 3 find_all_{int, bool, date} all based on integer
+
+inline TableView TableView::find_all_integer(size_t column_ndx, int64_t value)
+{
+    return TableViewBase::find_all_integer<TableView>(this, column_ndx, value);
+}
+
+inline ConstTableView TableView::find_all_integer(size_t column_ndx, int64_t value) const
+{
+    return TableViewBase::find_all_integer<ConstTableView>(this, column_ndx, value);
+}
+
+inline ConstTableView ConstTableView::find_all_integer(size_t column_ndx, int64_t value) const
+{
+    return TableViewBase::find_all_integer<ConstTableView>(this, column_ndx, value);
+}
+
+
+inline TableView TableView::find_all_int(size_t column_ndx, int64_t value)
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Int);
+    return find_all_integer(column_ndx, value);
+}
+
+inline TableView TableView::find_all_bool(size_t column_ndx, bool value)
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Bool);
+    return find_all_integer(column_ndx, value ? 1 : 0);
+}
+
+inline TableView TableView::find_all_olddatetime(size_t column_ndx, OldDateTime value)
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_OldDateTime);
+    return find_all_integer(column_ndx, int64_t(value.get_olddatetime()));
+}
+
+
+inline ConstTableView TableView::find_all_int(size_t column_ndx, int64_t value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Int);
+    return find_all_integer(column_ndx, value);
+}
+
+inline ConstTableView TableView::find_all_bool(size_t column_ndx, bool value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Bool);
+    return find_all_integer(column_ndx, value ? 1 : 0);
+}
+
+inline ConstTableView TableView::find_all_olddatetime(size_t column_ndx, OldDateTime value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_OldDateTime);
+    return find_all_integer(column_ndx, int64_t(value.get_olddatetime()));
+}
+
+
+inline ConstTableView ConstTableView::find_all_int(size_t column_ndx, int64_t value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Int);
+    return find_all_integer(column_ndx, value);
+}
+
+inline ConstTableView ConstTableView::find_all_bool(size_t column_ndx, bool value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_Bool);
+    return find_all_integer(column_ndx, value ? 1 : 0);
+}
+
+inline ConstTableView ConstTableView::find_all_olddatetime(size_t column_ndx, OldDateTime value) const
+{
+    REALM_ASSERT_COLUMN_AND_TYPE(column_ndx, type_OldDateTime);
+    return find_all_integer(column_ndx, int64_t(value.get_olddatetime()));
+}
+
+
+// Rows
+
+
+inline TableView::RowExpr TableView::get(size_t row_ndx) noexcept
+{
+    REALM_ASSERT_ROW(row_ndx);
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get(to_size_t(real_ndx));
+}
+
+inline TableView::ConstRowExpr TableView::get(size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_ROW(row_ndx);
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get(to_size_t(real_ndx));
+}
+
+inline ConstTableView::ConstRowExpr ConstTableView::get(size_t row_ndx) const noexcept
+{
+    REALM_ASSERT_ROW(row_ndx);
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get(to_size_t(real_ndx));
+}
+
+inline TableView::RowExpr TableView::front() noexcept
+{
+    return get(0);
+}
+
+inline TableView::ConstRowExpr TableView::front() const noexcept
+{
+    return get(0);
+}
+
+inline ConstTableView::ConstRowExpr ConstTableView::front() const noexcept
+{
+    return get(0);
+}
+
+inline TableView::RowExpr TableView::back() noexcept
+{
+    size_t last_row_ndx = size() - 1;
+    return get(last_row_ndx);
+}
+
+inline TableView::ConstRowExpr TableView::back() const noexcept
+{
+    size_t last_row_ndx = size() - 1;
+    return get(last_row_ndx);
+}
+
+inline ConstTableView::ConstRowExpr ConstTableView::back() const noexcept
+{
+    size_t last_row_ndx = size() - 1;
+    return get(last_row_ndx);
+}
+
+inline TableView::RowExpr TableView::operator[](size_t row_ndx) noexcept
+{
+    return get(row_ndx);
+}
+
+inline TableView::ConstRowExpr TableView::operator[](size_t row_ndx) const noexcept
+{
+    return get(row_ndx);
+}
+
+inline ConstTableView::ConstRowExpr ConstTableView::operator[](size_t row_ndx) const noexcept
+{
+    return get(row_ndx);
+}
+
+
+// Subtables
+
+
+inline TableRef TableView::get_subtable(size_t column_ndx, size_t row_ndx)
+{
+    REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_subtable(column_ndx, to_size_t(real_ndx));
+}
+
+inline ConstTableRef TableView::get_subtable(size_t column_ndx, size_t row_ndx) const
+{
+    REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_subtable(column_ndx, to_size_t(real_ndx));
+}
+
+inline ConstTableRef ConstTableView::get_subtable(size_t column_ndx, size_t row_ndx) const
+{
+    REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->get_subtable(column_ndx, to_size_t(real_ndx));
+}
+
+inline void TableView::clear_subtable(size_t column_ndx, size_t row_ndx)
+{
+    REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    return m_table->clear_subtable(column_ndx, to_size_t(real_ndx));
+}
+
+
+// Setters
+
+
+inline void TableView::set_int(size_t column_ndx, size_t row_ndx, int64_t value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Int);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_int(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_bool(size_t column_ndx, size_t row_ndx, bool value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Bool);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_bool(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_olddatetime(size_t column_ndx, size_t row_ndx, OldDateTime value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_OldDateTime);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_olddatetime(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_timestamp(size_t column_ndx, size_t row_ndx, Timestamp value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Timestamp);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_timestamp(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_float(size_t column_ndx, size_t row_ndx, float value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Float);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_float(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_double(size_t column_ndx, size_t row_ndx, double value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Double);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_double(column_ndx, to_size_t(real_ndx), value);
+}
+
+template <class E>
+inline void TableView::set_enum(size_t column_ndx, size_t row_ndx, E value)
+{
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_int(column_ndx, real_ndx, value);
+}
+
+inline void TableView::set_string(size_t column_ndx, size_t row_ndx, StringData value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_String);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_string(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_binary(size_t column_ndx, size_t row_ndx, BinaryData value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Binary);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_binary(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_mixed(size_t column_ndx, size_t row_ndx, Mixed value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Mixed);
+
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_mixed(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_subtable(size_t column_ndx, size_t row_ndx, const Table* value)
+{
+    REALM_ASSERT_INDEX_AND_TYPE_TABLE_OR_MIXED(column_ndx, row_ndx);
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_subtable(column_ndx, to_size_t(real_ndx), value);
+}
+
+inline void TableView::set_link(size_t column_ndx, size_t row_ndx, size_t target_row_ndx)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Link);
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->set_link(column_ndx, to_size_t(real_ndx), target_row_ndx);
+}
+
+inline void TableView::nullify_link(size_t column_ndx, size_t row_ndx)
+{
+    REALM_ASSERT_INDEX_AND_TYPE(column_ndx, row_ndx, type_Link);
+    const int64_t real_ndx = m_row_indexes.get(row_ndx);
+    REALM_ASSERT(real_ndx != detached_ref);
+    m_table->nullify_link(column_ndx, to_size_t(real_ndx));
+}
+
+} // namespace realm
+
+#endif // REALM_TABLE_VIEW_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/timestamp.hpp b/node_modules/realm/vendor/realm-ios/include/realm/timestamp.hpp
new file mode 100644
index 0000000..2108245
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/timestamp.hpp
@@ -0,0 +1,187 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_TIMESTAMP_HPP
+#define REALM_TIMESTAMP_HPP
+
+#include <cstdint>
+#include <ostream>
+#include <chrono>
+#include <realm/util/assert.hpp>
+#include <realm/null.hpp>
+
+namespace realm {
+
+class Timestamp {
+public:
+    // Construct from the number of seconds and nanoseconds since the UNIX epoch: 00:00:00 UTC on 1 January 1970
+    //
+    // To split a native nanosecond representation, only division and modulo are necessary:
+    //
+    //     s = native_nano / nanoseconds_per_second
+    //     n = native_nano % nanoseconds_per_second
+    //     Timestamp ts(s, n);
+    //
+    // To convert back into native nanosecond representation, simple multiply and add:
+    //
+    //     native_nano = ts.s * nanoseconds_per_second + ts.n
+    //
+    // Specifically this allows the nanosecond part to become negative (only) for Timestamps before the UNIX epoch.
+    // Usually this will not need special attention, but for reference, valid Timestamps will have one of the
+    // following sign combinations:
+    //
+    //     s | n
+    //     -----
+    //     + | +
+    //     + | 0
+    //     0 | +
+    //     0 | 0
+    //     0 | -
+    //     - | 0
+    //     - | -
+    //
+    // Examples:
+    //     The UNIX epoch is constructed by Timestamp(0, 0)
+    //     Relative times are constructed as follows:
+    //       +1 second is constructed by Timestamp(1, 0)
+    //       +1 nanosecond is constructed by Timestamp(0, 1)
+    //       +1.1 seconds (1100 milliseconds after the epoch) is constructed by Timestamp(1, 100000000)
+    //       -1.1 seconds (1100 milliseconds before the epoch) is constructed by Timestamp(-1, -100000000)
+    //
+    Timestamp(int64_t seconds, int32_t nanoseconds)
+        : m_seconds(seconds)
+        , m_nanoseconds(nanoseconds)
+        , m_is_null(false)
+    {
+        REALM_ASSERT_EX(-nanoseconds_per_second < nanoseconds && nanoseconds < nanoseconds_per_second, nanoseconds);
+        const bool both_non_negative = seconds >= 0 && nanoseconds >= 0;
+        const bool both_non_positive = seconds <= 0 && nanoseconds <= 0;
+        REALM_ASSERT_EX(both_non_negative || both_non_positive, both_non_negative, both_non_positive);
+    }
+    Timestamp(realm::null)
+        : m_is_null(true)
+    {
+    }
+    template <typename C = std::chrono::system_clock, typename D = typename C::duration>
+    Timestamp(std::chrono::time_point<C, D> tp)
+        : m_is_null(false)
+    {
+        int64_t native_nano = std::chrono::duration_cast<std::chrono::nanoseconds>(tp.time_since_epoch()).count();
+        m_seconds = native_nano / nanoseconds_per_second;
+        m_nanoseconds = static_cast<int32_t>(native_nano % nanoseconds_per_second);
+    }
+    Timestamp()
+        : Timestamp(null{})
+    {
+    }
+
+    bool is_null() const
+    {
+        return m_is_null;
+    }
+
+    int64_t get_seconds() const noexcept
+    {
+        REALM_ASSERT(!m_is_null);
+        return m_seconds;
+    }
+
+    int32_t get_nanoseconds() const noexcept
+    {
+        REALM_ASSERT(!m_is_null);
+        return m_nanoseconds;
+    }
+
+    template <typename C = std::chrono::system_clock, typename D = typename C::duration>
+    std::chrono::time_point<C, D> get_time_point()
+    {
+        REALM_ASSERT(!m_is_null);
+
+        int64_t native_nano = m_seconds * nanoseconds_per_second + m_nanoseconds;
+        auto duration = std::chrono::duration_cast<D>(std::chrono::duration<int64_t, std::nano>{native_nano});
+
+        return std::chrono::time_point<C, D>(duration);
+    }
+
+    // Note that only == and != operators work if one of the Timestamps are null! Else use realm::Greater,
+    // realm::Less, etc, instead. This is in order to collect all treatment of null behaviour in a single place for all
+    // types (query_conditions.hpp) to ensure that all types sort and compare null vs. non-null in the same manner,
+    // especially for int/float where we cannot override operators. This design is open for discussion, though,
+    // because it has usability drawbacks
+    bool operator==(const Timestamp& rhs) const
+    {
+        if (is_null() && rhs.is_null())
+            return true;
+
+        if (is_null() != rhs.is_null())
+            return false;
+
+        return m_seconds == rhs.m_seconds && m_nanoseconds == rhs.m_nanoseconds;
+    }
+    bool operator!=(const Timestamp& rhs) const
+    {
+        return !(*this == rhs);
+    }
+    bool operator>(const Timestamp& rhs) const
+    {
+        REALM_ASSERT(!is_null());
+        REALM_ASSERT(!rhs.is_null());
+        return (m_seconds > rhs.m_seconds) || (m_seconds == rhs.m_seconds && m_nanoseconds > rhs.m_nanoseconds);
+    }
+    bool operator<(const Timestamp& rhs) const
+    {
+        REALM_ASSERT(!is_null());
+        REALM_ASSERT(!rhs.is_null());
+        return (m_seconds < rhs.m_seconds) || (m_seconds == rhs.m_seconds && m_nanoseconds < rhs.m_nanoseconds);
+    }
+    bool operator<=(const Timestamp& rhs) const
+    {
+        REALM_ASSERT(!is_null());
+        REALM_ASSERT(!rhs.is_null());
+        return *this < rhs || *this == rhs;
+    }
+    bool operator>=(const Timestamp& rhs) const
+    {
+        REALM_ASSERT(!is_null());
+        REALM_ASSERT(!rhs.is_null());
+        return *this > rhs || *this == rhs;
+    }
+    Timestamp& operator=(const Timestamp& rhs) = default;
+
+    template <class Ch, class Tr>
+    friend std::basic_ostream<Ch, Tr>& operator<<(std::basic_ostream<Ch, Tr>& out, const Timestamp&);
+    static constexpr int32_t nanoseconds_per_second = 1000000000;
+
+private:
+    int64_t m_seconds;
+    int32_t m_nanoseconds;
+    bool m_is_null;
+};
+
+// LCOV_EXCL_START
+template <class C, class T>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, const Timestamp& d)
+{
+    out << "Timestamp(" << d.m_seconds << ", " << d.m_nanoseconds << ")";
+    return out;
+}
+// LCOV_EXCL_STOP
+
+} // namespace realm
+
+#endif // REALM_TIMESTAMP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/unicode.hpp b/node_modules/realm/vendor/realm-ios/include/realm/unicode.hpp
new file mode 100644
index 0000000..d8b3d33
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/unicode.hpp
@@ -0,0 +1,163 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UNICODE_HPP
+#define REALM_UNICODE_HPP
+
+#include <locale>
+#include <cstdint>
+#include <string>
+
+#include <realm/string_data.hpp>
+#include <realm/util/features.h>
+#include <realm/utilities.hpp>
+
+
+namespace realm {
+
+enum string_compare_method_t {
+    STRING_COMPARE_CORE,
+    STRING_COMPARE_CPP11,
+    STRING_COMPARE_CALLBACK,
+    STRING_COMPARE_CORE_SIMILAR
+};
+
+extern StringCompareCallback string_compare_callback;
+extern string_compare_method_t string_compare_method;
+
+// Description for set_string_compare_method():
+//
+// Short summary: iOS language binding: call
+//     set_string_compare_method() for fast but slightly inaccurate sort in some countries, or
+//     set_string_compare_method(2, callbackptr) for slow but precise sort (see callbackptr below)
+//
+// Different countries ('locales') have different sorting order for strings and letters. Because there unfortunatly
+// doesn't exist any unified standardized way to compare strings in C++ on multiple platforms, we need this method.
+//
+// It determins how sorting a TableView by a String column must take place. The 'method' argument can be:
+//
+// 0: Fast core-only compare (no OS/framework calls). LIMITATIONS: Works only upto 'Latin Extended 2' (unicodes
+// 0...591). Also, sorting order is according to 'en_US' so it may be slightly inaccurate for some countries.
+// 'callback' argument is ignored.
+//
+// Return value: Always 'true'
+//
+// 1: Native C++11 method if core is compiled as C++11. Gives precise sorting according
+// to user's current locale. LIMITATIONS: Currently works only on Windows and on Linux with clang. Does NOT work on
+// iOS (due to only 'C' locale being available in CoreFoundation, which puts 'Z' before 'a'). Unknown if works on
+// Windows Phone / Android. Furthermore it does NOT work on Linux with gcc 4.7 or 4.8 (lack of c++11 feature that
+// can convert utf8->wstring without calls to setlocale()).
+//
+// Return value: 'true' if supported, otherwise 'false' (if so, then previous setting, if any, is preserved).
+//
+// 2: Callback method. Language binding / C++ user must provide a utf-8 callback method of prototype:
+// bool callback(const char* string1, const char* string2) where 'callback' must return bool(string1 < string2).
+//
+// Return value: Always 'true'
+//
+// Default is method = 0 if the function is never called
+//
+// NOT THREAD SAFE! Call once during initialization or make sure it's not called simultaneously with different
+// arguments. The setting is remembered per-process; it does NOT need to be called prior to each sort
+bool set_string_compare_method(string_compare_method_t method, StringCompareCallback callback);
+
+
+// Return size in bytes of utf8 character. No error checking
+size_t sequence_length(char lead);
+
+// Limitations for case insensitive string search
+// Case insensitive search (equal, begins_with, ends_with, like and contains)
+// only works for unicodes 0...0x7f which is the same as the 0...127
+// ASCII character set (letters a-z and A-Z).
+
+// In does *not* work for the 0...255 ANSI character set that contains
+// characters from many European countries like Germany, France, Denmark,
+// etc.
+
+// It also does not work for characters from non-western countries like
+// Japan, Russia, Arabia, etc.
+
+// If there exists characters outside the ASCII range either in the text
+// to be searched for, or in the Realm string column which is searched
+// in, then the compare yields a random result such that the row may or
+// may not be included in the result set.
+
+// Return bool(string1 < string2)
+bool utf8_compare(StringData string1, StringData string2);
+
+// Return unicode value of character.
+uint32_t utf8value(const char* character);
+
+inline bool equal_sequence(const char*& begin, const char* end, const char* begin2);
+
+// FIXME: The current approach to case insensitive comparison requires
+// that case mappings can be done in a way that does not change he
+// number of bytes used to encode the individual Unicode
+// character. This is not generally the case, so, as far as I can see,
+// this approach has no future.
+//
+// FIXME: The current approach to case insensitive comparison relies
+// on checking each "haystack" character against the corresponding
+// character in both a lower cased and an upper cased version of the
+// "needle". While this leads to efficient comparison, it ignores the
+// fact that "case folding" is the only correct approach to case
+// insensitive comparison in a locale agnostic Unicode
+// environment.
+//
+// See
+//   http://www.w3.org/International/wiki/Case_folding
+//   http://userguide.icu-project.org/transforms/casemappings#TOC-Case-Folding.
+//
+// The ideal API would probably be something like this:
+//
+//   case_fold:        utf_8 -> case_folded
+//   equal_case_fold:  (needle_case_folded, single_haystack_entry_utf_8) -> found
+//   search_case_fold: (needle_case_folded, huge_haystack_string_utf_8) -> found_at_position
+//
+// The case folded form would probably be using UTF-32 or UTF-16.
+
+
+/// If successful, returns a string of the same size as \a source.
+/// Returns none if invalid UTF-8 encoding was encountered.
+util::Optional<std::string> case_map(StringData source, bool upper);
+
+enum IgnoreErrorsTag { IgnoreErrors };
+std::string case_map(StringData source, bool upper, IgnoreErrorsTag);
+
+/// Assumes that the sizes of \a needle_upper and \a needle_lower are
+/// identical to the size of \a haystack. Returns false if the needle
+/// is different from the haystack.
+bool equal_case_fold(StringData haystack, const char* needle_upper, const char* needle_lower);
+
+/// Assumes that the sizes of \a needle_upper and \a needle_lower are
+/// both equal to \a needle_size. Returns haystack.size() if the
+/// needle was not found.
+size_t search_case_fold(StringData haystack, const char* needle_upper, const char* needle_lower, size_t needle_size);
+    
+/// Assumes that the sizes of \a needle_upper and \a needle_lower are
+/// both equal to \a needle_size. Returns false if the
+/// needle was not found.
+bool contains_ins(StringData haystack, const char* needle_upper, const char* needle_lower, size_t needle_size, const std::array<uint8_t, 256> &charmap);
+
+/// Case insensitive wildcard matching ('?' for single char, '*' for zero or more chars)
+bool string_like_ins(StringData text, StringData pattern) noexcept;
+bool string_like_ins(StringData text, StringData upper, StringData lower) noexcept;
+
+} // namespace realm
+
+#endif // REALM_UNICODE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/aes_cryptor.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/aes_cryptor.hpp
new file mode 100644
index 0000000..23720b1
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/aes_cryptor.hpp
@@ -0,0 +1,113 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#include <cstddef>
+#include <memory>
+#include <realm/util/features.h>
+#include <cstdint>
+#include <vector>
+#include <realm/util/file.hpp>
+
+#if REALM_ENABLE_ENCRYPTION
+
+#if REALM_PLATFORM_APPLE
+#include <CommonCrypto/CommonCrypto.h>
+#elif defined(_WIN32)
+#include <windows.h>
+#include <stdio.h>
+#include <bcrypt.h>
+#pragma comment(lib, "bcrypt.lib")
+#else
+#include <openssl/sha.h>
+#include <openssl/evp.h>
+#endif
+
+namespace realm {
+namespace util {
+
+struct iv_table;
+class EncryptedFileMapping;
+
+class AESCryptor {
+public:
+    AESCryptor(const uint8_t* key);
+    ~AESCryptor() noexcept;
+
+    void set_file_size(off_t new_size);
+
+    bool read(FileDesc fd, off_t pos, char* dst, size_t size);
+    void write(FileDesc fd, off_t pos, const char* src, size_t size) noexcept;
+
+private:
+    enum EncryptionMode {
+#if REALM_PLATFORM_APPLE
+        mode_Encrypt = kCCEncrypt,
+        mode_Decrypt = kCCDecrypt
+#elif defined(_WIN32)
+        mode_Encrypt = 0,
+        mode_Decrypt = 1
+#else
+        mode_Encrypt = 1,
+        mode_Decrypt = 0
+#endif
+    };
+
+#if REALM_PLATFORM_APPLE
+    CCCryptorRef m_encr;
+    CCCryptorRef m_decr;
+#elif defined(_WIN32)
+    BCRYPT_KEY_HANDLE m_aes_key_handle;
+#else
+    uint8_t m_aesKey[32];
+    EVP_CIPHER_CTX* m_ctx;
+#endif
+
+    uint8_t m_hmacKey[32];
+    std::vector<iv_table> m_iv_buffer;
+    std::unique_ptr<char[]> m_rw_buffer;
+    std::unique_ptr<char[]> m_dst_buffer;
+
+    void calc_hmac(const void* src, size_t len, uint8_t* dst, const uint8_t* key) const;
+    bool check_hmac(const void* data, size_t len, const uint8_t* hmac) const;
+    void crypt(EncryptionMode mode, off_t pos, char* dst, const char* src, const char* stored_iv) noexcept;
+    iv_table& get_iv_table(FileDesc fd, off_t data_pos) noexcept;
+    void handle_error();
+};
+
+struct ReaderInfo {
+    const void* reader_ID;
+    uint64_t version;
+};
+
+struct SharedFileInfo {
+    FileDesc fd;
+    AESCryptor cryptor;
+    std::vector<EncryptedFileMapping*> mappings;
+    uint64_t last_scanned_version = 0;
+    uint64_t current_version = 0;
+    size_t num_decrypted_pages = 0;
+    size_t num_reclaimed_pages = 0;
+    size_t progress_index = 0;
+    std::vector<ReaderInfo> readers;
+
+    SharedFileInfo(const uint8_t* key, FileDesc file_descriptor);
+};
+}
+}
+
+#endif // REALM_ENABLE_ENCRYPTION
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/allocation_metrics.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/allocation_metrics.hpp
new file mode 100644
index 0000000..10176e7
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/allocation_metrics.hpp
@@ -0,0 +1,326 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_ALLOCATION_METRICS_HPP
+#define REALM_UTIL_ALLOCATION_METRICS_HPP
+
+#include <atomic>
+#include <vector>
+
+#include <realm/util/allocator.hpp>
+
+namespace realm {
+namespace util {
+
+/// Designate a name to be used in heap allocation metrics.
+///
+/// An instance can be used with `AllocationMetricsContext::get_metric()` to
+/// obtain an instance of `MeteredAllocator` that counts
+/// allocations/deallocations towards this name, within that context.
+///
+/// Instances of `AllocationMetricName` should be statically allocated. When an
+/// instance has been initialized, it must not be destroyed until the program
+/// terminates. This is to ensure that iterating over existing names is
+/// thread-safe and lock-free.
+///
+/// Similarly, when an instance of `AllocationMetricsContext` has been
+/// allocated, no further instances of AllocationMetricName must be
+/// instantiated.
+struct AllocationMetricName {
+    explicit AllocationMetricName(const char* name) noexcept;
+
+    /// Get the string name.
+    ///
+    /// This method is thread-safe.
+    const char* name() const noexcept;
+
+    /// Get the index of this metric. The index corresponds to an allocator
+    /// inside the current instance of AllocatorMetricTenant.
+    ///
+    /// This method is thread-safe.
+    size_t index() const noexcept;
+
+    /// Get the next name. The names are returned in no particular order.
+    ///
+    /// This method is thread-safe.
+    const AllocationMetricName* next() const noexcept;
+
+    /// Get the first name in the internal list of names, for the purpose
+    /// of iterating over all names in the program.
+    ///
+    /// This method is thread-safe.
+    static const AllocationMetricName* get_top() noexcept;
+    static const AllocationMetricName* find(const char* name) noexcept;
+private:
+    const char* m_name;
+    size_t m_index; // Index into `AllocationMetricsContext::m_metrics`.
+
+    // This is used to iterate over all existing components. Instances of
+    // AllocationMetricName are expected to be statically allocated.
+    const AllocationMetricName* m_next = nullptr;
+};
+
+
+/// A heap memory allocator that keeps track of how much was
+/// allocated/deallocated throughout its lifetime.
+///
+/// Memory is allocated with `DefaultAllocator`.
+///
+/// All methods on instances of this class are thread-safe.
+class MeteredAllocator final : public AllocatorBase {
+public:
+    MeteredAllocator() noexcept;
+
+    static MeteredAllocator& unknown() noexcept;
+
+    /// Return the currently allocated number of bytes.
+    ///
+    /// This method is thread-safe, but may temporarily return slightly
+    /// inaccurate results if allocations/deallocations are happening while it
+    /// is being called.
+    std::size_t get_currently_allocated_bytes() const noexcept;
+
+    /// Return the total number of bytes that have been allocated (including
+    /// allocations that have since been freed).
+    ///
+    /// This method is thread-safe.
+    std::size_t get_total_allocated_bytes() const noexcept;
+
+    /// Return the total number of bytes that have been freed.
+    ///
+    /// This method is thread-safe.
+    std::size_t get_total_deallocated_bytes() const noexcept;
+
+    // AllocatorBase interface:
+
+    /// Return a reference to an MeteredAllocator that belongs to the current
+    /// AllocationMetricsContext (if any) and the current AllocationMetricNameScope
+    /// (if any).
+    ///
+    /// The returned reference is valid for the duration of the lifetime of the
+    /// instance of AllocationMetricsContext that is "current" at the time of
+    /// calling this function, and namely it is valid beyond the lifetime of
+    /// the current AllocationMetricNameScope.
+    ///
+    /// If there is no current AllocationMetricsContext, the global "unknown"
+    /// tenant will be used.
+    ///
+    /// If no metric name is currently in scope (through the use of
+    /// AllocationMetricNameScope), allocations and deallocations will be counted
+    /// towards the default "unknown" metric.
+    ///
+    /// This method is thread-safe.
+    static MeteredAllocator& get_default() noexcept;
+
+    /// Allocate memory, accounting for the allocation in metrics.
+    ///
+    /// This method is thread-safe.
+    void* allocate(size_t size, size_t align) override final;
+
+    /// Free memory, accounting for the deallocation in metrics.
+    ///
+    /// This method is thread-safe.
+    void free(void* ptr, size_t size) noexcept override final;
+
+    /// Notify metrics that an allocation happened.
+    ///
+    /// This method is thread-safe.
+    void did_allocate_bytes(std::size_t) noexcept;
+
+    /// Notify metrics that a deallocation happened.
+    ///
+    /// This method is thread-safe.
+    void did_free_bytes(std::size_t) noexcept;
+
+private:
+    std::atomic<std::size_t> m_allocated_bytes;
+    // These members are spaced by 64 bytes to prevent false sharing
+    // (inter-processor CPU locks when multiple processes are modifying them
+    // concurrently).
+    char dummy[56];
+    std::atomic<std::size_t> m_deallocated_bytes;
+    char dummy2[56]; // Prevent false sharing with the next element.
+};
+
+/// `AllocationMetricsContext` represents a runtime scope for metrics, such as
+/// for instance a server running in a multi-tenant scenario, where each tenant
+/// would have one context associated with it.
+///
+/// `AllocationMetricsContext` is not available on mobile, due to lack of
+/// thread-local storage support on iOS.
+struct AllocationMetricsContext {
+public:
+    AllocationMetricsContext();
+    ~AllocationMetricsContext();
+
+#if !REALM_MOBILE
+    /// Get the thread-specific AllocationMetricsContext. If none has been set, a
+    /// reference to a  globally-allocated "unknown" tenant will be returned.
+    static AllocationMetricsContext& get_current() noexcept;
+#endif
+
+    /// Get the statically-allocated "unknown" tenant.
+    static AllocationMetricsContext& get_unknown();
+
+    MeteredAllocator& get_metric(const AllocationMetricName& name) noexcept;
+private:
+    std::unique_ptr<MeteredAllocator[]> m_metrics;
+
+    // In debug builds, this is incremented/decremented by
+    // `AllocationMetricsContextScope`, and checked in the destructor, to avoid
+    // dangling references.
+    std::atomic<std::size_t> m_refcount;
+    friend class AllocationMetricsContextScope;
+};
+
+/// Open a scope where metered memory allocations are counted towards the given
+/// name.
+///
+/// Creating an instance of this class causes calls to
+/// `MeteredAllocator::get_default()` from the current thread to return a
+/// reference to an allocator that accounts for allocations/deallocations
+/// under the named metric specified as the constructor argument.
+///
+/// When such an instance is destroyed, the previous scope will come back
+/// in effect (if one exists; if none exists, the "unknown" metric will be
+/// used).
+///
+/// It is usually an error to create instances of this class with non-scope
+/// lifetime, for example on the heap. For that reason, `operator new` is
+/// disabled as a precaution.
+///
+/// If no `AllocationMetricsContext` is current (by instantiation of
+/// `AllocationMetricsContextScope`), metrics recorded in the scope introduced
+/// by this instance will count towards the "unknown" context, accessible by
+/// calling `AllocationMetricsContext::get_unknown()`.
+class AllocationMetricNameScope final {
+public:
+    /// Establish a scope under which all allocations will be tracked as
+    /// belonging to \a name.
+    explicit AllocationMetricNameScope(const AllocationMetricName& name) noexcept;
+    ~AllocationMetricNameScope();
+    AllocationMetricNameScope(AllocationMetricNameScope&&) = delete;
+    AllocationMetricNameScope& operator=(AllocationMetricNameScope&&) = delete;
+
+    void* operator new(std::size_t) = delete;
+private:
+    const AllocationMetricName& m_name;
+    const AllocationMetricName* m_previous = nullptr;
+};
+
+/// Open a scope using the given context for allocation metrics.
+///
+/// Creating an instance of this class causes calls to
+/// `AllocationMetricsContext::get_current()` to return the provided
+/// instance. This function is called when by `MeteredAllocator::get_default()`
+/// to return an instance that belongs to the given context.
+///
+/// When the instance is destroyed, the previous context will become active, or
+/// the "unknown" context if there was none.
+///
+/// It is usually an error to create instances of this class with non-scope
+/// lifetime, for example on the heap. For that reason, `operator new` is
+/// disabled as a precaution.
+class AllocationMetricsContextScope final {
+public:
+    explicit AllocationMetricsContextScope(AllocationMetricsContext& context) noexcept;
+    ~AllocationMetricsContextScope();
+    AllocationMetricsContextScope(AllocationMetricsContextScope&&) = delete;
+    AllocationMetricsContextScope& operator=(AllocationMetricsContextScope&&) = delete;
+
+    void* operator new(std::size_t) = delete;
+
+private:
+    AllocationMetricsContext& m_context;
+    AllocationMetricsContext& m_previous;
+};
+
+
+/// Convenience STL-compatible allocator that counts allocations as part of the
+/// current AllocationMetricNameScope.
+template <class T>
+using MeteredSTLAllocator = STLAllocator<T, MeteredAllocator>;
+
+
+// Implementation:
+
+inline const char* AllocationMetricName::name() const noexcept
+{
+    return m_name;
+}
+
+inline size_t AllocationMetricName::index() const noexcept
+{
+    return m_index;
+}
+
+inline const AllocationMetricName* AllocationMetricName::next() const noexcept
+{
+    return m_next;
+}
+
+inline std::size_t MeteredAllocator::get_currently_allocated_bytes() const noexcept
+{
+    return get_total_allocated_bytes() - get_total_deallocated_bytes();
+}
+
+inline std::size_t MeteredAllocator::get_total_allocated_bytes() const noexcept
+{
+    return m_allocated_bytes.load(std::memory_order_relaxed);
+}
+
+inline std::size_t MeteredAllocator::get_total_deallocated_bytes() const noexcept
+{
+    return m_deallocated_bytes.load(std::memory_order_relaxed);
+}
+
+inline void* MeteredAllocator::allocate(size_t size, size_t align)
+{
+    void* ptr = DefaultAllocator::get_default().allocate(size, align);
+    did_allocate_bytes(size);
+    return ptr;
+}
+
+inline void MeteredAllocator::free(void* ptr, size_t size) noexcept
+{
+    DefaultAllocator::get_default().free(ptr, size);
+    did_free_bytes(size);
+}
+
+inline void MeteredAllocator::did_allocate_bytes(std::size_t size) noexcept
+{
+#if !REALM_MOBILE
+    m_allocated_bytes.fetch_add(size, std::memory_order_relaxed);
+#else
+    static_cast<void>(size);
+#endif
+}
+
+inline void MeteredAllocator::did_free_bytes(std::size_t size) noexcept
+{
+#if !REALM_MOBILE
+    m_deallocated_bytes.fetch_add(size, std::memory_order_relaxed);
+#else
+    static_cast<void>(size);
+#endif
+}
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_ALLOCATION_METRICS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/allocator.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/allocator.hpp
new file mode 100644
index 0000000..c0a0a83
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/allocator.hpp
@@ -0,0 +1,398 @@
+/*************************************************************************
+ *
+ * Copyright 2018 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_ALLOCATOR_HPP
+#define REALM_UTIL_ALLOCATOR_HPP
+
+#include <cstdlib>
+#include <memory>
+#include <realm/util/backtrace.hpp>
+
+namespace realm {
+namespace util {
+
+/// Dynamic heap allocation interface.
+///
+/// Implementors may optionally implement a static method `get_default()`, which
+/// should return a reference to an allocator instance. This allows
+/// `STLAllocator` to be default-constructed.
+///
+/// NOTE: This base class is not related to the `realm::Allocator` interface,
+/// which is used in the context of allocating memory inside a Realm file.
+struct AllocatorBase {
+    static constexpr std::size_t max_alignment = 16; // FIXME: This is arch-dependent
+
+    /// Allocate \a size bytes at aligned at \a align.
+    ///
+    /// May throw `std::bad_alloc` if allocation fails. May **NOT** return
+    /// an invalid pointer (such as `nullptr`).
+    virtual void* allocate(std::size_t size, std::size_t align) = 0;
+
+    /// Free the previously allocated block of memory. \a size is not required
+    /// to be accurate, and is only provided for statistics and debugging
+    /// purposes.
+    ///
+    /// \a ptr may be `nullptr`, in which case this shall be a noop.
+    virtual void free(void* ptr, size_t size) noexcept = 0;
+};
+
+/// Implementation of AllocatorBase that uses `operator new`/`operator delete`.
+///
+/// Using this allocator with standard containers is zero-overhead: No
+/// additional storage is required at any level.
+struct DefaultAllocator final : AllocatorBase {
+    /// Return a reference to a global singleton.
+    ///
+    /// This method is thread-safe.
+    static DefaultAllocator& get_default() noexcept;
+
+    /// Allocate memory (using `operator new`).
+    ///
+    /// \a align must not exceed `max_alignment` before C++17.
+    ///
+    /// This method is thread-safe.
+    void* allocate(std::size_t size, std::size_t align) final;
+
+    /// Free memory (using `operator delete`).
+    ///
+    /// If \a ptr equals `nullptr`, this is a no-op.
+    ///
+    /// This method is thread-safe.
+    void free(void* ptr, std::size_t size) noexcept final;
+
+private:
+    static DefaultAllocator g_instance;
+    DefaultAllocator()
+    {
+    }
+};
+
+template <class T, class Allocator = AllocatorBase>
+struct STLDeleter;
+
+namespace detail {
+/// Base class for things that hold a reference to an allocator. The default
+/// implementation carries a pointer to the allocator instance. Singleton
+/// allocators (such as `DefaultAllocator`) may specialize this class such that
+/// no extra storage is needed.
+template <class Allocator>
+struct GetAllocator {
+    // Note: Some allocators may not define get_default(). This is OK, and
+    // this constructor will not be instantiated (SFINAE).
+    GetAllocator() noexcept
+        : m_allocator(&Allocator::get_default())
+    {
+    }
+
+    template <class A>
+    GetAllocator(A& allocator) noexcept
+        : m_allocator(&allocator)
+    {
+    }
+
+    template <class A>
+    GetAllocator& operator=(const GetAllocator<A>& other) noexcept
+    {
+        m_allocator = &other.get_allocator();
+        return *this;
+    }
+
+    Allocator& get_allocator() const noexcept
+    {
+        return *m_allocator;
+    }
+
+    bool operator==(const GetAllocator& other) const noexcept
+    {
+        return m_allocator == other.m_allocator;
+    }
+
+    bool operator!=(const GetAllocator& other) const noexcept
+    {
+        return m_allocator != other.m_allocator;
+    }
+
+    Allocator* m_allocator;
+};
+
+/// Specialization for `DefaultAllocator` that has zero size, i.e. no extra
+/// storage requirements compared with `std::allocator<T>`.
+template <>
+struct GetAllocator<DefaultAllocator> {
+    GetAllocator() noexcept
+    {
+    }
+
+    GetAllocator(DefaultAllocator&) noexcept
+    {
+    }
+
+    DefaultAllocator& get_allocator() const noexcept
+    {
+        return DefaultAllocator::get_default();
+    }
+
+    bool operator==(const GetAllocator&) const noexcept
+    {
+        return true;
+    }
+
+    bool operator!=(const GetAllocator&) const noexcept
+    {
+        return false;
+    }
+};
+} // namespace detail
+
+/// STL-compatible static dispatch bridge to a dynamic implementation of
+/// `AllocatorBase`. Wraps a pointer to an object that adheres to the
+/// `AllocatorBase` interface. It is optional whether the `Allocator` class
+/// template argument actually derives from `AllocatorBase`.
+///
+/// The intention is that users of this class can set `Allocator` to the
+/// nearest-known base class of the expected allocator implementations, such
+/// that appropriate devirtualization can take place.
+template <class T, class Allocator = AllocatorBase>
+struct STLAllocator : detail::GetAllocator<Allocator> {
+    using value_type = T;
+    using Deleter = STLDeleter<T, Allocator>;
+
+    // These typedefs are optional, but GCC 4.9 requires them when using the
+    // allocator together with std::map, std::basic_string, etc.
+    using size_type = std::size_t;
+    using difference_type = std::ptrdiff_t;
+    using reference = T&;
+    using const_reference = const T&;
+    using pointer = T*;
+    using const_pointer = const T*;
+
+    /// The default constructor is only availble when the static method
+    /// `Allocator::get_default()` exists.
+    STLAllocator() noexcept
+    {
+    }
+
+    constexpr STLAllocator(Allocator& base) noexcept
+        : detail::GetAllocator<Allocator>(base)
+    {
+    }
+    template <class U, class A>
+    constexpr STLAllocator(const STLAllocator<U, A>& other) noexcept
+        : detail::GetAllocator<Allocator>(other.get_allocator())
+    {
+    }
+
+    STLAllocator& operator=(const STLAllocator& other) noexcept = default;
+
+    T* allocate(std::size_t n)
+    {
+        static_assert(alignof(T) <= Allocator::max_alignment, "Over-aligned allocation");
+        void* ptr = this->get_allocator().allocate(sizeof(T) * n, alignof(T));
+        return static_cast<T*>(ptr);
+    }
+
+    void deallocate(T* ptr, std::size_t n) noexcept
+    {
+        this->get_allocator().free(ptr, sizeof(T) * n);
+    }
+
+    operator Allocator&() const
+    {
+        return this->get_allocator();
+    }
+
+    template <class U>
+    struct rebind {
+        using other = STLAllocator<U, Allocator>;
+    };
+
+    // construct() and destroy() are optional, but are required by some
+    // containers under GCC 4.9 (verified for at least std::list).
+    template <class... Args>
+    void construct(T* ptr, Args&&... args)
+    {
+        ::new (ptr) T(std::forward<Args>(args)...);
+    }
+
+    template <class U>
+    void destroy(U* ptr)
+    {
+        ptr->~U();
+    }
+
+private:
+    template <class U, class A>
+    friend struct STLAllocator;
+};
+
+template <class T, class Allocator>
+struct STLDeleter : detail::GetAllocator<Allocator> {
+    // The reason for this member is to accurately pass `size` to `free()` when
+    // deallocating. `sizeof(T)` may not be good enough, because the pointer may
+    // have been cast to a relative type of different size.
+    size_t m_size;
+
+    explicit STLDeleter(Allocator& allocator) noexcept
+        : STLDeleter(0, allocator)
+    {
+    }
+    explicit STLDeleter(size_t size, Allocator& allocator) noexcept
+        : detail::GetAllocator<Allocator>(allocator)
+        , m_size(size)
+    {
+    }
+
+    template <class U, class A>
+    STLDeleter(const STLDeleter<U, A>& other) noexcept
+        : detail::GetAllocator<Allocator>(other.get_allocator())
+        , m_size(other.m_size)
+    {
+    }
+
+    void operator()(T* ptr)
+    {
+        ptr->~T();
+        this->get_allocator().free(ptr, m_size);
+    }
+};
+
+template <class T, class Allocator>
+struct STLDeleter<T[], Allocator> : detail::GetAllocator<Allocator> {
+    // Note: Array-allocated pointers cannot be upcast to base classes, because
+    // of array slicing.
+    size_t m_count;
+    explicit STLDeleter(Allocator& allocator) noexcept
+        : STLDeleter(0, allocator)
+    {
+    }
+    explicit STLDeleter(size_t count, Allocator& allocator) noexcept
+        : detail::GetAllocator<Allocator>(allocator)
+        , m_count(count)
+    {
+    }
+
+    template <class A>
+    STLDeleter(const STLDeleter<T[], A>& other) noexcept
+        : detail::GetAllocator<Allocator>(other.get_allocator())
+        , m_count(other.m_count)
+    {
+    }
+
+    template <class A>
+    STLDeleter& operator=(const STLDeleter<T[], A>& other) noexcept
+    {
+        static_cast<detail::GetAllocator<Allocator>&>(*this) =
+            static_cast<const detail::GetAllocator<A>&>(other);
+        m_count = other.m_count;
+        return *this;
+    }
+
+    void operator()(T* ptr)
+    {
+        for (size_t i = 0; i < m_count; ++i) {
+            ptr[i].~T();
+        }
+        this->get_allocator().free(ptr, m_count * sizeof(T));
+    }
+};
+
+/// make_unique with custom allocator (non-array version)
+template <class T, class Allocator = DefaultAllocator, class... Args>
+auto make_unique(Allocator& allocator, Args&&... args)
+    -> std::enable_if_t<!std::is_array<T>::value, std::unique_ptr<T, STLDeleter<T, Allocator>>>
+{
+    void* memory = allocator.allocate(sizeof(T), alignof(T)); // Throws
+    T* ptr;
+    try {
+        ptr = new (memory) T(std::forward<Args>(args)...); // Throws
+    }
+    catch (...) {
+        allocator.free(memory, sizeof(T));
+        throw;
+    }
+    std::unique_ptr<T, STLDeleter<T, Allocator>> result{ptr, STLDeleter<T, Allocator>{sizeof(T), allocator}};
+    return result;
+}
+
+/// make_unique with custom allocator supporting `get_default()`
+/// (non-array-version)
+template <class T, class Allocator = DefaultAllocator, class... Args>
+auto make_unique(Args&&... args)
+    -> std::enable_if_t<!std::is_array<T>::value, std::unique_ptr<T, STLDeleter<T, Allocator>>>
+{
+    return make_unique<T, Allocator>(Allocator::get_default(), std::forward<Args>(args)...);
+}
+
+/// make_unique with custom allocator (array version)
+template <class Tv, class Allocator>
+auto make_unique(Allocator& allocator, size_t count)
+    -> std::enable_if_t<std::is_array<Tv>::value, std::unique_ptr<Tv, STLDeleter<Tv, Allocator>>>
+{
+    using T = std::remove_extent_t<Tv>;
+    void* memory = allocator.allocate(sizeof(T) * count, alignof(T)); // Throws
+    T* ptr = reinterpret_cast<T*>(memory);
+    size_t constructed = 0;
+    try {
+        // FIXME: Can't use array placement new, because MSVC has a buggy
+        // implementation of it. :-(
+        while (constructed < count) {
+            new (&ptr[constructed]) T; // Throws
+            ++constructed;
+        }
+    }
+    catch (...) {
+        for (size_t i = 0; i < constructed; ++i) {
+            ptr[i].~T();
+        }
+        allocator.free(memory, sizeof(T) * count);
+        throw;
+    }
+    std::unique_ptr<T[], STLDeleter<T[], Allocator>> result{ptr, STLDeleter<T[], Allocator>{count, allocator}};
+    return result;
+}
+
+/// make_unique with custom allocator supporting `get_default()` (array version)
+template <class Tv, class Allocator = DefaultAllocator>
+auto make_unique(size_t count)
+    -> std::enable_if_t<std::is_array<Tv>::value, std::unique_ptr<Tv, STLDeleter<Tv, Allocator>>>
+{
+    return make_unique<Tv, Allocator>(Allocator::get_default(), count);
+}
+
+
+// Implementation:
+
+inline DefaultAllocator& DefaultAllocator::get_default() noexcept
+{
+    return g_instance;
+}
+
+inline void* DefaultAllocator::allocate(std::size_t size, std::size_t)
+{
+    return new char[size];
+}
+
+inline void DefaultAllocator::free(void* ptr, std::size_t) noexcept
+{
+    delete[] static_cast<char*>(ptr);
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_ALLOCATOR_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/any.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/any.hpp
new file mode 100644
index 0000000..5ac72b2
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/any.hpp
@@ -0,0 +1,165 @@
+////////////////////////////////////////////////////////////////////////////
+//
+// Copyright 2017 Realm Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+////////////////////////////////////////////////////////////////////////////
+
+#ifndef REALM_UTIL_ANY_HPP
+#define REALM_UTIL_ANY_HPP
+
+#include <memory>
+#include <stdexcept>
+#include <type_traits>
+#include <typeinfo>
+
+#include <realm/util/backtrace.hpp>
+
+namespace realm {
+namespace util {
+
+using bad_cast = ExceptionWithBacktrace<std::bad_cast>;
+
+// A naive implementation of C++17's std::any
+// This does not perform the small-object optimization or make any particular
+// attempt at being performant
+class Any final {
+public:
+    // Constructors
+
+    Any() = default;
+    Any(Any&&) noexcept = default;
+    ~Any() = default;
+    Any& operator=(Any&&) noexcept = default;
+
+    Any(Any const& rhs)
+    : m_value(rhs.m_value ? rhs.m_value->copy() : nullptr)
+    {
+    }
+
+    template<typename T, typename = typename std::enable_if<!std::is_same<typename std::decay<T>::type, Any>::value>::type>
+    Any(T&& value)
+    : m_value(std::make_unique<Value<typename std::decay<T>::type>>(std::forward<T>(value)))
+    {
+    }
+
+    Any& operator=(Any const& rhs)
+    {
+        m_value = rhs.m_value ? rhs.m_value->copy() : nullptr;
+        return *this;
+    }
+
+    template<typename T, typename = typename std::enable_if<!std::is_same<typename std::decay<T>::type, Any>::value>::type>
+    Any& operator=(T&& value)
+    {
+        m_value = std::make_unique<Value<typename std::decay<T>::type>>(std::forward<T>(value));
+        return *this;
+    }
+
+    // Modifiers
+
+    void reset() noexcept { m_value.reset(); }
+    void swap(Any& rhs) noexcept { std::swap(m_value, rhs.m_value); }
+
+    // Observers
+
+    bool has_value() const noexcept { return m_value != nullptr; }
+    std::type_info const& type() const noexcept { return m_value ? m_value->type() : typeid(void); }
+
+private:
+    struct ValueBase {
+        virtual ~ValueBase() noexcept { }
+        virtual std::type_info const& type() const noexcept = 0;
+        virtual std::unique_ptr<ValueBase> copy() const = 0;
+    };
+    template<typename T>
+    struct Value : ValueBase {
+        T value;
+        template<typename U> Value(U&& v) : value(std::forward<U>(v)) { }
+
+        std::type_info const& type() const noexcept override { return typeid(T); }
+        std::unique_ptr<ValueBase> copy() const override
+        {
+            return std::make_unique<Value<T>>(value);
+        }
+    };
+    std::unique_ptr<ValueBase> m_value;
+
+    template<typename T>
+    friend const T* any_cast(const Any* operand) noexcept;
+    template<typename T>
+    friend T* any_cast(Any* operand) noexcept;
+
+    template<typename T>
+    const T* cast() const noexcept
+    {
+        return &static_cast<Value<T>*>(m_value.get())->value;
+    }
+
+    template<typename T>
+    T* cast() noexcept
+    {
+        return &static_cast<Value<T>*>(m_value.get())->value;
+    }
+};
+
+template<typename T>
+T any_cast(Any const& value)
+{
+    auto ptr = any_cast<typename std::add_const<typename std::remove_reference<T>::type>::type>(&value);
+    if (!ptr)
+        throw bad_cast();
+    return *ptr;
+}
+
+template<typename T>
+T any_cast(Any& value)
+{
+    auto ptr = any_cast<typename std::remove_reference<T>::type>(&value);
+    if (!ptr)
+        throw bad_cast();
+    return *ptr;
+}
+
+template<typename T>
+T any_cast(Any&& value)
+{
+    auto ptr = any_cast<typename std::remove_reference<T>::type>(&value);
+    if (!ptr)
+        throw bad_cast();
+    return std::move(*ptr);
+}
+
+template<typename T>
+T* any_cast(Any* value) noexcept
+{
+    return value && value->type() == typeid(T) ? value->cast<T>() : nullptr;
+}
+
+template<typename T>
+const T* any_cast(const Any* value) noexcept
+{
+    return value && value->type() == typeid(T) ? value->cast<T>() : nullptr;
+}
+} // namespace util
+} // namespace realm
+
+namespace std {
+inline void swap(realm::util::Any& lhs, realm::util::Any& rhs) noexcept
+{
+    lhs.swap(rhs);
+}
+} // namespace std
+
+#endif // REALM_UTIL_ANY_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/assert.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/assert.hpp
new file mode 100644
index 0000000..5e75066
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/assert.hpp
@@ -0,0 +1,107 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_ASSERT_HPP
+#define REALM_UTIL_ASSERT_HPP
+
+#include <realm/util/features.h>
+#include <realm/util/terminate.hpp>
+
+#if REALM_ENABLE_ASSERTIONS || defined(REALM_DEBUG)
+#define REALM_ASSERTIONS_ENABLED 1
+#else
+#define REALM_ASSERTIONS_ENABLED 0
+#endif
+
+#define REALM_ASSERT_RELEASE(condition)                                                                              \
+    (REALM_LIKELY(condition) ? static_cast<void>(0)                                                                  \
+                             : realm::util::terminate("Assertion failed: " #condition, __FILE__, __LINE__))
+
+#if REALM_ASSERTIONS_ENABLED
+#define REALM_ASSERT(condition) REALM_ASSERT_RELEASE(condition)
+#else
+#define REALM_ASSERT(condition) static_cast<void>(sizeof bool(condition))
+#endif
+
+#ifdef REALM_DEBUG
+#define REALM_ASSERT_DEBUG(condition) REALM_ASSERT_RELEASE(condition)
+#else
+#define REALM_ASSERT_DEBUG(condition) static_cast<void>(sizeof bool(condition))
+#endif
+
+#define REALM_STRINGIFY(X) #X
+
+#define REALM_ASSERT_RELEASE_EX(condition, ...)                                                                      \
+    (REALM_LIKELY(condition) ? static_cast<void>(0)                                                                  \
+                             : realm::util::terminate_with_info("Assertion failed: " #condition, __LINE__, __FILE__, \
+                                                                REALM_STRINGIFY((__VA_ARGS__)), __VA_ARGS__))
+
+#ifdef REALM_DEBUG
+#define REALM_ASSERT_DEBUG_EX REALM_ASSERT_RELEASE_EX
+#else
+#define REALM_ASSERT_DEBUG_EX(condition, ...) static_cast<void>(sizeof bool(condition))
+#endif
+
+// Becase the assert is used in noexcept methods, it's a bad idea to allocate
+// buffer space for the message so therefore we must pass it to terminate which
+// will 'cerr' it for us without needing any buffer
+#if REALM_ENABLE_ASSERTIONS || defined(REALM_DEBUG)
+
+#define REALM_ASSERT_EX REALM_ASSERT_RELEASE_EX
+
+#define REALM_ASSERT_3(left, cmp, right)                                                                             \
+    (REALM_LIKELY((left)cmp(right)) ? static_cast<void>(0)                                                           \
+                                    : realm::util::terminate("Assertion failed: "                                    \
+                                                             "" #left " " #cmp " " #right,                           \
+                                                             __FILE__, __LINE__, left, right))
+
+#define REALM_ASSERT_7(left1, cmp1, right1, logical, left2, cmp2, right2)                                            \
+    (REALM_LIKELY(((left1)cmp1(right1))logical((left2)cmp2(right2)))                                                 \
+         ? static_cast<void>(0)                                                                                      \
+         : realm::util::terminate("Assertion failed: "                                                               \
+                                  "" #left1 " " #cmp1 " " #right1 " " #logical " "                                   \
+                                  "" #left2 " " #cmp2 " " #right2,                                                   \
+                                  __FILE__, __LINE__, left1, right1, left2, right2))
+
+#define REALM_ASSERT_11(left1, cmp1, right1, logical1, left2, cmp2, right2, logical2, left3, cmp3, right3)           \
+    (REALM_LIKELY(((left1)cmp1(right1))logical1((left2)cmp2(right2)) logical2((left3)cmp3(right3)))                  \
+         ? static_cast<void>(0)                                                                                      \
+         : realm::util::terminate("Assertion failed: "                                                               \
+                                  "" #left1 " " #cmp1 " " #right1 " " #logical1 " "                                  \
+                                  "" #left2 " " #cmp2 " " #right2 " " #logical2 " "                                  \
+                                  "" #left3 " " #cmp3 " " #right3,                                                   \
+                                  __FILE__, __LINE__, left1, right1, left2, right2, left3, right3))
+#else
+#define REALM_ASSERT_EX(condition, ...) static_cast<void>(sizeof bool(condition))
+#define REALM_ASSERT_3(left, cmp, right) static_cast<void>(sizeof bool((left)cmp(right)))
+#define REALM_ASSERT_7(left1, cmp1, right1, logical, left2, cmp2, right2)                                            \
+    static_cast<void>(sizeof bool(((left1)cmp1(right1))logical((left2)cmp2(right2))))
+#define REALM_ASSERT_11(left1, cmp1, right1, logical1, left2, cmp2, right2, logical2, left3, cmp3, right3)           \
+    static_cast<void>(sizeof bool(((left1)cmp1(right1))logical1((left2)cmp2(right2)) logical2((left3)cmp3(right3))))
+#endif
+
+#define REALM_UNREACHABLE() realm::util::terminate("Unreachable code", __FILE__, __LINE__)
+#ifdef REALM_COVER
+#define REALM_COVER_NEVER(x) false
+#define REALM_COVER_ALWAYS(x) true
+#else
+#define REALM_COVER_NEVER(x) (x)
+#define REALM_COVER_ALWAYS(x) (x)
+#endif
+
+#endif // REALM_UTIL_ASSERT_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/backtrace.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/backtrace.hpp
new file mode 100644
index 0000000..8011023
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/backtrace.hpp
@@ -0,0 +1,226 @@
+/*************************************************************************
+ *
+ * Copyright 2018 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_BACKTRACE_HPP
+#define REALM_UTIL_BACKTRACE_HPP
+
+#include <string>
+#include <iosfwd>
+#include <stdexcept>
+
+namespace realm {
+namespace util {
+
+/// Backtrace encapsulates a stack trace, usually as captured by `backtrace()`
+/// and `backtrace_symbols()` (or platform-specific equivalents).
+struct Backtrace {
+    /// Capture a symbolicated stack trace, excluding the call to `capture()`
+    /// itself. If any error occurs while capturing the stack trace or
+    /// translating symbol names, a `Backtrace` object is returned containing a
+    /// single line describing the error.
+    ///
+    /// This function only allocates memory as part of calling
+    /// `backtrace_symbols()` (or the current platform's equivalent).
+    static Backtrace capture() noexcept;
+
+    /// Print the backtrace to the stream. Each line is separated by a newline.
+    /// The format of the output is unspecified.
+    void print(std::ostream&) const;
+
+    /// Construct an empty stack trace.
+    Backtrace() noexcept
+    {
+    }
+
+    /// Move constructor. This operation cannot fail.
+    Backtrace(Backtrace&&) noexcept;
+
+    /// Copy constructor. See the copy assignment operator.
+    Backtrace(const Backtrace&) noexcept;
+
+    ~Backtrace();
+
+    /// Move assignment operator. This operation cannot fail.
+    Backtrace& operator=(Backtrace&&) noexcept;
+
+    /// Copy assignment operator. Copying a `Backtrace` object may result in a
+    /// memory allocation. If such an allocation fails, the backtrace is
+    /// replaced with a single line describing the error.
+    Backtrace& operator=(const Backtrace&) noexcept;
+
+private:
+    Backtrace(void* memory, const char* const* strs, size_t len)
+        : m_memory(memory)
+        , m_strs(strs)
+        , m_len(len)
+    {
+    }
+    Backtrace(void* memory, size_t len)
+        : m_memory(memory)
+        , m_strs(static_cast<char* const*>(memory))
+        , m_len(len)
+    {
+    }
+
+    // m_memory is a pointer to the memory block returned by
+    // `backtrace_symbols()`. It is usually equal to `m_strs`, except in the
+    // case where an error has occurred and `m_strs` points to statically
+    // allocated memory describing the error.
+    //
+    // When `m_memory` is non-null, the memory is owned by this object.
+    void* m_memory = nullptr;
+
+    // A pointer to a list of string pointers describing the stack trace (same
+    // format as returned by `backtrace_symbols()`).
+    const char* const* m_strs = nullptr;
+
+    // Number of entries in this stack trace.
+    size_t m_len = 0;
+};
+
+namespace detail {
+
+class ExceptionWithBacktraceBase {
+public:
+    ExceptionWithBacktraceBase()
+        : m_backtrace(util::Backtrace::capture())
+    {
+    }
+    const util::Backtrace& backtrace() const noexcept
+    {
+        return m_backtrace;
+    }
+    virtual const char* message() const noexcept = 0;
+
+protected:
+    util::Backtrace m_backtrace;
+    // Cannot use Optional here, because Optional wants to use
+    // ExceptionWithBacktrace.
+    mutable bool m_has_materialized_message = false;
+    mutable std::string m_materialized_message;
+
+    // Render the message and the backtrace into m_message_with_backtrace. If an
+    // exception is thrown while rendering the message, the message without the
+    // backtrace will be returned.
+    const char* materialize_message() const noexcept;
+};
+
+} // namespace detail
+
+/// Base class for exceptions that record a stack trace of where they were
+/// thrown.
+///
+/// The template argument is expected to be an exception type conforming to the
+/// standard library exception API (`std::exception` and friends).
+///
+/// It is possible to opt in to exception backtraces in two ways, (a) as part of
+/// the exception type, in which case the backtrace will always be included for
+/// all exceptions of that type, or (b) at the call-site of an opaque exception
+/// type, in which case it is up to the throw-site to decide whether a backtrace
+/// should be included.
+///
+/// Example (a):
+/// ```
+///     class MyException : ExceptionWithBacktrace<std::exception> {
+///     public:
+///         const char* message() const noexcept override
+///         {
+///             return "MyException error message";
+///         }
+///     };
+///
+///     ...
+///
+///     try {
+///         throw MyException{};
+///     }
+///     catch (const MyException& ex) {
+///         // Print the backtrace without the message:
+///         std::cerr << ex.backtrace() << "\n";
+///         // Print the exception message and the backtrace:
+///         std::cerr << ex.what() << "\n";
+///         // Print the exception message without the backtrace:
+///         std::cerr << ex.message() << "\n";
+///     }
+/// ```
+///
+/// Example (b):
+/// ```
+///     class MyException : std::exception {
+///     public:
+///         const char* what() const noexcept override
+///         {
+///             return "MyException error message";
+///         }
+///     };
+///
+///     ...
+///
+///     try {
+///         throw ExceptionWithBacktrace<MyException>{};
+///     }
+///     catch (const MyException& ex) {
+///         // Print the exception message and the backtrace:
+///         std::cerr << ex.what() << "\n";
+///     }
+/// ```
+template <class Base = std::runtime_error>
+class ExceptionWithBacktrace : public Base, public detail::ExceptionWithBacktraceBase {
+public:
+    template <class... Args>
+    inline ExceptionWithBacktrace(Args&&... args)
+        : Base(std::forward<Args>(args)...)
+        , detail::ExceptionWithBacktraceBase() // backtrace captured here
+    {
+    }
+
+    /// Return the message of the exception, including the backtrace of where
+    /// the exception was thrown.
+    const char* what() const noexcept final
+    {
+        return materialize_message();
+    }
+
+    /// Return the message of the exception without the backtrace. The default
+    /// implementation calls `Base::what()`.
+    const char* message() const noexcept override
+    {
+        return Base::what();
+    }
+};
+
+// Wrappers for standard exception types with backtrace support
+using runtime_error = ExceptionWithBacktrace<std::runtime_error>;
+using range_error = ExceptionWithBacktrace<std::range_error>;
+using overflow_error = ExceptionWithBacktrace<std::overflow_error>;
+using underflow_error = ExceptionWithBacktrace<std::underflow_error>;
+using bad_alloc = ExceptionWithBacktrace<std::bad_alloc>;
+using invalid_argument = ExceptionWithBacktrace<std::invalid_argument>;
+using out_of_range = ExceptionWithBacktrace<std::out_of_range>;
+using logic_error = ExceptionWithBacktrace<std::logic_error>;
+
+} // namespace util
+} // namespace realm
+
+inline std::ostream& operator<<(std::ostream& os, const realm::util::Backtrace& bt)
+{
+    bt.print(os);
+    return os;
+}
+
+#endif // REALM_UTIL_BACKTRACE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/base64.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/base64.hpp
new file mode 100644
index 0000000..8d808a6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/base64.hpp
@@ -0,0 +1,79 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_BASE64_HPP
+#define REALM_UTIL_BASE64_HPP
+
+#include <vector>
+#include <realm/string_data.hpp>
+#include <realm/util/optional.hpp>
+
+namespace realm {
+namespace util {
+
+
+/// base64_encode() encodes the bnary data in \param in_buffer of size \param in_buffer_size.
+/// The encoded data is placed in \param out_buffer. The size of \param \out_buffer is passed in
+/// \param out_buffer_size. The output buffer \param out_buffer must be
+/// large enough to hold the base64 encoded data. The size can be obtained from the function
+/// base64_encoded_size. \param out_buffer_size is only used to assert that the output buffer is
+/// large enough.
+size_t base64_encode(const char *in_buffer, size_t in_buffer_size, char* out_buffer, size_t out_buffer_size) noexcept;
+
+/// base64_encoded_size() returns the exact size of the base64 encoded
+/// data as a function of the size of the input data.
+inline size_t base64_encoded_size(size_t in_buffer_size) noexcept
+{
+    return 4 * ((in_buffer_size + 2) / 3);
+}
+
+
+/// Decode base64-encoded string in input, and places the result in out_buffer.
+/// The length of the out_buffer must be at least 3 * input.size() / 4.
+///
+/// The input must be padded base64 (i.e. the number of non-whitespace
+/// characters in the input must be a multiple of 4). Whitespace (spaces, tabs,
+/// newlines) is ignored.
+///
+/// The algorithm stops when the first character not in the base64 character
+/// set is encountered, or when the end of the input is reached.
+///
+/// \returns the number of successfully decoded bytes written to out_buffer, or
+/// none if the whole input was not valid base64.
+Optional<size_t> base64_decode(StringData input, char* out_buffer, size_t out_buffer_len) noexcept;
+
+/// Return an upper bound on the decoded size of a Base64-encoded data
+/// stream of length \a base64_size. The returned value is suitable for
+/// allocation of buffers containing decoded data.
+inline size_t base64_decoded_size(size_t base64_size) noexcept
+{
+    return (base64_size * 3 + 3) / 4;
+}
+
+
+
+/// base64_decode_to_vector() is a convenience function that decodes \param
+/// encoded and returns the result in a std::vector<char> with the correct size.
+/// This function returns none if the input is invalid.
+Optional<std::vector<char>> base64_decode_to_vector(StringData encoded);
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_BASE64_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/basic_system_errors.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/basic_system_errors.hpp
new file mode 100644
index 0000000..8f7a626
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/basic_system_errors.hpp
@@ -0,0 +1,89 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_BASIC_SYSTEM_ERRORS_HPP
+#define REALM_UTIL_BASIC_SYSTEM_ERRORS_HPP
+
+#include <cerrno>
+#include <system_error>
+
+
+namespace realm {
+namespace util {
+namespace error {
+
+enum basic_system_errors {
+    /// Address family not supported by protocol.
+    address_family_not_supported = EAFNOSUPPORT,
+
+    /// Invalid argument.
+    invalid_argument = EINVAL,
+
+    /// Cannot allocate memory.
+    no_memory = ENOMEM,
+
+    /// Operation cancelled.
+    operation_aborted = ECANCELED,
+
+    /// Connection aborted.
+    connection_aborted = ECONNABORTED,
+
+    /// Connection reset by peer
+    connection_reset = ECONNRESET,
+
+    /// Broken pipe
+    broken_pipe = EPIPE,
+
+    /// Resource temporarily unavailable
+    resource_unavailable_try_again = EAGAIN,
+};
+
+std::error_code make_error_code(basic_system_errors) noexcept;
+
+} // namespace error
+} // namespace util
+} // namespace realm
+
+namespace std {
+
+template <>
+class is_error_code_enum<realm::util::error::basic_system_errors> {
+public:
+    static const bool value = true;
+};
+
+} // namespace std
+
+namespace realm {
+namespace util {
+
+std::error_code make_basic_system_error_code(int) noexcept;
+
+
+// implementation
+
+inline std::error_code make_basic_system_error_code(int err) noexcept
+{
+    using namespace error;
+    return make_error_code(basic_system_errors(err));
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_BASIC_SYSTEM_ERRORS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/bind_ptr.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/bind_ptr.hpp
new file mode 100644
index 0000000..e5b8a99
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/bind_ptr.hpp
@@ -0,0 +1,484 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_BIND_PTR_HPP
+#define REALM_UTIL_BIND_PTR_HPP
+
+#include <algorithm>
+#include <atomic>
+#include <ostream>
+#include <utility>
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+
+
+namespace realm {
+namespace util {
+
+class bind_ptr_base {
+public:
+    struct adopt_tag {
+    };
+};
+
+
+/// A generic intrusive smart pointer that binds itself explicitely to
+/// the target object.
+///
+/// This class is agnostic towards what 'binding' means for the target
+/// object, but a common use is 'reference counting'. See RefCountBase
+/// for an example of that.
+///
+/// This smart pointer implementation assumes that the target object
+/// destructor never throws.
+template <class T>
+class bind_ptr : public bind_ptr_base {
+public:
+    constexpr bind_ptr() noexcept
+        : m_ptr(nullptr)
+    {
+    }
+    ~bind_ptr() noexcept
+    {
+        unbind();
+    }
+
+    explicit bind_ptr(T* p) noexcept
+    {
+        bind(p);
+    }
+    template <class U>
+    explicit bind_ptr(U* p) noexcept
+    {
+        bind(p);
+    }
+
+    bind_ptr(T* p, adopt_tag) noexcept
+    {
+        m_ptr = p;
+    }
+    template <class U>
+    bind_ptr(U* p, adopt_tag) noexcept
+    {
+        m_ptr = p;
+    }
+
+    // Copy construct
+    bind_ptr(const bind_ptr& p) noexcept
+    {
+        bind(p.m_ptr);
+    }
+    template <class U>
+    bind_ptr(const bind_ptr<U>& p) noexcept
+    {
+        bind(p.m_ptr);
+    }
+
+    // Copy assign
+    bind_ptr& operator=(const bind_ptr& p) noexcept
+    {
+        bind_ptr(p).swap(*this);
+        return *this;
+    }
+    template <class U>
+    bind_ptr& operator=(const bind_ptr<U>& p) noexcept
+    {
+        bind_ptr(p).swap(*this);
+        return *this;
+    }
+
+    // Move construct
+    bind_ptr(bind_ptr&& p) noexcept
+        : m_ptr(p.release())
+    {
+    }
+    template <class U>
+    bind_ptr(bind_ptr<U>&& p) noexcept
+        : m_ptr(p.release())
+    {
+    }
+
+    // Move assign
+    bind_ptr& operator=(bind_ptr&& p) noexcept
+    {
+        bind_ptr(std::move(p)).swap(*this);
+        return *this;
+    }
+    template <class U>
+    bind_ptr& operator=(bind_ptr<U>&& p) noexcept
+    {
+        bind_ptr(std::move(p)).swap(*this);
+        return *this;
+    }
+
+    //@{
+    // Comparison
+    template <class U>
+    bool operator==(const bind_ptr<U>&) const noexcept;
+
+    template <class U>
+    bool operator==(U*) const noexcept;
+
+    template <class U>
+    bool operator!=(const bind_ptr<U>&) const noexcept;
+
+    template <class U>
+    bool operator!=(U*) const noexcept;
+
+    template <class U>
+    bool operator<(const bind_ptr<U>&) const noexcept;
+
+    template <class U>
+    bool operator<(U*) const noexcept;
+
+    template <class U>
+    bool operator>(const bind_ptr<U>&) const noexcept;
+
+    template <class U>
+    bool operator>(U*) const noexcept;
+
+    template <class U>
+    bool operator<=(const bind_ptr<U>&) const noexcept;
+
+    template <class U>
+    bool operator<=(U*) const noexcept;
+
+    template <class U>
+    bool operator>=(const bind_ptr<U>&) const noexcept;
+
+    template <class U>
+    bool operator>=(U*) const noexcept;
+    //@}
+
+    // Dereference
+    T& operator*() const noexcept
+    {
+        return *m_ptr;
+    }
+    T* operator->() const noexcept
+    {
+        return m_ptr;
+    }
+
+    explicit operator bool() const noexcept
+    {
+        return m_ptr != 0;
+    }
+
+    T* get() const noexcept
+    {
+        return m_ptr;
+    }
+    void reset() noexcept
+    {
+        bind_ptr().swap(*this);
+    }
+    void reset(T* p) noexcept
+    {
+        bind_ptr(p).swap(*this);
+    }
+    template <class U>
+    void reset(U* p) noexcept
+    {
+        bind_ptr(p).swap(*this);
+    }
+
+    T* release() noexcept
+    {
+        T* const p = m_ptr;
+        m_ptr = nullptr;
+        return p;
+    }
+
+    void swap(bind_ptr& p) noexcept
+    {
+        std::swap(m_ptr, p.m_ptr);
+    }
+    friend void swap(bind_ptr& a, bind_ptr& b) noexcept
+    {
+        a.swap(b);
+    }
+
+protected:
+    struct casting_move_tag {
+    };
+    template <class U>
+    bind_ptr(bind_ptr<U>* p, casting_move_tag) noexcept
+        : m_ptr(static_cast<T*>(p->release()))
+    {
+    }
+
+private:
+    T* m_ptr;
+
+    void bind(T* p) noexcept
+    {
+        if (p)
+            p->bind_ptr();
+        m_ptr = p;
+    }
+    void unbind() noexcept
+    {
+        if (m_ptr)
+            m_ptr->unbind_ptr();
+    }
+
+    template <class>
+    friend class bind_ptr;
+};
+
+
+template <class C, class T, class U>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, const bind_ptr<U>& p)
+{
+    out << static_cast<const void*>(p.get());
+    return out;
+}
+
+
+//@{
+// Comparison
+template <class T, class U>
+bool operator==(T*, const bind_ptr<U>&) noexcept;
+template <class T, class U>
+bool operator!=(T*, const bind_ptr<U>&) noexcept;
+template <class T, class U>
+bool operator<(T*, const bind_ptr<U>&) noexcept;
+template <class T, class U>
+bool operator>(T*, const bind_ptr<U>&) noexcept;
+template <class T, class U>
+bool operator<=(T*, const bind_ptr<U>&) noexcept;
+template <class T, class U>
+bool operator>=(T*, const bind_ptr<U>&) noexcept;
+//@}
+
+
+/// Polymorphic convenience base class for reference counting objects.
+///
+/// Together with bind_ptr, this class delivers simple instrusive
+/// reference counting.
+///
+/// \sa bind_ptr
+class RefCountBase {
+public:
+    RefCountBase() noexcept
+        : m_ref_count(0)
+    {
+    }
+    virtual ~RefCountBase() noexcept
+    {
+        REALM_ASSERT(m_ref_count == 0);
+    }
+
+    RefCountBase(const RefCountBase&) = delete;
+    RefCountBase(RefCountBase&&) = delete;
+
+    void operator=(const RefCountBase&) = delete;
+    void operator=(RefCountBase&&) = delete;
+
+protected:
+    void bind_ptr() const noexcept
+    {
+        ++m_ref_count;
+    }
+    void unbind_ptr() const noexcept
+    {
+        if (--m_ref_count == 0)
+            delete this;
+    }
+
+private:
+    mutable unsigned long m_ref_count;
+
+    template <class>
+    friend class bind_ptr;
+};
+
+
+/// Same as RefCountBase, but this one makes the copying of, and the
+/// destruction of counted references thread-safe.
+///
+/// \sa RefCountBase
+/// \sa bind_ptr
+class AtomicRefCountBase {
+public:
+    AtomicRefCountBase() noexcept
+        : m_ref_count(0)
+    {
+    }
+    virtual ~AtomicRefCountBase() noexcept
+    {
+        REALM_ASSERT(m_ref_count == 0);
+    }
+
+    AtomicRefCountBase(const AtomicRefCountBase&) = delete;
+    AtomicRefCountBase(AtomicRefCountBase&&) = delete;
+
+    void operator=(const AtomicRefCountBase&) = delete;
+    void operator=(AtomicRefCountBase&&) = delete;
+
+protected:
+    // FIXME: Operators ++ and -- as used below use
+    // std::memory_order_seq_cst. This can be optimized.
+    void bind_ptr() const noexcept
+    {
+        ++m_ref_count;
+    }
+    void unbind_ptr() const noexcept
+    {
+        if (--m_ref_count == 0) {
+            delete this;
+        }
+    }
+
+private:
+    mutable std::atomic<unsigned long> m_ref_count;
+
+    template <class>
+    friend class bind_ptr;
+};
+
+
+// Implementation:
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator==(const bind_ptr<U>& p) const noexcept
+{
+    return m_ptr == p.m_ptr;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator==(U* p) const noexcept
+{
+    return m_ptr == p;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator!=(const bind_ptr<U>& p) const noexcept
+{
+    return m_ptr != p.m_ptr;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator!=(U* p) const noexcept
+{
+    return m_ptr != p;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator<(const bind_ptr<U>& p) const noexcept
+{
+    return m_ptr < p.m_ptr;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator<(U* p) const noexcept
+{
+    return m_ptr < p;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator>(const bind_ptr<U>& p) const noexcept
+{
+    return m_ptr > p.m_ptr;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator>(U* p) const noexcept
+{
+    return m_ptr > p;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator<=(const bind_ptr<U>& p) const noexcept
+{
+    return m_ptr <= p.m_ptr;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator<=(U* p) const noexcept
+{
+    return m_ptr <= p;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator>=(const bind_ptr<U>& p) const noexcept
+{
+    return m_ptr >= p.m_ptr;
+}
+
+template <class T>
+template <class U>
+bool bind_ptr<T>::operator>=(U* p) const noexcept
+{
+    return m_ptr >= p;
+}
+
+template <class T, class U>
+bool operator==(T* a, const bind_ptr<U>& b) noexcept
+{
+    return b == a;
+}
+
+template <class T, class U>
+bool operator!=(T* a, const bind_ptr<U>& b) noexcept
+{
+    return b != a;
+}
+
+template <class T, class U>
+bool operator<(T* a, const bind_ptr<U>& b) noexcept
+{
+    return b > a;
+}
+
+template <class T, class U>
+bool operator>(T* a, const bind_ptr<U>& b) noexcept
+{
+    return b < a;
+}
+
+template <class T, class U>
+bool operator<=(T* a, const bind_ptr<U>& b) noexcept
+{
+    return b >= a;
+}
+
+template <class T, class U>
+bool operator>=(T* a, const bind_ptr<U>& b) noexcept
+{
+    return b <= a;
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_BIND_PTR_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/buffer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/buffer.hpp
new file mode 100644
index 0000000..d65bdaf
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/buffer.hpp
@@ -0,0 +1,302 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_BUFFER_HPP
+#define REALM_UTIL_BUFFER_HPP
+
+#include <cstddef>
+#include <algorithm>
+#include <exception>
+#include <limits>
+#include <utility>
+
+#include <realm/util/features.h>
+#include <realm/utilities.hpp>
+#include <realm/util/safe_int_ops.hpp>
+#include <realm/util/allocator.hpp>
+#include <memory>
+
+namespace realm {
+namespace util {
+
+
+/// A simple buffer concept that owns a region of memory and knows its
+/// size.
+template <class T, class Allocator = DefaultAllocator>
+class Buffer {
+public:
+    Buffer(Allocator& alloc = Allocator::get_default()) noexcept
+        : m_data(nullptr, STLDeleter<T[], Allocator>{alloc})
+        , m_size(0)
+    {
+    }
+    explicit Buffer(size_t initial_size, Allocator& alloc = Allocator::get_default());
+    Buffer(Buffer&&) noexcept = default;
+    Buffer<T, Allocator>& operator=(Buffer&&) noexcept = default;
+
+    T& operator[](size_t i) noexcept
+    {
+        return m_data[i];
+    }
+    const T& operator[](size_t i) const noexcept
+    {
+        return m_data[i];
+    }
+
+    T* data() noexcept
+    {
+        return m_data.get();
+    }
+    const T* data() const noexcept
+    {
+        return m_data.get();
+    }
+    size_t size() const noexcept
+    {
+        return m_size;
+    }
+
+    /// False iff the data() returns null.
+    explicit operator bool() const noexcept
+    {
+        return bool(m_data);
+    }
+
+    /// Discards the original contents.
+    void set_size(size_t new_size);
+
+    /// \param new_size Specifies the new buffer size.
+    /// \param copy_begin, copy_end Specifies a range of element
+    /// values to be retained. \a copy_end must be less than, or equal
+    /// to size().
+    ///
+    /// \param copy_to Specifies where the retained range should be
+    /// copied to. `\a copy_to + \a copy_end - \a copy_begin` must be
+    /// less than, or equal to \a new_size.
+    void resize(size_t new_size, size_t copy_begin, size_t copy_end, size_t copy_to);
+
+    void reserve(size_t used_size, size_t min_capacity);
+
+    void reserve_extra(size_t used_size, size_t min_extra_capacity);
+
+    /// Release the internal buffer to the caller.
+    REALM_NODISCARD std::unique_ptr<T[], STLDeleter<T[], Allocator>> release() noexcept;
+
+    friend void swap(Buffer& a, Buffer& b) noexcept
+    {
+        using std::swap;
+        swap(a.m_data, b.m_data);
+        swap(a.m_size, b.m_size);
+    }
+
+    Allocator& get_allocator() const noexcept
+    {
+        return m_data.get_deleter().get_allocator();
+    }
+
+private:
+    std::unique_ptr<T[], STLDeleter<T[], Allocator>> m_data;
+    size_t m_size;
+};
+
+
+/// A buffer that can be efficiently resized. It acheives this by
+/// using an underlying buffer that may be larger than the logical
+/// size, and is automatically expanded in progressively larger steps.
+template <class T, class Allocator = DefaultAllocator>
+class AppendBuffer {
+public:
+    AppendBuffer(Allocator& alloc = Allocator::get_default()) noexcept;
+    AppendBuffer(AppendBuffer&&) noexcept = default;
+    AppendBuffer& operator=(AppendBuffer&&) noexcept = default;
+
+    /// Returns the current size of the buffer.
+    size_t size() const noexcept;
+
+    /// Gives read and write access to the elements.
+    T* data() noexcept;
+
+    /// Gives read access the elements.
+    const T* data() const noexcept;
+
+    /// Append the specified elements. This increases the size of this
+    /// buffer by \a append_data_size. If the caller has previously requested
+    /// a minimum capacity that is greater than, or equal to the
+    /// resulting size, this function is guaranteed to not throw.
+    void append(const T* append_data, size_t append_data_size);
+
+    /// If the specified size is less than the current size, then the
+    /// buffer contents is truncated accordingly. If the specified
+    /// size is greater than the current size, then the extra elements
+    /// will have undefined values. If the caller has previously
+    /// requested a minimum capacity that is greater than, or equal to
+    /// the specified size, this function is guaranteed to not throw.
+    void resize(size_t new_size);
+
+    /// This operation does not change the size of the buffer as
+    /// returned by size(). If the specified capacity is less than the
+    /// current capacity, this operation has no effect.
+    void reserve(size_t min_capacity);
+
+    /// Set the size to zero. The capacity remains unchanged.
+    void clear() noexcept;
+
+    /// Release the underlying buffer and reset the size. Note: The returned
+    /// buffer may be larger than the amount of data appended to this buffer.
+    /// Callers should call `size()` prior to releasing the buffer to know the
+    /// usable/logical size.
+    REALM_NODISCARD Buffer<T, Allocator> release() noexcept;
+
+private:
+    util::Buffer<T, Allocator> m_buffer;
+    size_t m_size;
+};
+
+
+// Implementation:
+
+class BufferSizeOverflow : public std::exception {
+public:
+    const char* what() const noexcept override
+    {
+        return "Buffer size overflow";
+    }
+};
+
+template <class T, class A>
+inline Buffer<T, A>::Buffer(size_t initial_size, A& alloc)
+    : m_data(util::make_unique<T[]>(alloc, initial_size)) // Throws
+    , m_size(initial_size)
+{
+}
+
+template <class T, class A>
+inline void Buffer<T, A>::set_size(size_t new_size)
+{
+    m_data = util::make_unique<T[]>(get_allocator(), new_size); // Throws
+    m_size = new_size;
+}
+
+template <class T, class A>
+inline void Buffer<T, A>::resize(size_t new_size, size_t copy_begin, size_t copy_end, size_t copy_to)
+{
+    auto new_data = util::make_unique<T[]>(get_allocator(), new_size); // Throws
+    realm::safe_copy_n(m_data.get() + copy_begin, copy_end - copy_begin, new_data.get() + copy_to);
+    m_data = std::move(new_data);
+    m_size = new_size;
+}
+
+template <class T, class A>
+inline void Buffer<T, A>::reserve(size_t used_size, size_t min_capacity)
+{
+    size_t current_capacity = m_size;
+    if (REALM_LIKELY(current_capacity >= min_capacity))
+        return;
+    size_t new_capacity = current_capacity;
+
+    // Use growth factor 1.5.
+    if (REALM_UNLIKELY(int_multiply_with_overflow_detect(new_capacity, 3)))
+        new_capacity = std::numeric_limits<size_t>::max();
+    new_capacity /= 2;
+
+    if (REALM_UNLIKELY(new_capacity < min_capacity))
+        new_capacity = min_capacity;
+    resize(new_capacity, 0, used_size, 0); // Throws
+}
+
+template <class T, class A>
+inline void Buffer<T, A>::reserve_extra(size_t used_size, size_t min_extra_capacity)
+{
+    size_t min_capacity = used_size;
+    if (REALM_UNLIKELY(int_add_with_overflow_detect(min_capacity, min_extra_capacity)))
+        throw BufferSizeOverflow();
+    reserve(used_size, min_capacity); // Throws
+}
+
+template <class T, class A>
+inline std::unique_ptr<T[], STLDeleter<T[], A>> Buffer<T, A>::release() noexcept
+{
+    m_size = 0;
+    return std::move(m_data);
+}
+
+
+template <class T, class A>
+inline AppendBuffer<T, A>::AppendBuffer(A& alloc) noexcept
+    : m_buffer(alloc)
+    , m_size(0)
+{
+}
+
+template <class T, class A>
+inline size_t AppendBuffer<T, A>::size() const noexcept
+{
+    return m_size;
+}
+
+template <class T, class A>
+inline T* AppendBuffer<T, A>::data() noexcept
+{
+    return m_buffer.data();
+}
+
+template <class T, class A>
+inline const T* AppendBuffer<T, A>::data() const noexcept
+{
+    return m_buffer.data();
+}
+
+template <class T, class A>
+inline void AppendBuffer<T, A>::append(const T* append_data, size_t append_data_size)
+{
+    m_buffer.reserve_extra(m_size, append_data_size); // Throws
+    realm::safe_copy_n(append_data, append_data_size, m_buffer.data() + m_size);
+    m_size += append_data_size;
+}
+
+template <class T, class A>
+inline void AppendBuffer<T, A>::reserve(size_t min_capacity)
+{
+    m_buffer.reserve(m_size, min_capacity);
+}
+
+template <class T, class A>
+inline void AppendBuffer<T, A>::resize(size_t new_size)
+{
+    reserve(new_size);
+    m_size = new_size;
+}
+
+template <class T, class A>
+inline void AppendBuffer<T, A>::clear() noexcept
+{
+    m_size = 0;
+}
+
+template <class T, class A>
+inline Buffer<T, A> AppendBuffer<T, A>::release() noexcept
+{
+    m_size = 0;
+    return std::move(m_buffer);
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_BUFFER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/buffer_stream.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/buffer_stream.hpp
new file mode 100644
index 0000000..be5064e
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/buffer_stream.hpp
@@ -0,0 +1,151 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_BUFFER_STREAM_HPP
+#define REALM_UTIL_BUFFER_STREAM_HPP
+
+#include <cstddef>
+#include <sstream>
+
+namespace realm {
+namespace util {
+
+
+template<class C, class T = std::char_traits<C>, class A = std::allocator<C> >
+class BasicResettableExpandableOutputStreambuf: public std::basic_stringbuf<C,T,A> {
+public:
+    using char_type = typename std::basic_stringbuf<C,T,A>::char_type;
+
+    /// Reset current writing position (std::basic_streambuf::pptr()) to the
+    /// beginning of the output buffer without reallocating buffer memory.
+    void reset() noexcept;
+
+    //@{
+    /// Get a pointer to the beginning of the output buffer
+    /// (std::basic_streambuf::pbase()). Note that this will change as the
+    /// buffer is reallocated.
+    char_type* data() noexcept;
+    const char_type* data() const noexcept;
+    //@}
+
+    /// Get the number of bytes written to the output buffer since the creation
+    /// of the stream buffer, or since the last invocation of reset()
+    /// (std::basic_streambuf::pptr() - std::basic_streambuf::pbase()).
+    std::size_t size() const noexcept;
+};
+
+
+template<class C, class T = std::char_traits<C>, class A = std::allocator<C> >
+class BasicResettableExpandableBufferOutputStream: public std::basic_ostream<C,T> {
+public:
+    using char_type = typename std::basic_ostream<C,T>::char_type;
+
+    BasicResettableExpandableBufferOutputStream();
+
+    /// Calls BasicResettableExpandableOutputStreambuf::reset().
+    void reset() noexcept;
+
+    //@{
+    /// Calls BasicResettableExpandableOutputStreambuf::data().
+    char_type* data() noexcept;
+    const char_type* data() const noexcept;
+    //@}
+
+    /// Calls BasicResettableExpandableOutputStreambuf::size().
+    std::size_t size() const noexcept;
+
+private:
+    BasicResettableExpandableOutputStreambuf<C,T,A> m_streambuf;
+};
+
+
+using ResettableExpandableBufferOutputStream = BasicResettableExpandableBufferOutputStream<char>;
+
+
+
+
+// Implementation
+
+template<class C, class T, class A>
+inline void BasicResettableExpandableOutputStreambuf<C,T,A>::reset() noexcept
+{
+    char_type* pbeg = this->pbase();
+    char_type* pend = this->epptr();
+    this->setp(pbeg, pend);
+}
+
+template<class C, class T, class A>
+inline typename BasicResettableExpandableOutputStreambuf<C,T,A>::char_type*
+BasicResettableExpandableOutputStreambuf<C,T,A>::data() noexcept
+{
+    return this->pbase();
+}
+
+template<class C, class T, class A>
+inline const typename BasicResettableExpandableOutputStreambuf<C,T,A>::char_type*
+BasicResettableExpandableOutputStreambuf<C,T,A>::data() const noexcept
+{
+    return this->pbase();
+}
+
+template<class C, class T, class A>
+inline std::size_t BasicResettableExpandableOutputStreambuf<C,T,A>::size() const noexcept
+{
+    std::size_t size = std::size_t(this->pptr() - this->pbase());
+    return size;
+}
+
+template<class C, class T, class A>
+inline BasicResettableExpandableBufferOutputStream<C,T,A>::
+BasicResettableExpandableBufferOutputStream():
+    std::basic_ostream<C,T>(&m_streambuf) // Throws
+{
+}
+
+template<class C, class T, class A>
+inline void BasicResettableExpandableBufferOutputStream<C,T,A>::reset() noexcept
+{
+    m_streambuf.reset();
+}
+
+template<class C, class T, class A>
+inline typename BasicResettableExpandableBufferOutputStream<C,T,A>::char_type*
+BasicResettableExpandableBufferOutputStream<C,T,A>::data() noexcept
+{
+    return m_streambuf.data();
+}
+
+template<class C, class T, class A>
+inline const typename BasicResettableExpandableBufferOutputStream<C,T,A>::char_type*
+BasicResettableExpandableBufferOutputStream<C,T,A>::data() const noexcept
+{
+    return m_streambuf.data();
+}
+
+template<class C, class T, class A>
+inline std::size_t BasicResettableExpandableBufferOutputStream<C,T,A>::size() const noexcept
+{
+    return m_streambuf.size();
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_BUFFER_STREAM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/call_with_tuple.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/call_with_tuple.hpp
new file mode 100644
index 0000000..7d2eab0
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/call_with_tuple.hpp
@@ -0,0 +1,66 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_CALL_WITH_TUPLE_HPP
+#define REALM_UTIL_CALL_WITH_TUPLE_HPP
+
+#include <cstddef>
+#include <tuple>
+
+namespace realm {
+namespace _impl {
+
+/// \cond doxygen_skip
+/// Doxygen warns about a recursive class relation, but this is intentional.
+
+template <size_t...>
+struct Indexes {
+};
+template <size_t N, size_t... I>
+struct GenIndexes : GenIndexes<N - 1, N - 1, I...> {
+};
+template <size_t... I>
+struct GenIndexes<0, I...> {
+    typedef Indexes<I...> type;
+};
+
+/// \endcond
+
+template <class F, class... A, size_t... I>
+auto call_with_tuple(F func, std::tuple<A...> args, Indexes<I...>) -> decltype(func(std::get<I>(args)...))
+{
+    static_cast<void>(args); // Prevent GCC warning when tuple is empty
+    return func(std::get<I>(args)...);
+}
+
+} // namespace _impl
+
+namespace util {
+
+template <class F, class... A>
+auto call_with_tuple(F func, std::tuple<A...> args)
+    -> decltype(_impl::call_with_tuple(std::move(func), std::move(args),
+                                       typename _impl::GenIndexes<sizeof...(A)>::type()))
+{
+    return _impl::call_with_tuple(std::move(func), std::move(args), typename _impl::GenIndexes<sizeof...(A)>::type());
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_CALL_WITH_TUPLE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/cf_ptr.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/cf_ptr.hpp
new file mode 100644
index 0000000..a1ec431
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/cf_ptr.hpp
@@ -0,0 +1,108 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_CF_PTR_HPP
+#define REALM_UTIL_CF_PTR_HPP
+
+#include <realm/util/assert.hpp>
+
+#if REALM_PLATFORM_APPLE
+
+#include <CoreFoundation/CoreFoundation.h>
+
+namespace realm {
+namespace util {
+
+template <class Ref>
+class CFPtr {
+public:
+    explicit CFPtr(Ref ref = nullptr) noexcept
+        : m_ref(ref)
+    {
+    }
+
+    CFPtr(CFPtr&& rg) noexcept
+        : m_ref(rg.m_ref)
+    {
+        rg.m_ref = nullptr;
+    }
+
+    ~CFPtr() noexcept
+    {
+        if (m_ref)
+            CFRelease(m_ref);
+    }
+
+    CFPtr& operator=(CFPtr&& rg) noexcept
+    {
+        REALM_ASSERT(!m_ref || m_ref != rg.m_ref);
+        if (m_ref)
+            CFRelease(m_ref);
+        m_ref = rg.m_ref;
+        rg.m_ref = nullptr;
+        return *this;
+    }
+
+    explicit operator bool() const noexcept
+    {
+        return bool(m_ref);
+    }
+
+    Ref get() const noexcept
+    {
+        return m_ref;
+    }
+
+    Ref release() noexcept
+    {
+        Ref ref = m_ref;
+        m_ref = nullptr;
+        return ref;
+    }
+
+    void reset(Ref ref = nullptr) noexcept
+    {
+        REALM_ASSERT(!m_ref || m_ref != ref);
+        if (m_ref)
+            CFRelease(m_ref);
+        m_ref = ref;
+    }
+
+private:
+    Ref m_ref;
+};
+
+template <class Ref>
+CFPtr<Ref> adoptCF(Ref ptr)
+{
+    return CFPtr<Ref>(ptr);
+}
+
+template <class Ref>
+CFPtr<Ref> retainCF(Ref ptr)
+{
+    CFRetain(ptr);
+    return CFPtr<Ref>(ptr);
+}
+}
+}
+
+
+#endif // REALM_PLATFORM_APPLE
+
+#endif // REALM_UTIL_CF_PTR_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/circular_buffer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/circular_buffer.hpp
new file mode 100644
index 0000000..4ae07cc
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/circular_buffer.hpp
@@ -0,0 +1,1011 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_CIRCULAR_BUFFER_HPP
+#define REALM_UTIL_CIRCULAR_BUFFER_HPP
+
+#include <cstddef>
+#include <type_traits>
+#include <limits>
+#include <memory>
+#include <iterator>
+#include <algorithm>
+#include <utility>
+#include <stdexcept>
+#include <initializer_list>
+
+#include <realm/util/safe_int_ops.hpp>
+#include <realm/util/backtrace.hpp>
+
+namespace realm {
+namespace util {
+
+/// \brief A container backed by a "circular buffer".
+///
+/// This container is similar to std::deque in that it offers efficient element
+/// insertion and removal at both ends. Insertion at either end occurs in
+/// amortized constant time. Removal at either end occurs in constant time.
+///
+/// As opposed to std::deque, this container allows for reservation of buffer
+/// space, such that value insertion can be guaranteed to not reallocate buffer
+/// memory, and to not throw.
+///
+/// More specifically, a single insert operation, that inserts zero or more
+/// values at either end, is guaranteed to not reallocate buffer memory if the
+/// prior capacity (capacity()) is greater than, or equal to the prior size
+/// (size()) plus the number of inserted values. Further more, such an operation
+/// is guaranteed to not throw if the capacity is sufficient, and the relevant
+/// constructor of the value type does not throw, and, in the case of inserting
+/// a range of values specified as a pair of iterators, if no exception is
+/// thrown while operating on those iterators.
+///
+/// This container uses a single contiguous chunk of memory as backing storage,
+/// but it allows for the logical sequence of values to wrap around from the
+/// end, to the beginning of that chunk. Because the logical sequence of values
+/// can have a storage-wise discontinuity of this kind, this container does not
+/// meet the requirements of `ContiguousContainer` (as defined by C++17).
+///
+/// When the first element is removed (pop_front()), iterators pointing to the
+/// removed element will be invalidated. All other iterators, including "end
+/// iterators" (end()), will remain valid.
+///
+/// When the last element is removed (pop_back()), iterators pointing to the
+/// removed element will become "end iterators" (end()), and "end iterators"
+/// will be invalidated. All other iterators will remain valid.
+///
+/// When an element is inserted at the front (push_front()), and the prior
+/// capacity (capacity()) is strictly greater than the prior size (size()), all
+/// iterators remain valid.
+///
+/// When an element is inserted at the back (push_back()), and the prior
+/// capacity (capacity()) is strictly greater than the prior size (size()), "end
+/// iterators" (end()) become iterators to the inserted element, and all other
+/// iterators remain valid.
+///
+/// Operations pop_front(), pop_back(), and clear(), are guaranteed to leave the
+/// capacity unchanged.
+///
+/// Iterators are of the "random access" kind (std::random_access_iterator_tag).
+template<class T> class CircularBuffer {
+private:
+    template<class> class Iter;
+
+    template<class I> using RequireIter =
+        std::enable_if_t<std::is_convertible<typename std::iterator_traits<I>::iterator_category,
+                                             std::input_iterator_tag>::value>;
+
+public:
+    static_assert(std::is_nothrow_destructible<T>::value, "");
+
+    using value_type      = T;
+    using size_type       = std::size_t;
+    using reference       = value_type&;
+    using const_reference = const value_type&;
+    using iterator        = Iter<value_type>;
+    using const_iterator  = Iter<const value_type>;
+    using reverse_iterator       = std::reverse_iterator<iterator>;
+    using const_reverse_iterator = std::reverse_iterator<const_iterator>;
+
+    CircularBuffer() noexcept;
+    CircularBuffer(const CircularBuffer&);
+    CircularBuffer(CircularBuffer&&) noexcept;
+    CircularBuffer(std::initializer_list<T>);
+    explicit CircularBuffer(size_type size);
+    CircularBuffer(size_type size, const T& value);
+    template<class I, class = RequireIter<I>> CircularBuffer(I begin, I end);
+    ~CircularBuffer() noexcept;
+
+    CircularBuffer& operator=(const CircularBuffer&);
+    CircularBuffer& operator=(CircularBuffer&&) noexcept;
+    CircularBuffer& operator=(std::initializer_list<T>);
+
+    void assign(std::initializer_list<T>);
+    void assign(size_type size, const T& value);
+    template<class I, class = RequireIter<I>> void assign(I begin, I end);
+
+    // Element access
+
+    reference at(size_type);
+    const_reference at(size_type) const;
+
+    reference operator[](size_type) noexcept;
+    const_reference operator[](size_type) const noexcept;
+
+    reference front() noexcept;
+    const_reference front() const noexcept;
+
+    reference back() noexcept;
+    const_reference back() const noexcept;
+
+    // Iterators
+
+    iterator begin() noexcept;
+    const_iterator begin() const noexcept;
+    const_iterator cbegin() const noexcept;
+
+    iterator end() noexcept;
+    const_iterator end() const noexcept;
+    const_iterator cend() const noexcept;
+
+    reverse_iterator rbegin() noexcept;
+    const_reverse_iterator rbegin() const noexcept;
+    const_reverse_iterator crbegin() const noexcept;
+
+    reverse_iterator rend() noexcept;
+    const_reverse_iterator rend() const noexcept;
+    const_reverse_iterator crend() const noexcept;
+
+    // Size / capacity
+
+    bool empty() const noexcept;
+    size_type size() const noexcept;
+    size_type capacity() const noexcept;
+
+    void reserve(size_type capacity);
+    void shrink_to_fit();
+
+    // Modifiers
+
+    reference push_front(const T&);
+    reference push_back(const T&);
+
+    reference push_front(T&&);
+    reference push_back(T&&);
+
+    template<class... Args> reference emplace_front(Args&&...);
+    template<class... Args> reference emplace_back(Args&&...);
+
+    void pop_front() noexcept;
+    void pop_back() noexcept;
+
+    // FIXME: emplace(const_iterator i, ...) -> j = unwrap(i.m_index); if (j >= (m_size+1)/2) insert_near_back(j, ...); else insert_near_front(j, ...);                            
+
+    void clear() noexcept;
+    void resize(size_type size);
+    void resize(size_type size, const T& value);
+
+    void swap(CircularBuffer&) noexcept;
+
+    // Comparison
+
+    template<class U> bool operator==(const CircularBuffer<U>&) const
+        noexcept(noexcept(std::declval<T>() == std::declval<U>()));
+    template<class U> bool operator!=(const CircularBuffer<U>&) const
+        noexcept(noexcept(std::declval<T>() == std::declval<U>()));
+    template<class U> bool operator<(const CircularBuffer<U>&) const
+        noexcept(noexcept(std::declval<T>() < std::declval<U>()));
+    template<class U> bool operator>(const CircularBuffer<U>&) const
+        noexcept(noexcept(std::declval<T>() < std::declval<U>()));
+    template<class U> bool operator<=(const CircularBuffer<U>&) const
+        noexcept(noexcept(std::declval<T>() < std::declval<U>()));
+    template<class U> bool operator>=(const CircularBuffer<U>&) const
+        noexcept(noexcept(std::declval<T>() < std::declval<U>()));
+
+private:
+    using Strut = typename std::aligned_storage<sizeof(T), alignof(T)>::type;
+    std::unique_ptr<Strut[]> m_memory_owner;
+
+    // Index of first element in allocated memory chunk.
+    size_type m_begin = 0;
+
+    // The number of elements within the allocated memory chunk, that are
+    // currently in use, i.e., the logical size of the circular buffer.
+    size_type m_size = 0;
+
+    // Number of elements of type T that will fit into the currently allocated
+    // memory chunk.
+    //
+    // Except when m_size is zero, m_allocated_size must be strictly greater
+    // than m_size. This is required to ensure that the iterators returned by
+    // begin() and end() are equal only when the buffer is empty.
+    //
+    // INVARIANT: m_size == 0 ? m_allocated_size == 0 : m_size < m_allocated_size
+    size_type m_allocated_size = 0;
+
+    T* get_memory_ptr() noexcept;
+
+    // Assumption: index < m_allocated_size
+    size_type circular_inc(size_type index) noexcept;
+    size_type circular_dec(size_type index) noexcept;
+    size_type wrap(size_type index) noexcept;
+    size_type unwrap(size_type index) noexcept;
+
+    template<class I> void copy(I begin, I end);
+    template<class I> void copy(I begin, I end, std::input_iterator_tag);
+    template<class I> void copy(I begin, I end, std::forward_iterator_tag);
+
+    void destroy(size_type offset = 0) noexcept;
+
+    void realloc(size_type new_allocated_size);
+};
+
+
+template<class T> void swap(CircularBuffer<T>&, CircularBuffer<T>&) noexcept;
+
+
+
+
+// Implementation
+
+template<class T> template<class U> class CircularBuffer<T>::Iter :
+        public std::iterator<std::random_access_iterator_tag, U> {
+public:
+    using difference_type = std::ptrdiff_t;
+
+    Iter() noexcept
+    {
+    }
+
+    template<class V> Iter(const Iter<V>& i) noexcept
+    {
+        operator=(i);
+    }
+
+    template<class V> Iter& operator=(const Iter<V>& i) noexcept
+    {
+        // Check constness convertability
+        static_assert(std::is_convertible<V*,U*>::value, "");
+        m_buffer = i.m_buffer;
+        m_index = i.m_index;
+        return *this;
+    }
+
+    U& operator*() const noexcept
+    {
+        T* memory = m_buffer->get_memory_ptr();
+        return memory[m_index];
+    }
+
+    U* operator->() const noexcept
+    {
+        return &operator*();
+    }
+
+    U& operator[](difference_type i) const noexcept
+    {
+        Iter j = *this;
+        j += i;
+        return *j;
+    }
+
+    Iter& operator++() noexcept
+    {
+        m_index = m_buffer->circular_inc(m_index);
+        return *this;
+    }
+
+    Iter& operator--() noexcept
+    {
+        m_index = m_buffer->circular_dec(m_index);
+        return *this;
+    }
+
+    Iter operator++(int) noexcept
+    {
+        size_type i = m_index;
+        operator++();
+        return Iter{m_buffer, i};
+    }
+
+    Iter operator--(int) noexcept
+    {
+        size_type i = m_index;
+        operator--();
+        return Iter{m_buffer, i};
+    }
+
+    Iter& operator+=(difference_type value) noexcept
+    {
+        // Care is needed to avoid unspecified arithmetic behaviour here. We can
+        // assume, however, that if `i` is the unwrapped (logical) index of the
+        // element pointed to by this iterator, then the mathematical value of i
+        // + value is representable in `size_type` (otherwise the resulting
+        // iterator would escape the boundaries of the buffer). We can therefore
+        // safely perform the addition in the unsigned domain of unwrapped
+        // element indexes, and rely on two's complement representation for
+        // negative values.
+        size_type i = m_buffer->unwrap(m_index);
+        i += size_type(value);
+        m_index = m_buffer->wrap(i);
+        return *this;
+    }
+
+    Iter& operator-=(difference_type value) noexcept
+    {
+        // Care is needed to avoid unspecified arithmetic behaviour here. See
+        // the comment in the implementation of operator+=().
+        size_type i = m_buffer->unwrap(m_index);
+        i -= size_type(value);
+        m_index = m_buffer->wrap(i);
+        return *this;
+    }
+
+    Iter operator+(difference_type value) const noexcept
+    {
+        Iter i = *this;
+        i += value;
+        return i;
+    }
+
+    Iter operator-(difference_type value) const noexcept
+    {
+        Iter i = *this;
+        i -= value;
+        return i;
+    }
+
+    friend Iter operator+(difference_type value, const Iter& i) noexcept
+    {
+        Iter j = i;
+        j += value;
+        return j;
+    }
+
+    template<class V> difference_type operator-(const Iter<V>& i) const noexcept
+    {
+        REALM_ASSERT(m_buffer == i.m_buffer);
+        size_type i_1 = m_buffer->unwrap(m_index);
+        size_type i_2 = i.m_buffer->unwrap(i.m_index);
+        return from_twos_compl<difference_type>(size_type(i_1 - i_2));
+    }
+
+    template<class V> bool operator==(const Iter<V>& i) const noexcept
+    {
+        REALM_ASSERT(m_buffer == i.m_buffer);
+        return (m_index == i.m_index);
+    }
+
+    template<class V> bool operator!=(const Iter<V>& i) const noexcept
+    {
+        return !operator==(i);
+    }
+
+    template<class V> bool operator<(const Iter<V>& i) const noexcept
+    {
+        REALM_ASSERT(m_buffer == i.m_buffer);
+        size_type i_1 = m_buffer->unwrap(m_index);
+        size_type i_2 = i.m_buffer->unwrap(i.m_index);
+        return (i_1 < i_2);
+    }
+
+    template<class V> bool operator>(const Iter<V>& i) const noexcept
+    {
+        return (i < *this);
+    }
+
+    template<class V> bool operator<=(const Iter<V>& i) const noexcept
+    {
+        return !operator>(i);
+    }
+
+    template<class V> bool operator>=(const Iter<V>& i) const noexcept
+    {
+        return !operator<(i);
+    }
+
+private:
+    CircularBuffer* m_buffer = nullptr;
+
+    // Index of iterator position from beginning of allocated memory, i.e., from
+    // beginning of m_buffer->get_memory_ptr().
+    size_type m_index = 0;
+
+    Iter(CircularBuffer* buffer, size_type index) noexcept :
+        m_buffer{buffer},
+        m_index{index}
+    {
+    }
+
+    friend class CircularBuffer<T>;
+    template<class> friend class Iter;
+};
+
+template<class T> inline CircularBuffer<T>::CircularBuffer() noexcept
+{
+}
+
+template<class T> inline CircularBuffer<T>::CircularBuffer(const CircularBuffer& buffer)
+{
+    try {
+        copy(buffer.begin(), buffer.end()); // Throws
+    }
+    catch (...) {
+        // If an exception was thrown above, the destructor will not be called,
+        // so we need to manually destroy the copies that were already made.
+        destroy();
+        throw;
+    }
+}
+
+template<class T> inline CircularBuffer<T>::CircularBuffer(CircularBuffer&& buffer) noexcept :
+    m_memory_owner{std::move(buffer.m_memory_owner)},
+    m_begin{buffer.m_begin},
+    m_size{buffer.m_size},
+    m_allocated_size{buffer.m_allocated_size}
+{
+    buffer.m_begin          = 0;
+    buffer.m_size           = 0;
+    buffer.m_allocated_size = 0;
+}
+
+template<class T> inline CircularBuffer<T>::CircularBuffer(std::initializer_list<T> list)
+{
+    try {
+        copy(list.begin(), list.end()); // Throws
+    }
+    catch (...) {
+        // If an exception was thrown above, the destructor will not be called,
+        // so we need to manually destroy the copies that were already made.
+        destroy();
+        throw;
+    }
+}
+
+template<class T> inline CircularBuffer<T>::CircularBuffer(size_type count)
+{
+    try {
+        resize(count); // Throws
+    }
+    catch (...) {
+        // If an exception was thrown above, the destructor will not be called,
+        // so we need to manually destroy the instances that were already
+        // created.
+        destroy();
+        throw;
+    }
+}
+
+template<class T> inline CircularBuffer<T>::CircularBuffer(size_type count, const T& value)
+{
+    try {
+        resize(count, value); // Throws
+    }
+    catch (...) {
+        // If an exception was thrown above, the destructor will not be called,
+        // so we need to manually destroy the copies that were already made.
+        destroy();
+        throw;
+    }
+}
+
+template<class T> template<class I, class> inline CircularBuffer<T>::CircularBuffer(I begin, I end)
+{
+    try {
+        copy(begin, end); // Throws
+    }
+    catch (...) {
+        // If an exception was thrown above, the destructor will not be called,
+        // so we need to manually destroy the copies that were already made.
+        destroy();
+        throw;
+    }
+}
+
+template<class T> inline CircularBuffer<T>::~CircularBuffer() noexcept
+{
+    destroy();
+}
+
+template<class T>
+inline auto CircularBuffer<T>::operator=(const CircularBuffer& buffer) -> CircularBuffer&
+{
+    clear();
+    copy(buffer.begin(), buffer.end()); // Throws
+    return *this;
+}
+
+template<class T>
+inline auto CircularBuffer<T>::operator=(CircularBuffer&& buffer) noexcept -> CircularBuffer&
+{
+    destroy();
+    m_memory_owner   = std::move(buffer.m_memory_owner);
+    m_begin          = buffer.m_begin;
+    m_size           = buffer.m_size;
+    m_allocated_size = buffer.m_allocated_size;
+    buffer.m_begin          = 0;
+    buffer.m_size           = 0;
+    buffer.m_allocated_size = 0;
+    return *this;
+}
+
+template<class T>
+inline auto CircularBuffer<T>::operator=(std::initializer_list<T> list) -> CircularBuffer&
+{
+    clear();
+    copy(list.begin(), list.end()); // Throws
+    return *this;
+}
+
+template<class T> inline void CircularBuffer<T>::assign(std::initializer_list<T> list)
+{
+    clear();
+    copy(list.begin(), list.end()); // Throws
+}
+
+template<class T> inline void CircularBuffer<T>::assign(size_type count, const T& value)
+{
+    clear();
+    resize(count, value); // Throws
+}
+
+template<class T> template<class I, class> inline void CircularBuffer<T>::assign(I begin, I end)
+{
+    clear();
+    copy(begin, end); // Throws
+}
+
+template<class T> inline auto CircularBuffer<T>::at(size_type i) -> reference
+{
+    if (REALM_LIKELY(i < m_size))
+        return operator[](i);
+    throw util::out_of_range{"Index"};
+}
+
+template<class T> inline auto CircularBuffer<T>::at(size_type i) const -> const_reference
+{
+    return const_cast<CircularBuffer*>(this)->at(i); // Throws
+}
+
+template<class T>
+inline auto CircularBuffer<T>::operator[](size_type i) noexcept -> reference
+{
+    REALM_ASSERT(i < m_size);
+    T* memory = get_memory_ptr();
+    size_type j = wrap(i);
+    return memory[j];
+}
+
+template<class T>
+inline auto CircularBuffer<T>::operator[](size_type i) const noexcept -> const_reference
+{
+    return const_cast<CircularBuffer*>(this)->operator[](i);
+}
+
+template<class T> inline auto CircularBuffer<T>::front() noexcept -> reference
+{
+    return operator[](0);
+}
+
+template<class T> inline auto CircularBuffer<T>::front() const noexcept -> const_reference
+{
+    return operator[](0);
+}
+
+template<class T> inline auto CircularBuffer<T>::back() noexcept -> reference
+{
+    return operator[](m_size-1);
+}
+
+template<class T>
+inline auto CircularBuffer<T>::back() const noexcept -> const_reference
+{
+    return operator[](m_size-1);
+}
+
+template<class T> inline auto CircularBuffer<T>::begin() noexcept -> iterator
+{
+    return iterator{this, m_begin};
+}
+
+template<class T> inline auto CircularBuffer<T>::begin() const noexcept -> const_iterator
+{
+    return const_cast<CircularBuffer*>(this)->begin();
+}
+
+template<class T> inline auto CircularBuffer<T>::cbegin() const noexcept -> const_iterator
+{
+    return begin();
+}
+
+template<class T> inline auto CircularBuffer<T>::end() noexcept -> iterator
+{
+    size_type i = wrap(m_size);
+    return iterator{this, i};
+}
+
+template<class T> inline auto CircularBuffer<T>::end() const noexcept -> const_iterator
+{
+    return const_cast<CircularBuffer*>(this)->end();
+}
+
+template<class T> inline auto CircularBuffer<T>::cend() const noexcept -> const_iterator
+{
+    return end();
+}
+
+template<class T> inline auto CircularBuffer<T>::rbegin() noexcept -> reverse_iterator
+{
+    return std::reverse_iterator<iterator>(end());
+}
+
+template<class T> inline auto CircularBuffer<T>::rbegin() const noexcept -> const_reverse_iterator
+{
+    return const_cast<CircularBuffer*>(this)->rbegin();
+}
+
+template<class T> inline auto CircularBuffer<T>::crbegin() const noexcept -> const_reverse_iterator
+{
+    return rbegin();
+}
+
+template<class T> inline auto CircularBuffer<T>::rend() noexcept -> reverse_iterator
+{
+    return std::reverse_iterator<iterator>(begin());
+}
+
+template<class T> inline auto CircularBuffer<T>::rend() const noexcept -> const_reverse_iterator
+{
+    return const_cast<CircularBuffer*>(this)->rend();
+}
+
+template<class T> inline auto CircularBuffer<T>::crend() const noexcept -> const_reverse_iterator
+{
+    return rend();
+}
+
+template<class T> inline bool CircularBuffer<T>::empty() const noexcept
+{
+    return (m_size == 0);
+}
+
+template<class T> inline auto CircularBuffer<T>::size() const noexcept -> size_type
+{
+    return m_size;
+}
+
+template<class T> void CircularBuffer<T>::reserve(size_type capacity)
+{
+    if (capacity == 0)
+        return;
+
+    // An extra element of capacity is needed such that the end iterator can
+    // always point one beyond the last element without becomeing equal to an
+    // iterator to the first element.
+    size_type min_allocated_size = capacity;
+    if (REALM_UNLIKELY(int_add_with_overflow_detect(min_allocated_size, 1)))
+        throw util::overflow_error{"Capacity"};
+
+    if (min_allocated_size <= m_allocated_size)
+        return;
+
+    size_type new_allocated_size = m_allocated_size;
+    if (REALM_UNLIKELY(int_multiply_with_overflow_detect(new_allocated_size, 2)))
+        new_allocated_size = std::numeric_limits<size_type>::max();
+    if (new_allocated_size < min_allocated_size)
+        new_allocated_size = min_allocated_size;
+    realloc(new_allocated_size); // Throws
+}
+
+template<class T> inline void CircularBuffer<T>::shrink_to_fit()
+{
+    if (m_size > 0) {
+        // An extra element of capacity is needed such that the end iterator can
+        // always point one beyond the last element without becomeing equal to
+        // an iterator to the first element.
+        size_type new_allocated_size = m_size + 1;
+        if (new_allocated_size < m_allocated_size)
+            realloc(new_allocated_size); // Throws
+    }
+    else {
+        m_memory_owner.reset();
+        m_begin = 0;
+        m_allocated_size = 0;
+    }
+}
+
+template<class T> inline auto CircularBuffer<T>::capacity() const noexcept -> size_type
+{
+    return (m_allocated_size > 0 ? m_allocated_size - 1 : 0);
+}
+
+template<class T> inline auto CircularBuffer<T>::push_front(const T& value) -> reference
+{
+    return emplace_front(value); // Throws
+}
+
+template<class T> inline auto CircularBuffer<T>::push_back(const T& value) -> reference
+{
+    return emplace_back(value); // Throws
+}
+
+template<class T> inline auto CircularBuffer<T>::push_front(T&& value) -> reference
+{
+    return emplace_front(value); // Throws
+}
+
+template<class T> inline auto CircularBuffer<T>::push_back(T&& value) -> reference
+{
+    return emplace_back(value); // Throws
+}
+
+template<class T>
+template<class... Args> inline auto CircularBuffer<T>::emplace_front(Args&&... args) -> reference
+{
+    size_type new_size = m_size + 1;
+    reserve(new_size); // Throws
+    REALM_ASSERT(m_allocated_size > 0);
+    T* memory = get_memory_ptr();
+    size_type i = circular_dec(m_begin);
+    new (&memory[i]) T(std::forward<Args>(args)...); // Throws
+    m_begin = i;
+    m_size = new_size;
+    return memory[i];
+}
+
+template<class T>
+template<class... Args> inline auto CircularBuffer<T>::emplace_back(Args&&... args) -> reference
+{
+    size_type new_size = m_size + 1;
+    reserve(new_size); // Throws
+    REALM_ASSERT(m_allocated_size > 0);
+    T* memory = get_memory_ptr();
+    size_type i = wrap(m_size);
+    new (&memory[i]) T(std::forward<Args>(args)...); // Throws
+    m_size = new_size;
+    return memory[i];
+}
+
+template<class T> inline void CircularBuffer<T>::pop_front() noexcept
+{
+    REALM_ASSERT(m_size > 0);
+    T* memory = get_memory_ptr();
+    memory[m_begin].~T();
+    m_begin = circular_inc(m_begin);
+    --m_size;
+}
+
+template<class T> inline void CircularBuffer<T>::pop_back() noexcept
+{
+    REALM_ASSERT(m_size > 0);
+    T* memory = get_memory_ptr();
+    size_type new_size = m_size - 1;
+    size_type i = wrap(new_size);
+    memory[i].~T();
+    m_size = new_size;
+}
+
+template<class T> inline void CircularBuffer<T>::clear() noexcept
+{
+    destroy();
+    m_begin = 0;
+    m_size = 0;
+}
+
+template<class T> inline void CircularBuffer<T>::resize(size_type size)
+{
+    if (size <= m_size) {
+        size_type offset = size;
+        destroy(offset);
+        m_size = size;
+        return;
+    }
+    reserve(size); // Throws
+    T* memory = get_memory_ptr();
+    size_type i = wrap(m_size);
+    do {
+        new (&memory[i]) T(); // Throws
+        i = circular_inc(i);
+        ++m_size;
+    }
+    while (m_size < size);
+}
+
+template<class T> inline void CircularBuffer<T>::resize(size_type size, const T& value)
+{
+    if (size <= m_size) {
+        size_type offset = size;
+        destroy(offset);
+        m_size = size;
+        return;
+    }
+    reserve(size); // Throws
+    T* memory = get_memory_ptr();
+    size_type i = wrap(m_size);
+    do {
+        new (&memory[i]) T(value); // Throws
+        i = circular_inc(i);
+        ++m_size;
+    }
+    while (m_size < size);
+}
+
+template<class T> inline void CircularBuffer<T>::swap(CircularBuffer& buffer) noexcept
+{
+    std::swap(m_memory_owner,   buffer.m_memory_owner);
+    std::swap(m_begin,          buffer.m_begin);
+    std::swap(m_size,           buffer.m_size);
+    std::swap(m_allocated_size, buffer.m_allocated_size);
+}
+
+template<class T> template<class U>
+inline bool CircularBuffer<T>::operator==(const CircularBuffer<U>& buffer) const
+    noexcept(noexcept(std::declval<T>() == std::declval<U>()))
+{
+    return std::equal(begin(), end(), buffer.begin(), buffer.end()); // Throws
+}
+
+template<class T> template<class U>
+inline bool CircularBuffer<T>::operator!=(const CircularBuffer<U>& buffer) const
+    noexcept(noexcept(std::declval<T>() == std::declval<U>()))
+{
+    return !operator==(buffer); // Throws
+}
+
+template<class T> template<class U>
+inline bool CircularBuffer<T>::operator<(const CircularBuffer<U>& buffer) const
+    noexcept(noexcept(std::declval<T>() < std::declval<U>()))
+{
+    return std::lexicographical_compare(begin(), end(), buffer.begin(), buffer.end()); // Throws
+}
+
+template<class T> template<class U>
+inline bool CircularBuffer<T>::operator>(const CircularBuffer<U>& buffer) const
+    noexcept(noexcept(std::declval<T>() < std::declval<U>()))
+{
+    return (buffer < *this); // Throws
+}
+
+template<class T> template<class U>
+inline bool CircularBuffer<T>::operator<=(const CircularBuffer<U>& buffer) const
+    noexcept(noexcept(std::declval<T>() < std::declval<U>()))
+{
+    return !operator>(buffer); // Throws
+}
+
+template<class T> template<class U>
+inline bool CircularBuffer<T>::operator>=(const CircularBuffer<U>& buffer) const
+    noexcept(noexcept(std::declval<T>() < std::declval<U>()))
+{
+    return !operator<(buffer); // Throws
+}
+
+template<class T> inline T* CircularBuffer<T>::get_memory_ptr() noexcept
+{
+    return static_cast<T*>(static_cast<void*>(m_memory_owner.get()));
+}
+
+template<class T>
+inline auto CircularBuffer<T>::circular_inc(size_type index) noexcept -> size_type
+{
+    size_type index_2 = index + 1;
+    if (REALM_LIKELY(index_2 < m_allocated_size))
+        return index_2;
+    return 0;
+}
+
+template<class T>
+inline auto CircularBuffer<T>::circular_dec(size_type index) noexcept -> size_type
+{
+    if (REALM_LIKELY(index > 0))
+        return index - 1;
+    return m_allocated_size - 1;
+}
+
+template<class T>
+inline auto CircularBuffer<T>::wrap(size_type index) noexcept -> size_type
+{
+    size_type top = m_allocated_size - m_begin;
+    if (index < top)
+        return m_begin + index;
+    return index - top;
+}
+
+template<class T>
+inline auto CircularBuffer<T>::unwrap(size_type index) noexcept -> size_type
+{
+    if (index >= m_begin)
+        return index - m_begin;
+    return m_allocated_size - (m_begin - index);
+}
+
+template<class T> template<class I> inline void CircularBuffer<T>::copy(I begin, I end)
+{
+    using iterator_category = typename std::iterator_traits<I>::iterator_category;
+    copy(begin, end, iterator_category{}); // Throws
+}
+
+template<class T> template<class I>
+inline void CircularBuffer<T>::copy(I begin, I end, std::input_iterator_tag)
+{
+    for (I j = begin; j != end; ++j)
+        push_back(*j); // Throws
+}
+
+template<class T> template<class I>
+inline void CircularBuffer<T>::copy(I begin, I end, std::forward_iterator_tag)
+{
+    REALM_ASSERT(m_begin == 0);
+    REALM_ASSERT(m_size == 0);
+    size_type size = std::distance(begin, end);
+    reserve(size); // Throws
+    T* memory = get_memory_ptr();
+    for (I i = begin; i != end; ++i) {
+        new (&memory[m_size]) T(*i); // Throws
+        ++m_size;
+    }
+}
+
+template<class T> inline void CircularBuffer<T>::destroy(size_type offset) noexcept
+{
+    T* memory = get_memory_ptr();
+    size_type j = m_begin;
+    for (size_type i = offset; i < m_size; ++i) {
+        memory[j].~T();
+        j = circular_inc(j);
+    }
+}
+
+template<class T> void CircularBuffer<T>::realloc(size_type new_allocated_size)
+{
+    REALM_ASSERT(new_allocated_size > 1);
+    REALM_ASSERT(new_allocated_size > m_size);
+
+    // Allocate new buffer
+    std::unique_ptr<Strut[]> new_memory_owner =
+        std::make_unique<Strut[]>(new_allocated_size); // Throws
+    T* memory = get_memory_ptr();
+
+    // Move or copy elements to new buffer
+    {
+        T* new_memory = static_cast<T*>(static_cast<void*>(new_memory_owner.get()));
+        size_type i = 0;
+        try {
+            size_type j = m_begin;
+            while (i < m_size) {
+                new (&new_memory[i]) T(std::move_if_noexcept(memory[j])); // Throws
+                ++i;
+                j = circular_inc(j);
+            }
+        }
+        catch (...) {
+            // If an exception was thrown above, we know that elements were
+            // copied, and not moved (assuming that T is copy constructable if
+            // it is not nothrow move constructible), so we need to back out by
+            // destroying the copies that were already made.
+            for (size_type j = 0; j < i; ++j)
+                new_memory[j].~T();
+            throw;
+        }
+    }
+
+    // Destroy old elements
+    {
+        size_type j = m_begin;
+        for (size_type i = 0; i < m_size; ++i) {
+            memory[j].~T();
+            j = circular_inc(j);
+        }
+    }
+
+    m_memory_owner = std::move(new_memory_owner);
+    m_begin = 0;
+    m_allocated_size = new_allocated_size;
+}
+
+template<class T> inline void swap(CircularBuffer<T>& a, CircularBuffer<T>& b) noexcept
+{
+    a.swap(b);
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_CIRCULAR_BUFFER_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/config.h b/node_modules/realm/vendor/realm-ios/include/realm/util/config.h
new file mode 100644
index 0000000..0ebbbe2
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/config.h
@@ -0,0 +1,23 @@
+// Version information
+#define REALM_VERSION ""
+
+// Specific headers
+#define HAVE_MALLOC_H 0
+
+// Realm-specific configuration
+#define REALM_MAX_BPNODE_SIZE 1000
+#define REALM_ENABLE_ASSERTIONS 1
+#define REALM_ENABLE_ALLOC_SET_ZERO 0
+#define REALM_ENABLE_ENCRYPTION 1
+#define REALM_ENABLE_MEMDEBUG 0
+#define REALM_VALGRIND 0
+#define REALM_METRICS 1
+#define REALM_ASAN 0
+#define REALM_TSAN 0
+
+#define REALM_INSTALL_PREFIX "/usr/local"
+#define REALM_INSTALL_INCLUDEDIR "include"
+#define REALM_INSTALL_BINDIR "bin"
+#define REALM_INSTALL_LIBDIR "lib"
+#define REALM_INSTALL_LIBEXECDIR "libexec"
+#define REALM_INSTALL_EXEC_PREFIX "/usr/local"
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/demangle.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/demangle.hpp
new file mode 100644
index 0000000..7af4fb8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/demangle.hpp
@@ -0,0 +1,54 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_DEMANGLE_HPP
+#define REALM_UTIL_DEMANGLE_HPP
+
+#include <typeinfo>
+#include <string>
+
+namespace realm {
+namespace util {
+
+
+/// Demangle the specified C++ ABI identifier.
+///
+/// See for example
+/// http://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen/namespaceabi.html
+std::string demangle(const std::string&);
+
+
+/// Get the demangled name of the specified type.
+template<class T> inline std::string get_type_name()
+{
+    return demangle(typeid(T).name());
+}
+
+
+/// Get the demangled name of the type of the specified argument.
+template<class T> inline std::string get_type_name(const T& v)
+{
+    return demangle(typeid(v).name());
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_DEMANGLE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/duplicating_logger.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/duplicating_logger.hpp
new file mode 100644
index 0000000..774df3c
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/duplicating_logger.hpp
@@ -0,0 +1,63 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_DUPLICATING_LOGGER_HPP
+#define REALM_UTIL_DUPLICATING_LOGGER_HPP
+
+#include <realm/util/logger.hpp>
+
+
+namespace realm {
+namespace util {
+
+/// The log level threshold of a logger of this type will be decided by the
+/// associated base logger. Therefore, the log level threshold specified via the
+/// auxiliary logger will be ignored.
+///
+/// Loggers of this type are thread-safe if the base logger and the auxiliary
+/// loggers are both thread-safe.
+class DuplicatingLogger : public Logger {
+public:
+    explicit DuplicatingLogger(Logger& base_logger, Logger& aux_logger) noexcept;
+
+protected:
+    void do_log(Logger::Level, std::string message) override;
+
+private:
+    Logger& m_base_logger;
+    Logger& m_aux_logger;
+};
+
+
+
+
+// Implementation
+
+inline DuplicatingLogger::DuplicatingLogger(Logger& base_logger, Logger& aux_logger) noexcept :
+    Logger{base_logger.level_threshold},
+    m_base_logger{base_logger}, m_aux_logger{aux_logger}
+{
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_DUPLICATING_LOGGER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/encrypted_file_mapping.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/encrypted_file_mapping.hpp
new file mode 100644
index 0000000..6f5fd3c
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/encrypted_file_mapping.hpp
@@ -0,0 +1,181 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_ENCRYPTED_FILE_MAPPING_HPP
+#define REALM_UTIL_ENCRYPTED_FILE_MAPPING_HPP
+
+#include <realm/util/file.hpp>
+#include <realm/util/thread.hpp>
+#include <realm/util/features.h>
+
+#if REALM_ENABLE_ENCRYPTION
+
+typedef size_t (*Header_to_size)(const char* addr);
+
+#include <vector>
+
+namespace realm {
+namespace util {
+
+struct SharedFileInfo;
+class EncryptedFileMapping;
+
+class EncryptedFileMapping {
+public:
+    // Adds the newly-created object to file.mappings iff it's successfully constructed
+    EncryptedFileMapping(SharedFileInfo& file, size_t file_offset, void* addr, size_t size, File::AccessMode access);
+    ~EncryptedFileMapping();
+
+    // Default implementations of copy/assign can trigger multiple destructions
+    EncryptedFileMapping(const EncryptedFileMapping&) = delete;
+    EncryptedFileMapping& operator=(const EncryptedFileMapping&) = delete;
+
+    // Write all dirty pages to disk and mark them read-only
+    // Does not call fsync
+    void flush() noexcept;
+
+    // Sync this file to disk
+    void sync() noexcept;
+
+    // Make sure that memory in the specified range is synchronized with any
+    // changes made globally visible through call to write_barrier
+    void read_barrier(const void* addr, size_t size, Header_to_size header_to_size);
+
+    // Ensures that any changes made to memory in the specified range
+    // becomes visible to any later calls to read_barrier()
+    void write_barrier(const void* addr, size_t size) noexcept;
+
+    // Set this mapping to a new address and size
+    // Flushes any remaining dirty pages from the old mapping
+    void set(void* new_addr, size_t new_size, size_t new_file_offset);
+
+    size_t collect_decryption_count()
+    {
+        return m_num_decrypted;
+    }
+    // reclaim any untouched pages - this is thread safe with respect to
+    // concurrent access/touching of pages - but must be called with the mutex locked.
+    void reclaim_untouched(size_t& progress_ptr, size_t& accumulated_savings) noexcept;
+
+    bool contains_page(size_t page_in_file) const;
+    size_t get_local_index_of_address(const void* addr, size_t offset = 0) const;
+
+    size_t get_end_index()
+    {
+        return m_first_page + m_page_state.size();
+    }
+    size_t get_start_index()
+    {
+        return m_first_page;
+    }
+
+private:
+    SharedFileInfo& m_file;
+
+    size_t m_page_shift;
+    size_t m_blocks_per_page;
+
+    void* m_addr = nullptr;
+
+    size_t m_first_page;
+    size_t m_num_decrypted; // 1 for every page decrypted
+
+    enum PageState {
+        Touched = 1,           // a ref->ptr translation has taken place
+        UpToDate = 2,          // the page is fully up to date
+        PartiallyUpToDate = 4, // the page is valid for old translations, but requires re-decryption for new
+        Dirty = 8              // the page has been modified with respect to what's on file.
+    };
+    std::vector<PageState> m_page_state;
+    // little helpers:
+    inline void clear(PageState& ps, int p)
+    {
+        ps = PageState(ps & ~p);
+    }
+    inline bool is_not(PageState& ps, int p)
+    {
+        return (ps & p) == 0;
+    }
+    inline bool is(PageState& ps, int p)
+    {
+        return (ps & p) != 0;
+    }
+    inline void set(PageState& ps, int p)
+    {
+        ps = PageState(ps | p);
+    }
+    // 1K pages form a chunk - this array allows us to skip entire chunks during scanning
+    std::vector<bool> m_chunk_dont_scan;
+    static constexpr int page_to_chunk_shift = 10;
+    static constexpr size_t page_to_chunk_factor = size_t(1) << page_to_chunk_shift;
+
+    File::AccessMode m_access;
+
+#ifdef REALM_DEBUG
+    std::unique_ptr<char[]> m_validate_buffer;
+#endif
+
+    char* page_addr(size_t local_page_ndx) const noexcept;
+
+    void mark_outdated(size_t local_page_ndx) noexcept;
+    bool copy_up_to_date_page(size_t local_page_ndx) noexcept;
+    void refresh_page(size_t local_page_ndx);
+    void write_page(size_t local_page_ndx) noexcept;
+    void write_and_update_all(size_t local_page_ndx, size_t begin_offset, size_t end_offset) noexcept;
+    void reclaim_page(size_t page_ndx);
+    void validate_page(size_t local_page_ndx) noexcept;
+    void validate() noexcept;
+};
+
+inline size_t EncryptedFileMapping::get_local_index_of_address(const void* addr, size_t offset) const
+{
+    REALM_ASSERT_EX(addr >= m_addr, addr, m_addr);
+
+    size_t local_ndx = ((reinterpret_cast<uintptr_t>(addr) - reinterpret_cast<uintptr_t>(m_addr) + offset) >> m_page_shift);
+    REALM_ASSERT_EX(local_ndx < m_page_state.size(), local_ndx, m_page_state.size());
+    return local_ndx;
+}
+
+inline bool EncryptedFileMapping::contains_page(size_t page_in_file) const
+{
+    // first check for (page_in_file >= m_first_page) so that the following
+    // subtraction using unsigned types never wraps under 0
+    return page_in_file >= m_first_page && page_in_file - m_first_page < m_page_state.size();
+}
+
+
+}
+}
+
+#endif // REALM_ENABLE_ENCRYPTION
+
+namespace realm {
+namespace util {
+
+/// Thrown by EncryptedFileMapping if a file opened is non-empty and does not
+/// contain valid encrypted data
+struct DecryptionFailed : util::File::AccessError {
+    DecryptionFailed()
+        : util::File::AccessError("Decryption failed", std::string())
+    {
+    }
+};
+}
+}
+
+#endif // REALM_UTIL_ENCRYPTED_FILE_MAPPING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/enum.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/enum.hpp
new file mode 100644
index 0000000..c11d166
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/enum.hpp
@@ -0,0 +1,224 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_ENUM_HPP
+#define REALM_UTIL_ENUM_HPP
+
+#include <map>
+#include <string>
+#include <ios>
+#include <locale>
+
+
+namespace realm {
+namespace util {
+
+/// This template class allows you to endow a fundamental `enum` type with
+/// information about how to print out the individual values, and how to parse
+/// them.
+///
+/// Here is an example:
+///
+///     // Declaration
+///
+///     enum class Color { orange, purple, brown };
+///
+///     struct ColorSpec { static EnumAssoc map[]; };
+///     using ColorEnum = Enum<Color, ColorSpec>;
+///
+///     // Implementation
+///
+///     EnumAssoc ColorSpec::map[] = {
+///         { int(Color::orange), "orange" },
+///         { int(Color::purple), "purple" },
+///         { int(Color::brown),  "brown"  },
+///         { 0, 0 }
+///     };
+///
+///     // Application
+///
+///     ColorEnum color = Color::purple;
+///
+///     std::cout << color;  // Write a color
+///     std::cin  >> color;  // Read a color
+///
+/// The current implementation is restricted to enumeration types whose values
+/// can all be represented in a regular integer.
+template<class E, class S, bool ignore_case = false> class Enum {
+public:
+    using base_enum_type = E;
+
+    Enum(E = {}) noexcept;
+
+    operator E() const noexcept;
+
+    const std::string& str() const;
+
+    bool str(const std::string*&) const noexcept;
+
+    /// \return True if, and only if successful.
+    static bool parse(const std::string& string, E& value);
+
+private:
+    E m_value = E{};
+};
+
+template<class C, class T, class E, class S, bool ignore_case>
+std::basic_ostream<C,T>& operator<<(std::basic_ostream<C,T>&,
+                                    const Enum<E, S, ignore_case>&);
+
+template<class C, class T, class E, class S, bool ignore_case>
+std::basic_istream<C,T>& operator>>(std::basic_istream<C,T>&,
+                                    Enum<E, S, ignore_case>&);
+
+
+struct EnumAssoc {
+    const int value;
+    const char* const name;
+};
+
+
+
+
+// Implementation
+
+} // namespace util
+
+namespace _impl {
+
+class EnumMapper {
+public:
+    EnumMapper(const util::EnumAssoc*, bool ignore_case);
+
+    bool parse(const std::string& string, int& value, bool ignore_case) const;
+
+    std::map<int, std::string> value_to_name;
+    std::map<std::string, int> name_to_value;
+};
+
+template<class S, bool ignore_case> const EnumMapper& get_enum_mapper()
+{
+    static EnumMapper mapper{S::map, ignore_case}; // Throws
+    return mapper;
+}
+
+} // namespace _impl
+
+namespace util {
+
+template<class E, class S, bool ignore_case>
+inline Enum<E, S, ignore_case>::Enum(E value) noexcept :
+    m_value{value}
+{
+}
+
+template<class E, class S, bool ignore_case>
+inline Enum<E, S, ignore_case>::operator E() const noexcept
+{
+    return m_value;
+}
+
+template<class E, class S, bool ignore_case>
+inline const std::string& Enum<E, S, ignore_case>::str() const
+{
+    return _impl::get_enum_mapper<S, ignore_case>().val_to_name.at(m_value); // Throws
+}
+
+template<class E, class S, bool ignore_case>
+inline bool Enum<E, S, ignore_case>::str(const std::string*& string) const noexcept
+{
+    const auto& value_to_name = _impl::get_enum_mapper<S, ignore_case>().value_to_name;
+    auto i = value_to_name.find(int(m_value));
+    if (i == value_to_name.end())
+        return false;
+    string = &i->second;
+    return true;
+}
+
+template<class E, class S, bool ignore_case>
+inline bool Enum<E, S, ignore_case>::parse(const std::string& string, E& value)
+{
+    int value_2;
+    if (!_impl::get_enum_mapper<S, ignore_case>().parse(string, value_2, ignore_case)) // Throws
+        return false;
+    value = E(value_2);
+    return true;
+}
+
+template<class C, class T, class E, class S, bool ignore_case>
+inline std::basic_ostream<C,T>& operator<<(std::basic_ostream<C,T>& out,
+                                           const Enum<E, S, ignore_case>& e)
+{
+    const std::string* string;
+    if (e.str(string)) {
+        out << *string;
+    }
+    else {
+        out << int(E(e));
+    }
+    return out;
+}
+
+template<class C, class T, class E, class S, bool ignore_case>
+std::basic_istream<C,T>& operator>>(std::basic_istream<C,T>& in,
+                                    Enum<E, S, ignore_case>& e)
+{
+    if (in.bad() || in.fail())
+        return in;
+    std::string string;
+    const std::ctype<C>& ctype = std::use_facet<std::ctype<C>>(in.getloc());
+    C underscore(ctype.widen('_'));
+    for (;;) {
+        C ch;
+        // Allow white-spaces to be skipped when stream is configured
+        // that way
+        if (string.empty()) {
+            in >> ch;
+        }
+        else {
+            in.get(ch);
+        }
+        if (!in) {
+            if (in.bad())
+                return in;
+            in.clear(in.rdstate() & ~std::ios_base::failbit);
+            break;
+        }
+        if (!ctype.is(std::ctype_base::alnum, ch) && ch != underscore) {
+            in.unget();
+            break;
+        }
+        char ch_2 = ctype.narrow(ch, '\0');
+        string += ch_2;
+    }
+    E value = E{};
+    if (!Enum<E, S, ignore_case>::parse(string, value)) { // Throws
+        in.setstate(std::ios_base::badbit);
+    }
+    else {
+        e = value;
+    }
+    return in;
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_ENUM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/errno.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/errno.hpp
new file mode 100644
index 0000000..4907f36
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/errno.hpp
@@ -0,0 +1,39 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_ERRNO_HPP
+#define REALM_UTIL_ERRNO_HPP
+
+#include <string>
+
+#include <realm/util/basic_system_errors.hpp>
+
+
+namespace realm {
+namespace util {
+
+// Get the error message for a given error code, and append it to `prefix`
+inline std::string get_errno_msg(const char* prefix, int err)
+{
+    return prefix + make_basic_system_error_code(err).message();
+}
+
+} // namespace util
+} // namespace realm
+
+#endif
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/features.h b/node_modules/realm/vendor/realm-ios/include/realm/util/features.h
new file mode 100644
index 0000000..ed6d55a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/features.h
@@ -0,0 +1,344 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_FEATURES_H
+#define REALM_UTIL_FEATURES_H
+
+#ifdef _MSC_VER
+#pragma warning(disable : 4800) // Visual Studio int->bool performance warnings
+#endif
+
+#if defined(_WIN32) && !defined(NOMINMAX)
+#define NOMINMAX
+#endif
+
+#ifndef REALM_NO_CONFIG
+#include <realm/util/config.h>
+#endif
+
+/* The maximum number of elements in a B+-tree node. Applies to inner nodes and
+ * to leaves. The minimum allowable value is 2.
+ */
+#ifndef REALM_MAX_BPNODE_SIZE
+#define REALM_MAX_BPNODE_SIZE 1000
+#endif
+
+
+#define REALM_QUOTE_2(x) #x
+#define REALM_QUOTE(x) REALM_QUOTE_2(x)
+
+/* See these links for information about feature check macroes in GCC,
+ * Clang, and MSVC:
+ *
+ * http://gcc.gnu.org/projects/cxx0x.html
+ * http://clang.llvm.org/cxx_status.html
+ * http://clang.llvm.org/docs/LanguageExtensions.html#checks-for-standard-language-features
+ * http://msdn.microsoft.com/en-us/library/vstudio/hh567368.aspx
+ * http://sourceforge.net/p/predef/wiki/Compilers
+ */
+
+
+/* Compiler is GCC and version is greater than or equal to the specified version */
+#define REALM_HAVE_AT_LEAST_GCC(maj, min) \
+    (__GNUC__ > (maj) || __GNUC__ == (maj) && __GNUC_MINOR__ >= (min))
+
+#if defined(__clang__)
+#define REALM_HAVE_CLANG_FEATURE(feature) __has_feature(feature)
+#define REALM_HAVE_CLANG_WARNING(warning) __has_warning(warning)
+#else
+#define REALM_HAVE_CLANG_FEATURE(feature) 0
+#define REALM_HAVE_CLANG_WARNING(warning) 0
+#endif
+
+#ifdef __has_cpp_attribute
+#define REALM_HAS_CPP_ATTRIBUTE(attr) __has_cpp_attribute(attr)
+#else
+#define REALM_HAS_CPP_ATTRIBUTE(attr) 0
+#endif
+
+#if REALM_HAS_CPP_ATTRIBUTE(clang::fallthrough)
+#define REALM_FALLTHROUGH [[clang::fallthrough]]
+#elif REALM_HAS_CPP_ATTRIBUTE(gnu::fallthrough)
+#define REALM_FALLTHROUGH [[gnu::fallthrough]]
+#elif REALM_HAS_CPP_ATTRIBUTE(fallthrough)
+#define REALM_FALLTHROUGH [[fallthrough]]
+#else
+#define REALM_FALLTHROUGH
+#endif
+
+// This should be renamed to REALM_UNREACHABLE as soon as REALM_UNREACHABLE is renamed to
+// REALM_ASSERT_NOT_REACHED which will better reflect its nature
+#if defined(__GNUC__) || defined(__clang__)
+#define REALM_COMPILER_HINT_UNREACHABLE __builtin_unreachable
+#else
+#define REALM_COMPILER_HINT_UNREACHABLE abort
+#endif
+
+#if defined(__GNUC__) // clang or GCC
+#define REALM_PRAGMA(v) _Pragma(REALM_QUOTE_2(v))
+#elif defined(_MSC_VER) // VS
+#define REALM_PRAGMA(v) __pragma(v)
+#else
+#define REALM_PRAGMA(v)
+#endif
+
+#if defined(__clang__)
+#define REALM_DIAG(v) REALM_PRAGMA(clang diagnostic v)
+#elif defined(__GNUC__)
+#define REALM_DIAG(v) REALM_PRAGMA(GCC diagnostic v)
+#else
+#define REALM_DIAG(v)
+#endif
+
+#define REALM_DIAG_PUSH() REALM_DIAG(push)
+#define REALM_DIAG_POP() REALM_DIAG(pop)
+
+#ifdef _MSC_VER
+#define REALM_VS_WARNING_DISABLE #pragma warning (default: 4297)
+#endif
+
+#if REALM_HAVE_CLANG_WARNING("-Wtautological-compare") || REALM_HAVE_AT_LEAST_GCC(6, 0)
+#define REALM_DIAG_IGNORE_TAUTOLOGICAL_COMPARE() REALM_DIAG(ignored "-Wtautological-compare")
+#else
+#define REALM_DIAG_IGNORE_TAUTOLOGICAL_COMPARE()
+#endif
+
+#ifdef _MSC_VER
+#  define REALM_DIAG_IGNORE_UNSIGNED_MINUS() REALM_PRAGMA(warning(disable:4146))
+#else
+#define REALM_DIAG_IGNORE_UNSIGNED_MINUS()
+#endif
+
+/* Compiler is MSVC (Microsoft Visual C++) */
+#if defined(_MSC_VER) && _MSC_VER >= 1600
+#define REALM_HAVE_AT_LEAST_MSVC_10_2010 1
+#endif
+#if defined(_MSC_VER) && _MSC_VER >= 1700
+#define REALM_HAVE_AT_LEAST_MSVC_11_2012 1
+#endif
+#if defined(_MSC_VER) && _MSC_VER >= 1800
+#define REALM_HAVE_AT_LEAST_MSVC_12_2013 1
+#endif
+
+
+/* The way to specify that a function never returns. */
+#if REALM_HAVE_AT_LEAST_GCC(4, 8) || REALM_HAVE_CLANG_FEATURE(cxx_attributes)
+#define REALM_NORETURN [[noreturn]]
+#elif __GNUC__
+#define REALM_NORETURN __attribute__((noreturn))
+#elif defined(_MSC_VER)
+#define REALM_NORETURN __declspec(noreturn)
+#else
+#define REALM_NORETURN
+#endif
+
+
+/* The way to specify that a variable or type is intended to possibly
+ * not be used. Use it to suppress a warning from the compiler. */
+#if __GNUC__
+#define REALM_UNUSED __attribute__((unused))
+#else
+#define REALM_UNUSED
+#endif
+
+/* The way to specify that a function is deprecated
+ * not be used. Use it to suppress a warning from the compiler. */
+#if __GNUC__
+#define REALM_DEPRECATED(x) [[deprecated(x)]]
+#else
+#define REALM_DEPRECATED(x) __declspec(deprecated(x))
+#endif
+
+
+#if __GNUC__ || defined __INTEL_COMPILER
+#define REALM_UNLIKELY(expr) __builtin_expect(!!(expr), 0)
+#define REALM_LIKELY(expr) __builtin_expect(!!(expr), 1)
+#else
+#define REALM_UNLIKELY(expr) (expr)
+#define REALM_LIKELY(expr) (expr)
+#endif
+
+
+#if defined(__GNUC__) || defined(__HP_aCC)
+#define REALM_FORCEINLINE inline __attribute__((always_inline))
+#elif defined(_MSC_VER)
+#define REALM_FORCEINLINE __forceinline
+#else
+#define REALM_FORCEINLINE inline
+#endif
+
+
+#if defined(__GNUC__) || defined(__HP_aCC)
+#define REALM_NOINLINE __attribute__((noinline))
+#elif defined(_MSC_VER)
+#define REALM_NOINLINE __declspec(noinline)
+#else
+#define REALM_NOINLINE
+#endif
+
+
+// FIXME: Change this to use [[nodiscard]] in C++17.
+#if defined(__GNUC__) || defined(__HP_aCC)
+#define REALM_NODISCARD __attribute__((warn_unused_result))
+#elif defined(_MSC_VER)
+#define REALM_NODISCARD _Check_return_
+#else
+#define REALM_NODISCARD
+#endif
+
+
+/* Thread specific data (only for POD types) */
+#if defined __clang__
+#define REALM_THREAD_LOCAL __thread
+#else
+#define REALM_THREAD_LOCAL thread_local
+#endif
+
+
+#if defined ANDROID
+#define REALM_ANDROID 1
+#else
+#define REALM_ANDROID 0
+#endif
+
+#if defined _WIN32
+#  include <winapifamily.h>
+#  if WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_DESKTOP | WINAPI_PARTITION_SYSTEM)
+#    define REALM_WINDOWS 1
+#    define REALM_UWP 0
+#  elif WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_APP)
+#    define REALM_WINDOWS 0
+#    define REALM_UWP 1
+#  endif
+#else
+#define REALM_WINDOWS 0
+#define REALM_UWP 0
+#endif
+
+// Some documentation of the defines provided by Apple:
+// http://developer.apple.com/library/mac/documentation/Porting/Conceptual/PortingUnix/compiling/compiling.html#//apple_ref/doc/uid/TP40002850-SW13
+#if defined __APPLE__ && defined __MACH__
+#define REALM_PLATFORM_APPLE 1
+/* Apple OSX and iOS (Darwin). */
+#include <Availability.h>
+#include <TargetConditionals.h>
+#if TARGET_OS_IPHONE == 1
+/* Device (iPhone or iPad) or simulator. */
+#define REALM_IOS 1
+#else
+#define REALM_IOS 0
+#endif
+#if TARGET_OS_WATCH == 1
+/* Device (Apple Watch) or simulator. */
+#define REALM_WATCHOS 1
+#else
+#define REALM_WATCHOS 0
+#endif
+#if TARGET_OS_TV
+/* Device (Apple TV) or simulator. */
+#define REALM_TVOS 1
+#else
+#define REALM_TVOS 0
+#endif
+#else
+#define REALM_PLATFORM_APPLE 0
+#define REALM_IOS 0
+#define REALM_WATCHOS 0
+#define REALM_TVOS 0
+#endif
+
+// asl_log is deprecated in favor of os_log as of the following versions:
+// macos(10.12), ios(10.0), watchos(3.0), tvos(10.0)
+// versions are defined in /usr/include/Availability.h
+// __MAC_10_12   101200
+// __IPHONE_10_0 100000
+// __WATCHOS_3_0  30000
+// __TVOS_10_0   100000
+#if REALM_PLATFORM_APPLE \
+    && ( \
+        (REALM_IOS && defined(__IPHONE_OS_VERSION_MIN_REQUIRED) \
+         && __IPHONE_OS_VERSION_MIN_REQUIRED >= 100000) \
+     || (REALM_TVOS && defined(__TV_OS_VERSION_MIN_REQUIRED) \
+         &&  __TV_OS_VERSION_MIN_REQUIRED >= 100000) \
+     || (REALM_WATCHOS && defined(__WATCH_OS_VERSION_MIN_REQUIRED) \
+         && __WATCH_OS_VERSION_MIN_REQUIRED >= 30000) \
+     || (defined(__MAC_OS_X_VERSION_MIN_REQUIRED) \
+         && __MAC_OS_X_VERSION_MIN_REQUIRED >= 101200) \
+       )
+#define REALM_APPLE_OS_LOG 1
+#else
+#define REALM_APPLE_OS_LOG 0
+#endif
+
+#if REALM_ANDROID || REALM_IOS || REALM_WATCHOS || REALM_TVOS || REALM_UWP
+#define REALM_MOBILE 1
+#else
+#define REALM_MOBILE 0
+#endif
+
+
+#if defined(REALM_DEBUG) && !defined(REALM_COOKIE_CHECK)
+#define REALM_COOKIE_CHECK
+#endif
+
+#if !REALM_IOS && !REALM_WATCHOS && !REALM_TVOS && !defined(_WIN32) && !REALM_ANDROID
+#define REALM_ASYNC_DAEMON
+#endif
+
+// We're in i686 mode
+#if defined(__i386) || defined(__i386__) || defined(__i686__) || defined(_M_I86) || defined(_M_IX86)
+#define REALM_ARCHITECTURE_X86_32 1
+#else
+#define REALM_ARCHITECTURE_X86_32 0
+#endif
+
+// We're in amd64 mode
+#if defined(__amd64) || defined(__amd64__) || defined(__x86_64) || defined(__x86_64__) || defined(_M_X64) || \
+    defined(_M_AMD64)
+#define REALM_ARCHITECTURE_X86_64 1
+#else
+#define REALM_ARCHITECTURE_X86_64 0
+#endif
+
+// Address Sanitizer
+#if defined(__has_feature) // Clang
+#  if __has_feature(address_sanitizer)
+#    define REALM_SANITIZE_ADDRESS 1
+#  else
+#    define REALM_SANITIZE_ADDRESS 0
+#  endif
+#elif defined(__SANITIZE_ADDRESS__) && __SANITIZE_ADDRESS__ // GCC
+#  define REALM_SANITIZE_ADDRESS 1
+#else
+#  define REALM_SANITIZE_ADDRESS 0
+#endif
+
+// Thread Sanitizer
+#if defined(__has_feature) // Clang
+#  if __has_feature(thread_sanitizer)
+#    define REALM_SANITIZE_THREAD 1
+#  else
+#    define REALM_SANITIZE_THREAD 0
+#  endif
+#elif defined(__SANITIZE_THREAD__) && __SANITIZE_THREAD__ // GCC
+#  define REALM_SANITIZE_THREAD 1
+#else
+#  define REALM_SANITIZE_THREAD 0
+#endif
+
+#endif /* REALM_UTIL_FEATURES_H */
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/fifo_helper.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/fifo_helper.hpp
new file mode 100644
index 0000000..6ca8d75
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/fifo_helper.hpp
@@ -0,0 +1,43 @@
+/*************************************************************************
+ *
+ * Copyright 2019 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_FIFO_HELPER_HPP
+#define REALM_UTIL_FIFO_HELPER_HPP
+
+#include <string>
+
+namespace realm {
+namespace util {
+
+// Attempts to create a FIFO file at the location determined by `path`.
+// If creating the FIFO at this location fails, an exception is thrown.
+// If a FIFO already exists at the given location, this method does nothing.
+void create_fifo(std::string path); // throws
+
+// Same as above, but returns `false` if the FIFO could not be created instead of throwing.
+bool try_create_fifo(const std::string& path);
+
+// Ensure that a path representing a directory ends with `/`
+inline std::string normalize_dir(const std::string& path) {
+    return (!path.empty() && path.back() != '/') ? path + '/' : path;
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_FIFO_HELPER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/file.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/file.hpp
new file mode 100644
index 0000000..797dd88
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/file.hpp
@@ -0,0 +1,1330 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_FILE_HPP
+#define REALM_UTIL_FILE_HPP
+
+#include <cstddef>
+#include <cstdint>
+#include <memory>
+#include <functional>
+#include <stdexcept>
+#include <string>
+#include <streambuf>
+#include <iostream>
+
+#ifndef _WIN32
+#include <dirent.h> // POSIX.1-2001
+#endif
+
+#if defined(_MSC_VER) && _MSC_VER >= 1900 // compiling with at least Visual Studio 2015
+#include <experimental/filesystem>
+namespace std {
+    namespace filesystem = std::experimental::filesystem::v1;
+}
+#define REALM_HAVE_STD_FILESYSTEM 1
+#else
+#define REALM_HAVE_STD_FILESYSTEM 0
+#endif
+
+#include <realm/utilities.hpp>
+#include <realm/util/backtrace.hpp>
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/safe_int_ops.hpp>
+
+
+namespace realm {
+namespace util {
+
+class EncryptedFileMapping;
+
+/// Create the specified directory in the file system.
+///
+/// \throw File::AccessError If the directory could not be created. If
+/// the reason corresponds to one of the exception types that are
+/// derived from File::AccessError, the derived exception type is
+/// thrown (as long as the underlying system provides the information
+/// to unambiguously distinguish that particular reason).
+void make_dir(const std::string& path);
+
+/// Same as make_dir() except that this one returns false, rather than throwing
+/// an exception, if the specified directory already existed. If the directory
+// did not already exist and was newly created, this returns true.
+bool try_make_dir(const std::string& path);
+
+/// Remove the specified empty directory path from the file system. It is an
+/// error if the specified path is not a directory, or if it is a nonempty
+/// directory. In so far as the specified path is a directory, std::remove(const
+/// char*) is equivalent to this function.
+///
+/// \throw File::AccessError If the directory could not be removed. If the
+/// reason corresponds to one of the exception types that are derived from
+/// File::AccessError, the derived exception type is thrown (as long as the
+/// underlying system provides the information to unambiguously distinguish that
+/// particular reason).
+void remove_dir(const std::string& path);
+
+/// Same as remove_dir() except that this one returns false, rather
+/// than throwing an exception, if the specified directory did not
+/// exist. If the directory did exist, and was deleted, this function
+/// returns true.
+bool try_remove_dir(const std::string& path);
+
+/// Remove the specified directory after removing all its contents. Files
+/// (nondirectory entries) will be removed as if by a call to File::remove(),
+/// and empty directories as if by a call to remove_dir().
+///
+/// \throw File::AccessError If removal of the directory, or any of its contents
+/// fail.
+///
+/// remove_dir_recursive() assumes that no other process or thread is making
+/// simultaneous changes in the directory.
+void remove_dir_recursive(const std::string& path);
+
+/// Same as remove_dir_recursive() except that this one returns false, rather
+/// than throwing an exception, if the specified directory did not
+/// exist. If the directory did exist, and was deleted, this function
+/// returns true.
+///
+/// try_remove_dir_recursive() assumes that no other process or thread is making
+/// simultaneous changes in the directory.
+bool try_remove_dir_recursive(const std::string& path);
+
+/// Create a new unique directory for temporary files. The absolute
+/// path to the new directory is returned without a trailing slash.
+std::string make_temp_dir();
+
+size_t page_size();
+
+
+/// This class provides a RAII abstraction over the concept of a file
+/// descriptor (or file handle).
+///
+/// Locks are automatically and immediately released when the File
+/// instance is closed.
+///
+/// You can use CloseGuard and UnlockGuard to acheive exception-safe
+/// closing or unlocking prior to the File instance being detroyed.
+///
+/// A single File instance must never be accessed concurrently by
+/// multiple threads.
+///
+/// You can write to a file via an std::ostream as follows:
+///
+/// \code{.cpp}
+///
+///   File::Streambuf my_streambuf(&my_file);
+///   std::ostream out(&my_strerambuf);
+///   out << 7945.9;
+///
+/// \endcode
+class File {
+public:
+    enum Mode {
+        mode_Read,   ///< access_ReadOnly,  create_Never             (fopen: rb)
+        mode_Update, ///< access_ReadWrite, create_Never             (fopen: rb+)
+        mode_Write,  ///< access_ReadWrite, create_Auto, flag_Trunc  (fopen: wb+)
+        mode_Append  ///< access_ReadWrite, create_Auto, flag_Append (fopen: ab+)
+    };
+
+    /// Equivalent to calling open(const std::string&, Mode) on a
+    /// default constructed instance.
+    explicit File(const std::string& path, Mode = mode_Read);
+
+    /// Create an instance that is not initially attached to an open
+    /// file.
+    File() noexcept;
+
+    ~File() noexcept;
+
+    File(File&&) noexcept;
+    File& operator=(File&&) noexcept;
+
+    // Disable copying by l-value. Copying an open file will create a scenario
+    // where the same file descriptor will be opened once but closed twice.
+    File(const File&) = delete;
+    File& operator=(const File&) = delete;
+
+    /// Calling this function on an instance that is already attached
+    /// to an open file has undefined behavior.
+    ///
+    /// \throw AccessError If the file could not be opened. If the
+    /// reason corresponds to one of the exception types that are
+    /// derived from AccessError, the derived exception type is thrown
+    /// (as long as the underlying system provides the information to
+    /// unambiguously distinguish that particular reason).
+    void open(const std::string& path, Mode = mode_Read);
+
+    /// This function is idempotent, that is, it is valid to call it
+    /// regardless of whether this instance currently is attached to
+    /// an open file.
+    void close() noexcept;
+
+    /// Check whether this File instance is currently attached to an
+    /// open file.
+    bool is_attached() const noexcept;
+
+    enum AccessMode {
+        access_ReadOnly,
+        access_ReadWrite,
+    };
+
+    enum CreateMode {
+        create_Auto,  ///< Create the file if it does not already exist.
+        create_Never, ///< Fail if the file does not already exist.
+        create_Must   ///< Fail if the file already exists.
+    };
+
+    enum {
+        flag_Trunc = 1, ///< Truncate the file if it already exists.
+        flag_Append = 2 ///< Move to end of file before each write.
+    };
+
+    /// See open(const std::string&, Mode).
+    ///
+    /// Specifying access_ReadOnly together with a create mode that is
+    /// not create_Never, or together with a non-zero \a flags
+    /// argument, results in undefined behavior. Specifying flag_Trunc
+    /// together with create_Must results in undefined behavior.
+    void open(const std::string& path, AccessMode, CreateMode, int flags);
+
+    /// Same as open(path, access_ReadWrite, create_Auto, 0), except
+    /// that this one returns an indication of whether a new file was
+    /// created, or an existing file was opened.
+    void open(const std::string& path, bool& was_created);
+
+    /// Read data into the specified buffer and return the number of
+    /// bytes read. If the returned number of bytes is less than \a
+    /// size, then the end of the file has been reached.
+    ///
+    /// Calling this function on an instance, that is not currently
+    /// attached to an open file, has undefined behavior.
+    size_t read(char* data, size_t size);
+    static size_t read_static(FileDesc fd, char* data, size_t size);
+
+    /// Write the specified data to this file.
+    ///
+    /// Calling this function on an instance, that is not currently
+    /// attached to an open file, has undefined behavior.
+    ///
+    /// Calling this function on an instance, that was opened in
+    /// read-only mode, has undefined behavior.
+    void write(const char* data, size_t size);
+    static void write_static(FileDesc fd, const char* data, size_t size);
+
+    // Tells current file pointer of fd
+    static uint64_t get_file_pos(FileDesc fd);
+
+    /// Calls write(s.data(), s.size()).
+    void write(const std::string& s)
+    {
+        write(s.data(), s.size());
+    }
+
+    /// Calls read(data, N).
+    template <size_t N>
+    size_t read(char (&data)[N])
+    {
+        return read(data, N);
+    }
+
+    /// Calls write(data(), N).
+    template <size_t N>
+    void write(const char (&data)[N])
+    {
+        write(data, N);
+    }
+
+    /// Plays the same role as off_t in POSIX
+    typedef int_fast64_t SizeType;
+
+    /// Calling this function on an instance that is not attached to
+    /// an open file has undefined behavior.
+    SizeType get_size() const;
+    static SizeType get_size_static(FileDesc fd);
+
+    /// If this causes the file to grow, then the new section will
+    /// have undefined contents. Setting the size with this function
+    /// does not necessarily allocate space on the target device. If
+    /// you want to ensure allocation, call alloc(). Calling this
+    /// function will generally affect the read/write offset
+    /// associated with this File instance.
+    ///
+    /// Calling this function on an instance that is not attached to
+    /// an open file has undefined behavior. Calling this function on
+    /// a file that is opened in read-only mode, is an error.
+    void resize(SizeType);
+
+    /// Same effect as prealloc_if_supported(original_size, new_size);
+    ///
+    /// The downside is that this function is not guaranteed to have
+    /// atomic behaviour on all systems, that is, two processes, or
+    /// two threads should never call this function concurrently for
+    /// the same underlying file even though they access the file
+    /// through distinct File instances.
+    ///
+    /// \sa prealloc_if_supported()
+    void prealloc(size_t new_size);
+
+    /// When supported by the system, allocate space on the target
+    /// device for the specified region of the file. If the region
+    /// extends beyond the current end of the file, the file size is
+    /// increased as necessary.
+    ///
+    /// On systems that do not support this operation, this function
+    /// has no effect. You may call is_prealloc_supported() to
+    /// determine if it is supported on your system.
+    ///
+    /// Calling this function on an instance, that is not attached to
+    /// an open file, has undefined behavior. Calling this function on
+    /// a file, that is opened in read-only mode, is an error.
+    ///
+    /// This function is guaranteed to have atomic behaviour, that is,
+    /// there is never any risk of the file size being reduced even
+    /// with concurrently executing invocations.
+    ///
+    /// \sa prealloc()
+    /// \sa is_prealloc_supported()
+    bool prealloc_if_supported(SizeType offset, size_t size);
+
+    /// See prealloc_if_supported().
+    static bool is_prealloc_supported();
+
+    /// Reposition the read/write offset of this File
+    /// instance. Distinct File instances have separate independent
+    /// offsets, as long as the cucrrent process is not forked.
+    void seek(SizeType);
+    static void seek_static(FileDesc, SizeType);
+
+    /// Flush in-kernel buffers to disk. This blocks the caller until the
+    /// synchronization operation is complete. On POSIX systems this function
+    /// calls `fsync()`. On Apple platforms if calls `fcntl()` with command
+    /// `F_FULLFSYNC`.
+    void sync();
+
+    /// Place an exclusive lock on this file. This blocks the caller
+    /// until all other locks have been released.
+    ///
+    /// Locks acquired on distinct File instances have fully recursive
+    /// behavior, even if they are acquired in the same process (or
+    /// thread) and are attached to the same underlying file.
+    ///
+    /// Calling this function on an instance that is not attached to
+    /// an open file, or on an instance that is already locked has
+    /// undefined behavior.
+    void lock_exclusive();
+
+    /// Place an shared lock on this file. This blocks the caller
+    /// until all other exclusive locks have been released.
+    ///
+    /// Locks acquired on distinct File instances have fully recursive
+    /// behavior, even if they are acquired in the same process (or
+    /// thread) and are attached to the same underlying file.
+    ///
+    /// Calling this function on an instance that is not attached to
+    /// an open file, or on an instance that is already locked has
+    /// undefined behavior.
+    void lock_shared();
+
+    /// Non-blocking version of lock_exclusive(). Returns true iff it
+    /// succeeds.
+    bool try_lock_exclusive();
+
+    /// Non-blocking version of lock_shared(). Returns true iff it
+    /// succeeds.
+    bool try_lock_shared();
+
+    /// Release a previously acquired lock on this file. This function
+    /// is idempotent.
+    void unlock() noexcept;
+
+    /// Set the encryption key used for this file. Must be called before any
+    /// mappings are created or any data is read from or written to the file.
+    ///
+    /// \param key A 64-byte encryption key, or null to disable encryption.
+    void set_encryption_key(const char* key);
+
+    /// Get the encryption key set by set_encryption_key(),
+    /// null_ptr if no key set.
+    const char* get_encryption_key();
+    enum {
+        /// If possible, disable opportunistic flushing of dirted
+        /// pages of a memory mapped file to physical medium. On some
+        /// systems this cannot be disabled. On other systems it is
+        /// the default behavior. An explicit call to sync_map() will
+        /// flush the buffers regardless of whether this flag is
+        /// specified or not.
+        map_NoSync = 1
+    };
+
+    /// Map this file into memory. The file is mapped as shared
+    /// memory. This allows two processes to interact under exatly the
+    /// same rules as applies to the interaction via regular memory of
+    /// multiple threads inside a single process.
+    ///
+    /// This File instance does not need to remain in existence after
+    /// the mapping is established.
+    ///
+    /// Multiple concurrent mappings may be created from the same File
+    /// instance.
+    ///
+    /// Specifying access_ReadWrite for a file that is opened in
+    /// read-only mode, is an error.
+    ///
+    /// Calling this function on an instance that is not attached to
+    /// an open file, or one that is attached to an empty file has
+    /// undefined behavior.
+    ///
+    /// Calling this function with a size that is greater than the
+    /// size of the file has undefined behavior.
+    void* map(AccessMode, size_t size, int map_flags = 0, size_t offset = 0) const;
+
+    /// The same as unmap(old_addr, old_size) followed by map(a,
+    /// new_size, map_flags), but more efficient on some systems.
+    ///
+    /// The old address range must have been acquired by a call to
+    /// map() or remap() on this File instance, the specified access
+    /// mode and flags must be the same as the ones specified
+    /// previously, and this File instance must not have been reopend
+    /// in the meantime. Failing to adhere to these rules will result
+    /// in undefined behavior.
+    ///
+    /// If this function throws, the old address range will remain
+    /// mapped.
+    void* remap(void* old_addr, size_t old_size, AccessMode a, size_t new_size, int map_flags = 0,
+                size_t file_offset = 0) const;
+
+#if REALM_ENABLE_ENCRYPTION
+    void* map(AccessMode, size_t size, EncryptedFileMapping*& mapping, int map_flags = 0, size_t offset = 0) const;
+#endif
+    /// Unmap the specified address range which must have been
+    /// previously returned by map().
+    static void unmap(void* addr, size_t size) noexcept;
+
+    /// Flush in-kernel buffers to disk. This blocks the caller until
+    /// the synchronization operation is complete. The specified
+    /// address range must be (a subset of) one that was previously returned by
+    /// map().
+    static void sync_map(FileDesc fd, void* addr, size_t size);
+
+    /// Check whether the specified file or directory exists. Note
+    /// that a file or directory that resides in a directory that the
+    /// calling process has no access to, will necessarily be reported
+    /// as not existing.
+    static bool exists(const std::string& path);
+
+    /// Check whether the specified path exists and refers to a directory. If
+    /// the referenced file system object resides in an inaccessible directory,
+    /// this function returns false.
+    static bool is_dir(const std::string& path);
+
+    /// Remove the specified file path from the file system. It is an error if
+    /// the specified path is a directory. If the specified file is a symbolic
+    /// link, the link is removed, leaving the liked file intact. In so far as
+    /// the specified path is not a directory, std::remove(const char*) is
+    /// equivalent to this function.
+    ///
+    /// The specified file must not be open by the calling process. If
+    /// it is, this function has undefined behaviour. Note that an
+    /// open memory map of the file counts as "the file being open".
+    ///
+    /// \throw AccessError If the specified directory entry could not
+    /// be removed. If the reason corresponds to one of the exception
+    /// types that are derived from AccessError, the derived exception
+    /// type is thrown (as long as the underlying system provides the
+    /// information to unambiguously distinguish that particular
+    /// reason).
+    static void remove(const std::string& path);
+
+    /// Same as remove() except that this one returns false, rather
+    /// than throwing an exception, if the specified file does not
+    /// exist. If the file did exist, and was deleted, this function
+    /// returns true.
+    static bool try_remove(const std::string& path);
+
+    /// Change the path of a directory entry. This can be used to
+    /// rename a file, and/or to move it from one directory to
+    /// another. This function is equivalent to std::rename(const
+    /// char*, const char*).
+    ///
+    /// \throw AccessError If the path of the directory entry could
+    /// not be changed. If the reason corresponds to one of the
+    /// exception types that are derived from AccessError, the derived
+    /// exception type is thrown (as long as the underlying system
+    /// provides the information to unambiguously distinguish that
+    /// particular reason).
+    static void move(const std::string& old_path, const std::string& new_path);
+
+    /// Copy the file at the specified origin path to the specified target path.
+    static void copy(const std::string& origin_path, const std::string& target_path);
+
+    /// Compare the two files at the specified paths for equality. Returns true
+    /// if, and only if they are equal.
+    static bool compare(const std::string& path_1, const std::string& path_2);
+
+    /// Check whether two open file descriptors refer to the same
+    /// underlying file, that is, if writing via one of them, will
+    /// affect what is read from the other. In UNIX this boils down to
+    /// comparing inode numbers.
+    ///
+    /// Both instances have to be attached to open files. If they are
+    /// not, this function has undefined behavior.
+    bool is_same_file(const File&) const;
+    static bool is_same_file_static(FileDesc f1, FileDesc f2);
+
+    // FIXME: Get rid of this method
+    bool is_removed() const;
+
+    /// Resolve the specified path against the specified base directory.
+    ///
+    /// If \a path is absolute, or if \a base_dir is empty, \p path is returned
+    /// unmodified, otherwise \a path is resolved against \a base_dir.
+    ///
+    /// Examples (assuming POSIX):
+    ///
+    ///    resolve("file", "dir")        -> "dir/file"
+    ///    resolve("../baz", "/foo/bar") -> "/foo/baz"
+    ///    resolve("foo", ".")           -> "./foo"
+    ///    resolve(".", "/foo/")         -> "/foo"
+    ///    resolve("..", "foo")          -> "."
+    ///    resolve("../..", "foo")       -> ".."
+    ///    resolve("..", "..")           -> "../.."
+    ///    resolve("", "")               -> "."
+    ///    resolve("", "/")              -> "/."
+    ///    resolve("..", "/")            -> "/."
+    ///    resolve("..", "foo//bar")     -> "foo"
+    ///
+    /// This function does not access the file system.
+    ///
+    /// \param path The path to be resolved. An empty string produces the same
+    /// result as as if "." was passed. The result has a trailing directory
+    /// separator (`/`) if, and only if this path has a trailing directory
+    /// separator.
+    ///
+    /// \param base_dir The base directory path, which may be relative or
+    /// absolute. A final directory separator (`/`) is optional. The empty
+    /// string is interpreted as a relative path.
+    static std::string resolve(const std::string& path, const std::string& base_dir);
+
+    using ForEachHandler = std::function<bool(const std::string& file, const std::string& dir)>;
+
+    /// Scan the specified directory recursivle, and report each file
+    /// (nondirectory entry) via the specified handler.
+    ///
+    /// The first argument passed to the handler is the name of a file (not the
+    /// whole path), and the second argument is the directory in which that file
+    /// resides. The directory will be specified as a path, and relative to \a
+    /// dir_path. The directory will be the empty string for files residing
+    /// directly in \a dir_path.
+    ///
+    /// If the handler returns false, scanning will be aborted immediately, and
+    /// for_each() will return false. Otherwise for_each() will return true.
+    ///
+    /// Scanning is done as if by a recursive set of DirScanner objects.
+    static bool for_each(const std::string& dir_path, ForEachHandler handler);
+
+    struct UniqueID {
+#ifdef _WIN32 // Windows version
+// FIXME: This is not implemented for Windows
+#else
+        // NDK r10e has a bug in sys/stat.h dev_t ino_t are 4 bytes,
+        // but stat.st_dev and st_ino are 8 bytes. So we just use uint64 instead.
+        dev_t device;
+        uint_fast64_t inode;
+#endif
+    };
+    // Return the unique id for the current opened file descriptor.
+    // Same UniqueID means they are the same file.
+    UniqueID get_unique_id() const;
+    // Return the file descriptor for the file
+    FileDesc get_descriptor() const;
+    // Return the path of the open file, or an empty string if
+    // this file has never been opened.
+    std::string get_path() const;
+    // Return false if the file doesn't exist. Otherwise uid will be set.
+    static bool get_unique_id(const std::string& path, UniqueID& uid);
+
+    class ExclusiveLock;
+    class SharedLock;
+
+    template <class>
+    class Map;
+
+    class CloseGuard;
+    class UnlockGuard;
+    class UnmapGuard;
+
+    class Streambuf;
+
+    // Exceptions
+    class AccessError;
+    class PermissionDenied;
+    class NotFound;
+    class Exists;
+
+private:
+#ifdef _WIN32
+    void* m_fd;
+    bool m_have_lock; // Only valid when m_fd is not null
+#else
+    int m_fd;
+#endif
+    std::unique_ptr<const char[]> m_encryption_key = nullptr;
+    std::string m_path;
+
+    bool lock(bool exclusive, bool non_blocking);
+    void open_internal(const std::string& path, AccessMode, CreateMode, int flags, bool* success);
+
+    struct MapBase {
+        void* m_addr = nullptr;
+        size_t m_size = 0;
+        FileDesc m_fd;
+
+        MapBase() noexcept;
+        ~MapBase() noexcept;
+
+        // Disable copying. Copying an opened MapBase will create a scenario
+        // where the same memory will be mapped once but unmapped twice.
+        MapBase(const MapBase&) = delete;
+        MapBase& operator=(const MapBase&) = delete;
+
+        void map(const File&, AccessMode, size_t size, int map_flags, size_t offset = 0);
+        void remap(const File&, AccessMode, size_t size, int map_flags);
+        void unmap() noexcept;
+        void sync();
+#if REALM_ENABLE_ENCRYPTION
+        util::EncryptedFileMapping* m_encrypted_mapping = nullptr;
+        inline util::EncryptedFileMapping* get_encrypted_mapping() const
+        {
+            return m_encrypted_mapping;
+        }
+#else
+        inline util::EncryptedFileMapping* get_encrypted_mapping() const
+        {
+            return nullptr;
+        }
+#endif
+    };
+};
+
+
+class File::ExclusiveLock {
+public:
+    ExclusiveLock(File& f)
+        : m_file(f)
+    {
+        f.lock_exclusive();
+    }
+    ~ExclusiveLock() noexcept
+    {
+        m_file.unlock();
+    }
+    // Disable copying. It is not how this class should be used.
+    ExclusiveLock(const ExclusiveLock&) = delete;
+    ExclusiveLock& operator=(const ExclusiveLock&) = delete;
+
+private:
+    File& m_file;
+};
+
+class File::SharedLock {
+public:
+    SharedLock(File& f)
+        : m_file(f)
+    {
+        f.lock_shared();
+    }
+    ~SharedLock() noexcept
+    {
+        m_file.unlock();
+    }
+    // Disable copying. It is not how this class should be used.
+    SharedLock(const SharedLock&) = delete;
+    SharedLock& operator=(const SharedLock&) = delete;
+
+private:
+    File& m_file;
+};
+
+
+/// This class provides a RAII abstraction over the concept of a
+/// memory mapped file.
+///
+/// Once created, the Map instance makes no reference to the File
+/// instance that it was based upon, and that File instance may be
+/// destroyed before the Map instance is destroyed.
+///
+/// Multiple concurrent mappings may be created from the same File
+/// instance.
+///
+/// You can use UnmapGuard to acheive exception-safe unmapping prior
+/// to the Map instance being detroyed.
+///
+/// A single Map instance must never be accessed concurrently by
+/// multiple threads.
+template <class T>
+class File::Map : private MapBase {
+public:
+    /// Equivalent to calling map() on a default constructed instance.
+    explicit Map(const File&, AccessMode = access_ReadOnly, size_t size = sizeof(T), int map_flags = 0);
+
+    explicit Map(const File&, size_t offset, AccessMode = access_ReadOnly, size_t size = sizeof(T),
+                 int map_flags = 0);
+
+    /// Create an instance that is not initially attached to a memory
+    /// mapped file.
+    Map() noexcept;
+
+    ~Map() noexcept;
+
+    // Disable copying. Copying an opened Map will create a scenario
+    // where the same memory will be mapped once but unmapped twice.
+    Map(const Map&) = delete;
+    Map& operator=(const Map&) = delete;
+
+    /// Move the mapping from another Map object to this Map object
+    File::Map<T>& operator=(File::Map<T>&& other)
+    {
+        if (m_addr)
+            unmap();
+        m_addr = other.get_addr();
+        m_size = other.m_size;
+        other.m_addr = 0;
+        other.m_size = 0;
+#if REALM_ENABLE_ENCRYPTION
+        m_encrypted_mapping = other.m_encrypted_mapping;
+        other.m_encrypted_mapping = nullptr;
+#endif
+        return *this;
+    }
+
+    /// See File::map().
+    ///
+    /// Calling this function on a Map instance that is already
+    /// attached to a memory mapped file has undefined behavior. The
+    /// returned pointer is the same as what will subsequently be
+    /// returned by get_addr().
+    T* map(const File&, AccessMode = access_ReadOnly, size_t size = sizeof(T), int map_flags = 0, size_t offset = 0);
+
+    /// See File::unmap(). This function is idempotent, that is, it is
+    /// valid to call it regardless of whether this instance is
+    /// currently attached to a memory mapped file.
+    void unmap() noexcept;
+
+    /// See File::remap().
+    ///
+    /// Calling this function on a Map instance that is not currently
+    /// attached to a memory mapped file has undefined behavior. The
+    /// returned pointer is the same as what will subsequently be
+    /// returned by get_addr().
+    T* remap(const File&, AccessMode = access_ReadOnly, size_t size = sizeof(T), int map_flags = 0);
+
+    /// See File::sync_map().
+    ///
+    /// Calling this function on an instance that is not currently
+    /// attached to a memory mapped file, has undefined behavior.
+    void sync();
+
+    /// Check whether this Map instance is currently attached to a
+    /// memory mapped file.
+    bool is_attached() const noexcept;
+
+    /// Returns a pointer to the beginning of the memory mapped file,
+    /// or null if this instance is not currently attached.
+    T* get_addr() const noexcept;
+
+    /// Returns the size of the mapped region, or zero if this
+    /// instance does not currently refer to a memory mapped
+    /// file. When this instance refers to a memory mapped file, the
+    /// returned value will always be identical to the size passed to
+    /// the constructor or to map().
+    size_t get_size() const noexcept;
+
+    /// Release the currently attached memory mapped file from this
+    /// Map instance. The address range may then be unmapped later by
+    /// a call to File::unmap().
+    T* release() noexcept;
+
+#if REALM_ENABLE_ENCRYPTION
+    /// Get the encrypted file mapping corresponding to this mapping
+    inline EncryptedFileMapping* get_encrypted_mapping() const
+    {
+        return m_encrypted_mapping;
+    }
+#else
+    inline EncryptedFileMapping* get_encrypted_mapping() const
+    {
+        return nullptr;
+    }
+#endif
+
+    friend class UnmapGuard;
+};
+
+
+class File::CloseGuard {
+public:
+    CloseGuard(File& f) noexcept
+        : m_file(&f)
+    {
+    }
+    ~CloseGuard() noexcept
+    {
+        if (m_file)
+            m_file->close();
+    }
+    void release() noexcept
+    {
+        m_file = nullptr;
+    }
+    // Disallow the default implementation of copy/assign, this is not how this
+    // class is intended to be used. For example we could get unexpected
+    // behaviour if one CloseGuard is copied and released but the other is not.
+    CloseGuard(const CloseGuard&) = delete;
+    CloseGuard& operator=(const CloseGuard&) = delete;
+
+private:
+    File* m_file;
+};
+
+
+class File::UnlockGuard {
+public:
+    UnlockGuard(File& f) noexcept
+        : m_file(&f)
+    {
+    }
+    ~UnlockGuard() noexcept
+    {
+        if (m_file)
+            m_file->unlock();
+    }
+    void release() noexcept
+    {
+        m_file = nullptr;
+    }
+    // Disallow the default implementation of copy/assign, this is not how this
+    // class is intended to be used. For example we could get unexpected
+    // behaviour if one UnlockGuard is copied and released but the other is not.
+    UnlockGuard(const UnlockGuard&) = delete;
+    UnlockGuard& operator=(const UnlockGuard&) = delete;
+
+private:
+    File* m_file;
+};
+
+
+class File::UnmapGuard {
+public:
+    template <class T>
+    UnmapGuard(Map<T>& m) noexcept
+        : m_map(&m)
+    {
+    }
+    ~UnmapGuard() noexcept
+    {
+        if (m_map)
+            m_map->unmap();
+    }
+    void release() noexcept
+    {
+        m_map = nullptr;
+    }
+    // Disallow the default implementation of copy/assign, this is not how this
+    // class is intended to be used. For example we could get unexpected
+    // behaviour if one UnmapGuard is copied and released but the other is not.
+    UnmapGuard(const UnmapGuard&) = delete;
+    UnmapGuard& operator=(const UnmapGuard&) = delete;
+
+private:
+    MapBase* m_map;
+};
+
+
+/// Only output is supported at this point.
+class File::Streambuf : public std::streambuf {
+public:
+    explicit Streambuf(File*, size_t = 4096);
+    ~Streambuf() noexcept;
+
+    // Disable copying
+    Streambuf(const Streambuf&) = delete;
+    Streambuf& operator=(const Streambuf&) = delete;
+
+private:
+    File& m_file;
+    std::unique_ptr<char[]> const m_buffer;
+
+    int_type overflow(int_type) override;
+    int sync() override;
+    pos_type seekpos(pos_type, std::ios_base::openmode) override;
+    void flush();
+};
+
+/// Used for any I/O related exception. Note the derived exception
+/// types that are used for various specific types of errors.
+class File::AccessError : public ExceptionWithBacktrace<std::runtime_error> {
+public:
+    AccessError(const std::string& msg, const std::string& path);
+
+    /// Return the associated file system path, or the empty string if there is
+    /// no associated file system path, or if the file system path is unknown.
+    std::string get_path() const;
+
+    const char* message() const noexcept
+    {
+        m_buffer = std::runtime_error::what();
+        if (m_path.size() > 0)
+            m_buffer += (std::string(" Path: ") + m_path);
+        return m_buffer.c_str();
+    }
+
+private:
+    std::string m_path;
+    mutable std::string m_buffer;
+};
+
+
+/// Thrown if the user does not have permission to open or create
+/// the specified file in the specified access mode.
+class File::PermissionDenied : public AccessError {
+public:
+    PermissionDenied(const std::string& msg, const std::string& path);
+};
+
+
+/// Thrown if the directory part of the specified path was not
+/// found, or create_Never was specified and the file did no
+/// exist.
+class File::NotFound : public AccessError {
+public:
+    NotFound(const std::string& msg, const std::string& path);
+};
+
+
+/// Thrown if create_Always was specified and the file did already
+/// exist.
+class File::Exists : public AccessError {
+public:
+    Exists(const std::string& msg, const std::string& path);
+};
+
+
+class DirScanner {
+public:
+    DirScanner(const std::string& path, bool allow_missing = false);
+    ~DirScanner() noexcept;
+    bool next(std::string& name);
+
+private:
+#ifndef _WIN32
+    DIR* m_dirp;
+#elif REALM_HAVE_STD_FILESYSTEM
+    std::filesystem::directory_iterator m_iterator;
+#endif
+};
+
+
+// Implementation:
+
+inline File::File(const std::string& path, Mode m)
+{
+#ifdef _WIN32
+    m_fd = nullptr;
+#else
+    m_fd = -1;
+#endif
+
+    open(path, m);
+}
+
+inline File::File() noexcept
+{
+#ifdef _WIN32
+    m_fd = nullptr;
+#else
+    m_fd = -1;
+#endif
+}
+
+inline File::~File() noexcept
+{
+    close();
+}
+
+inline File::File(File&& f) noexcept
+{
+#ifdef _WIN32
+    m_fd = f.m_fd;
+    m_have_lock = f.m_have_lock;
+    f.m_fd = nullptr;
+#else
+    m_fd = f.m_fd;
+    f.m_fd = -1;
+#endif
+    m_encryption_key = std::move(f.m_encryption_key);
+}
+
+inline File& File::operator=(File&& f) noexcept
+{
+    close();
+#ifdef _WIN32
+    m_fd = f.m_fd;
+    m_have_lock = f.m_have_lock;
+    f.m_fd = nullptr;
+#else
+    m_fd = f.m_fd;
+    f.m_fd = -1;
+#endif
+    m_encryption_key = std::move(f.m_encryption_key);
+    return *this;
+}
+
+inline void File::open(const std::string& path, Mode m)
+{
+    AccessMode a = access_ReadWrite;
+    CreateMode c = create_Auto;
+    int flags = 0;
+    switch (m) {
+        case mode_Read:
+            a = access_ReadOnly;
+            c = create_Never;
+            break;
+        case mode_Update:
+            c = create_Never;
+            break;
+        case mode_Write:
+            flags = flag_Trunc;
+            break;
+        case mode_Append:
+            flags = flag_Append;
+            break;
+    }
+    open(path, a, c, flags);
+}
+
+inline void File::open(const std::string& path, AccessMode am, CreateMode cm, int flags)
+{
+    open_internal(path, am, cm, flags, nullptr);
+}
+
+
+inline void File::open(const std::string& path, bool& was_created)
+{
+    while (1) {
+        bool success;
+        open_internal(path, access_ReadWrite, create_Must, 0, &success);
+        if (success) {
+            was_created = true;
+            return;
+        }
+        open_internal(path, access_ReadWrite, create_Never, 0, &success);
+        if (success) {
+            was_created = false;
+            return;
+        }
+    }
+}
+
+inline bool File::is_attached() const noexcept
+{
+#ifdef _WIN32
+    return (m_fd != nullptr);
+#else
+    return 0 <= m_fd;
+#endif
+}
+
+inline void File::lock_exclusive()
+{
+    lock(true, false);
+}
+
+inline void File::lock_shared()
+{
+    lock(false, false);
+}
+
+inline bool File::try_lock_exclusive()
+{
+    return lock(true, true);
+}
+
+inline bool File::try_lock_shared()
+{
+    return lock(false, true);
+}
+
+inline File::MapBase::MapBase() noexcept
+{
+    m_addr = nullptr;
+}
+
+inline File::MapBase::~MapBase() noexcept
+{
+    unmap();
+}
+
+inline void File::MapBase::map(const File& f, AccessMode a, size_t size, int map_flags, size_t offset)
+{
+    REALM_ASSERT(!m_addr);
+#if REALM_ENABLE_ENCRYPTION
+    m_addr = f.map(a, size, m_encrypted_mapping, map_flags, offset);
+#else
+    m_addr = f.map(a, size, map_flags, offset);
+#endif
+    m_size = size;
+    m_fd = f.m_fd;
+}
+
+inline void File::MapBase::unmap() noexcept
+{
+    if (!m_addr)
+        return;
+    File::unmap(m_addr, m_size);
+    m_addr = nullptr;
+#if REALM_ENABLE_ENCRYPTION
+    m_encrypted_mapping = nullptr;
+#endif
+    m_fd = 0;
+}
+
+inline void File::MapBase::remap(const File& f, AccessMode a, size_t size, int map_flags)
+{
+    REALM_ASSERT(m_addr);
+
+    //m_addr = f.remap(m_addr, m_size, a, size, map_flags);
+    // missing sync() here?
+    unmap();
+    map(f, a, size, map_flags);
+    m_size = size;
+    m_fd = f.m_fd;
+}
+
+inline void File::MapBase::sync()
+{
+    REALM_ASSERT(m_addr);
+
+    File::sync_map(m_fd, m_addr, m_size);
+}
+
+template <class T>
+inline File::Map<T>::Map(const File& f, AccessMode a, size_t size, int map_flags)
+{
+    map(f, a, size, map_flags);
+}
+
+template <class T>
+inline File::Map<T>::Map(const File& f, size_t offset, AccessMode a, size_t size, int map_flags)
+{
+    map(f, a, size, map_flags, offset);
+}
+
+template <class T>
+inline File::Map<T>::Map() noexcept
+{
+}
+
+template <class T>
+inline File::Map<T>::~Map() noexcept
+{
+}
+
+template <class T>
+inline T* File::Map<T>::map(const File& f, AccessMode a, size_t size, int map_flags, size_t offset)
+{
+    MapBase::map(f, a, size, map_flags, offset);
+    return static_cast<T*>(m_addr);
+}
+
+template <class T>
+inline void File::Map<T>::unmap() noexcept
+{
+    MapBase::unmap();
+}
+
+template <class T>
+inline T* File::Map<T>::remap(const File& f, AccessMode a, size_t size, int map_flags)
+{
+    MapBase::remap(f, a, size, map_flags);
+    return static_cast<T*>(m_addr);
+}
+
+template <class T>
+inline void File::Map<T>::sync()
+{
+    MapBase::sync();
+}
+
+template <class T>
+inline bool File::Map<T>::is_attached() const noexcept
+{
+    return (m_addr != nullptr);
+}
+
+template <class T>
+inline T* File::Map<T>::get_addr() const noexcept
+{
+    return static_cast<T*>(m_addr);
+}
+
+template <class T>
+inline size_t File::Map<T>::get_size() const noexcept
+{
+    return m_addr ? m_size : 0;
+}
+
+template <class T>
+inline T* File::Map<T>::release() noexcept
+{
+    T* addr = static_cast<T*>(m_addr);
+    m_addr = nullptr;
+    m_fd = 0;
+    return addr;
+}
+
+
+inline File::Streambuf::Streambuf(File* f, size_t buffer_size)
+    : m_file(*f)
+    , m_buffer(new char[buffer_size])
+{
+    char* b = m_buffer.get();
+    setp(b, b + buffer_size);
+}
+
+inline File::Streambuf::~Streambuf() noexcept
+{
+    try {
+        if (m_file.is_attached())
+            flush();
+    }
+    catch (...) {
+        // Errors deliberately ignored
+    }
+}
+
+inline File::Streambuf::int_type File::Streambuf::overflow(int_type c)
+{
+    flush();
+    if (c == traits_type::eof())
+        return traits_type::not_eof(c);
+    *pptr() = traits_type::to_char_type(c);
+    pbump(1);
+    return c;
+}
+
+inline int File::Streambuf::sync()
+{
+    flush();
+    return 0;
+}
+
+inline File::Streambuf::pos_type File::Streambuf::seekpos(pos_type pos, std::ios_base::openmode)
+{
+    flush();
+    SizeType pos2 = 0;
+    if (int_cast_with_overflow_detect(std::streamsize(pos), pos2))
+        throw util::overflow_error("Seek position overflow");
+    m_file.seek(pos2);
+    return pos;
+}
+
+inline void File::Streambuf::flush()
+{
+    size_t n = pptr() - pbase();
+    if (n > 0) {
+        m_file.write(pbase(), n);
+        setp(m_buffer.get(), epptr());
+    }
+}
+
+inline File::AccessError::AccessError(const std::string& msg, const std::string& path)
+    : ExceptionWithBacktrace<std::runtime_error>(msg)
+    , m_path(path)
+{
+}
+
+inline std::string File::AccessError::get_path() const
+{
+    return m_path;
+}
+
+inline File::PermissionDenied::PermissionDenied(const std::string& msg, const std::string& path)
+    : AccessError(msg, path)
+{
+}
+
+inline File::NotFound::NotFound(const std::string& msg, const std::string& path)
+    : AccessError(msg, path)
+{
+}
+
+inline File::Exists::Exists(const std::string& msg, const std::string& path)
+    : AccessError(msg, path)
+{
+}
+
+inline bool operator==(const File::UniqueID& lhs, const File::UniqueID& rhs)
+{
+#ifdef _WIN32 // Windows version
+    throw util::runtime_error("Not yet supported");
+#else // POSIX version
+    return lhs.device == rhs.device && lhs.inode == rhs.inode;
+#endif
+}
+
+inline bool operator!=(const File::UniqueID& lhs, const File::UniqueID& rhs)
+{
+    return !(lhs == rhs);
+}
+
+inline bool operator<(const File::UniqueID& lhs, const File::UniqueID& rhs)
+{
+#ifdef _WIN32 // Windows version
+    throw util::runtime_error("Not yet supported");
+#else // POSIX version
+    if (lhs.device < rhs.device)
+        return true;
+    if (lhs.device > rhs.device)
+        return false;
+    if (lhs.inode < rhs.inode)
+        return true;
+    return false;
+#endif
+}
+
+inline bool operator>(const File::UniqueID& lhs, const File::UniqueID& rhs)
+{
+    return rhs < lhs;
+}
+
+inline bool operator<=(const File::UniqueID& lhs, const File::UniqueID& rhs)
+{
+    return !(lhs > rhs);
+}
+
+inline bool operator>=(const File::UniqueID& lhs, const File::UniqueID& rhs)
+{
+    return !(lhs < rhs);
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_FILE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/file_mapper.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/file_mapper.hpp
new file mode 100644
index 0000000..d02f15d
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/file_mapper.hpp
@@ -0,0 +1,179 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_FILE_MAPPER_HPP
+#define REALM_UTIL_FILE_MAPPER_HPP
+
+#include <realm/util/file.hpp>
+#include <realm/utilities.hpp>
+#include <realm/util/thread.hpp>
+#include <realm/util/encrypted_file_mapping.hpp>
+
+#include <functional>
+
+namespace realm {
+namespace util {
+
+void* mmap(FileDesc fd, size_t size, File::AccessMode access, size_t offset, const char* encryption_key);
+void munmap(void* addr, size_t size);
+void* mremap(FileDesc fd, size_t file_offset, void* old_addr, size_t old_size, File::AccessMode a, size_t new_size,
+             const char* encryption_key);
+void msync(FileDesc fd, void* addr, size_t size);
+
+// A function which may be given to encryption_read_barrier. If present, the read barrier is a
+// a barrier for a full array. If absent, the read barrier is a barrier only for the address
+// range give as argument. If the barrier is for a full array, it will read the array header
+// and determine the address range from the header.
+using HeaderToSize = size_t (*)(const char* addr);
+class EncryptedFileMapping;
+
+class PageReclaimGovernor {
+public:
+    // Called by the page reclaimer with the current load (in bytes) and
+    // must return the target load (also in bytes). Returns no_match if no
+	// target can be set
+	static constexpr int64_t no_match = -1;
+    virtual std::function<int64_t()> current_target_getter(size_t load) = 0;
+    virtual void report_target_result(int64_t) = 0;
+};
+
+// Set a page reclaim governor. The governor is an object with a method which will be called periodically
+// and must return a 'target' amount of memory to hold decrypted pages. The page reclaim daemon
+// will then try to release pages to meet the target. The governor is called with the current
+// amount of data used, for the purpose of logging - or possibly for computing the target
+//
+// The governor is called approximately once per second.
+//
+// If no governor is installed, the page reclaim daemon will not start.
+void set_page_reclaim_governor(PageReclaimGovernor* governor);
+
+// Use the default governor. The default governor is used automatically if nothing else is set, so
+// this funciton is mostly useful for tests where changing back to the default could be desirable.
+inline void set_page_reclaim_governor_to_default()
+{
+    set_page_reclaim_governor(nullptr);
+}
+
+// Retrieves the number of in memory decrypted pages, across all open files.
+size_t get_num_decrypted_pages();
+
+// Retrieves the
+// - amount of memory used for decrypted pages, across all open files.
+// - current target for the reclaimer (desired number of decrypted pages)
+// - current workload size for the reclaimer, across all open files.
+struct decrypted_memory_stats_t {
+    size_t memory_size;
+    size_t reclaimer_target;
+    size_t reclaimer_workload;
+};
+
+decrypted_memory_stats_t get_decrypted_memory_stats();
+
+#if REALM_ENABLE_ENCRYPTION
+
+void encryption_note_reader_start(SharedFileInfo& info, const void* reader_id);
+void encryption_note_reader_end(SharedFileInfo& info, const void* reader_id) noexcept;
+
+SharedFileInfo* get_file_info_for_file(File& file);
+
+// This variant allows the caller to obtain direct access to the encrypted file mapping
+// for optimization purposes.
+void* mmap(FileDesc fd, size_t size, File::AccessMode access, size_t offset, const char* encryption_key,
+           EncryptedFileMapping*& mapping);
+
+void do_encryption_read_barrier(const void* addr, size_t size, HeaderToSize header_to_size,
+                                EncryptedFileMapping* mapping);
+
+void do_encryption_write_barrier(const void* addr, size_t size, EncryptedFileMapping* mapping);
+
+void inline encryption_read_barrier(const void* addr, size_t size, EncryptedFileMapping* mapping,
+                                    HeaderToSize header_to_size = nullptr)
+{
+    if (mapping)
+        do_encryption_read_barrier(addr, size, header_to_size, mapping);
+}
+
+void inline encryption_write_barrier(const void* addr, size_t size, EncryptedFileMapping* mapping)
+{
+    if (mapping)
+        do_encryption_write_barrier(addr, size, mapping);
+}
+
+
+extern util::Mutex& mapping_mutex;
+
+inline void do_encryption_read_barrier(const void* addr, size_t size, HeaderToSize header_to_size,
+                                       EncryptedFileMapping* mapping)
+{
+    UniqueLock lock(mapping_mutex);
+    mapping->read_barrier(addr, size, header_to_size);
+}
+
+inline void do_encryption_write_barrier(const void* addr, size_t size, EncryptedFileMapping* mapping)
+{
+    LockGuard lock(mapping_mutex);
+    mapping->write_barrier(addr, size);
+}
+
+#else
+
+void inline set_page_reclaim_governor(PageReclaimGovernor*)
+{
+}
+
+size_t inline get_num_decrypted_pages()
+{
+    return 0;
+}
+
+void inline encryption_read_barrier(const void*, size_t, EncryptedFileMapping*, HeaderToSize = nullptr)
+{
+}
+
+void inline encryption_write_barrier(const void*, size_t)
+{
+}
+
+void inline encryption_write_barrier(const void*, size_t, EncryptedFileMapping*)
+{
+}
+
+#endif
+
+// helpers for encrypted Maps
+template <typename T>
+void encryption_read_barrier(File::Map<T>& map, size_t index, size_t num_elements = 1)
+{
+    T* addr = map.get_addr();
+    encryption_read_barrier(addr + index, sizeof(T) * num_elements, map.get_encrypted_mapping());
+}
+
+template <typename T>
+void encryption_write_barrier(File::Map<T>& map, size_t index, size_t num_elements = 1)
+{
+    T* addr = map.get_addr();
+    encryption_write_barrier(addr + index, sizeof(T) * num_elements, map.get_encrypted_mapping());
+}
+
+File::SizeType encrypted_size_to_data_size(File::SizeType size) noexcept;
+File::SizeType data_size_to_encrypted_size(File::SizeType size) noexcept;
+
+size_t round_up_to_page_size(size_t size) noexcept;
+}
+}
+#endif
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/fixed_size_buffer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/fixed_size_buffer.hpp
new file mode 100644
index 0000000..8a512ee
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/fixed_size_buffer.hpp
@@ -0,0 +1,135 @@
+/*************************************************************************
+ *
+ * Copyright 2019 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_FIXED_SIZE_BUFFER_HPP
+#define REALM_UTIL_FIXED_SIZE_BUFFER_HPP
+
+#include <vector>
+#include <cstddef>
+#include <stdexcept>
+
+namespace realm {
+namespace util {
+
+/// This is a buffer with a fixed size. You can only insert elements.
+/// When the number of elements inserted matches the size of the buffer,
+/// additional insertions will overwrite the oldest elements.
+template <class T>
+class FixedSizeBuffer {
+public:
+    class iterator;
+
+    FixedSizeBuffer(size_t sz)
+        : m_size(sz)
+    {
+        if (sz == 0)
+            throw std::runtime_error("FixedSizeBuffer size cannot be 0");
+        m_buffer.reserve(sz);
+    }
+    size_t size()
+    {
+        return m_buffer.size();
+    }
+    void insert(const T& val)
+    {
+        if (m_buffer.size() < m_size) {
+            m_buffer.emplace_back(val);
+        }
+        else {
+            m_buffer[m_oldest] = val;
+            ++m_oldest;
+            if (m_oldest == m_size)
+                m_oldest = 0;
+        }
+    }
+    T& at(size_t n)
+    {
+        auto idx = (n + m_oldest) % m_size;
+        return m_buffer[idx];
+    }
+    T& operator[](size_t n)
+    {
+        return at(n);
+    }
+    iterator begin()
+    {
+        return iterator(*this, 0);
+    }
+    iterator end()
+    {
+        return iterator(*this, m_buffer.size());
+    }
+
+private:
+    std::vector<T> m_buffer;
+    size_t m_size;
+    size_t m_oldest = 0;
+};
+
+template <class T>
+class FixedSizeBuffer<T>::iterator {
+public:
+    typedef std::forward_iterator_tag iterator_category;
+    typedef T value_type;
+    typedef ptrdiff_t difference_type;
+    typedef T* pointer;
+    typedef T& reference;
+
+    iterator(FixedSizeBuffer<T>& b, size_t ndx)
+        : m_cb(b)
+        , m_ndx(ndx)
+    {
+    }
+    pointer operator->()
+    {
+        return &m_cb[m_ndx];
+    }
+    reference operator*()
+    {
+        return m_cb[m_ndx];
+    }
+    iterator& operator++()
+    {
+        ++m_ndx;
+        return *this;
+    }
+    iterator operator++(int)
+    {
+        iterator tmp(*this);
+        operator++();
+        return tmp;
+    }
+    bool operator!=(const iterator& rhs)
+    {
+        return m_ndx != rhs.m_ndx;
+    }
+    bool operator==(const iterator& rhs)
+    {
+        return m_ndx == rhs.m_ndx;
+    }
+
+private:
+    FixedSizeBuffer<T>& m_cb;
+    size_t m_ndx;
+};
+
+} // namespace util
+} // namespace realm
+
+
+#endif /* REALM_UTIL_FIXED_SIZE_BUFFER_HPP */
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/flat_map.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/flat_map.hpp
new file mode 100644
index 0000000..a3d6b54
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/flat_map.hpp
@@ -0,0 +1,201 @@
+
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2017] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_FLAT_MAP_HPP
+#define REALM_UTIL_FLAT_MAP_HPP
+
+#include <vector>
+#include <utility> // std::pair
+#include <algorithm> // std::lower_bound etc.
+#include <type_traits>
+
+#include <realm/util/backtrace.hpp>
+
+namespace realm {
+namespace util {
+
+template <class K, class V, class Container = std::vector<std::pair<K,V>>, class Cmp = std::less<>>
+struct FlatMap {
+    using value_type = std::pair<K, V>;
+    using key_type = K;
+    using mapped_type = V;
+    FlatMap() {}
+    FlatMap(const FlatMap&) = default;
+    FlatMap(FlatMap&&) = default;
+    FlatMap& operator=(const FlatMap&) = default;
+    FlatMap& operator=(FlatMap&&) = default;
+
+    V& at(K key)
+    {
+        auto it = lower_bound(key);
+        if (it == end() || it->first != key)
+            it = m_data.emplace(it, std::move(key), V{}); // Throws
+        return it->second;
+    }
+
+    const V& at(const K& key) const
+    {
+        auto it = find(key);
+        if (it == end())
+            throw util::out_of_range("no such key");
+        return it->second;
+    }
+
+    V& operator[](const K& key)
+    {
+        return at(key); // Throws
+    }
+
+    using iterator = typename Container::iterator;
+    using const_iterator = typename Container::const_iterator;
+    iterator begin() noexcept { return m_data.begin(); }
+    iterator end()   noexcept { return m_data.end(); }
+    const_iterator begin() const noexcept { return m_data.begin(); }
+    const_iterator end()   const noexcept { return m_data.end(); }
+
+
+    bool empty() const noexcept { return m_data.empty(); }
+    size_t size() const noexcept { return m_data.size(); }
+    void clear() noexcept { m_data.clear(); }
+
+    std::pair<iterator,bool> insert(value_type value)
+    {
+        auto it = lower_bound(value.first);
+        if (it != end() && it->first == value.first) {
+            return std::make_pair(it, false);
+        }
+        return std::make_pair(m_data.emplace(it, std::move(value)), true); // Throws
+    }
+
+    template <class P>
+    std::pair<iterator,bool> insert(P pair)
+    {
+        return insert(value_type{std::get<0>(pair), std::get<1>(pair)});
+    }
+
+    template <class InputIt>
+    void insert(InputIt first, InputIt last)
+    {
+        for (auto it = first; it != last; ++it) {
+            insert(*it);
+        }
+    }
+
+    template <class... Args>
+    std::pair<iterator,bool> emplace(Args&&... args)
+    {
+        value_type value{std::forward<Args>(args)...};
+        return insert(std::move(value));
+    }
+
+    template <class... Args>
+    std::pair<iterator, bool> emplace_hint(const_iterator pos, Args&&... args)
+    {
+        static_cast<void>(pos); // FIXME: TODO
+        return emplace(std::forward<Args>(args)...);
+    }
+
+    iterator erase(const_iterator pos) noexcept(std::is_nothrow_move_assignable<value_type>::value)
+    {
+        return m_data.erase(pos);
+    }
+
+    iterator erase(const_iterator first, const_iterator last) noexcept(std::is_nothrow_move_assignable<value_type>::value)
+    {
+        return m_data.erase(first, last);
+    }
+
+    size_t erase(const K& key) noexcept(std::is_nothrow_move_assignable<value_type>::value)
+    {
+        auto it = find(key);
+        if (it != end()) {
+            erase(it);
+            return 1;
+        }
+        return 0;
+    }
+
+    void swap(FlatMap& other)
+    {
+        m_data.swap(other.m_data);
+    }
+
+    template <class Key>
+    size_t count(const Key& key) const noexcept
+    {
+        return find(key) == end() ? 0 : 1;
+    }
+
+    template <class Key>
+    iterator find(const Key& key) noexcept
+    {
+        const FlatMap* This = this;
+        const_iterator pos = This->find(key);
+        return iterator{begin() + (pos - This->begin())};
+    }
+
+    template <class Key>
+    const_iterator find(const Key& key) const noexcept
+    {
+        auto it = lower_bound(key);
+        if (it != end() && it->first != key) {
+            return end();
+        }
+        return it;
+    }
+
+    template <class Key>
+    iterator lower_bound(const Key& key) noexcept
+    {
+        const FlatMap* This = this;
+        const_iterator pos = This->lower_bound(key);
+        return iterator{begin() + (pos - This->begin())};
+    }
+
+    template <class Key>
+    const_iterator lower_bound(const Key& key) const noexcept
+    {
+        auto it = std::lower_bound(begin(), end(), key, [](const value_type& a, const Key& b) {
+            return Cmp{}(a.first, b);
+        });
+        return it;
+    }
+
+    // FIXME: Not implemented yet.
+    template <class Key>
+    iterator upper_bound(const Key&) noexcept;
+    // FIXME: Not implemented yet.
+    template <class Key>
+    const_iterator upper_bound(const Key&) const noexcept;
+
+    void reserve(size_t size)
+    {
+        m_data.reserve(size); // Throws
+    }
+
+private:
+    Container m_data;
+};
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_FLAT_MAP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/get_file_size.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/get_file_size.hpp
new file mode 100644
index 0000000..29ca1a7
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/get_file_size.hpp
@@ -0,0 +1,45 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_GET_FILE_SIZE_HPP
+#define REALM_UTIL_GET_FILE_SIZE_HPP
+
+#include <realm/util/file.hpp>
+
+namespace realm {
+namespace util {
+
+/// FIXME: This function ought to be moved to <realm/util/file.hpp> in the
+/// realm-core repository.
+util::File::SizeType get_file_size(const std::string& path);
+
+
+
+// Implementation
+
+inline util::File::SizeType get_file_size(const std::string& path)
+{
+    util::File file{path}; // Throws
+    return file.get_size(); // Throws
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_GET_FILE_SIZE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/hex_dump.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/hex_dump.hpp
new file mode 100644
index 0000000..08f5d2b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/hex_dump.hpp
@@ -0,0 +1,54 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_HEX_DUMP_HPP
+#define REALM_UTIL_HEX_DUMP_HPP
+
+#include <cstddef>
+#include <type_traits>
+#include <limits>
+#include <string>
+#include <sstream>
+#include <iomanip>
+
+#include <realm/util/safe_int_ops.hpp>
+
+namespace realm {
+namespace util {
+
+template <class T>
+std::string hex_dump(const T* data, size_t size, const char* separator = " ", int min_digits = -1)
+{
+    using U = typename std::make_unsigned<T>::type;
+
+    if (min_digits < 0)
+        min_digits = (std::numeric_limits<U>::digits + 3) / 4;
+
+    std::ostringstream out;
+    for (const T* i = data; i != data + size; ++i) {
+        if (i != data)
+            out << separator;
+        out << std::setw(min_digits) << std::setfill('0') << std::hex << std::uppercase << util::promote(U(*i));
+    }
+    return out.str();
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_HEX_DUMP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/http.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/http.hpp
new file mode 100644
index 0000000..91da876
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/http.hpp
@@ -0,0 +1,541 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_HTTP_HPP
+#define REALM_UTIL_HTTP_HPP
+
+#include <cstdint>
+#include <type_traits>
+#include <map>
+#include <system_error>
+#include <iosfwd>
+#include <locale>
+
+#include <realm/util/optional.hpp>
+#include <realm/util/network.hpp>
+#include <realm/util/logger.hpp>
+#include <realm/util/string_view.hpp>
+#include <realm/string_data.hpp>
+
+namespace realm {
+namespace util {
+enum class HTTPParserError {
+    None = 0,
+    ContentTooLong,
+    HeaderLineTooLong,
+    MalformedResponse,
+    MalformedRequest,
+    BadRequest,
+};
+std::error_code make_error_code(HTTPParserError);
+} // namespace util
+} // namespace realm
+
+namespace std {
+template<> struct is_error_code_enum<realm::util::HTTPParserError> : std::true_type {};
+}
+
+namespace realm {
+namespace util {
+
+/// See: https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
+///
+/// It is guaranteed that the backing integer value of this enum corresponds
+/// to the numerical code representing the status.
+enum class HTTPStatus {
+    Unknown = 0,
+
+    Continue = 100,
+    SwitchingProtocols = 101,
+
+    Ok = 200,
+    Created = 201,
+    Accepted = 202,
+    NonAuthoritative = 203,
+    NoContent = 204,
+    ResetContent = 205,
+    PartialContent = 206,
+
+    MultipleChoices = 300,
+    MovedPermanently = 301,
+    Found = 302,
+    SeeOther = 303,
+    NotModified = 304,
+    UseProxy = 305,
+    SwitchProxy = 306,
+    TemporaryRedirect = 307,
+    PermanentRedirect = 308,
+
+    BadRequest = 400,
+    Unauthorized = 401,
+    PaymentRequired = 402,
+    Forbidden = 403,
+    NotFound = 404,
+    MethodNotAllowed = 405,
+    NotAcceptable = 406,
+    ProxyAuthenticationRequired = 407,
+    RequestTimeout = 408,
+    Conflict = 409,
+    Gone = 410,
+    LengthRequired = 411,
+    PreconditionFailed = 412,
+    PayloadTooLarge = 413,
+    UriTooLong = 414,
+    UnsupportedMediaType = 415,
+    RangeNotSatisfiable = 416,
+    ExpectationFailed = 417,
+    ImATeapot = 418,
+    MisdirectedRequest = 421,
+    UpgradeRequired = 426,
+    PreconditionRequired = 428,
+    TooManyRequests = 429,
+    RequestHeaderFieldsTooLarge = 431,
+    UnavailableForLegalReasons = 451,
+
+    InternalServerError = 500,
+    NotImplemented = 501,
+    BadGateway = 502,
+    ServiceUnavailable = 503,
+    GatewayTimeout = 504,
+    HttpVersionNotSupported = 505,
+    VariantAlsoNegotiates = 506,
+    NotExtended = 510,
+    NetworkAuthenticationRequired = 511,
+};
+
+bool valid_http_status_code(unsigned int code);
+
+/// See: https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html
+enum class HTTPMethod {
+    Options,
+    Get,
+    Head,
+    Post,
+    Put,
+    Delete,
+    Trace,
+    Connect,
+};
+
+struct HTTPAuthorization {
+    std::string scheme;
+    std::map<std::string, std::string> values;
+};
+
+HTTPAuthorization parse_authorization(const std::string&);
+
+class HeterogeneousCaseInsensitiveCompare {
+public:
+    using is_transparent = std::true_type;
+    template<class A, class B> bool operator()(const A& a, const B& b) const noexcept
+    {
+        return comp(StringView(a), StringView(b));
+    }
+private:
+    bool comp(StringView a, StringView b) const noexcept
+    {
+        auto cmp = [](char lhs, char rhs) {
+            return std::tolower(lhs, std::locale::classic()) <
+                   std::tolower(rhs, std::locale::classic());
+        };
+        return std::lexicographical_compare(begin(a), end(a), begin(b), end(b), cmp);
+    }
+};
+
+/// Case-insensitive map suitable for storing HTTP headers.
+using HTTPHeaders = std::map<std::string, std::string, HeterogeneousCaseInsensitiveCompare>;
+
+struct HTTPRequest {
+    HTTPMethod method = HTTPMethod::Get;
+    HTTPHeaders headers;
+    std::string path;
+
+    /// If the request object has a body, the Content-Length header MUST be
+    /// set to a string representation of the number of bytes in the body.
+    /// FIXME: Relax this restriction, and also support Transfer-Encoding
+    /// and other HTTP/1.1 features.
+    Optional<std::string> body;
+};
+
+struct HTTPResponse {
+    HTTPStatus status = HTTPStatus::Unknown;
+    std::string reason;
+    HTTPHeaders headers;
+
+    // A body is only read from the response stream if the server sent the
+    // Content-Length header.
+    // FIXME: Support other transfer methods, including Transfer-Encoding and
+    // HTTP/1.1 features.
+    Optional<std::string> body;
+};
+
+
+/// Serialize HTTP request to output stream.
+std::ostream& operator<<(std::ostream&, const HTTPRequest&);
+/// Serialize HTTP response to output stream.
+std::ostream& operator<<(std::ostream&, const HTTPResponse&);
+/// Serialize HTTP method to output stream ("GET", "POST", etc.).
+std::ostream& operator<<(std::ostream&, HTTPMethod);
+/// Serialize HTTP status to output stream, include reason string ("200 OK" etc.)
+std::ostream& operator<<(std::ostream&, HTTPStatus);
+
+
+struct HTTPParserBase {
+    util::Logger& logger;
+
+    // FIXME: Generally useful?
+    struct CallocDeleter {
+        void operator()(void* ptr)
+        {
+            std::free(ptr);
+        }
+    };
+
+    HTTPParserBase(util::Logger& logger_2):
+        logger {logger_2}
+    {
+        // Allocating read buffer with calloc to avoid accidentally spilling
+        // data from other sessions in case of a buffer overflow exploit.
+        m_read_buffer.reset(static_cast<char*>(std::calloc(read_buffer_size, 1)));
+    }
+    virtual ~HTTPParserBase() {}
+
+    std::string m_write_buffer;
+    std::unique_ptr<char[], CallocDeleter> m_read_buffer;
+    Optional<size_t> m_found_content_length;
+    static const size_t read_buffer_size = 8192;
+    static const size_t max_header_line_length = read_buffer_size;
+
+    /// Parses the contents of m_read_buffer as a HTTP header line,
+    /// and calls on_header() as appropriate. on_header() will be called at
+    /// most once per invocation.
+    /// Returns false if the contents of m_read_buffer is not a valid HTTP
+    /// header line.
+    bool parse_header_line(size_t len);
+
+    virtual std::error_code on_first_line(StringData line) = 0;
+    virtual void on_header(StringData key, StringData value) = 0;
+    virtual void on_body(StringData body) = 0;
+    virtual void on_complete(std::error_code = std::error_code{}) = 0;
+
+    /// If the input matches a known HTTP method string, return the appropriate
+    /// HTTPMethod enum value. Otherwise, returns none.
+    static Optional<HTTPMethod> parse_method_string(StringData method);
+
+    /// Interpret line as the first line of an HTTP request. If the return value
+    /// is true, out_method and out_uri have been assigned the appropriate
+    /// values found in the request line.
+    static bool parse_first_line_of_request(StringData line, HTTPMethod& out_method,
+                                            StringData& out_uri);
+
+    /// Interpret line as the first line of an HTTP response. If the return
+    /// value is true, out_status and out_reason have been assigned the
+    /// appropriate values found in the response line.
+    static bool parse_first_line_of_response(StringData line, HTTPStatus& out_status,
+                                             StringData& out_reason, util::Logger& logger);
+
+    void set_write_buffer(const HTTPRequest&);
+    void set_write_buffer(const HTTPResponse&);
+};
+
+
+template<class Socket>
+struct HTTPParser: protected HTTPParserBase {
+    explicit HTTPParser(Socket& socket, util::Logger& logger):
+        HTTPParserBase(logger),
+        m_socket(socket)
+    {}
+
+    void read_first_line()
+    {
+        auto handler = [this](std::error_code ec, size_t n) {
+            if (ec == error::operation_aborted) {
+                return;
+            }
+            if (ec) {
+                on_complete(ec);
+                return;
+            }
+            ec = on_first_line(StringData(m_read_buffer.get(), n));
+            if (ec) {
+                on_complete(ec);
+                return;
+            }
+            read_headers();
+        };
+        m_socket.async_read_until(m_read_buffer.get(), max_header_line_length, '\n',
+                                  std::move(handler));
+    }
+
+    void read_headers()
+    {
+        auto handler = [this](std::error_code ec, size_t n) {
+            if (ec == error::operation_aborted) {
+                return;
+            }
+            if (ec) {
+                on_complete(ec);
+                return;
+            }
+            if (n <= 2) {
+                read_body();
+                return;
+            }
+            if (!parse_header_line(n)) {
+                on_complete(HTTPParserError::BadRequest);
+                return;
+            }
+
+            // FIXME: Limit the total size of headers. Apache uses 8K.
+            read_headers();
+        };
+        m_socket.async_read_until(m_read_buffer.get(), max_header_line_length, '\n',
+                                  std::move(handler));
+    }
+
+    void read_body()
+    {
+        if (m_found_content_length) {
+            // FIXME: Support longer bodies.
+            // FIXME: Support multipart and other body types (no body shaming).
+            if (*m_found_content_length > read_buffer_size) {
+                on_complete(HTTPParserError::ContentTooLong);
+                return;
+            }
+
+            auto handler = [this](std::error_code ec, size_t n) {
+                if (ec == error::operation_aborted) {
+                    return;
+                }
+                if (!ec) {
+                    on_body(StringData(m_read_buffer.get(), n));
+                }
+                on_complete(ec);
+            };
+            m_socket.async_read(m_read_buffer.get(), *m_found_content_length,
+                                std::move(handler));
+        }
+        else {
+            // No body, just finish.
+            on_complete();
+        }
+    }
+
+    void write_buffer(std::function<void(std::error_code, size_t)> handler)
+    {
+        m_socket.async_write(m_write_buffer.data(), m_write_buffer.size(),
+                             std::move(handler));
+    }
+
+    Socket& m_socket;
+};
+
+
+template<class Socket>
+struct HTTPClient: protected HTTPParser<Socket> {
+    using Handler = void(HTTPResponse, std::error_code);
+
+    explicit HTTPClient(Socket& socket, util::Logger& logger) : HTTPParser<Socket>(socket, logger) {}
+
+    /// Serialize and send \a request over the connected socket asynchronously.
+    ///
+    /// When the response has been received, or an error occurs, \a handler will
+    /// be invoked with the appropriate parameters. The HTTPResponse object
+    /// passed to \a handler will only be complete in non-error conditions, but
+    /// may be partially populated.
+    ///
+    /// It is an error to start a request before the \a handler of a previous
+    /// request has been invoked. It is permitted to call async_request() from
+    /// the handler, unless an error has been reported representing a condition
+    /// where the underlying socket is no longer able to communicate (for
+    /// example, if it has been closed).
+    ///
+    /// If a request is already in progress, an exception will be thrown.
+    ///
+    /// This method is *NOT* thread-safe.
+    void async_request(const HTTPRequest& request, std::function<Handler> handler)
+    {
+        if (REALM_UNLIKELY(m_handler)) {
+            throw util::runtime_error("Request already in progress.");
+        }
+        this->set_write_buffer(request);
+        m_handler = std::move(handler);
+        this->write_buffer([this](std::error_code ec, size_t bytes_written) {
+            static_cast<void>(bytes_written);
+            if (ec == error::operation_aborted) {
+                return;
+            }
+            if (ec) {
+                this->on_complete(ec);
+                return;
+            }
+            this->read_first_line();
+        });
+    }
+
+private:
+    std::function<Handler> m_handler;
+    HTTPResponse m_response;
+
+    std::error_code on_first_line(StringData line) override final
+    {
+        HTTPStatus status;
+        StringData reason;
+        if (this->parse_first_line_of_response(line, status, reason, this->logger)) {
+            m_response.status = status;
+            m_response.reason = reason;
+            return std::error_code{};
+        }
+        return HTTPParserError::MalformedResponse;
+    }
+
+    void on_header(StringData key, StringData value) override final
+    {
+        // FIXME: Multiple headers with the same key should show up as a
+        // comma-separated list of their values, rather than overwriting.
+        m_response.headers[std::string(key)] = std::string(value);
+    }
+
+    void on_body(StringData body) override final
+    {
+        m_response.body = std::string(body);
+    }
+
+    void on_complete(std::error_code ec) override final
+    {
+        auto handler = std::move(m_handler);
+        m_handler = nullptr;
+        handler(std::move(m_response), ec);
+    }
+};
+
+
+template<class Socket>
+struct HTTPServer: protected HTTPParser<Socket> {
+    using RequestHandler = void(HTTPRequest, std::error_code);
+    using RespondHandler = void(std::error_code);
+
+    explicit HTTPServer(Socket& socket, util::Logger& logger): HTTPParser<Socket>(socket, logger)
+    {}
+
+    /// Receive a request on the underlying socket asynchronously.
+    ///
+    /// This function starts an asynchronous read operation and keeps reading
+    /// until an HTTP request has been received. \a handler is invoked when a
+    /// request has been received, or an error occurs.
+    ///
+    /// After a request is received, callers MUST invoke async_send_response()
+    /// to provide the client with a valid HTTP response, unless the error
+    /// passed to the handler represents a condition where the underlying socket
+    /// is no longer able to communicate (for example, if it has been closed).
+    ///
+    /// It is an error to attempt to receive a request before any previous
+    /// requests have been fully responded to, i.e. the \a handler argument of
+    /// async_send_response() must have been invoked before attempting to
+    /// receive the next request.
+    ///
+    /// This function is *NOT* thread-safe.
+    void async_receive_request(std::function<RequestHandler> handler)
+    {
+        if (REALM_UNLIKELY(m_request_handler)) {
+            throw util::runtime_error("Response already in progress.");
+        }
+        m_request_handler = std::move(handler);
+        this->read_first_line();
+    }
+
+    /// Send an HTTP response to a client asynchronously.
+    ///
+    /// This function starts an asynchronous write operation on the underlying
+    /// socket. \a handler is invoked when the response has been written to the
+    /// socket, or an error occurs.
+    ///
+    /// It is an error to call async_receive_request() again before \a handler
+    /// has been invoked, and it is an error to call async_send_response()
+    /// before the \a handler of a previous invocation has been invoked.
+    ///
+    /// This function is *NOT* thread-safe.
+    void async_send_response(const HTTPResponse& response,
+                             std::function<RespondHandler> handler)
+    {
+        if (REALM_UNLIKELY(!m_request_handler)) {
+            throw util::runtime_error("No request in progress.");
+        }
+        if (m_respond_handler) {
+            // FIXME: Proper exception type.
+            throw util::runtime_error("Already responding to request");
+        }
+        m_respond_handler = std::move(handler);
+        this->set_write_buffer(response);
+        this->write_buffer([this](std::error_code ec, size_t) {
+            if (ec == error::operation_aborted) {
+                return;
+            }
+            m_request_handler = nullptr;
+            auto handler = std::move(m_respond_handler);
+            handler(ec);
+        });;
+    }
+
+private:
+    std::function<RequestHandler> m_request_handler;
+    std::function<RespondHandler> m_respond_handler;
+    HTTPRequest m_request;
+
+    std::error_code on_first_line(StringData line) override final
+    {
+        HTTPMethod method;
+        StringData uri;
+        if (this->parse_first_line_of_request(line, method, uri)) {
+            m_request.method = method;
+            m_request.path = uri;
+            return std::error_code{};
+        }
+        return HTTPParserError::MalformedRequest;
+    }
+
+    void on_header(StringData key, StringData value) override final
+    {
+        // FIXME: Multiple headers with the same key should show up as a
+        // comma-separated list of their values, rather than overwriting.
+        m_request.headers[std::string(key)] = std::string(value);
+    }
+
+    void on_body(StringData body) override final
+    {
+        m_request.body = std::string(body);
+    }
+
+    void on_complete(std::error_code ec) override final
+    {
+        // Deliberately not nullifying m_request_handler so that we can
+        // check for invariants in async_send_response.
+        m_request_handler(std::move(m_request), ec);
+    }
+};
+
+
+std::string make_http_host(bool is_ssl, StringView address, std::uint_fast16_t port);
+
+} // namespace util
+} // namespace realm
+
+
+#endif // REALM_UTIL_HTTP_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/inspect.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/inspect.hpp
new file mode 100644
index 0000000..84a669d
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/inspect.hpp
@@ -0,0 +1,76 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_INSPECT_HPP
+#define REALM_UTIL_INSPECT_HPP
+
+#include <string>
+
+namespace realm {
+namespace util {
+
+// LCOV_EXCL_START
+//
+// Because these are templated functions, every combination of output stream
+// type and value(s) type(s) generates a new function.  This makes LCOV/GCOVR
+// report over 70 functions in this file, with only 6.6% function coverage,
+// even though line coverage is at 100%.
+
+template <class OS, class T>
+void inspect_value(OS& os, const T& value)
+{
+    os << value;
+}
+
+template <class OS>
+void inspect_value(OS& os, const std::string& value)
+{
+    // FIXME: Escape the string.
+    os << "\"" << value << "\"";
+}
+
+template <class OS>
+void inspect_value(OS& os, const char* value)
+{
+    // FIXME: Escape the string.
+    os << "\"" << value << "\"";
+}
+
+template <class OS>
+void inspect_all(OS&)
+{
+    // No-op
+}
+
+/// Convert all arguments to strings, and quote string arguments.
+template <class OS, class First, class... Args>
+void inspect_all(OS& os, First&& first, Args&&... args)
+{
+    inspect_value(os, std::forward<First>(first));
+    if (sizeof...(Args) != 0) {
+        os << ", ";
+    }
+    inspect_all(os, std::forward<Args>(args)...);
+}
+
+// LCOV_EXCL_STOP
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_INSPECT_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/interprocess_condvar.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/interprocess_condvar.hpp
new file mode 100644
index 0000000..0e5b586
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/interprocess_condvar.hpp
@@ -0,0 +1,151 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_INTERPROCESS_CONDVAR
+#define REALM_UTIL_INTERPROCESS_CONDVAR
+
+
+#include <realm/util/features.h>
+#include <realm/util/thread.hpp>
+#include <realm/util/interprocess_mutex.hpp>
+#include <cstdint>
+#include <fcntl.h>
+#include <sys/stat.h>
+#include <mutex>
+
+// Condvar Emulation is required if RobustMutex emulation is enabled
+#if defined(REALM_ROBUST_MUTEX_EMULATION) || defined(_WIN32)
+#define REALM_CONDVAR_EMULATION
+#endif
+
+namespace realm {
+namespace util {
+
+
+/// Condition variable for use in synchronization monitors.
+/// This condition variable uses emulation based on named pipes
+/// for the inter-process case, if enabled by REALM_CONDVAR_EMULATION.
+///
+/// FIXME: This implementation will never release/delete pipes. This is unlikely
+/// to be a problem as long as only a modest number of different database names
+/// are in use
+///
+/// A InterprocessCondVar is always process shared.
+class InterprocessCondVar {
+public:
+    InterprocessCondVar();
+    ~InterprocessCondVar() noexcept;
+
+    // Disable copying. Copying an open file will create a scenario
+    // where the same file descriptor will be opened once but closed twice.
+    InterprocessCondVar(const InterprocessCondVar&) = delete;
+    InterprocessCondVar& operator=(const InterprocessCondVar&) = delete;
+
+/// To use the InterprocessCondVar, you also must place a structure of type
+/// InterprocessCondVar::SharedPart in memory shared by multiple processes
+/// or in a memory mapped file, and use set_shared_part() to associate
+/// the condition variable with it's shared part. You must initialize
+/// the shared part using InterprocessCondVar::init_shared_part(), but only before
+/// first use and only when you have exclusive access to the shared part.
+
+#ifdef REALM_CONDVAR_EMULATION
+    struct SharedPart {
+#ifdef _WIN32
+        // Number of waiting threads.
+        int32_t m_waiters_count;
+        size_t m_was_broadcast;
+#else
+        uint64_t signal_counter;
+        uint64_t wait_counter;
+#endif
+    };
+#else
+    typedef CondVar SharedPart;
+#endif
+
+    /// You need to bind the emulation to a SharedPart in shared/mmapped memory.
+    /// The SharedPart is assumed to have been initialized (possibly by another process)
+    /// earlier through a call to init_shared_part.
+    void set_shared_part(SharedPart& shared_part, std::string path, std::string condvar_name, std::string tmp_path);
+
+    /// Initialize the shared part of a process shared condition variable.
+    /// A process shared condition variables may be represented by any number of
+    /// InterprocessCondVar instances in any number of different processes,
+    /// all sharing a common SharedPart instance, which must be in shared memory.
+    static void init_shared_part(SharedPart& shared_part);
+
+    /// Release any system resources allocated for the shared part. This should
+    /// be used *only* when you are certain, that nobody is using it.
+    void release_shared_part();
+
+    /// Wait for someone to call notify() or notify_all() on this condition
+    /// variable. The call to wait() may return spuriously, so the caller should
+    /// always re-evaluate the condition on which to wait and loop on wait()
+    /// if necessary.
+    void wait(InterprocessMutex& m, const struct timespec* tp);
+
+    /// If any threads are waiting for this condition, wake up at least one.
+    /// (Current implementation may actually wake all :-O ). The caller must
+    /// hold the lock associated with the condvar at the time of calling notify()
+    void notify() noexcept;
+
+    /// Wake up every thread that is currently waiting on this condition.
+    /// The caller must hold the lock associated with the condvar at the time
+    /// of calling notify_all().
+    void notify_all() noexcept;
+
+    /// Cleanup and release system resources if possible.
+    void close() noexcept;
+
+private:
+    // non-zero if a shared part has been registered (always 0 on process local instances)
+    SharedPart* m_shared_part = nullptr;
+#ifdef REALM_CONDVAR_EMULATION
+    // keep the path to allocated system resource so we can remove them again
+    std::string m_resource_path;
+    // pipe used for emulation. When using a named pipe, m_fd_read is read-write and m_fd_write is unused.
+    // When using an anonymous pipe (currently only for tvOS) m_fd_read is read-only and m_fd_write is write-only.
+    int m_fd_read = -1;
+    int m_fd_write = -1;
+
+#ifdef _WIN32
+    // Semaphore used to queue up threads waiting for the condition to
+    // become signaled. 
+    HANDLE m_sema = 0;
+    // An auto-reset event used by the broadcast/signal thread to wait
+    // for all the waiting thread(s) to wake up and be released from the
+    // semaphore. 
+    HANDLE m_waiters_done = 0;
+    std::string m_name;
+
+    // Serialize access to m_waiters_count
+    InterprocessMutex m_waiters_lockcount;
+#endif
+
+#endif
+};
+
+
+// Implementation:
+
+
+} // namespace util
+} // namespace realm
+
+
+#endif
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/interprocess_mutex.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/interprocess_mutex.hpp
new file mode 100644
index 0000000..b3af1c6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/interprocess_mutex.hpp
@@ -0,0 +1,375 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_INTERPROCESS_MUTEX
+#define REALM_UTIL_INTERPROCESS_MUTEX
+
+#include <realm/util/features.h>
+#include <realm/util/thread.hpp>
+#include <realm/util/file.hpp>
+#include <realm/utilities.hpp>
+#include <mutex>
+#include <map>
+#include <iostream>
+
+// Enable this only on platforms where it might be needed
+#if REALM_PLATFORM_APPLE || REALM_ANDROID
+#define REALM_ROBUST_MUTEX_EMULATION
+#endif
+
+namespace realm {
+namespace util {
+
+// fwd decl to support friend decl below
+class InterprocessCondVar;
+
+
+/// Emulation of a Robust Mutex.
+/// A Robust Mutex is an interprocess mutex which will automatically
+/// release any locks held by a process when it crashes. Contrary to
+/// Posix robust mutexes, this robust mutex is not capable of informing
+/// participants that they have been granted a lock after a crash of
+/// the process holding it (though it could be added if needed).
+
+class InterprocessMutex {
+public:
+    InterprocessMutex();
+    ~InterprocessMutex() noexcept;
+
+    // Disable copying. Copying a locked Mutex will create a scenario
+    // where the same file descriptor will be locked once but unlocked twice.
+    InterprocessMutex(const InterprocessMutex&) = delete;
+    InterprocessMutex& operator=(const InterprocessMutex&) = delete;
+
+#if defined(REALM_ROBUST_MUTEX_EMULATION) || defined(_WIN32)
+    struct SharedPart {
+    };
+#else
+    using SharedPart = RobustMutex;
+#endif
+
+    /// You need to bind the emulation to a SharedPart in shared/mmapped memory.
+    /// The SharedPart is assumed to have been initialized (possibly by another process)
+    /// elsewhere.
+    void set_shared_part(SharedPart& shared_part, const std::string& path, const std::string& mutex_name);
+    void set_shared_part(SharedPart& shared_part, File&& lock_file);
+
+    /// Destroy shared object. Potentially release system resources. Caller must
+    /// ensure that the shared_part is not in use at the point of call.
+    void release_shared_part();
+
+    /// Lock the mutex. If the mutex is already locked, wait for it to be unlocked.
+    void lock();
+
+    /// Non-blocking attempt to lock the mutex. Returns true if the lock is obtained.
+    /// If the lock can not be obtained return false immediately.
+    bool try_lock();
+
+    /// Unlock the mutex
+    void unlock();
+
+    /// Attempt to check if the mutex is valid (only relevant if not emulating)
+    bool is_valid() noexcept;
+
+    static bool is_robust_on_this_platform()
+    {
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+        return true; // we're faking it!
+#else
+        return RobustMutex::is_robust_on_this_platform();
+#endif
+    }
+
+private:
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    struct LockInfo {
+        File m_file;
+        Mutex m_local_mutex;
+        LockInfo() {}
+        ~LockInfo() noexcept;
+        // Disable copying.
+        LockInfo(const LockInfo&) = delete;
+        LockInfo& operator=(const LockInfo&) = delete;
+    };
+    /// InterprocessMutex created on the same file (same inode on POSIX) share the same LockInfo.
+    /// LockInfo will be saved in a static map as a weak ptr and use the UniqueID as the key.
+    /// Operations on the map need to be protected by s_mutex
+    static std::map<File::UniqueID, std::weak_ptr<LockInfo>>* s_info_map;
+    static Mutex* s_mutex;
+    /// We manually initialize these static variables when first needed,
+    /// creating them on the heap so that they last for the entire lifetime
+    /// of the process. The destructor of these is never called; the
+    /// process will clean up their memory when exiting. It is not enough
+    /// to count instances of InterprocessMutex and clean up these statics when
+    /// the count reaches zero because the program can create more
+    /// InterprocessMutex instances before the process ends, so we really need
+    /// these variables for the entire lifetime of the process.
+    static std::once_flag s_init_flag;
+    static void initialize_statics();
+
+    /// Only used for release_shared_part
+    std::string m_filename;
+    File::UniqueID m_fileuid;
+    std::shared_ptr<LockInfo> m_lock_info;
+
+    /// Free the lock info hold by this instance.
+    /// If it is the last reference, underly resources will be freed as well.
+    void free_lock_info();
+#else
+    SharedPart* m_shared_part = nullptr;
+
+#ifdef _WIN32
+    HANDLE m_handle = 0;
+#endif
+
+#endif
+    friend class InterprocessCondVar;
+};
+
+inline InterprocessMutex::InterprocessMutex()
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    std::call_once(s_init_flag, initialize_statics);
+#endif
+}
+
+inline InterprocessMutex::~InterprocessMutex() noexcept
+{
+#ifdef _WIN32
+    if (m_handle) {
+        bool b = CloseHandle(m_handle);
+        REALM_ASSERT_RELEASE(b);
+    }
+#endif
+
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    free_lock_info();
+#endif
+}
+
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+inline InterprocessMutex::LockInfo::~LockInfo() noexcept
+{
+    if (m_file.is_attached()) {
+        m_file.close();
+    }
+}
+
+inline void InterprocessMutex::free_lock_info()
+{
+    // It has not been initialized yet.
+    if (!m_lock_info)
+        return;
+
+    std::lock_guard<Mutex> guard(*s_mutex);
+
+    m_lock_info.reset();
+    if ((*s_info_map)[m_fileuid].expired()) {
+        s_info_map->erase(m_fileuid);
+    }
+    m_filename.clear();
+}
+
+inline void InterprocessMutex::initialize_statics()
+{
+    s_mutex = new Mutex();
+    s_info_map = new std::map<File::UniqueID, std::weak_ptr<LockInfo>>();
+}
+#endif
+
+inline void InterprocessMutex::set_shared_part(SharedPart& shared_part, const std::string& path,
+                                               const std::string& mutex_name)
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    static_cast<void>(shared_part);
+
+    free_lock_info();
+
+    m_filename = path + "." + mutex_name + ".mx";
+
+    std::lock_guard<Mutex> guard(*s_mutex);
+
+    // Try to get the file uid if the file exists
+    if (File::get_unique_id(m_filename, m_fileuid)) {
+        auto result = s_info_map->find(m_fileuid);
+        if (result != s_info_map->end()) {
+            // File exists and the lock info has been created in the map.
+            m_lock_info = result->second.lock();
+            return;
+        }
+    }
+
+    // LockInfo has not been created yet.
+    m_lock_info = std::make_shared<LockInfo>();
+    // Always use mod_Write to open file and retreive the uid in case other process
+    // deletes the file.
+    m_lock_info->m_file.open(m_filename, File::mode_Write);
+    m_fileuid = m_lock_info->m_file.get_unique_id();
+
+    (*s_info_map)[m_fileuid] = m_lock_info;
+#elif defined(_WIN32)
+    if (m_handle) {
+        bool b = CloseHandle(m_handle);
+        REALM_ASSERT_RELEASE(b);
+    }
+    // replace backslashes because they're significant in object namespace names
+    std::string path_escaped = path;
+    std::replace(path_escaped.begin(), path_escaped.end(), '\\', '/');
+    std::string name = "Local\\realm_named_intermutex_" + path_escaped + mutex_name;
+
+    std::wstring wname(name.begin(), name.end());
+    m_handle = CreateMutexW(0, false, wname.c_str());
+    if (!m_handle) {
+        throw std::system_error(GetLastError(), std::system_category(), "Error opening mutex");
+    }
+#else
+    m_shared_part = &shared_part;
+    static_cast<void>(path);
+    static_cast<void>(mutex_name);
+#endif
+}
+
+inline void InterprocessMutex::set_shared_part(SharedPart& shared_part, File&& lock_file)
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    static_cast<void>(shared_part);
+
+    free_lock_info();
+
+    std::lock_guard<Mutex> guard(*s_mutex);
+
+    m_fileuid = lock_file.get_unique_id();
+    auto result = s_info_map->find(m_fileuid);
+    if (result == s_info_map->end()) {
+        m_lock_info = std::make_shared<LockInfo>();
+        m_lock_info->m_file = std::move(lock_file);
+        (*s_info_map)[m_fileuid] = m_lock_info;
+    }
+    else {
+        // File exists and the lock info has been created in the map.
+        m_lock_info = result->second.lock();
+        lock_file.close();
+    }
+#else
+    m_shared_part = &shared_part;
+    static_cast<void>(lock_file);
+#endif
+}
+
+inline void InterprocessMutex::release_shared_part()
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    if (!m_filename.empty())
+        File::try_remove(m_filename);
+
+    free_lock_info();
+#else
+    m_shared_part = nullptr;
+#endif
+}
+
+inline void InterprocessMutex::lock()
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    std::unique_lock<Mutex> mutex_lock(m_lock_info->m_local_mutex);
+    m_lock_info->m_file.lock_exclusive();
+    mutex_lock.release();
+#else
+
+#ifdef _WIN32
+    DWORD d = WaitForSingleObject(m_handle, INFINITE);
+    REALM_ASSERT_RELEASE(d != WAIT_FAILED);
+#else
+    REALM_ASSERT(m_shared_part);
+    m_shared_part->lock([]() {});
+#endif
+#endif
+}
+
+inline bool InterprocessMutex::try_lock()
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    std::unique_lock<Mutex> mutex_lock(m_lock_info->m_local_mutex, std::try_to_lock_t());
+    if (!mutex_lock.owns_lock()) {
+        return false;
+    }
+    bool success = m_lock_info->m_file.try_lock_exclusive();
+    if (success) {
+        mutex_lock.release();
+        return true;
+    }
+    else {
+        return false;
+    }
+#else
+
+#ifdef _WIN32
+    DWORD ret = WaitForSingleObject(m_handle, 0);
+    REALM_ASSERT_RELEASE(ret != WAIT_FAILED);
+
+    if (ret == WAIT_OBJECT_0) {
+        return true;
+    }
+    else {
+        return false;
+    }
+#else
+    REALM_ASSERT(m_shared_part);
+    return m_shared_part->try_lock([]() {});
+#endif
+#endif
+}
+
+
+inline void InterprocessMutex::unlock()
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    m_lock_info->m_file.unlock();
+    m_lock_info->m_local_mutex.unlock();
+#else
+#ifdef _WIN32
+    bool b = ReleaseMutex(m_handle);
+    REALM_ASSERT_RELEASE(b);
+#else
+    REALM_ASSERT(m_shared_part);
+    m_shared_part->unlock();
+#endif
+#endif
+}
+
+
+inline bool InterprocessMutex::is_valid() noexcept
+{
+#ifdef REALM_ROBUST_MUTEX_EMULATION
+    return true;
+#elif defined(_WIN32)
+    // There is no safe way of testing if the m_handle mutex handle is valid on Windows, without having bad side effects
+    // for the cases where it is indeed invalid. If m_handle contains an arbitrary value, it might by coincidence be equal
+    // to a real live handle of another kind. This excludes a try_lock implementation and many other ideas.
+    return true;
+#else
+    REALM_ASSERT(m_shared_part);
+    return m_shared_part->is_valid();
+#endif
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // #ifndef REALM_UTIL_INTERPROCESS_MUTEX
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/json_parser.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/json_parser.hpp
new file mode 100644
index 0000000..bc6664a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/json_parser.hpp
@@ -0,0 +1,545 @@
+/*************************************************************************
+ * 
+ * REALM CONFIDENTIAL
+ * __________________
+ * 
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ * 
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_JSON_PARSER_HPP
+#define REALM_UTIL_JSON_PARSER_HPP
+
+#include <system_error>
+#include <algorithm>
+#include <cstdlib>
+#include <cctype>
+
+#include <realm/string_data.hpp>
+
+namespace realm {
+namespace util {
+
+/// A JSON parser that neither allocates heap memory nor throws exceptions.
+///
+/// The parser takes as input a range of characters, and emits a stream of events
+/// representing the structure of the JSON document.
+///
+/// Parser errors are represented as `std::error_condition`s.
+class JSONParser {
+public:
+    using InputIterator = const char*;
+
+    enum class EventType {
+        number,
+        string,
+        boolean,
+        null,
+        array_begin,
+        array_end,
+        object_begin,
+        object_end
+    };
+
+    using Range = StringData;
+
+    struct Event {
+        EventType type;
+        Range range;
+        Event(EventType type): type(type) {}
+
+        union {
+            bool boolean;
+            double number;
+        };
+
+        StringData escaped_string_value() const noexcept;
+
+        /// Unescape the string value into \a buffer.
+        /// The type of this event must be EventType::string.
+        ///
+        /// \param buffer is a pointer to a buffer big enough to hold the
+        /// unescaped string value. The unescaped string is guaranteed to be
+        /// shorter than the escaped string, so escaped_string_value().size() can
+        /// be used as an upper bound. Unicode sequences of the form "\uXXXX"
+        /// will be converted to UTF-8 sequences. Note that the escaped form of
+        /// a unicode point takes exactly 6 bytes, which is also the maximum
+        /// possible length of a UTF-8 encoded codepoint.
+        StringData unescape_string(char* buffer) const noexcept;
+    };
+
+    enum class Error {
+        unexpected_token = 1,
+        unexpected_end_of_stream = 2
+    };
+
+    JSONParser(StringData);
+
+    /// Parse the input data, and call f repeatedly with an argument of type Event
+    /// representing the token that the parser encountered.
+    ///
+    /// The stream of events is "flat", which is to say that it is the responsibility
+    /// of the function f to keep track of any nested object structures as it deems
+    /// appropriate.
+    ///
+    /// This function is guaranteed to never throw, as long as f never throws.
+    template<class F>
+    std::error_condition parse(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+
+    class ErrorCategory: public std::error_category {
+    public:
+        const char* name() const noexcept final;
+        std::string message(int) const final;
+    };
+    static const ErrorCategory error_category;
+private:
+    enum Token: char {
+        object_begin = '{',
+        object_end   = '}',
+        array_begin  = '[',
+        array_end    = ']',
+        colon        = ':',
+        comma        = ',',
+        dquote       = '"',
+        escape       = '\\',
+        minus        = '-',
+        space        = ' ',
+        tab          = '\t',
+        cr           = '\r',
+        lf           = '\n',
+    };
+
+    InputIterator m_current;
+    InputIterator m_end;
+
+    template<class F>
+    std::error_condition parse_object(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_pair(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_array(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_number(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_string(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_value(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_boolean(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+    template<class F>
+    std::error_condition parse_null(F&& f) noexcept(noexcept(f(std::declval<Event>())));
+
+    std::error_condition expect_token(char, Range& out_range) noexcept;
+    std::error_condition expect_token(Token, Range& out_range) noexcept;
+
+    // Returns true unless EOF was reached.
+    bool peek_char(char& out_c) noexcept;
+    bool peek_token(Token& out_t) noexcept;
+    bool is_whitespace(Token t) noexcept;
+    void skip_whitespace() noexcept;
+};
+
+std::error_condition make_error_condition(JSONParser::Error e);
+
+} // namespace util
+} // namespace realm
+
+namespace std {
+template<>
+struct is_error_condition_enum<realm::util::JSONParser::Error> {
+    static const bool value = true;
+};
+}
+
+namespace realm {
+namespace util {
+
+/// Implementation:
+
+
+inline JSONParser::JSONParser(StringData input):
+    m_current(input.data()), m_end(input.data() + input.size())
+{
+}
+
+template<class F>
+std::error_condition JSONParser::parse(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    return parse_value(f);
+}
+
+template<class F>
+std::error_condition JSONParser::parse_object(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    Event event{EventType::object_begin};
+    auto ec = expect_token(Token::object_begin, event.range);
+    if (ec)
+        return ec;
+    ec = f(event);
+    if (ec)
+        return ec;
+
+    while (true) {
+        ec = expect_token(Token::object_end, event.range);
+        if (!ec) {
+            // End of object
+            event.type = EventType::object_end;
+            ec = f(event);
+            if (ec)
+                return ec;
+            break;
+        }
+
+        if (ec != Error::unexpected_token)
+            return ec;
+
+        ec = parse_pair(f);
+        if (ec)
+            return ec;
+
+        skip_whitespace();
+
+        Token t;
+        if (peek_token(t)) {
+            if (t == Token::object_end) {
+                // Fine, will terminate on next iteration
+            }
+            else if (t == Token::comma)
+                ++m_current; // OK, because peek_char returned true
+            else
+                return Error::unexpected_token;
+        }
+        else {
+            return Error::unexpected_end_of_stream;
+        }
+    }
+
+    return std::error_condition{};
+}
+
+template<class F>
+std::error_condition JSONParser::parse_pair(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    skip_whitespace();
+
+    auto ec = parse_string(f);
+    if (ec)
+        return ec;
+
+    skip_whitespace();
+
+    Token t;
+    if (peek_token(t)) {
+        if (t == Token::colon) {
+            ++m_current;
+        }
+        else {
+            return Error::unexpected_token;
+        }
+    }
+
+    return parse_value(f);
+}
+
+template<class F>
+std::error_condition JSONParser::parse_array(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    Event event{EventType::array_begin};
+    auto ec = expect_token(Token::array_begin, event.range);
+    if (ec)
+        return ec;
+    ec = f(event);
+    if (ec)
+        return ec;
+
+    while (true) {
+        ec = expect_token(Token::array_end, event.range);
+        if (!ec) {
+            // End of array
+            event.type = EventType::array_end;
+            ec = f(event);
+            if (ec)
+                return ec;
+            break;
+        }
+
+        if (ec != Error::unexpected_token)
+            return ec;
+
+        ec = parse_value(f);
+        if (ec)
+            return ec;
+
+        skip_whitespace();
+
+        Token t;
+        if (peek_token(t)) {
+            if (t == Token::array_end) {
+                // Fine, will terminate next iteration.
+            }
+            else if (t == Token::comma)
+                ++m_current; // OK, because peek_char returned true
+            else
+                return Error::unexpected_token;
+        }
+        else {
+            return Error::unexpected_end_of_stream;
+        }
+    }
+
+    return std::error_condition{};
+}
+
+template<class F>
+std::error_condition JSONParser::parse_number(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    static const size_t buffer_size = 64;
+    char buffer[buffer_size] = {0};
+    size_t bytes_to_copy = std::min<size_t>(m_end - m_current, buffer_size - 1);
+    if (bytes_to_copy == 0)
+        return Error::unexpected_end_of_stream;
+
+    if (std::isspace(*m_current)) {
+        // JSON has a different idea of what constitutes whitespace than isspace(),
+        // but strtod() uses isspace() to skip initial whitespace. We have already
+        // skipped whitespace that JSON considers valid, so if there is any whitespace
+        // at m_current now, it is invalid according to JSON, and so is an error.
+        return Error::unexpected_token;
+    }
+
+    switch (m_current[0]) {
+        case 'N':
+            // strtod() parses "NAN", JSON does not.
+        case 'I':
+            // strtod() parses "INF", JSON does not.
+        case 'p':
+        case 'P':
+            // strtod() may parse exponent notation, JSON does not.
+            return Error::unexpected_token;
+        case '0':
+            if (bytes_to_copy > 2 && (m_current[1] == 'x' || m_current[1] == 'X')) {
+                // strtod() parses hexadecimal, JSON does not.
+                return Error::unexpected_token;
+            }
+    }
+
+    std::copy(m_current, m_current + bytes_to_copy, buffer);
+
+    char* endp = nullptr;
+    Event event{EventType::number};
+    event.number = std::strtod(buffer, &endp);
+
+    if (endp == buffer) {
+        return Error::unexpected_token;
+    }
+    size_t num_bytes_consumed = endp - buffer;
+    m_current += num_bytes_consumed;
+    return f(event);
+}
+
+template<class F>
+std::error_condition JSONParser::parse_string(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    InputIterator p = m_current;
+    if (p >= m_end)
+        return Error::unexpected_end_of_stream;
+
+    auto count_num_escapes_backwards = [](const char* p, const char* begin) -> size_t {
+        size_t result = 0;
+        for (; p > begin && *p == Token::escape; ++p)
+            ++result;
+        return result;
+    };
+
+    Token t = static_cast<Token>(*p);
+    InputIterator inner_end;
+    if (t == Token::dquote) {
+        inner_end = m_current;
+        do {
+            inner_end = std::find(inner_end + 1, m_end, Token::dquote);
+            if (inner_end == m_end)
+                return Error::unexpected_end_of_stream;
+        } while (count_num_escapes_backwards(inner_end - 1, m_current) % 2 == 1);
+
+        Event event{EventType::string};
+        event.range = Range(m_current, inner_end - m_current + 1);
+        m_current = inner_end + 1;
+        return f(event);
+    }
+    return Error::unexpected_token;
+}
+
+template<class F>
+std::error_condition JSONParser::parse_boolean(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    auto first_nonalpha = std::find_if_not(m_current, m_end, [](auto c) { return std::isalpha(c); });
+
+    Event event{EventType::boolean};
+    event.range = Range(m_current, first_nonalpha - m_current);
+    if (event.range == "true") {
+        event.boolean = true;
+        m_current += 4;
+        return f(event);
+    }
+    else if (event.range == "false") {
+        event.boolean = false;
+        m_current += 5;
+        return f(event);
+    }
+
+    return Error::unexpected_token;
+}
+
+template<class F>
+std::error_condition JSONParser::parse_null(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    auto first_nonalpha = std::find_if_not(m_current, m_end, [](auto c) { return std::isalpha(c); });
+
+    Event event{EventType::null};
+    event.range = Range(m_current, first_nonalpha - m_current);
+    if (event.range == "null") {
+        m_current += 4;
+        return f(event);
+    }
+
+    return Error::unexpected_token;
+}
+
+template<class F>
+std::error_condition JSONParser::parse_value(F&& f) noexcept(noexcept(f(std::declval<Event>())))
+{
+    skip_whitespace();
+
+    if (m_current >= m_end)
+        return Error::unexpected_end_of_stream;
+
+    if (*m_current == Token::object_begin)
+        return parse_object(f);
+
+    if (*m_current == Token::array_begin)
+        return parse_array(f);
+
+    if (*m_current == 't' || *m_current == 'f')
+        return parse_boolean(f);
+
+    if (*m_current == 'n')
+        return parse_null(f);
+
+    if (*m_current == Token::dquote)
+        return parse_string(f);
+
+    return parse_number(f);
+}
+
+inline
+bool JSONParser::is_whitespace(Token t) noexcept
+{
+    switch (t) {
+        case Token::space:
+        case Token::tab:
+        case Token::cr:
+        case Token::lf:
+            return true;
+        default:
+            return false;
+    }
+}
+
+inline
+void JSONParser::skip_whitespace() noexcept
+{
+    while (m_current < m_end && is_whitespace(static_cast<Token>(*m_current)))
+        ++m_current;
+}
+
+inline
+std::error_condition JSONParser::expect_token(char c, Range& out_range) noexcept
+{
+    skip_whitespace();
+    if (m_current == m_end)
+        return Error::unexpected_end_of_stream;
+    if (*m_current == c) {
+        out_range = Range(m_current, 1);
+        ++m_current;
+        return std::error_condition{};
+    }
+    return Error::unexpected_token;
+}
+
+inline
+std::error_condition JSONParser::expect_token(Token t, Range& out_range) noexcept
+{
+    return expect_token(static_cast<char>(t), out_range);
+}
+
+inline
+bool JSONParser::peek_char(char& out_c) noexcept
+{
+    if (m_current < m_end) {
+        out_c = *m_current;
+        return true;
+    }
+    return false;
+}
+
+inline
+bool JSONParser::peek_token(Token& out_t) noexcept
+{
+    if (m_current < m_end) {
+        out_t = static_cast<Token>(*m_current);
+        return true;
+    }
+    return false;
+}
+
+inline
+StringData JSONParser::Event::escaped_string_value() const noexcept
+{
+    REALM_ASSERT(type == EventType::string);
+    REALM_ASSERT(range.size() >= 2);
+    return StringData(range.data() + 1, range.size() - 2);
+}
+
+template<class OS>
+OS& operator<<(OS& os, JSONParser::EventType type)
+{
+    switch (type) {
+        case JSONParser::EventType::number:       os << "number"; return os;
+        case JSONParser::EventType::string:       os << "string"; return os;
+        case JSONParser::EventType::boolean:      os << "boolean"; return os;
+        case JSONParser::EventType::null:         os << "null"; return os;
+        case JSONParser::EventType::array_begin:  os << "["; return os;
+        case JSONParser::EventType::array_end:    os << "]"; return os;
+        case JSONParser::EventType::object_begin: os << "{"; return os;
+        case JSONParser::EventType::object_end:   os << "}"; return os;
+    }
+    REALM_UNREACHABLE();
+}
+
+template<class OS>
+OS& operator<<(OS& os, const JSONParser::Event& e) {
+    os << e.type;
+    switch (e.type) {
+        case JSONParser::EventType::number:       return os << "(" << e.number << ")";
+        case JSONParser::EventType::string:       return os << "(" << e.range << ")";
+        case JSONParser::EventType::boolean:      return os << "(" << e.boolean << ")"; 
+        default: return os;
+    }
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_JSON_PARSER_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/load_file.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/load_file.hpp
new file mode 100644
index 0000000..14090fc
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/load_file.hpp
@@ -0,0 +1,36 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_LOAD_FILE_HPP
+#define REALM_UTIL_LOAD_FILE_HPP
+
+#include <string>
+
+namespace realm {
+namespace util {
+
+// FIXME: These functions ought to be moved to <realm/util/file.hpp> in the
+// realm-core repository.
+std::string load_file(const std::string& path);
+std::string load_file_and_chomp(const std::string& path);
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_LOAD_FILE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/logger.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/logger.hpp
new file mode 100644
index 0000000..0946208
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/logger.hpp
@@ -0,0 +1,511 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_LOGGER_HPP
+#define REALM_UTIL_LOGGER_HPP
+
+#include <cstring>
+#include <utility>
+#include <string>
+#include <locale>
+#include <sstream>
+#include <iostream>
+
+#include <realm/util/features.h>
+#include <realm/util/thread.hpp>
+#include <realm/util/file.hpp>
+
+namespace realm {
+namespace util {
+
+
+/// All Logger objects store a reference to a LevelThreshold object which it
+/// uses to efficiently query about the current log level threshold
+/// (`level_threshold.get()`). All messages logged with a level that is lower
+/// than the current threshold will be dropped. For the sake of efficiency, this
+/// test happens before the message is formatted.
+///
+/// A logger is not inherently thread-safe, but specific implementations can be
+/// (see ThreadSafeLogger). For a logger to be thread-safe, the implementation
+/// of do_log() must be thread-safe and the referenced LevelThreshold object
+/// must have a thread-safe get() method.
+///
+/// Examples:
+///
+///    logger.error("Overlong message from master coordinator");
+///    logger.info("Listening for peers on %1:%2", listen_address, listen_port);
+class Logger {
+public:
+    template <class... Params>
+    void trace(const char* message, Params&&...);
+    template <class... Params>
+    void debug(const char* message, Params&&...);
+    template <class... Params>
+    void detail(const char* message, Params&&...);
+    template <class... Params>
+    void info(const char* message, Params&&...);
+    template <class... Params>
+    void warn(const char* message, Params&&...);
+    template <class... Params>
+    void error(const char* message, Params&&...);
+    template <class... Params>
+    void fatal(const char* message, Params&&...);
+
+    /// Specifies criticality when passed to log(). Functions as a criticality
+    /// threshold when returned from LevelThreshold::get().
+    ///
+    ///     error   Be silent unless when there is an error.
+    ///     warn    Be silent unless when there is an error or a warning.
+    ///     info    Reveal information about what is going on, but in a
+    ///             minimalistic fashion to avoid general overhead from logging
+    ///             and to keep volume down.
+    ///     detail  Same as 'info', but prioritize completeness over minimalism.
+    ///     debug   Reveal information that can aid debugging, no longer paying
+    ///             attention to efficiency.
+    ///     trace   A version of 'debug' that allows for very high volume
+    ///             output.
+    enum class Level { all, trace, debug, detail, info, warn, error, fatal, off };
+
+    template <class... Params>
+    void log(Level, const char* message, Params&&...);
+
+    /// Shorthand for `int(level) >= int(level_threshold.get())`.
+    bool would_log(Level level) const noexcept;
+
+    class LevelThreshold;
+
+    const LevelThreshold& level_threshold;
+
+    virtual ~Logger() noexcept;
+
+protected:
+    Logger(const LevelThreshold&) noexcept;
+
+    static void do_log(Logger&, Level, std::string message);
+
+    virtual void do_log(Level, std::string message) = 0;
+
+    static const char* get_level_prefix(Level) noexcept;
+
+private:
+    struct State;
+
+    template <class... Params>
+    REALM_NOINLINE void do_log(Level, const char* message, Params&&...);
+    void log_impl(State&);
+    template <class Param, class... Params>
+    void log_impl(State&, Param&&, Params&&...);
+    template <class Param>
+    static void subst(State&, Param&&);
+};
+
+template <class C, class T>
+std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>&, Logger::Level);
+
+template <class C, class T>
+std::basic_istream<C, T>& operator>>(std::basic_istream<C, T>&, Logger::Level&);
+
+class Logger::LevelThreshold {
+public:
+    virtual Level get() const noexcept = 0;
+};
+
+
+/// A root logger that is not thread-safe and allows for the log level threshold
+/// to be changed over time. The initial log level threshold is
+/// Logger::Level::info.
+class RootLogger : private Logger::LevelThreshold, public Logger {
+public:
+    void set_level_threshold(Level) noexcept;
+
+protected:
+    RootLogger();
+
+private:
+    Level m_level_threshold = Level::info;
+    Level get() const noexcept override final;
+};
+
+
+/// A logger that writes to STDERR. This logger is not thread-safe.
+///
+/// Since this class is a RootLogger, it contains modifiable a log level
+/// threshold.
+class StderrLogger : public RootLogger {
+protected:
+    void do_log(Level, std::string) override final;
+};
+
+
+/// A logger that writes to a stream. This logger is not thread-safe.
+///
+/// Since this class is a RootLogger, it contains modifiable a log level
+/// threshold.
+class StreamLogger : public RootLogger {
+public:
+    explicit StreamLogger(std::ostream&) noexcept;
+
+protected:
+    void do_log(Level, std::string) override final;
+
+private:
+    std::ostream& m_out;
+};
+
+
+/// A logger that writes to a file. This logger is not thread-safe.
+///
+/// Since this class is a RootLogger, it contains modifiable a log level
+/// threshold.
+class FileLogger : public StreamLogger {
+public:
+    explicit FileLogger(std::string path);
+    explicit FileLogger(util::File);
+
+private:
+    util::File m_file;
+    util::File::Streambuf m_streambuf;
+    std::ostream m_out;
+};
+
+
+/// A thread-safe logger. This logger ignores the level threshold of the base
+/// logger. Instead, it introduces new a LevelThreshold object with a fixed
+/// value to achieve thread safety.
+class ThreadSafeLogger : private Logger::LevelThreshold, public Logger {
+public:
+    explicit ThreadSafeLogger(Logger& base_logger, Level = Level::info);
+
+protected:
+    void do_log(Level, std::string) override final;
+
+private:
+    const Level m_level_threshold; // Immutable for thread safety
+    Logger& m_base_logger;
+    Mutex m_mutex;
+    Level get() const noexcept override final;
+};
+
+
+/// A logger that adds a fixed prefix to each message. This logger inherits the
+/// LevelThreshold object of the specified base logger. This logger is
+/// thread-safe if, and only if the base logger is thread-safe.
+class PrefixLogger : public Logger {
+public:
+    PrefixLogger(std::string prefix, Logger& base_logger) noexcept;
+
+protected:
+    void do_log(Level, std::string) override final;
+
+private:
+    const std::string m_prefix;
+    Logger& m_base_logger;
+};
+
+
+// Implementation
+
+struct Logger::State {
+    Logger::Level m_level;
+    std::string m_message;
+    std::string m_search;
+    int m_param_num = 1;
+    std::ostringstream m_formatter;
+    std::locale m_locale = std::locale::classic();
+    State(Logger::Level level, const char* s)
+        : m_level(level)
+        , m_message(s)
+        , m_search(m_message)
+    {
+        m_formatter.imbue(m_locale);
+    }
+};
+
+template <class... Params>
+inline void Logger::trace(const char* message, Params&&... params)
+{
+    log(Level::trace, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::debug(const char* message, Params&&... params)
+{
+    log(Level::debug, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::detail(const char* message, Params&&... params)
+{
+    log(Level::detail, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::info(const char* message, Params&&... params)
+{
+    log(Level::info, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::warn(const char* message, Params&&... params)
+{
+    log(Level::warn, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::error(const char* message, Params&&... params)
+{
+    log(Level::error, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::fatal(const char* message, Params&&... params)
+{
+    log(Level::fatal, message, std::forward<Params>(params)...); // Throws
+}
+
+template <class... Params>
+inline void Logger::log(Level level, const char* message, Params&&... params)
+{
+    if (would_log(level))
+        do_log(level, message, std::forward<Params>(params)...); // Throws
+}
+
+inline bool Logger::would_log(Level level) const noexcept
+{
+    return int(level) >= int(level_threshold.get());
+}
+
+inline Logger::~Logger() noexcept
+{
+}
+
+inline Logger::Logger(const LevelThreshold& lt) noexcept
+    : level_threshold(lt)
+{
+}
+
+inline void Logger::do_log(Logger& logger, Level level, std::string message)
+{
+    logger.do_log(level, std::move(message)); // Throws
+}
+
+template <class... Params>
+void Logger::do_log(Level level, const char* message, Params&&... params)
+{
+    State state(level, message);
+    log_impl(state, std::forward<Params>(params)...); // Throws
+}
+
+inline void Logger::log_impl(State& state)
+{
+    do_log(state.m_level, std::move(state.m_message)); // Throws
+}
+
+template <class Param, class... Params>
+inline void Logger::log_impl(State& state, Param&& param, Params&&... params)
+{
+    subst(state, std::forward<Param>(param));         // Throws
+    log_impl(state, std::forward<Params>(params)...); // Throws
+}
+
+template <class Param>
+void Logger::subst(State& state, Param&& param)
+{
+    state.m_formatter << "%" << state.m_param_num;
+    std::string key = state.m_formatter.str();
+    state.m_formatter.str(std::string());
+    std::string::size_type j = state.m_search.find(key);
+    if (j != std::string::npos) {
+        state.m_formatter << std::forward<Param>(param);
+        std::string str = state.m_formatter.str();
+        state.m_formatter.str(std::string());
+        state.m_message.replace(j, key.size(), str);
+        state.m_search.replace(j, key.size(), std::string(str.size(), '\0'));
+    }
+    ++state.m_param_num;
+}
+
+template <class C, class T>
+std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, Logger::Level level)
+{
+    switch (level) {
+        case Logger::Level::all:
+            out << "all";
+            return out;
+        case Logger::Level::trace:
+            out << "trace";
+            return out;
+        case Logger::Level::debug:
+            out << "debug";
+            return out;
+        case Logger::Level::detail:
+            out << "detail";
+            return out;
+        case Logger::Level::info:
+            out << "info";
+            return out;
+        case Logger::Level::warn:
+            out << "warn";
+            return out;
+        case Logger::Level::error:
+            out << "error";
+            return out;
+        case Logger::Level::fatal:
+            out << "fatal";
+            return out;
+        case Logger::Level::off:
+            out << "off";
+            return out;
+    }
+    REALM_ASSERT(false);
+    return out;
+}
+
+template <class C, class T>
+std::basic_istream<C, T>& operator>>(std::basic_istream<C, T>& in, Logger::Level& level)
+{
+    std::basic_string<C, T> str;
+    auto check = [&](const char* name) {
+        size_t n = strlen(name);
+        if (n != str.size())
+            return false;
+        for (size_t i = 0; i < n; ++i) {
+            if (in.widen(name[i]) != str[i])
+                return false;
+        }
+        return true;
+    };
+    if (in >> str) {
+        if (check("all")) {
+            level = Logger::Level::all;
+        }
+        else if (check("trace")) {
+            level = Logger::Level::trace;
+        }
+        else if (check("debug")) {
+            level = Logger::Level::debug;
+        }
+        else if (check("detail")) {
+            level = Logger::Level::detail;
+        }
+        else if (check("info")) {
+            level = Logger::Level::info;
+        }
+        else if (check("warn")) {
+            level = Logger::Level::warn;
+        }
+        else if (check("error")) {
+            level = Logger::Level::error;
+        }
+        else if (check("fatal")) {
+            level = Logger::Level::fatal;
+        }
+        else if (check("off")) {
+            level = Logger::Level::off;
+        }
+        else {
+            in.setstate(std::ios_base::failbit);
+        }
+    }
+    return in;
+}
+
+inline void RootLogger::set_level_threshold(Level new_level_threshold) noexcept
+{
+    m_level_threshold = new_level_threshold;
+}
+
+inline RootLogger::RootLogger()
+    : Logger::LevelThreshold()
+    , Logger(static_cast<Logger::LevelThreshold&>(*this))
+{
+}
+
+inline Logger::Level RootLogger::get() const noexcept
+{
+    return m_level_threshold;
+}
+
+inline void StderrLogger::do_log(Level level, std::string message)
+{
+    std::cerr << get_level_prefix(level) << message << '\n'; // Throws
+    std::cerr.flush();                                       // Throws
+}
+
+inline StreamLogger::StreamLogger(std::ostream& out) noexcept
+    : m_out(out)
+{
+}
+
+inline void StreamLogger::do_log(Level level, std::string message)
+{
+    m_out << get_level_prefix(level) << message << '\n'; // Throws
+    m_out.flush();                                       // Throws
+}
+
+inline FileLogger::FileLogger(std::string path)
+    : StreamLogger(m_out)
+    , m_file(path, util::File::mode_Write) // Throws
+    , m_streambuf(&m_file)                 // Throws
+    , m_out(&m_streambuf)                  // Throws
+{
+}
+
+inline FileLogger::FileLogger(util::File file)
+    : StreamLogger(m_out)
+    , m_file(std::move(file))
+    , m_streambuf(&m_file) // Throws
+    , m_out(&m_streambuf)  // Throws
+{
+}
+
+inline ThreadSafeLogger::ThreadSafeLogger(Logger& base_logger, Level threshold)
+    : Logger::LevelThreshold()
+    , Logger(static_cast<Logger::LevelThreshold&>(*this))
+    , m_level_threshold(threshold)
+    , m_base_logger(base_logger)
+{
+}
+
+inline void ThreadSafeLogger::do_log(Level level, std::string message)
+{
+    LockGuard l(m_mutex);
+    Logger::do_log(m_base_logger, level, message); // Throws
+}
+
+inline Logger::Level ThreadSafeLogger::get() const noexcept
+{
+    return m_level_threshold;
+}
+
+inline PrefixLogger::PrefixLogger(std::string prefix, Logger& base_logger) noexcept
+    : Logger(base_logger.level_threshold)
+    , m_prefix(std::move(prefix))
+    , m_base_logger(base_logger)
+{
+}
+
+inline void PrefixLogger::do_log(Level level, std::string message)
+{
+    Logger::do_log(m_base_logger, level, m_prefix + message); // Throws
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_LOGGER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/memory_stream.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/memory_stream.hpp
new file mode 100644
index 0000000..81a4852
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/memory_stream.hpp
@@ -0,0 +1,212 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_MEMORY_STREAM_HPP
+#define REALM_UTIL_MEMORY_STREAM_HPP
+
+#include <cstddef>
+#include <string>
+#include <istream>
+#include <ostream>
+
+namespace realm {
+namespace util {
+
+class MemoryInputStreambuf : public std::streambuf {
+public:
+    MemoryInputStreambuf();
+    ~MemoryInputStreambuf() noexcept;
+
+    /// Behavior is undefined if the size of the specified buffer exceeds
+    /// PTRDIFF_MAX.
+    void set_buffer(const char* begin, const char* end) noexcept;
+
+private:
+    const char* m_begin;
+    const char* m_end;
+    const char* m_curr;
+
+    int_type underflow() override;
+    int_type uflow() override;
+    int_type pbackfail(int_type) override;
+    std::streamsize showmanyc() override;
+    pos_type seekoff(off_type, std::ios_base::seekdir, std::ios_base::openmode) override;
+    pos_type seekpos(pos_type, std::ios_base::openmode) override;
+
+    pos_type do_seekoff(off_type, std::ios_base::seekdir, std::ios_base::openmode);
+};
+
+
+class MemoryOutputStreambuf : public std::streambuf {
+public:
+    MemoryOutputStreambuf();
+    ~MemoryOutputStreambuf() noexcept;
+
+    /// Behavior is undefined if the size of the specified buffer exceeds
+    /// PTRDIFF_MAX.
+    void set_buffer(char* begin, char* end) noexcept;
+
+    /// Returns the amount of data written to the buffer.
+    size_t size() const noexcept;
+};
+
+
+class MemoryInputStream : public std::istream {
+public:
+    MemoryInputStream();
+    ~MemoryInputStream() noexcept;
+
+    /// \{ Behavior is undefined if the size of the specified buffer exceeds
+    /// PTRDIFF_MAX.
+    void set_buffer(const char* begin, const char* end) noexcept;
+    template <size_t N> void set_buffer(const char (&buffer)[N]) noexcept;
+    void set_string(const std::string&) noexcept;
+    void set_c_string(const char* c_str) noexcept;
+    /// \}
+
+private:
+    MemoryInputStreambuf m_streambuf;
+};
+
+
+class MemoryOutputStream : public std::ostream {
+public:
+    MemoryOutputStream();
+    ~MemoryOutputStream() noexcept;
+
+    /// \{ Behavior is undefined if the size of the specified buffer exceeds
+    /// PTRDIFF_MAX.
+    void set_buffer(char* begin, char* end) noexcept;
+    template <size_t N> void set_buffer(char (&buffer)[N]) noexcept;
+    /// \}
+
+    /// Returns the amount of data written to the underlying buffer.
+    size_t size() const noexcept;
+
+private:
+    MemoryOutputStreambuf m_streambuf;
+};
+
+
+// Implementation
+
+inline MemoryInputStreambuf::MemoryInputStreambuf()
+    : m_begin(nullptr)
+    , m_end(nullptr)
+    , m_curr(nullptr)
+{
+}
+
+inline MemoryInputStreambuf::~MemoryInputStreambuf() noexcept
+{
+}
+
+inline void MemoryInputStreambuf::set_buffer(const char* b, const char* e) noexcept
+{
+    m_begin = b;
+    m_end = e;
+    m_curr = b;
+}
+
+
+inline MemoryOutputStreambuf::MemoryOutputStreambuf()
+{
+}
+
+inline MemoryOutputStreambuf::~MemoryOutputStreambuf() noexcept
+{
+}
+
+inline void MemoryOutputStreambuf::set_buffer(char* b, char* e) noexcept
+{
+    setp(b, e);
+}
+
+inline size_t MemoryOutputStreambuf::size() const noexcept
+{
+    return pptr() - pbase();
+}
+
+
+inline MemoryInputStream::MemoryInputStream()
+    : std::istream(&m_streambuf)
+{
+}
+
+inline MemoryInputStream::~MemoryInputStream() noexcept
+{
+}
+
+inline void MemoryInputStream::set_buffer(const char* b, const char* e) noexcept
+{
+    m_streambuf.set_buffer(b, e);
+    clear();
+}
+
+template <size_t N> inline void MemoryInputStream::set_buffer(const char (&buffer)[N]) noexcept
+{
+    const char* b = buffer;
+    const char* e = b + N;
+    set_buffer(b, e);
+}
+
+inline void MemoryInputStream::set_string(const std::string& str) noexcept
+{
+    const char* b = str.data();
+    const char* e = b + str.size();
+    set_buffer(b, e);
+}
+
+inline void MemoryInputStream::set_c_string(const char* c_str) noexcept
+{
+    const char* b = c_str;
+    const char* e = b + traits_type::length(c_str);
+    set_buffer(b, e);
+}
+
+
+inline MemoryOutputStream::MemoryOutputStream()
+    : std::ostream(&m_streambuf)
+{
+}
+
+inline MemoryOutputStream::~MemoryOutputStream() noexcept
+{
+}
+
+inline void MemoryOutputStream::set_buffer(char* b, char* e) noexcept
+{
+    m_streambuf.set_buffer(b, e);
+    clear();
+}
+
+template <size_t N>
+inline void MemoryOutputStream::set_buffer(char (&buffer)[N]) noexcept
+{
+    set_buffer(buffer, buffer + N);
+}
+
+inline size_t MemoryOutputStream::size() const noexcept
+{
+    return m_streambuf.size();
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_MEMORY_STREAM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/deque.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/deque.hpp
new file mode 100644
index 0000000..41c1b71
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/deque.hpp
@@ -0,0 +1,37 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_DEQUE_HPP
+#define REALM_UTIL_METERED_DEQUE_HPP
+
+#include <deque>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// Vector with metered allocation
+template <class T, class Alloc = MeteredSTLAllocator<T>>
+using deque = std::deque<T, Alloc>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_DEQUE_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/map.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/map.hpp
new file mode 100644
index 0000000..be03f9e
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/map.hpp
@@ -0,0 +1,41 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_MAP_HPP
+#define REALM_UTIL_METERED_MAP_HPP
+
+#include <map>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// Map with metered allocation. Additionally, the default Compare is changed to
+/// `std::less<>` instead of `std::less<K>`, which allows heterogenous lookup.
+template <class K,
+          class V,
+          class Compare = std::less<>,
+          class Alloc = MeteredSTLAllocator<std::pair<const K, V>>>
+using map = std::map<K, V, Compare, Alloc>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_MAP_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/set.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/set.hpp
new file mode 100644
index 0000000..95f1e73
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/set.hpp
@@ -0,0 +1,38 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_SET_HPP
+#define REALM_UTIL_METERED_SET_HPP
+
+#include <set>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// Set with metered allocation. Additionally, the default Compare is changed to
+/// `std::less<>` instead of `std::less<K>`, which allows heterogenous lookup.
+template <class T, class Compare = std::less<>, class Alloc = MeteredSTLAllocator<T>>
+using set = std::set<T, Compare, Alloc>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_SET_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/string.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/string.hpp
new file mode 100644
index 0000000..b3a52db
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/string.hpp
@@ -0,0 +1,36 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_STRING_HPP
+#define REALM_UTIL_METERED_STRING_HPP
+
+#include <string>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// String with metered allocation
+using string = std::basic_string<char, std::char_traits<char>, MeteredSTLAllocator<char>>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_STRING_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/unordered_map.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/unordered_map.hpp
new file mode 100644
index 0000000..8ead21a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/unordered_map.hpp
@@ -0,0 +1,41 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_UNORDERED_MAP_HPP
+#define REALM_UTIL_METERED_UNORDERED_MAP_HPP
+
+#include <unordered_map>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// Unordered map with metered allocation
+template <class K,
+          class V,
+          class Hash = std::hash<K>,
+          class KeyEqual = std::equal_to<K>,
+          class Alloc = MeteredSTLAllocator<std::pair<const K, V>>>
+using unordered_map = std::unordered_map<K, V, Hash, KeyEqual, Alloc>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_UNORDERED_MAP_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/unordered_set.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/unordered_set.hpp
new file mode 100644
index 0000000..ad0dc5f
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/unordered_set.hpp
@@ -0,0 +1,40 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_UNORDERED_SET_HPP
+#define REALM_UTIL_METERED_UNORDERED_SET_HPP
+
+#include <unordered_set>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// Unordered set with metered allocation
+template <class T,
+          class Hash = std::hash<T>,
+          class KeyEqual = std::equal_to<T>,
+          class Alloc = MeteredSTLAllocator<T>>
+using unordered_set = std::unordered_set<T, Hash, KeyEqual, Alloc>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_UNORDERED_SET_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/metered/vector.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/vector.hpp
new file mode 100644
index 0000000..cbbf177
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/metered/vector.hpp
@@ -0,0 +1,37 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2018] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_METERED_VECTOR_HPP
+#define REALM_UTIL_METERED_VECTOR_HPP
+
+#include <vector>
+#include <realm/util/allocation_metrics.hpp>
+
+namespace realm {
+namespace util {
+namespace metered {
+/// Vector with metered allocation
+template <class T, class Alloc = MeteredSTLAllocator<T>>
+using vector = std::vector<T, Alloc>;
+} // namespace metered
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_METERED_VECTOR_HPP
+
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/misc_errors.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/misc_errors.hpp
new file mode 100644
index 0000000..9335ba9
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/misc_errors.hpp
@@ -0,0 +1,49 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_MISC_ERRORS_HPP
+#define REALM_UTIL_MISC_ERRORS_HPP
+
+#include <system_error>
+
+
+namespace realm {
+namespace util {
+namespace error {
+
+enum misc_errors {
+    unknown = 1,
+};
+
+std::error_code make_error_code(misc_errors);
+
+} // namespace error
+} // namespace util
+} // namespace realm
+
+namespace std {
+
+template <>
+class is_error_code_enum<realm::util::error::misc_errors> {
+public:
+    static const bool value = true;
+};
+
+} // namespace std
+
+#endif // REALM_UTIL_MISC_ERRORS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/misc_ext_errors.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/misc_ext_errors.hpp
new file mode 100644
index 0000000..6b70998
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/misc_ext_errors.hpp
@@ -0,0 +1,72 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_MISC_EXT_ERRORS_HPP
+#define REALM_UTIL_MISC_EXT_ERRORS_HPP
+
+#include <system_error>
+
+namespace realm {
+namespace util {
+
+/// FIXME: The intention is that this enum will be merged into, and subsumed by
+/// util::MiscErrors in `<realm/util/misc_errors.hpp>` in the core library.
+enum class MiscExtErrors {
+    /// End of input.
+    end_of_input = 1,
+
+    /// Premature end of input. That is, end of input at an unexpected, or
+    /// illegal place in an input stream.
+    premature_end_of_input,
+
+    /// Delimiter not found.
+    delim_not_found,
+
+    /// Operation not supported
+    operation_not_supported,
+};
+
+class MiscExtErrorCategory : public std::error_category {
+public:
+    const char* name() const noexcept override final;
+    std::string message(int) const override final;
+};
+
+/// The error category associated with MiscErrors. The name of this category is
+/// `realm.util.misc_ext`.
+extern MiscExtErrorCategory misc_ext_error_category;
+
+inline std::error_code make_error_code(MiscExtErrors err)
+{
+    return std::error_code(int(err), misc_ext_error_category);
+}
+
+} // namespace util
+} // namespace realm
+
+namespace std {
+
+template<> class is_error_code_enum<realm::util::MiscExtErrors> {
+public:
+    static const bool value = true;
+};
+
+} // namespace std
+
+#endif // REALM_UTIL_MISC_EXT_ERRORS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/miscellaneous.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/miscellaneous.hpp
new file mode 100644
index 0000000..c45e4f3
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/miscellaneous.hpp
@@ -0,0 +1,49 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_MISCELLANEOUS_HPP
+#define REALM_UTIL_MISCELLANEOUS_HPP
+
+#include <type_traits>
+
+namespace realm {
+namespace util {
+
+// FIXME: Replace this with std::add_const_t when we switch over to C++14 by
+// default.
+/// \brief Adds const qualifier, unless T already has the const qualifier
+template <class T>
+using add_const_t = typename std::add_const<T>::type;
+
+// FIXME: Replace this with std::as_const when we switch over to C++17 by
+// default.
+/// \brief Forms an lvalue reference to const T
+template <class T>
+constexpr add_const_t<T>& as_const(T& v) noexcept
+{
+    return v;
+}
+
+/// \brief Disallows rvalue arguments
+template <class T>
+add_const_t<T>& as_const(const T&&) = delete;
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_MISCELLANEOUS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/network.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/network.hpp
new file mode 100644
index 0000000..6ff5b91
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/network.hpp
@@ -0,0 +1,3708 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_NETWORK_HPP
+#define REALM_UTIL_NETWORK_HPP
+
+#include <cstddef>
+#include <memory>
+#include <chrono>
+#include <string>
+#include <system_error>
+#include <ostream>
+
+#include <sys/types.h>
+
+#ifdef _WIN32
+#  include <winsock2.h>
+#  include <ws2tcpip.h>
+#  include <stdio.h>
+#  include <Ws2def.h>
+#  pragma comment(lib, "Ws2_32.lib")
+#else
+#  include <sys/socket.h>
+#  include <arpa/inet.h>
+#  include <netdb.h>
+#endif
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/bind_ptr.hpp>
+#include <realm/util/buffer.hpp>
+#include <realm/util/misc_ext_errors.hpp>
+#include <realm/util/basic_system_errors.hpp>
+#include <realm/util/backtrace.hpp>
+
+// Linux epoll
+//
+// Require Linux kernel version >= 2.6.27 such that we have epoll_create1(),
+// `O_CLOEXEC`, and `EPOLLRDHUP`.
+#if defined(__linux__)
+#  include <linux/version.h>
+#  if !defined(REALM_HAVE_EPOLL)
+#    if !defined(REALM_DISABLE_UTIL_NETWORK_EPOLL)
+#      if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,27)
+#        define REALM_HAVE_EPOLL 1
+#      endif
+#    endif
+#  endif
+#endif
+#if !defined(REALM_HAVE_EPOLL)
+#  define REALM_HAVE_EPOLL 0
+#endif
+
+// FreeBSD Kqueue.
+//
+// Available on Mac OS X, FreeBSD, NetBSD, OpenBSD
+#if (defined(__MACH__) && defined(__APPLE__)) || defined(__FreeBSD__) || \
+    defined(__NetBSD__) || defined(__OpenBSD__)
+#  if !defined(REALM_HAVE_KQUEUE)
+#    if !defined(REALM_DISABLE_UTIL_NETWORK_KQUEUE)
+#      define REALM_HAVE_KQUEUE 1
+#    endif
+#  endif
+#endif
+#if !defined(REALM_HAVE_KQUEUE)
+#  define REALM_HAVE_KQUEUE 0
+#endif
+
+
+
+// FIXME: Unfinished business around `Address::m_ip_v6_scope_id`.
+
+
+namespace realm {
+namespace util {
+
+/// \brief TCP/IP networking API.
+///
+/// The design of this networking API is heavily inspired by the ASIO C++
+/// library (http://think-async.com).
+///
+///
+/// ### Thread safety
+///
+/// A *service context* is a set of objects consisting of an instance of
+/// Service, and all the objects that are associated with that instance (\ref
+/// Resolver, \ref Socket`, \ref Acceptor`, \ref DeadlineTimer, \ref Trigger,
+/// and \ref ssl::Stream).
+///
+/// In general, it is unsafe for two threads to call functions on the same
+/// object, or on different objects in the same service context. This also
+/// applies to destructors. Notable exceptions are the fully thread-safe
+/// functions, such as Service::post(), Service::stop(), and Service::reset().
+///
+/// On the other hand, it is always safe for two threads to call functions on
+/// objects belonging to different service contexts.
+///
+/// One implication of these rules is that at most one thread must execute run()
+/// at any given time, and if one thread is executing run(), then no other
+/// thread is allowed to access objects in the same service context (with the
+/// mentioned exceptions).
+///
+/// Unless otherwise specified, free-standing objects, such as \ref
+/// StreamProtocol, \ref Address, \ref Endpoint, and \ref Endpoint::List are
+/// fully thread-safe as long as they are not mutated. If one thread is mutating
+/// such an object, no other thread may access it. Note that these free-standing
+/// objects are not associcated with an instance of Service, and are therefore
+/// not part of a service context.
+///
+///
+/// ### Comparison with ASIO
+///
+/// There is a crucial difference between the two libraries in regards to the
+/// guarantees that are provided about the cancelability of asynchronous
+/// operations. The Realm networking library (this library) considers an
+/// asynchronous operation to be complete precisely when the completion handler
+/// starts to execute, and it guarantees that such an operation is cancelable up
+/// until that point in time. In particular, if `cancel()` is called on a socket
+/// or a deadline timer object before the completion handler starts to execute,
+/// then that operation will be canceled, and will receive
+/// `error::operation_aborted`. This guarantee is possible to provide (and free
+/// of ambiguities) precisely because this library prohibits multiple threads
+/// from executing the event loop concurrently, and because `cancel()` is
+/// allowed to be called only from a completion handler (executed by the event
+/// loop thread) or while no thread is executing the event loop. This guarantee
+/// allows for safe destruction of sockets and deadline timers as long as the
+/// completion handlers react appropriately to `error::operation_aborted`, in
+/// particular, that they do not attempt to access the socket or deadline timer
+/// object in such cases.
+///
+/// ASIO, on the other hand, allows for an asynchronous operation to complete
+/// and become **uncancellable** before the completion handler starts to
+/// execute. For this reason, it is possible with ASIO to get the completion
+/// handler of an asynchronous wait operation to start executing and receive an
+/// error code other than "operation aborted" at a point in time where
+/// `cancel()` has already been called on the deadline timer object, or even at
+/// a point in timer where the deadline timer has been destroyed. This seems
+/// like an inevitable consequence of the fact that ASIO allows for multiple
+/// threads to execute the event loop concurrently. This generally forces ASIO
+/// applications to invent ways of extending the lifetime of deadline timer and
+/// socket objects until the completion handler starts executing.
+///
+/// IMPORTANT: Even if ASIO is used in a way where at most one thread executes
+/// the event loop, there is still no guarantee that an asynchronous operation
+/// remains cancelable up until the point in time where the completion handler
+/// starts to execute.
+namespace network {
+
+std::string host_name();
+
+
+class StreamProtocol;
+class Address;
+class Endpoint;
+class Service;
+class Resolver;
+class SocketBase;
+class Socket;
+class Acceptor;
+class DeadlineTimer;
+class Trigger;
+class ReadAheadBuffer;
+namespace ssl {
+class Stream;
+} // namespace ssl
+
+
+/// \brief An IP protocol descriptor.
+class StreamProtocol {
+public:
+    static StreamProtocol ip_v4();
+    static StreamProtocol ip_v6();
+
+    bool is_ip_v4() const;
+    bool is_ip_v6() const;
+
+    int protocol() const;
+    int family() const;
+
+    StreamProtocol();
+    ~StreamProtocol() noexcept {}
+
+private:
+    int m_family;
+    int m_socktype;
+    int m_protocol;
+
+    friend class Service;
+    friend class SocketBase;
+};
+
+
+/// \brief An IP address (IPv4 or IPv6).
+class Address {
+public:
+    bool is_ip_v4() const;
+    bool is_ip_v6() const;
+
+    template<class C, class T>
+    friend std::basic_ostream<C,T>& operator<<(std::basic_ostream<C,T>&, const Address&);
+
+    Address();
+    ~Address() noexcept {}
+
+private:
+    using ip_v4_type = in_addr;
+    using ip_v6_type = in6_addr;
+    union union_type {
+        ip_v4_type m_ip_v4;
+        ip_v6_type m_ip_v6;
+    };
+    union_type m_union;
+    std::uint_least32_t m_ip_v6_scope_id = 0;
+    bool m_is_ip_v6 = false;
+
+    friend Address make_address(const char*, std::error_code&) noexcept;
+    friend class Endpoint;
+};
+
+Address make_address(const char* c_str);
+Address make_address(const char* c_str, std::error_code& ec) noexcept;
+Address make_address(const std::string&);
+Address make_address(const std::string&, std::error_code& ec) noexcept;
+
+
+/// \brief An IP endpoint.
+///
+/// An IP endpoint is a triplet (`protocol`, `address`, `port`).
+class Endpoint {
+public:
+    using port_type = std::uint_fast16_t;
+    class List;
+
+    StreamProtocol protocol() const;
+    Address address() const;
+    port_type port() const;
+
+    Endpoint();
+    Endpoint(const StreamProtocol&, port_type);
+    Endpoint(const Address&, port_type);
+    ~Endpoint() noexcept {}
+
+    using data_type = sockaddr;
+    data_type* data();
+    const data_type* data() const;
+
+private:
+    StreamProtocol m_protocol;
+
+    using sockaddr_base_type  = sockaddr;
+    using sockaddr_ip_v4_type = sockaddr_in;
+    using sockaddr_ip_v6_type = sockaddr_in6;
+    union sockaddr_union_type {
+        sockaddr_base_type  m_base;
+        sockaddr_ip_v4_type m_ip_v4;
+        sockaddr_ip_v6_type m_ip_v6;
+    };
+    sockaddr_union_type m_sockaddr_union;
+
+    friend class Service;
+    friend class Resolver;
+    friend class SocketBase;
+    friend class Socket;
+};
+
+
+/// \brief A list of IP endpoints.
+class Endpoint::List {
+public:
+    using iterator = const Endpoint*;
+
+    iterator begin() const noexcept;
+    iterator end() const noexcept;
+    std::size_t size() const noexcept;
+    bool empty() const noexcept;
+
+    List() noexcept = default;
+    List(List&&) noexcept = default;
+    ~List() noexcept = default;
+
+    List& operator=(List&&) noexcept = default;
+
+private:
+    Buffer<Endpoint> m_endpoints;
+
+    friend class Service;
+};
+
+
+/// \brief TCP/IP networking service.
+class Service {
+public:
+    Service();
+    ~Service() noexcept;
+
+    /// \brief Execute the event loop.
+    ///
+    /// Execute completion handlers of completed asynchronous operations, or
+    /// wait for more completion handlers to become ready for
+    /// execution. Handlers submitted via post() are considered immeditely
+    /// ready. If there are no completion handlers ready for execution, and
+    /// there are no asynchronous operations in progress, run() returns.
+    ///
+    /// All completion handlers, including handlers submitted via post() will be
+    /// executed from run(), that is, by the thread that executes run(). If no
+    /// thread executes run(), then the completion handlers will not be
+    /// executed.
+    ///
+    /// Exceptions thrown by completion handlers will always propagate back
+    /// through run().
+    ///
+    /// Syncronous operations (e.g., Socket::connect()) execute independently of
+    /// the event loop, and do not require that any thread calls run().
+    void run();
+
+    /// @{ \brief Stop event loop execution.
+    ///
+    /// stop() puts the event loop into the stopped mode. If a thread is
+    /// currently executing run(), it will be made to return in a timely
+    /// fashion, that is, without further blocking. If a thread is currently
+    /// blocked in run(), it will be unblocked. Handlers that can be executed
+    /// immediately, may, or may not be executed before run() returns, but new
+    /// handlers submitted by these, will not be executed before run()
+    /// returns. Also, if a handler is submitted by a call to post, and that
+    /// call happens after stop() returns, then that handler is guaranteed to
+    /// not be executed before run() returns (assuming that reset() is not called
+    /// before run() returns).
+    ///
+    /// The event loop will remain in the stopped mode until reset() is
+    /// called. If reset() is called before run() returns, it may, or may not
+    /// cause run() to resume normal operation without returning.
+    ///
+    /// Both stop() and reset() are thread-safe, that is, they may be called by
+    /// any thread. Also, both of these function may be called from completion
+    /// handlers (including posted handlers).
+    void stop() noexcept;
+    void reset() noexcept;
+    /// @}
+
+    /// \brief Submit a handler to be executed by the event loop thread.
+    ///
+    /// Register the sepcified completion handler for immediate asynchronous
+    /// execution. The specified handler will be executed by an expression on
+    /// the form `handler()`. If the the handler object is movable, it will
+    /// never be copied. Otherwise, it will be copied as necessary.
+    ///
+    /// This function is thread-safe, that is, it may be called by any
+    /// thread. It may also be called from other completion handlers.
+    ///
+    /// The handler will never be called as part of the execution of post(). It
+    /// will always be called by a thread that is executing run(). If no thread
+    /// is currently executing run(), the handler will not be executed until a
+    /// thread starts executing run(). If post() is called while another thread
+    /// is executing run(), the handler may be called before post() returns. If
+    /// post() is called from another completion handler, the submitted handler
+    /// is guaranteed to not be called during the execution of post().
+    ///
+    /// Completion handlers added through post() will be executed in the order
+    /// that they are added. More precisely, if post() is called twice to add
+    /// two handlers, A and B, and the execution of post(A) ends before the
+    /// beginning of the execution of post(B), then A is guaranteed to execute
+    /// before B.
+    template<class H> void post(H handler);
+
+    /// Argument `saturation` is the fraction of time that is not spent
+    /// sleeping. Argument `inefficiency` is the fraction of time not spent
+    /// sleeping, and not spent executing completion handlers. Both values are
+    /// guaranteed to always be in the range 0 to 1 (both inclusive). The value
+    /// passed as `inefficiency` is guaranteed to always be less than, or equal
+    /// to the value passed as `saturation`.
+    using EventLoopMetricsHandler = void(double saturation, double inefficiency);
+
+    /// \brief Report event loop metrics via the specified handler.
+    ///
+    /// The handler will be called approximately every 30 seconds.
+    ///
+    /// report_event_loop_metrics() must be called prior to any invocation of
+    /// run(). report_event_loop_metrics() is not thread-safe.
+    ///
+    /// This feature is only available if
+    /// `REALM_UTIL_NETWORK_EVENT_LOOP_METRICS` was defined during
+    /// compilation. When the feature is not available, the specified handler
+    /// will never be called.
+    void report_event_loop_metrics(std::function<EventLoopMetricsHandler>);
+
+private:
+    enum class Want { nothing = 0, read, write };
+
+    template<class Oper> class OperQueue;
+    class Descriptor;
+    class AsyncOper;
+    class ResolveOperBase;
+    class WaitOperBase;
+    class TriggerExecOperBase;
+    class PostOperBase;
+    template<class H> class PostOper;
+    class IoOper;
+    class UnusedOper; // Allocated, but currently unused memory
+
+    template<class S> class BasicStreamOps;
+
+    struct OwnersOperDeleter {
+        void operator()(AsyncOper*) const noexcept;
+    };
+    struct LendersOperDeleter {
+        void operator()(AsyncOper*) const noexcept;
+    };
+    using OwnersOperPtr         = std::unique_ptr<AsyncOper,       OwnersOperDeleter>;
+    using LendersOperPtr        = std::unique_ptr<AsyncOper,       LendersOperDeleter>;
+    using LendersResolveOperPtr = std::unique_ptr<ResolveOperBase, LendersOperDeleter>;
+    using LendersWaitOperPtr    = std::unique_ptr<WaitOperBase,    LendersOperDeleter>;
+    using LendersIoOperPtr      = std::unique_ptr<IoOper,          LendersOperDeleter>;
+
+    class IoReactor;
+    class Impl;
+    const std::unique_ptr<Impl> m_impl;
+
+    template<class Oper, class... Args>
+    static std::unique_ptr<Oper, LendersOperDeleter> alloc(OwnersOperPtr&, Args&&...);
+
+    using PostOperConstr = PostOperBase*(void* addr, std::size_t size, Impl&, void* cookie);
+    void do_post(PostOperConstr, std::size_t size, void* cookie);
+    template<class H>
+    static PostOperBase* post_oper_constr(void* addr, std::size_t size, Impl&, void* cookie);
+    static void recycle_post_oper(Impl&, PostOperBase*) noexcept;
+    static void trigger_exec(Impl&, TriggerExecOperBase&) noexcept;
+    static void reset_trigger_exec(Impl&, TriggerExecOperBase&) noexcept;
+
+    using clock = std::chrono::steady_clock;
+
+    friend class Resolver;
+    friend class SocketBase;
+    friend class Socket;
+    friend class Acceptor;
+    friend class DeadlineTimer;
+    friend class Trigger;
+    friend class ReadAheadBuffer;
+    friend class ssl::Stream;
+};
+
+
+template<class Oper> class Service::OperQueue {
+public:
+    using LendersOperPtr = std::unique_ptr<Oper, LendersOperDeleter>;
+    bool empty() const noexcept;
+    void push_back(LendersOperPtr) noexcept;
+    template<class Oper2> void push_back(OperQueue<Oper2>&) noexcept;
+    LendersOperPtr pop_front() noexcept;
+    void clear() noexcept;
+    OperQueue() noexcept = default;
+    OperQueue(OperQueue&&) noexcept;
+    ~OperQueue() noexcept;
+private:
+    Oper* m_back = nullptr;
+    template<class> friend class OperQueue;
+};
+
+
+class Service::Descriptor {
+public:
+#ifdef _WIN32
+    using native_handle_type = SOCKET;
+#else
+    using native_handle_type = int;
+#endif
+
+    Impl& service_impl;
+
+    Descriptor(Impl& service) noexcept;
+    ~Descriptor() noexcept;
+
+    /// \param in_blocking_mode Must be true if, and only if the passed file
+    /// descriptor refers to a file description in which the file status flag
+    /// O_NONBLOCK is not set.
+    ///
+    /// The passed file descriptor must have the file descriptor flag FD_CLOEXEC
+    /// set.
+    void assign(native_handle_type fd, bool in_blocking_mode) noexcept;
+    void close() noexcept;
+    native_handle_type release() noexcept;
+
+    bool is_open() const noexcept;
+
+    native_handle_type native_handle() const noexcept;
+    bool in_blocking_mode() const noexcept;
+
+    void accept(Descriptor&, StreamProtocol, Endpoint*, std::error_code&) noexcept;
+    std::size_t read_some(char* buffer, std::size_t size, std::error_code&) noexcept;
+    std::size_t write_some(const char* data, std::size_t size, std::error_code&) noexcept;
+
+    /// \tparam Oper An operation type inherited from IoOper with an initate()
+    /// function that initiates the operation and figures out whether it needs
+    /// to read from, or write to the underlying descriptor to
+    /// proceed. `initiate()` must return Want::read if the operation needs to
+    /// read, or Want::write if the operation needs to write. If the operation
+    /// completes immediately (e.g. due to a failure during initialization),
+    /// `initiate()` must return Want::nothing.
+    template<class Oper, class... Args>
+    void initiate_oper(std::unique_ptr<Oper, LendersOperDeleter>, Args&&...);
+
+    void ensure_blocking_mode();
+    void ensure_nonblocking_mode();
+
+private:
+    native_handle_type m_fd = -1;
+    bool m_in_blocking_mode; // Not in nonblocking mode
+
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    bool m_read_ready;
+    bool m_write_ready;
+    bool m_imminent_end_of_input; // Kernel has seen the end of input
+    bool m_is_registered;
+    OperQueue<IoOper> m_suspended_read_ops, m_suspended_write_ops;
+
+    void deregister_for_async() noexcept;
+#endif
+
+    bool assume_read_would_block() const noexcept;
+    bool assume_write_would_block() const noexcept;
+
+    void set_read_ready(bool) noexcept;
+    void set_write_ready(bool) noexcept;
+
+    void set_nonblock_flag(bool value);
+    void add_initiated_oper(LendersIoOperPtr, Want);
+
+    void do_close() noexcept;
+    native_handle_type do_release() noexcept;
+
+    friend class IoReactor;
+};
+
+
+class Resolver {
+public:
+    class Query;
+
+    Resolver(Service&);
+    ~Resolver() noexcept;
+
+    /// Thread-safe.
+    Service& get_service() noexcept;
+
+    /// @{ \brief Resolve the specified query to one or more endpoints.
+    Endpoint::List resolve(const Query&);
+    Endpoint::List resolve(const Query&, std::error_code&);
+    /// @}
+
+    /// \brief Perform an asynchronous resolve operation.
+    ///
+    /// Initiate an asynchronous resolve operation. The completion handler will
+    /// be called when the operation completes. The operation completes when it
+    /// succeeds, or an error occurs.
+    ///
+    /// The completion handler is always executed by the event loop thread,
+    /// i.e., by a thread that is executing Service::run(). Conversely, the
+    /// completion handler is guaranteed to not be called while no thread is
+    /// executing Service::run(). The execution of the completion handler is
+    /// always deferred to the event loop, meaning that it never happens as a
+    /// synchronous side effect of the execution of async_resolve(), even when
+    /// async_resolve() is executed by the event loop thread. The completion
+    /// handler is guaranteed to be called eventually, as long as there is time
+    /// enough for the operation to complete or fail, and a thread is executing
+    /// Service::run() for long enough.
+    ///
+    /// The operation can be canceled by calling cancel(), and will be
+    /// automatically canceled if the resolver object is destroyed. If the
+    /// operation is canceled, it will fail with `error::operation_aborted`. The
+    /// operation remains cancelable up until the point in time where the
+    /// completion handler starts to execute. This means that if cancel() is
+    /// called before the completion handler starts to execute, then the
+    /// completion handler is guaranteed to have `error::operation_aborted`
+    /// passed to it. This is true regardless of whether cancel() is called
+    /// explicitly or implicitly, such as when the resolver is destroyed.
+    ///
+    /// The specified handler will be executed by an expression on the form
+    /// `handler(ec, endpoints)` where `ec` is the error code and `endpoints` is
+    /// an object of type `Endpoint::List`. If the the handler object is
+    /// movable, it will never be copied. Otherwise, it will be copied as
+    /// necessary.
+    ///
+    /// It is an error to start a new resolve operation (synchronous or
+    /// asynchronous) while an asynchronous resolve operation is in progress via
+    /// the same resolver object. An asynchronous resolve operation is
+    /// considered complete as soon as the completion handler starts to
+    /// execute. This means that a new resolve operation can be started from the
+    /// completion handler.
+    template<class H> void async_resolve(Query, H handler);
+
+    /// \brief Cancel all asynchronous operations.
+    ///
+    /// Cause all incomplete asynchronous operations, that are associated with
+    /// this resolver (at most one), to fail with `error::operation_aborted`. An
+    /// asynchronous operation is complete precisely when its completion handler
+    /// starts executing.
+    ///
+    /// Completion handlers of canceled operations will become immediately ready
+    /// to execute, but will never be executed directly as part of the execution
+    /// of cancel().
+    ///
+    /// Cancellation happens automatically when the resolver object is destroyed.
+    void cancel() noexcept;
+
+private:
+    template<class H> class ResolveOper;
+
+    Service::Impl& m_service_impl;
+
+    Service::OwnersOperPtr m_resolve_oper;
+
+    void initiate_oper(Service::LendersResolveOperPtr);
+};
+
+
+class Resolver::Query {
+public:
+    enum {
+        /// Locally bound socket endpoint (server side)
+        passive = AI_PASSIVE,
+
+        /// Ignore families without a configured non-loopback address
+        address_configured = AI_ADDRCONFIG
+    };
+
+    Query(std::string service_port, int init_flags = passive|address_configured);
+    Query(const StreamProtocol&, std::string service_port,
+          int init_flags = passive|address_configured);
+    Query(std::string host_name, std::string service_port,
+          int init_flags = address_configured);
+    Query(const StreamProtocol&, std::string host_name, std::string service_port,
+          int init_flags = address_configured);
+
+    ~Query() noexcept;
+
+    int flags() const;
+    StreamProtocol protocol() const;
+    std::string host() const;
+    std::string service() const;
+
+private:
+    int m_flags;
+    StreamProtocol m_protocol;
+    std::string m_host;    // hostname
+    std::string m_service; // port
+
+    friend class Service;
+};
+
+
+class SocketBase {
+public:
+    using native_handle_type = Service::Descriptor::native_handle_type;
+
+    ~SocketBase() noexcept;
+
+    /// Thread-safe.
+    Service& get_service() noexcept;
+
+    bool is_open() const noexcept;
+    native_handle_type native_handle() const noexcept;
+
+    /// @{ \brief Open the socket for use with the specified protocol.
+    ///
+    /// It is an error to call open() on a socket that is already open.
+    void open(const StreamProtocol&);
+    std::error_code open(const StreamProtocol&, std::error_code&);
+    /// @}
+
+    /// \brief Close this socket.
+    ///
+    /// If the socket is open, it will be closed. If it is already closed (or
+    /// never opened), this function does nothing (idempotency).
+    ///
+    /// A socket is automatically closed when destroyed.
+    ///
+    /// When the socket is closed, any incomplete asynchronous operation will be
+    /// canceled (as if cancel() was called).
+    void close() noexcept;
+
+    /// \brief Cancel all asynchronous operations.
+    ///
+    /// Cause all incomplete asynchronous operations, that are associated with
+    /// this socket, to fail with `error::operation_aborted`. An asynchronous
+    /// operation is complete precisely when its completion handler starts
+    /// executing.
+    ///
+    /// Completion handlers of canceled operations will become immediately ready
+    /// to execute, but will never be executed directly as part of the execution
+    /// of cancel().
+    void cancel() noexcept;
+
+    template<class O>
+    void get_option(O& opt) const;
+
+    template<class O>
+    std::error_code get_option(O& opt, std::error_code&) const;
+
+    template<class O>
+    void set_option(const O& opt);
+
+    template<class O>
+    std::error_code set_option(const O& opt, std::error_code&);
+
+    void bind(const Endpoint&);
+    std::error_code bind(const Endpoint&, std::error_code&);
+
+    Endpoint local_endpoint() const;
+    Endpoint local_endpoint(std::error_code&) const;
+
+    /// Release the ownership of this socket object over the native handle and
+    /// return the native handle to the caller. The caller assumes ownership
+    /// over the returned handle. The socket is left in a closed
+    /// state. Incomplete asynchronous operations will be canceled as if close()
+    /// had been called.
+    ///
+    /// If called on a closed socket, this function is a no-op, and returns the
+    /// same value as would be returned by native_handle()
+    native_handle_type release_native_handle() noexcept;
+
+private:
+    enum opt_enum {
+        opt_ReuseAddr, ///< `SOL_SOCKET`, `SO_REUSEADDR`
+        opt_Linger,    ///< `SOL_SOCKET`, `SO_LINGER`
+        opt_NoDelay,   ///< `IPPROTO_TCP`, `TCP_NODELAY` (disable the Nagle algorithm)
+    };
+
+    template<class, int, class> class Option;
+
+public:
+    using reuse_address = Option<bool, opt_ReuseAddr, int>;
+    using no_delay      = Option<bool, opt_NoDelay,   int>;
+
+    // linger struct defined by POSIX sys/socket.h.
+    struct linger_opt;
+    using linger = Option<linger_opt, opt_Linger, struct linger>;
+
+protected:
+    Service::Descriptor m_desc;
+
+private:
+    StreamProtocol m_protocol;
+
+protected:
+    Service::OwnersOperPtr m_read_oper;  // Read or accept
+    Service::OwnersOperPtr m_write_oper; // Write or connect
+
+    SocketBase(Service&);
+
+    const StreamProtocol& get_protocol() const noexcept;
+    std::error_code do_assign(const StreamProtocol&, native_handle_type, std::error_code&);
+    void do_close() noexcept;
+
+    void get_option(opt_enum, void* value_data, std::size_t& value_size, std::error_code&) const;
+    void set_option(opt_enum, const void* value_data, std::size_t value_size, std::error_code&);
+    void map_option(opt_enum, int& level, int& option_name) const;
+
+    friend class Acceptor;
+};
+
+
+template<class T, int opt, class U> class SocketBase::Option {
+public:
+    Option(T value = T());
+    T value() const;
+
+private:
+    T m_value;
+
+    void get(const SocketBase&, std::error_code&);
+    void set(SocketBase&, std::error_code&) const;
+
+    friend class SocketBase;
+};
+
+struct SocketBase::linger_opt {
+    linger_opt(bool enable, int timeout_seconds = 0)
+    {
+        m_linger.l_onoff = enable ? 1 : 0;
+        m_linger.l_linger = timeout_seconds;
+    }
+
+    ::linger m_linger;
+
+    operator ::linger() const { return m_linger; }
+
+    bool enabled() const { return m_linger.l_onoff != 0; }
+    int  timeout() const { return m_linger.l_linger; }
+};
+
+
+/// Switching between synchronous and asynchronous operations is allowed, but
+/// only in a nonoverlapping fashion. That is, a synchronous operation is not
+/// allowed to run concurrently with an asynchronous one on the same
+/// socket. Note that an asynchronous operation is considered to be running
+/// until its completion handler starts executing.
+class Socket : public SocketBase {
+public:
+    Socket(Service&);
+
+    /// \brief Create a socket with an already-connected native socket handle.
+    ///
+    /// This constructor is shorthand for creating the socket with the
+    /// one-argument constructor, and then calling the two-argument assign()
+    /// with the specified protocol and native handle.
+    Socket(Service&, const StreamProtocol&, native_handle_type);
+
+    ~Socket() noexcept;
+
+    void connect(const Endpoint&);
+    std::error_code connect(const Endpoint&, std::error_code&);
+
+    /// @{ \brief Perform a synchronous read operation.
+    ///
+    /// read() will not return until the specified buffer is full, or an error
+    /// occurs. Reaching the end of input before the buffer is filled, is
+    /// considered an error, and will cause the operation to fail with
+    /// MiscExtErrors::end_of_input.
+    ///
+    /// read_until() will not return until the specified buffer contains the
+    /// specified delimiter, or an error occurs. If the buffer is filled before
+    /// the delimiter is found, the operation fails with
+    /// MiscExtErrors::delim_not_found. Otherwise, if the end of input is
+    /// reached before the delimiter is found, the operation fails with
+    /// MiscExtErrors::end_of_input. If the operation succeeds, the last byte
+    /// placed in the buffer is the delimiter.
+    ///
+    /// The versions that take a ReadAheadBuffer argument will read through that
+    /// buffer. This allows for fewer larger reads on the underlying
+    /// socket. Since unconsumed data may be left in the read-ahead buffer after
+    /// a read operation returns, it is important that the same read-ahead
+    /// buffer is passed to the next read operation.
+    ///
+    /// The versions of read() and read_until() that do not take an
+    /// `std::error_code&` argument will throw std::system_error on failure.
+    ///
+    /// The versions that do take an `std::error_code&` argument will set \a ec
+    /// to `std::error_code()` on success, and to something else on failure. On
+    /// failure they will return the number of bytes placed in the specified
+    /// buffer before the error occured.
+    ///
+    /// \return The number of bytes places in the specified buffer upon return.
+    std::size_t read(char* buffer, std::size_t size);
+    std::size_t read(char* buffer, std::size_t size, std::error_code& ec);
+    std::size_t read(char* buffer, std::size_t size, ReadAheadBuffer&);
+    std::size_t read(char* buffer, std::size_t size, ReadAheadBuffer&, std::error_code& ec);
+    std::size_t read_until(char* buffer, std::size_t size, char delim, ReadAheadBuffer&);
+    std::size_t read_until(char* buffer, std::size_t size, char delim, ReadAheadBuffer&,
+                           std::error_code& ec);
+    /// @}
+
+    /// @{ \brief Perform a synchronous write operation.
+    ///
+    /// write() will not return until all the specified bytes have been written
+    /// to the socket, or an error occurs.
+    ///
+    /// The versions of write() that does not take an `std::error_code&`
+    /// argument will throw std::system_error on failure. When it succeeds, it
+    /// always returns \a size.
+    ///
+    /// The versions that does take an `std::error_code&` argument will set \a
+    /// ec to `std::error_code()` on success, and to something else on
+    /// failure. On success it returns \a size. On faulure it returns the number
+    /// of bytes written before the failure occured.
+    std::size_t write(const char* data, std::size_t size);
+    std::size_t write(const char* data, std::size_t size, std::error_code& ec);
+    /// @}
+
+    /// @{ \brief Read at least one byte from this socket.
+    ///
+    /// If \a size is zero, both versions of read_some() will return zero
+    /// without blocking. Read errors may or may not be detected in this case.
+    ///
+    /// Otherwise, if \a size is greater than zero, and at least one byte is
+    /// immediately available, that is, without blocking, then both versions
+    /// will read at least one byte (but generally as many immediately available
+    /// bytes as will fit into the specified buffer), and return without
+    /// blocking.
+    ///
+    /// Otherwise, both versions will block the calling thread until at least one
+    /// byte becomes available, or an error occurs.
+    ///
+    /// In this context, it counts as an error, if the end of input is reached
+    /// before at least one byte becomes available (see
+    /// MiscExtErrors::end_of_input).
+    ///
+    /// If no error occurs, both versions will return the number of bytes placed
+    /// in the specified buffer, which is generally as many as are immediately
+    /// available at the time when the first byte becomes available, although
+    /// never more than \a size.
+    ///
+    /// If no error occurs, the three-argument version will set \a ec to
+    /// indicate success.
+    ///
+    /// If an error occurs, the two-argument version will throw
+    /// `std::system_error`, while the three-argument version will set \a ec to
+    /// indicate the error, and return zero.
+    ///
+    /// As long as \a size is greater than zero, the two argument version will
+    /// always return a value that is greater than zero, while the three
+    /// argument version will return a value greater than zero when, and only
+    /// when \a ec is set to indicate success (no error, and no end of input).
+    std::size_t read_some(char* buffer, std::size_t size);
+    std::size_t read_some(char* buffer, std::size_t size, std::error_code& ec);
+    /// @}
+
+    /// @{ \brief Write at least one byte to this socket.
+    ///
+    /// If \a size is zero, both versions of write_some() will return zero
+    /// without blocking. Write errors may or may not be detected in this case.
+    ///
+    /// Otherwise, if \a size is greater than zero, and at least one byte can be
+    /// written immediately, that is, without blocking, then both versions will
+    /// write at least one byte (but generally as many as can be written
+    /// immediately), and return without blocking.
+    ///
+    /// Otherwise, both versions will block the calling thread until at least one
+    /// byte can be written, or an error occurs.
+    ///
+    /// If no error occurs, both versions will return the number of bytes
+    /// written, which is generally as many as can be written immediately at the
+    /// time when the first byte can be written.
+    ///
+    /// If no error occurs, the three-argument version will set \a ec to
+    /// indicate success.
+    ///
+    /// If an error occurs, the two-argument version will throw
+    /// `std::system_error`, while the three-argument version will set \a ec to
+    /// indicate the error, and return zero.
+    ///
+    /// As long as \a size is greater than zero, the two argument version will
+    /// always return a value that is greater than zero, while the three
+    /// argument version will return a value greater than zero when, and only
+    /// when \a ec is set to indicate success.
+    std::size_t write_some(const char* data, std::size_t size);
+    std::size_t write_some(const char* data, std::size_t size, std::error_code&);
+    /// @}
+
+    /// \brief Perform an asynchronous connect operation.
+    ///
+    /// Initiate an asynchronous connect operation. The completion handler is
+    /// called when the operation completes. The operation completes when the
+    /// connection is established, or an error occurs.
+    ///
+    /// The completion handler is always executed by the event loop thread,
+    /// i.e., by a thread that is executing Service::run(). Conversely, the
+    /// completion handler is guaranteed to not be called while no thread is
+    /// executing Service::run(). The execution of the completion handler is
+    /// always deferred to the event loop, meaning that it never happens as a
+    /// synchronous side effect of the execution of async_connect(), even when
+    /// async_connect() is executed by the event loop thread. The completion
+    /// handler is guaranteed to be called eventually, as long as there is time
+    /// enough for the operation to complete or fail, and a thread is executing
+    /// Service::run() for long enough.
+    ///
+    /// The operation can be canceled by calling cancel(), and will be
+    /// automatically canceled if the socket is closed. If the operation is
+    /// canceled, it will fail with `error::operation_aborted`. The operation
+    /// remains cancelable up until the point in time where the completion
+    /// handler starts to execute. This means that if cancel() is called before
+    /// the completion handler starts to execute, then the completion handler is
+    /// guaranteed to have `error::operation_aborted` passed to it. This is true
+    /// regardless of whether cancel() is called explicitly or implicitly, such
+    /// as when the socket is destroyed.
+    ///
+    /// If the socket is not already open, it will be opened as part of the
+    /// connect operation as if by calling `open(ep.protocol())`. If the opening
+    /// operation succeeds, but the connect operation fails, the socket will be
+    /// left in the opened state.
+    ///
+    /// The specified handler will be executed by an expression on the form
+    /// `handler(ec)` where `ec` is the error code. If the the handler object is
+    /// movable, it will never be copied. Otherwise, it will be copied as
+    /// necessary.
+    ///
+    /// It is an error to start a new connect operation (synchronous or
+    /// asynchronous) while an asynchronous connect operation is in progress. An
+    /// asynchronous connect operation is considered complete as soon as the
+    /// completion handler starts to execute.
+    ///
+    /// \param ep The remote endpoint of the connection to be established.
+    template<class H> void async_connect(const Endpoint& ep, H handler);
+
+    /// @{ \brief Perform an asynchronous read operation.
+    ///
+    /// Initiate an asynchronous buffered read operation on the associated
+    /// socket. The completion handler will be called when the operation
+    /// completes, or an error occurs.
+    ///
+    /// async_read() will continue reading until the specified buffer is full,
+    /// or an error occurs. If the end of input is reached before the buffer is
+    /// filled, the operation fails with MiscExtErrors::end_of_input.
+    ///
+    /// async_read_until() will continue reading until the specified buffer
+    /// contains the specified delimiter, or an error occurs. If the buffer is
+    /// filled before a delimiter is found, the operation fails with
+    /// MiscExtErrors::delim_not_found. Otherwise, if the end of input is
+    /// reached before a delimiter is found, the operation fails with
+    /// MiscExtErrors::end_of_input. Otherwise, if the operation succeeds, the
+    /// last byte placed in the buffer is the delimiter.
+    ///
+    /// The versions that take a ReadAheadBuffer argument will read through that
+    /// buffer. This allows for fewer larger reads on the underlying
+    /// socket. Since unconsumed data may be left in the read-ahead buffer after
+    /// a read operation completes, it is important that the same read-ahead
+    /// buffer is passed to the next read operation.
+    ///
+    /// The completion handler is always executed by the event loop thread,
+    /// i.e., by a thread that is executing Service::run(). Conversely, the
+    /// completion handler is guaranteed to not be called while no thread is
+    /// executing Service::run(). The execution of the completion handler is
+    /// always deferred to the event loop, meaning that it never happens as a
+    /// synchronous side effect of the execution of async_read() or
+    /// async_read_until(), even when async_read() or async_read_until() is
+    /// executed by the event loop thread. The completion handler is guaranteed
+    /// to be called eventually, as long as there is time enough for the
+    /// operation to complete or fail, and a thread is executing Service::run()
+    /// for long enough.
+    ///
+    /// The operation can be canceled by calling cancel() on the associated
+    /// socket, and will be automatically canceled if the associated socket is
+    /// closed. If the operation is canceled, it will fail with
+    /// `error::operation_aborted`. The operation remains cancelable up until
+    /// the point in time where the completion handler starts to execute. This
+    /// means that if cancel() is called before the completion handler starts to
+    /// execute, then the completion handler is guaranteed to have
+    /// `error::operation_aborted` passed to it. This is true regardless of
+    /// whether cancel() is called explicitly or implicitly, such as when the
+    /// socket is destroyed.
+    ///
+    /// The specified handler will be executed by an expression on the form
+    /// `handler(ec, n)` where `ec` is the error code, and `n` is the number of
+    /// bytes placed in the buffer (of type `std::size_t`). `n` is guaranteed to
+    /// be less than, or equal to \a size. If the the handler object is movable,
+    /// it will never be copied. Otherwise, it will be copied as necessary.
+    ///
+    /// It is an error to start a read operation before the associated socket is
+    /// connected.
+    ///
+    /// It is an error to start a new read operation (synchronous or
+    /// asynchronous) while an asynchronous read operation is in progress. An
+    /// asynchronous read operation is considered complete as soon as the
+    /// completion handler starts executing. This means that a new read
+    /// operation can be started from the completion handler of another
+    /// asynchronous buffered read operation.
+    template<class H> void async_read(char* buffer, std::size_t size, H handler);
+    template<class H> void async_read(char* buffer, std::size_t size, ReadAheadBuffer&, H handler);
+    template<class H> void async_read_until(char* buffer, std::size_t size, char delim,
+                                            ReadAheadBuffer&, H handler);
+    /// @}
+
+    /// \brief Perform an asynchronous write operation.
+    ///
+    /// Initiate an asynchronous write operation. The completion handler is
+    /// called when the operation completes. The operation completes when all
+    /// the specified bytes have been written to the socket, or an error occurs.
+    ///
+    /// The completion handler is always executed by the event loop thread,
+    /// i.e., by a thread that is executing Service::run(). Conversely, the
+    /// completion handler is guaranteed to not be called while no thread is
+    /// executing Service::run(). The execution of the completion handler is
+    /// always deferred to the event loop, meaning that it never happens as a
+    /// synchronous side effect of the execution of async_write(), even when
+    /// async_write() is executed by the event loop thread. The completion
+    /// handler is guaranteed to be called eventually, as long as there is time
+    /// enough for the operation to complete or fail, and a thread is executing
+    /// Service::run() for long enough.
+    ///
+    /// The operation can be canceled by calling cancel(), and will be
+    /// automatically canceled if the socket is closed. If the operation is
+    /// canceled, it will fail with `error::operation_aborted`. The operation
+    /// remains cancelable up until the point in time where the completion
+    /// handler starts to execute. This means that if cancel() is called before
+    /// the completion handler starts to execute, then the completion handler is
+    /// guaranteed to have `error::operation_aborted` passed to it. This is true
+    /// regardless of whether cancel() is called explicitly or implicitly, such
+    /// as when the socket is destroyed.
+    ///
+    /// The specified handler will be executed by an expression on the form
+    /// `handler(ec, n)` where `ec` is the error code, and `n` is the number of
+    /// bytes written (of type `std::size_t`). If the the handler object is
+    /// movable, it will never be copied. Otherwise, it will be copied as
+    /// necessary.
+    ///
+    /// It is an error to start an asynchronous write operation before the
+    /// socket is connected.
+    ///
+    /// It is an error to start a new write operation (synchronous or
+    /// asynchronous) while an asynchronous write operation is in progress. An
+    /// asynchronous write operation is considered complete as soon as the
+    /// completion handler starts to execute. This means that a new write
+    /// operation can be started from the completion handler of another
+    /// asynchronous write operation.
+    template<class H> void async_write(const char* data, std::size_t size, H handler);
+
+    template<class H> void async_read_some(char* buffer, std::size_t size, H handler);
+    template<class H> void async_write_some(const char* data, std::size_t size, H handler);
+
+    enum shutdown_type {
+#ifdef _WIN32
+        /// Shutdown the receiving side of the socket.
+        shutdown_receive = SD_RECEIVE,
+
+        /// Shutdown the sending side of the socket.
+        shutdown_send = SD_SEND,
+
+        /// Shutdown both sending and receiving side of the socket.
+        shutdown_both = SD_BOTH
+#else
+        shutdown_receive = SHUT_RD,
+        shutdown_send = SHUT_WR,
+        shutdown_both = SHUT_RDWR
+#endif
+    };
+
+    /// @{ \brief Shut down the connected sockets sending and/or receiving
+    /// side.
+    ///
+    /// It is an error to call this function when the socket is not both open
+    /// and connected.
+    void shutdown(shutdown_type);
+    std::error_code shutdown(shutdown_type, std::error_code&);
+    /// @}
+
+    /// @{ \brief Initialize socket with an already-connected native socket
+    /// handle.
+    ///
+    /// The specified native handle must refer to a socket that is already fully
+    /// open and connected.
+    ///
+    /// If the assignment operation succeeds, this socket object has taken
+    /// ownership of the specified native handle, and the handle will be closed
+    /// when the socket object is destroyed, (or when close() is called). If the
+    /// operation fails, the caller still owns the specified native handle.
+    ///
+    /// It is an error to call connect() or async_connect() on a socket object
+    /// that is initialized this way (unless it is first closed).
+    ///
+    /// It is an error to call this function on a socket object that is already
+    /// open.
+    void assign(const StreamProtocol&, native_handle_type);
+    std::error_code assign(const StreamProtocol&, native_handle_type, std::error_code&);
+    /// @}
+
+    /// Returns a reference to this socket, as this socket is the lowest layer
+    /// of a stream.
+    Socket& lowest_layer() noexcept;
+
+private:
+    using Want = Service::Want;
+    using StreamOps = Service::BasicStreamOps<Socket>;
+
+    class ConnectOperBase;
+    template<class H> class ConnectOper;
+
+    using LendersConnectOperPtr = std::unique_ptr<ConnectOperBase, Service::LendersOperDeleter>;
+
+    // `ec` untouched on success, but no immediate completion
+    bool initiate_async_connect(const Endpoint&, std::error_code& ec);
+    // `ec` untouched on success
+    std::error_code finalize_async_connect(std::error_code& ec) noexcept;
+
+    // See Service::BasicStreamOps for details on these these 6 functions.
+    void do_init_read_async(std::error_code&, Want&) noexcept;
+    void do_init_write_async(std::error_code&, Want&) noexcept;
+    std::size_t do_read_some_sync(char* buffer, std::size_t size,
+                                  std::error_code&) noexcept;
+    std::size_t do_write_some_sync(const char* data, std::size_t size,
+                                   std::error_code&) noexcept;
+    std::size_t do_read_some_async(char* buffer, std::size_t size,
+                                   std::error_code&, Want&) noexcept;
+    std::size_t do_write_some_async(const char* data, std::size_t size,
+                                    std::error_code&, Want&) noexcept;
+
+    friend class Service::BasicStreamOps<Socket>;
+    friend class Service::BasicStreamOps<ssl::Stream>;
+    friend class ReadAheadBuffer;
+    friend class ssl::Stream;
+};
+
+
+/// Switching between synchronous and asynchronous operations is allowed, but
+/// only in a nonoverlapping fashion. That is, a synchronous operation is not
+/// allowed to run concurrently with an asynchronous one on the same
+/// acceptor. Note that an asynchronous operation is considered to be running
+/// until its completion handler starts executing.
+class Acceptor : public SocketBase {
+public:
+    Acceptor(Service&);
+    ~Acceptor() noexcept;
+
+    static constexpr int max_connections = SOMAXCONN;
+
+    void listen(int backlog = max_connections);
+    std::error_code listen(int backlog, std::error_code&);
+
+    void accept(Socket&);
+    void accept(Socket&, Endpoint&);
+    std::error_code accept(Socket&, std::error_code&);
+    std::error_code accept(Socket&, Endpoint&, std::error_code&);
+
+    /// @{ \brief Perform an asynchronous accept operation.
+    ///
+    /// Initiate an asynchronous accept operation. The completion handler will
+    /// be called when the operation completes. The operation completes when the
+    /// connection is accepted, or an error occurs. If the operation succeeds,
+    /// the specified local socket will have become connected to a remote
+    /// socket.
+    ///
+    /// The completion handler is always executed by the event loop thread,
+    /// i.e., by a thread that is executing Service::run(). Conversely, the
+    /// completion handler is guaranteed to not be called while no thread is
+    /// executing Service::run(). The execution of the completion handler is
+    /// always deferred to the event loop, meaning that it never happens as a
+    /// synchronous side effect of the execution of async_accept(), even when
+    /// async_accept() is executed by the event loop thread. The completion
+    /// handler is guaranteed to be called eventually, as long as there is time
+    /// enough for the operation to complete or fail, and a thread is executing
+    /// Service::run() for long enough.
+    ///
+    /// The operation can be canceled by calling cancel(), and will be
+    /// automatically canceled if the acceptor is closed. If the operation is
+    /// canceled, it will fail with `error::operation_aborted`. The operation
+    /// remains cancelable up until the point in time where the completion
+    /// handler starts to execute. This means that if cancel() is called before
+    /// the completion handler starts to execute, then the completion handler is
+    /// guaranteed to have `error::operation_aborted` passed to it. This is true
+    /// regardless of whether cancel() is called explicitly or implicitly, such
+    /// as when the acceptor is destroyed.
+    ///
+    /// The specified handler will be executed by an expression on the form
+    /// `handler(ec)` where `ec` is the error code. If the the handler object is
+    /// movable, it will never be copied. Otherwise, it will be copied as
+    /// necessary.
+    ///
+    /// It is an error to start a new accept operation (synchronous or
+    /// asynchronous) while an asynchronous accept operation is in progress. An
+    /// asynchronous accept operation is considered complete as soon as the
+    /// completion handler starts executing. This means that a new accept
+    /// operation can be started from the completion handler.
+    ///
+    /// \param sock This is the local socket, that upon successful completion
+    /// will have become connected to the remote socket. It must be in the
+    /// closed state (Socket::is_open()) when async_accept() is called.
+    ///
+    /// \param ep Upon completion, the remote peer endpoint will have been
+    /// assigned to this variable.
+    template<class H> void async_accept(Socket& sock, H handler);
+    template<class H> void async_accept(Socket& sock, Endpoint& ep, H handler);
+    /// @}
+
+private:
+    using Want = Service::Want;
+
+    class AcceptOperBase;
+    template<class H> class AcceptOper;
+
+    using LendersAcceptOperPtr = std::unique_ptr<AcceptOperBase, Service::LendersOperDeleter>;
+
+    std::error_code accept(Socket&, Endpoint*, std::error_code&);
+    Want do_accept_async(Socket&, Endpoint*, std::error_code&) noexcept;
+
+    template<class H> void async_accept(Socket&, Endpoint*, H);
+};
+
+
+/// \brief A timer object supporting asynchronous wait operations.
+class DeadlineTimer {
+public:
+    DeadlineTimer(Service&);
+    ~DeadlineTimer() noexcept;
+
+    /// Thread-safe.
+    Service& get_service() noexcept;
+
+    /// \brief Perform an asynchronous wait operation.
+    ///
+    /// Initiate an asynchronous wait operation. The completion handler becomes
+    /// ready to execute when the expiration time is reached, or an error occurs
+    /// (cancellation counts as an error here). The expiration time is the time
+    /// of initiation plus the specified delay. The error code passed to the
+    /// complition handler will **never** indicate success, unless the
+    /// expiration time was reached.
+    ///
+    /// The completion handler is always executed by the event loop thread,
+    /// i.e., by a thread that is executing Service::run(). Conversely, the
+    /// completion handler is guaranteed to not be called while no thread is
+    /// executing Service::run(). The execution of the completion handler is
+    /// always deferred to the event loop, meaning that it never happens as a
+    /// synchronous side effect of the execution of async_wait(), even when
+    /// async_wait() is executed by the event loop thread. The completion
+    /// handler is guaranteed to be called eventually, as long as there is time
+    /// enough for the operation to complete or fail, and a thread is executing
+    /// Service::run() for long enough.
+    ///
+    /// The operation can be canceled by calling cancel(), and will be
+    /// automatically canceled if the timer is destroyed. If the operation is
+    /// canceled, it will fail with `error::operation_aborted`. The operation
+    /// remains cancelable up until the point in time where the completion
+    /// handler starts to execute. This means that if cancel() is called before
+    /// the completion handler starts to execute, then the completion handler is
+    /// guaranteed to have `error::operation_aborted` passed to it. This is true
+    /// regardless of whether cancel() is called explicitly or implicitly, such
+    /// as when the timer is destroyed.
+    ///
+    /// The specified handler will be executed by an expression on the form
+    /// `handler(ec)` where `ec` is the error code. If the the handler object is
+    /// movable, it will never be copied. Otherwise, it will be copied as
+    /// necessary.
+    ///
+    /// It is an error to start a new asynchronous wait operation while an
+    /// another one is in progress. An asynchronous wait operation is in
+    /// progress until its completion handler starts executing.
+    template<class R, class P, class H>
+    void async_wait(std::chrono::duration<R,P> delay, H handler);
+
+    /// \brief Cancel an asynchronous wait operation.
+    ///
+    /// If an asynchronous wait operation, that is associated with this deadline
+    /// timer, is in progress, cause it to fail with
+    /// `error::operation_aborted`. An asynchronous wait operation is in
+    /// progress until its completion handler starts executing.
+    ///
+    /// Completion handlers of canceled operations will become immediately ready
+    /// to execute, but will never be executed directly as part of the execution
+    /// of cancel().
+    ///
+    /// Cancellation happens automatically when the timer object is destroyed.
+    void cancel() noexcept;
+
+private:
+    template<class H> class WaitOper;
+
+    using clock = Service::clock;
+
+    Service::Impl& m_service_impl;
+    Service::OwnersOperPtr m_wait_oper;
+
+    void initiate_oper(Service::LendersWaitOperPtr);
+};
+
+
+/// \brief Register a function whose invocation can be triggered repeatedly.
+///
+/// While the function is always executed by the event loop thread, the
+/// triggering of its execution can be done by any thread, and the triggering
+/// operation is guaranteed to never throw.
+///
+/// The function is guaranteed to not be called after the Trigger object is
+/// destroyed.
+///
+/// It is safe to destroy the Trigger object during execution of the function.
+///
+/// Note that even though the trigger() function is thread-safe, the Trigger
+/// object, as a whole, is not. In particular, construction and destruction must
+/// not be considered thread-safe.
+///
+/// ### Relation to post()
+///
+/// For a particular execution of trigger() and a particular invocation of
+/// Service::post(), if the execution of trigger() ends before the execution of
+/// Service::post() begins, then it is guaranteed that the function associated
+/// with the trigger gets to execute at least once after the execution of
+/// trigger() begins, and before the post handler gets to execute.
+class Trigger {
+public:
+    template<class F> Trigger(Service&, F func);
+    ~Trigger() noexcept;
+
+    Trigger() noexcept = default;
+    Trigger(Trigger&&) noexcept = default;
+    Trigger& operator=(Trigger&&) noexcept = default;
+
+    /// \brief Trigger another invocation of the associated function.
+    ///
+    /// An invocation of trigger() puts the Trigger object into the triggered
+    /// state. It remains in the triggered state until shortly before the
+    /// function starts to execute. While the Trigger object is in the triggered
+    /// state, trigger() has no effect. This means that the number of executions
+    /// of the function will generally be less that the number of times
+    /// trigger() is invoked().
+    ///
+    /// A particular invocation of trigger() ensures that there will be at least
+    /// one invocation of the associated function whose execution begins after
+    /// the beginning of the execution of trigger(), so long as the event loop
+    /// thread does not exit prematurely from run().
+    ///
+    /// If trigger() is invoked from the event loop thread, the next execution
+    /// of the associated function will not begin until after trigger returns(),
+    /// effectively preventing reentrancy for the associated function.
+    ///
+    /// If trigger() is invoked from another thread, the associated function may
+    /// start to execute before trigger() returns.
+    ///
+    /// Note that the associated function can retrigger itself, i.e., if the
+    /// associated function calls trigger(), then that will lead to another
+    /// invocation of the associated function, but not until the first
+    /// invocation ends (no reentrance).
+    ///
+    /// This function is thread-safe.
+    void trigger() noexcept;
+
+private:
+    template<class H> class ExecOper;
+
+    util::bind_ptr<Service::TriggerExecOperBase> m_exec_oper;
+};
+
+
+class ReadAheadBuffer {
+public:
+    ReadAheadBuffer();
+
+    /// Discard any buffered data.
+    void clear() noexcept;
+
+private:
+    using Want = Service::Want;
+
+    char* m_begin = nullptr;
+    char* m_end   = nullptr;
+    static constexpr std::size_t s_size = 1024;
+    const std::unique_ptr<char[]> m_buffer;
+
+    bool empty() const noexcept;
+    bool read(char*& begin, char* end, int delim, std::error_code&) noexcept;
+    template<class S> void refill_sync(S& stream, std::error_code&) noexcept;
+    template<class S> bool refill_async(S& stream, std::error_code&, Want&) noexcept;
+
+    template<class> friend class Service::BasicStreamOps;
+};
+
+
+enum class ResolveErrors {
+    /// Host not found (authoritative).
+    host_not_found = 1,
+
+    /// Host not found (non-authoritative).
+    host_not_found_try_again,
+
+    /// The query is valid but does not have associated address data.
+    no_data,
+
+    /// A non-recoverable error occurred.
+    no_recovery,
+
+    /// The service is not supported for the given socket type.
+    service_not_found,
+
+    /// The socket type is not supported.
+    socket_type_not_supported
+};
+
+class ResolveErrorCategory : public std::error_category {
+public:
+    const char* name() const noexcept override final;
+    std::string message(int) const override final;
+};
+
+/// The error category associated with ResolveErrors. The name of this category is
+/// `realm.util.network.resolve`.
+extern ResolveErrorCategory resolve_error_category;
+
+inline std::error_code make_error_code(ResolveErrors err)
+{
+    return std::error_code(int(err), resolve_error_category);
+}
+
+} // namespace network
+} // namespace util
+} // namespace realm
+
+namespace std {
+
+template<> class is_error_code_enum<realm::util::network::ResolveErrors> {
+public:
+    static const bool value = true;
+};
+
+} // namespace std
+
+namespace realm {
+namespace util {
+namespace network {
+
+
+
+
+
+// Implementation
+
+// ---------------- StreamProtocol ----------------
+
+inline StreamProtocol StreamProtocol::ip_v4()
+{
+    StreamProtocol prot;
+    prot.m_family = AF_INET;
+    return prot;
+}
+
+inline StreamProtocol StreamProtocol::ip_v6()
+{
+    StreamProtocol prot;
+    prot.m_family = AF_INET6;
+    return prot;
+}
+
+inline bool StreamProtocol::is_ip_v4() const
+{
+    return m_family == AF_INET;
+}
+
+inline bool StreamProtocol::is_ip_v6() const
+{
+    return m_family == AF_INET6;
+}
+
+inline int StreamProtocol::family() const
+{
+    return m_family;
+}
+
+inline int StreamProtocol::protocol() const
+{
+    return m_protocol;
+}
+
+inline StreamProtocol::StreamProtocol() :
+    m_family{AF_UNSPEC},     // Allow both IPv4 and IPv6
+    m_socktype{SOCK_STREAM}, // Or SOCK_DGRAM for UDP
+    m_protocol{0}            // Any protocol
+{
+}
+
+// ---------------- Address ----------------
+
+inline bool Address::is_ip_v4() const
+{
+    return !m_is_ip_v6;
+}
+
+inline bool Address::is_ip_v6() const
+{
+    return m_is_ip_v6;
+}
+
+template<class C, class T>
+inline std::basic_ostream<C,T>& operator<<(std::basic_ostream<C,T>& out, const Address& addr)
+{
+    // FIXME: Not taking `addr.m_ip_v6_scope_id` into account. What does ASIO
+    // do?
+    union buffer_union {
+        char ip_v4[INET_ADDRSTRLEN];
+        char ip_v6[INET6_ADDRSTRLEN];
+    };
+    char buffer[sizeof (buffer_union)];
+    int af = addr.m_is_ip_v6 ? AF_INET6 : AF_INET;
+#ifdef _WIN32
+    void* src = const_cast<void*>(reinterpret_cast<const void*>(&addr.m_union));
+#else
+    const void* src = &addr.m_union;
+#endif
+    const char* ret = ::inet_ntop(af, src, buffer, sizeof buffer);
+    if (ret == 0) {
+        std::error_code ec = make_basic_system_error_code(errno);
+        throw std::system_error(ec);
+    }
+    out << ret;
+    return out;
+}
+
+inline Address::Address()
+{
+    m_union.m_ip_v4 = ip_v4_type();
+}
+
+inline Address make_address(const char* c_str)
+{
+    std::error_code ec;
+    Address addr = make_address(c_str, ec);
+    if (ec)
+        throw std::system_error(ec);
+    return addr;
+}
+
+inline Address make_address(const std::string& str)
+{
+    std::error_code ec;
+    Address addr = make_address(str, ec);
+    if (ec)
+        throw std::system_error(ec);
+    return addr;
+}
+
+inline Address make_address(const std::string& str, std::error_code& ec) noexcept
+{
+    return make_address(str.c_str(), ec);
+}
+
+// ---------------- Endpoint ----------------
+
+inline StreamProtocol Endpoint::protocol() const
+{
+    return m_protocol;
+}
+
+inline Address Endpoint::address() const
+{
+    Address addr;
+    if (m_protocol.is_ip_v4()) {
+        addr.m_union.m_ip_v4 = m_sockaddr_union.m_ip_v4.sin_addr;
+    }
+    else {
+        addr.m_union.m_ip_v6 = m_sockaddr_union.m_ip_v6.sin6_addr;
+        addr.m_ip_v6_scope_id = m_sockaddr_union.m_ip_v6.sin6_scope_id;
+        addr.m_is_ip_v6 = true;
+    }
+    return addr;
+}
+
+inline Endpoint::port_type Endpoint::port() const
+{
+    return ntohs(m_protocol.is_ip_v4() ? m_sockaddr_union.m_ip_v4.sin_port :
+                 m_sockaddr_union.m_ip_v6.sin6_port);
+}
+
+inline Endpoint::data_type* Endpoint::data()
+{
+    return &m_sockaddr_union.m_base;
+}
+
+inline const Endpoint::data_type* Endpoint::data() const
+{
+    return &m_sockaddr_union.m_base;
+}
+
+inline Endpoint::Endpoint() :
+    Endpoint{StreamProtocol::ip_v4(), 0}
+{
+}
+
+inline Endpoint::Endpoint(const StreamProtocol& protocol, port_type port) :
+    m_protocol{protocol}
+{
+    int family = m_protocol.family();
+    if (family == AF_INET) {
+        m_sockaddr_union.m_ip_v4 = sockaddr_ip_v4_type(); // Clear
+        m_sockaddr_union.m_ip_v4.sin_family = AF_INET;
+        m_sockaddr_union.m_ip_v4.sin_port = htons(port);
+        m_sockaddr_union.m_ip_v4.sin_addr.s_addr = INADDR_ANY;
+    }
+    else if (family == AF_INET6) {
+        m_sockaddr_union.m_ip_v6 = sockaddr_ip_v6_type(); // Clear
+        m_sockaddr_union.m_ip_v6.sin6_family = AF_INET6;
+        m_sockaddr_union.m_ip_v6.sin6_port = htons(port);
+    }
+    else {
+        m_sockaddr_union.m_ip_v4 = sockaddr_ip_v4_type(); // Clear
+        m_sockaddr_union.m_ip_v4.sin_family = AF_UNSPEC;
+        m_sockaddr_union.m_ip_v4.sin_port = htons(port);
+        m_sockaddr_union.m_ip_v4.sin_addr.s_addr = INADDR_ANY;
+    }
+}
+
+inline Endpoint::Endpoint(const Address& addr, port_type port)
+{
+    if (addr.m_is_ip_v6) {
+        m_protocol = StreamProtocol::ip_v6();
+        m_sockaddr_union.m_ip_v6.sin6_family = AF_INET6;
+        m_sockaddr_union.m_ip_v6.sin6_port = htons(port);
+        m_sockaddr_union.m_ip_v6.sin6_flowinfo = 0;
+        m_sockaddr_union.m_ip_v6.sin6_addr = addr.m_union.m_ip_v6;
+        m_sockaddr_union.m_ip_v6.sin6_scope_id = addr.m_ip_v6_scope_id;
+    }
+    else {
+        m_protocol = StreamProtocol::ip_v4();
+        m_sockaddr_union.m_ip_v4.sin_family = AF_INET;
+        m_sockaddr_union.m_ip_v4.sin_port = htons(port);
+        m_sockaddr_union.m_ip_v4.sin_addr = addr.m_union.m_ip_v4;
+    }
+}
+
+inline Endpoint::List::iterator Endpoint::List::begin() const noexcept
+{
+    return m_endpoints.data();
+}
+
+inline Endpoint::List::iterator Endpoint::List::end() const noexcept
+{
+    return m_endpoints.data() + m_endpoints.size();
+}
+
+inline std::size_t Endpoint::List::size() const noexcept
+{
+    return m_endpoints.size();
+}
+
+inline bool Endpoint::List::empty() const noexcept
+{
+    return m_endpoints.size() == 0;
+}
+
+// ---------------- Service::OperQueue ----------------
+
+template<class Oper> inline bool Service::OperQueue<Oper>::empty() const noexcept
+{
+    return !m_back;
+}
+
+template<class Oper> inline void Service::OperQueue<Oper>::push_back(LendersOperPtr op) noexcept
+{
+    REALM_ASSERT(!op->m_next);
+    if (m_back) {
+        op->m_next = m_back->m_next;
+        m_back->m_next = op.get();
+    }
+    else {
+        op->m_next = op.get();
+    }
+    m_back = op.release();
+}
+
+template<class Oper> template<class Oper2>
+inline void Service::OperQueue<Oper>::push_back(OperQueue<Oper2>& q) noexcept
+{
+    if (!q.m_back)
+        return;
+    if (m_back)
+        std::swap(m_back->m_next, q.m_back->m_next);
+    m_back = q.m_back;
+    q.m_back = nullptr;
+}
+
+template<class Oper> inline auto Service::OperQueue<Oper>::pop_front() noexcept -> LendersOperPtr
+{
+    Oper* op = nullptr;
+    if (m_back) {
+        op = static_cast<Oper*>(m_back->m_next);
+        if (op != m_back) {
+            m_back->m_next = op->m_next;
+        }
+        else {
+            m_back = nullptr;
+        }
+        op->m_next = nullptr;
+    }
+    return LendersOperPtr(op);
+}
+
+template<class Oper> inline void Service::OperQueue<Oper>::clear() noexcept
+{
+    if (m_back) {
+        LendersOperPtr op(m_back);
+        while (op->m_next != m_back)
+            op.reset(static_cast<Oper*>(op->m_next));
+        m_back = nullptr;
+    }
+}
+
+template<class Oper> inline Service::OperQueue<Oper>::OperQueue(OperQueue&& q) noexcept :
+    m_back{q.m_back}
+{
+    q.m_back = nullptr;
+}
+
+template<class Oper> inline Service::OperQueue<Oper>::~OperQueue() noexcept
+{
+    clear();
+}
+
+// ---------------- Service::Descriptor ----------------
+
+inline Service::Descriptor::Descriptor(Impl& s) noexcept :
+    service_impl{s}
+{
+}
+
+inline Service::Descriptor::~Descriptor() noexcept
+{
+    if (is_open())
+        close();
+}
+
+inline void Service::Descriptor::assign(native_handle_type fd, bool in_blocking_mode) noexcept
+{
+    REALM_ASSERT(!is_open());
+    m_fd = fd;
+    m_in_blocking_mode = in_blocking_mode;
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    m_read_ready  = false;
+    m_write_ready = false;
+    m_imminent_end_of_input = false;
+    m_is_registered = false;
+#endif
+}
+
+inline void Service::Descriptor::close() noexcept
+{
+    REALM_ASSERT(is_open());
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    if (m_is_registered)
+        deregister_for_async();
+    m_is_registered = false;
+#endif
+    do_close();
+}
+
+inline auto Service::Descriptor::release() noexcept -> native_handle_type
+{
+    REALM_ASSERT(is_open());
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    if (m_is_registered)
+        deregister_for_async();
+    m_is_registered = false;
+#endif
+    return do_release();
+}
+
+inline bool Service::Descriptor::is_open() const noexcept
+{
+    return (m_fd != -1);
+}
+
+inline auto Service::Descriptor::native_handle() const noexcept -> native_handle_type
+{
+    return m_fd;
+}
+
+inline bool Service::Descriptor::in_blocking_mode() const noexcept
+{
+    return m_in_blocking_mode;
+}
+
+template<class Oper, class... Args>
+inline void Service::Descriptor::initiate_oper(std::unique_ptr<Oper, LendersOperDeleter> op,
+                                               Args&&... args)
+{
+    Service::Want want = op->initiate(std::forward<Args>(args)...); // Throws
+    add_initiated_oper(std::move(op), want); // Throws
+}
+
+inline void Service::Descriptor::ensure_blocking_mode()
+{
+    // Assuming that descriptors are either used mostly in blocking mode, or
+    // mostly in nonblocking mode.
+    if (REALM_UNLIKELY(!m_in_blocking_mode)) {
+        bool value = false;
+        set_nonblock_flag(value); // Throws
+        m_in_blocking_mode = true;
+    }
+}
+
+inline void Service::Descriptor::ensure_nonblocking_mode()
+{
+    // Assuming that descriptors are either used mostly in blocking mode, or
+    // mostly in nonblocking mode.
+    if (REALM_UNLIKELY(m_in_blocking_mode)) {
+        bool value = true;
+        set_nonblock_flag(value); // Throws
+        m_in_blocking_mode = false;
+    }
+}
+
+inline bool Service::Descriptor::assume_read_would_block() const noexcept
+{
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    return !m_in_blocking_mode && !m_read_ready;
+#else
+    return false;
+#endif
+}
+
+inline bool Service::Descriptor::assume_write_would_block() const noexcept
+{
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    return !m_in_blocking_mode && !m_write_ready;
+#else
+    return false;
+#endif
+}
+
+inline void Service::Descriptor::set_read_ready(bool value) noexcept
+{
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    m_read_ready = value;
+#else
+    // No-op
+    static_cast<void>(value);
+#endif
+}
+
+inline void Service::Descriptor::set_write_ready(bool value) noexcept
+{
+#if REALM_HAVE_EPOLL || REALM_HAVE_KQUEUE
+    m_write_ready = value;
+#else
+    // No-op
+    static_cast<void>(value);
+#endif
+}
+
+// ---------------- Service ----------------
+
+class Service::AsyncOper {
+public:
+    bool in_use() const noexcept;
+    bool is_complete() const noexcept;
+    bool is_canceled() const noexcept;
+    void cancel() noexcept;
+    /// Every object of type \ref AsyncOper must be destroyed either by a call
+    /// to this function or to recycle(). This function recycles the operation
+    /// object (commits suicide), even if it throws.
+    virtual void recycle_and_execute() = 0;
+    /// Every object of type \ref AsyncOper must be destroyed either by a call
+    /// to recycle_and_execute() or to this function. This function destroys the
+    /// object (commits suicide).
+    virtual void recycle() noexcept = 0;
+    /// Must be called when the owner dies, and the object is in use (not an
+    /// instance of UnusedOper).
+    virtual void orphan()  noexcept = 0;
+protected:
+    AsyncOper(std::size_t size, bool in_use) noexcept;
+    virtual ~AsyncOper() noexcept {}
+    void set_is_complete(bool value) noexcept;
+    template<class H, class... Args>
+    void do_recycle_and_execute(bool orphaned, H& handler, Args&&...);
+    void do_recycle(bool orphaned) noexcept;
+private:
+    std::size_t m_size; // Allocated number of bytes
+    bool m_in_use = false;
+    // Set to true when the operation completes successfully or fails. If the
+    // operation is canceled before this happens, it will never be set to
+    // true. Always false when not in use
+    bool m_complete = false;
+    // Set to true when the operation is canceled. Always false when not in use.
+    bool m_canceled = false;
+    AsyncOper* m_next = nullptr; // Always null when not in use
+    template<class H, class... Args>
+    void do_recycle_and_execute_helper(bool orphaned, bool& was_recycled, H handler, Args...);
+    friend class Service;
+};
+
+class Service::ResolveOperBase : public AsyncOper {
+public:
+    ResolveOperBase(std::size_t size, Resolver& resolver, Resolver::Query query) noexcept :
+        AsyncOper{size, true},
+        m_resolver{&resolver},
+        m_query{std::move(query)}
+    {
+    }
+    void complete() noexcept
+    {
+        set_is_complete(true);
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_resolver;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_resolver = nullptr;
+    }
+protected:
+    Resolver* m_resolver;
+    Resolver::Query m_query;
+    Endpoint::List m_endpoints;
+    std::error_code m_error_code;
+    friend class Service;
+};
+
+class Service::WaitOperBase : public AsyncOper {
+public:
+    WaitOperBase(std::size_t size, DeadlineTimer& timer,
+                 clock::time_point expiration_time) noexcept :
+        AsyncOper{size, true}, // Second argument is `in_use`
+        m_timer{&timer},
+        m_expiration_time{expiration_time}
+    {
+    }
+    void complete() noexcept
+    {
+        set_is_complete(true);
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_timer;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_timer = nullptr;
+    }
+protected:
+    DeadlineTimer* m_timer;
+    clock::time_point m_expiration_time;
+    friend class Service;
+};
+
+class Service::TriggerExecOperBase : public AsyncOper, public AtomicRefCountBase {
+public:
+    TriggerExecOperBase(Impl& service) noexcept :
+        AsyncOper{0, false}, // First arg is `size` (unused), second arg is `in_use`
+        m_service{&service}
+    {
+    }
+    void recycle() noexcept override final
+    {
+        REALM_ASSERT(in_use());
+        REALM_ASSERT(!m_service);
+        // Note: Potential suicide when `self` goes out of scope
+        util::bind_ptr<TriggerExecOperBase> self{this, bind_ptr_base::adopt_tag{}};
+    }
+    void orphan() noexcept override final
+    {
+        REALM_ASSERT(m_service);
+        m_service = nullptr;
+    }
+    void trigger() noexcept
+    {
+        REALM_ASSERT(m_service);
+        Service::trigger_exec(*m_service, *this);
+    }
+protected:
+    Impl* m_service;
+};
+
+class Service::PostOperBase : public AsyncOper {
+public:
+    PostOperBase(std::size_t size, Impl& service) noexcept :
+        AsyncOper{size, true}, // Second argument is `in_use`
+        m_service{service}
+    {
+    }
+    void recycle() noexcept override final
+    {
+        // Service::recycle_post_oper() destroys this operation object
+        Service::recycle_post_oper(m_service, this);
+    }
+    void orphan() noexcept override final
+    {
+        REALM_ASSERT(false); // Never called
+    }
+protected:
+    Impl& m_service;
+};
+
+template<class H> class Service::PostOper : public PostOperBase {
+public:
+    PostOper(std::size_t size, Impl& service, H handler) :
+        PostOperBase{size, service},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        // Recycle the operation object before the handler is exceuted, such
+        // that the memory is available for a new post operation that might be
+        // initiated during the execution of the handler.
+        bool was_recycled = false;
+        try {
+            H handler = std::move(m_handler); // Throws
+            // Service::recycle_post_oper() destroys this operation object
+            Service::recycle_post_oper(m_service, this);
+            was_recycled = true;
+            handler(); // Throws
+        }
+        catch (...) {
+            if (!was_recycled) {
+                // Service::recycle_post_oper() destroys this operation object
+                Service::recycle_post_oper(m_service, this);
+            }
+            throw;
+        }
+    }
+private:
+    H m_handler;
+};
+
+class Service::IoOper : public AsyncOper {
+public:
+    IoOper(std::size_t size) noexcept :
+        AsyncOper{size, true} // Second argument is `in_use`
+    {
+    }
+    virtual Descriptor& descriptor() noexcept = 0;
+    /// Advance this operation and figure out out whether it needs to read from,
+    /// or write to the underlying descriptor to advance further. This function
+    /// must return Want::read if the operation needs to read, or Want::write if
+    /// the operation needs to write to advance further. If the operation
+    /// completes (due to success or failure), this function must return
+    /// Want::nothing.
+    virtual Want advance() noexcept = 0;
+};
+
+class Service::UnusedOper : public AsyncOper {
+public:
+    UnusedOper(std::size_t size) noexcept :
+        AsyncOper{size, false} // Second argument is `in_use`
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        // Must never be called
+        REALM_ASSERT(false);
+    }
+    void recycle() noexcept override final
+    {
+        // Must never be called
+        REALM_ASSERT(false);
+    }
+    void orphan() noexcept override final
+    {
+        // Must never be called
+        REALM_ASSERT(false);
+    }
+};
+
+// `S` must be a stream class with the following member functions:
+//
+//    Socket& lowest_layer() noexcept;
+//
+//    void do_init_read_async(std::error_code& ec, Want& want) noexcept;
+//    void do_init_write_async(std::error_code& ec, Want& want) noexcept;
+//
+//    std::size_t do_read_some_sync(char* buffer, std::size_t size,
+//                                  std::error_code& ec) noexcept;
+//    std::size_t do_write_some_sync(const char* data, std::size_t size,
+//                                   std::error_code& ec) noexcept;
+//    std::size_t do_read_some_async(char* buffer, std::size_t size,
+//                                   std::error_code& ec, Want& want) noexcept;
+//    std::size_t do_write_some_async(const char* data, std::size_t size,
+//                                    std::error_code& ec, Want& want) noexcept;
+//
+// If an error occurs during any of these 6 functions, the `ec` argument must be
+// set accordingly. Otherwise the `ec` argument must be set to
+// `std::error_code()`.
+//
+// The do_init_*_async() functions must update the `want` argument to indicate
+// how the operation must be initiated:
+//
+//    Want::read      Wait for read readiness, then call do_*_some_async().
+//    Want::write     Wait for write readiness, then call do_*_some_async().
+//    Want::nothing   Call do_*_some_async() immediately without waiting for
+//                    read or write readiness.
+//
+// If end-of-input occurs while reading, do_read_some_*() must fail, set `ec` to
+// MiscExtErrors::end_of_input, and return zero.
+//
+// If an error occurs during reading or writing, do_*_some_sync() must set `ec`
+// accordingly (to something other than `std::system_error()`) and return
+// zero. Otherwise they must set `ec` to `std::system_error()` and return the
+// number of bytes read or written, which **must** be at least 1. If the
+// underlying socket is in nonblocking mode, and no bytes could be immediately
+// read or written, these functions must fail with
+// `error::resource_unavailable_try_again`.
+//
+// If an error occurs during reading or writing, do_*_some_async() must set `ec`
+// accordingly (to something other than `std::system_error()`), `want` to
+// `Want::nothing`, and return zero. Otherwise they must set `ec` to
+// `std::system_error()` and return the number of bytes read or written, which
+// must be zero if no bytes could be immediately read or written. Note, in this
+// case it is not an error if the underlying socket is in nonblocking mode, and
+// no bytes could be immediately read or written. When these functions succeed,
+// but return zero because no bytes could be immediately read or written, they
+// must set `want` to something other than `Want::nothing`.
+//
+// If no error occurs, do_*_some_async() must set `want` to indicate how the
+// operation should proceed if additional data needs to be read or written, or
+// if no bytes were transferred:
+//
+//    Want::read      Wait for read readiness, then call do_*_some_async() again.
+//    Want::write     Wait for write readiness, then call do_*_some_async() again.
+//    Want::nothing   Call do_*_some_async() again without waiting for read or
+//                    write readiness.
+//
+// NOTE: If, for example, do_read_some_async() sets `want` to `Want::write`, it
+// means that the stream needs to write data to the underlying TCP socket before
+// it is able to deliver any additional data to the caller. While such a
+// situation will never occur on a raw TCP socket, it can occur on an SSL stream
+// (Secure Socket Layer).
+//
+// When do_*_some_async() returns `n`, at least one of the following conditions
+// must be true:
+//
+//    n > 0                     Bytes were transferred.
+//    ec != std::error_code()   An error occured.
+//    want != Want::nothing     Wait for read/write readiness.
+//
+// This is of critical importance, as it is the only way we can avoid falling
+// into a busy loop of repeated invocations of do_*_some_async().
+//
+// NOTE: do_*_some_async() are allowed to set `want` to `Want::read` or
+// `Want::write`, even when they succesfully transfer a nonzero number of bytes.
+template<class S> class Service::BasicStreamOps {
+public:
+    class StreamOper;
+    class ReadOperBase;
+    class WriteOperBase;
+    class BufferedReadOperBase;
+    template<class H> class ReadOper;
+    template<class H> class WriteOper;
+    template<class H> class BufferedReadOper;
+
+    using LendersReadOperPtr          = std::unique_ptr<ReadOperBase,         LendersOperDeleter>;
+    using LendersWriteOperPtr         = std::unique_ptr<WriteOperBase,        LendersOperDeleter>;
+    using LendersBufferedReadOperPtr  = std::unique_ptr<BufferedReadOperBase, LendersOperDeleter>;
+
+    // Synchronous read
+    static std::size_t read(S& stream, char* buffer, std::size_t size,
+                            std::error_code& ec)
+    {
+        REALM_ASSERT(!stream.lowest_layer().m_read_oper ||
+                     !stream.lowest_layer().m_read_oper->in_use());
+        stream.lowest_layer().m_desc.ensure_blocking_mode(); // Throws
+        char* begin = buffer;
+        char* end   = buffer + size;
+        char* curr  = begin;
+        for (;;) {
+            if (curr == end) {
+                ec = std::error_code(); // Success
+                break;
+            }
+            char* buffer_2 = curr;
+            std::size_t size_2 = std::size_t(end - curr);
+            std::size_t n = stream.do_read_some_sync(buffer_2, size_2, ec);
+            if (REALM_UNLIKELY(ec))
+                break;
+            REALM_ASSERT(n > 0);
+            REALM_ASSERT(n <= size_2);
+            curr += n;
+        }
+        std::size_t n = std::size_t(curr - begin);
+        return n;
+    }
+
+    // Synchronous write
+    static std::size_t write(S& stream, const char* data, std::size_t size,
+                             std::error_code& ec)
+    {
+        REALM_ASSERT(!stream.lowest_layer().m_write_oper ||
+                     !stream.lowest_layer().m_write_oper->in_use());
+        stream.lowest_layer().m_desc.ensure_blocking_mode(); // Throws
+        const char* begin = data;
+        const char* end   = data + size;
+        const char* curr  = begin;
+        for (;;) {
+            if (curr == end) {
+                ec = std::error_code(); // Success
+                break;
+            }
+            const char* data_2 = curr;
+            std::size_t size_2 = std::size_t(end - curr);
+            std::size_t n = stream.do_write_some_sync(data_2, size_2, ec);
+            if (REALM_UNLIKELY(ec))
+                break;
+            REALM_ASSERT(n > 0);
+            REALM_ASSERT(n <= size_2);
+            curr += n;
+        }
+        std::size_t n = std::size_t(curr - begin);
+        return n;
+    }
+
+    // Synchronous read
+    static std::size_t buffered_read(S& stream, char* buffer, std::size_t size, int delim,
+                                     ReadAheadBuffer& rab, std::error_code& ec)
+    {
+        REALM_ASSERT(!stream.lowest_layer().m_read_oper ||
+                     !stream.lowest_layer().m_read_oper->in_use());
+        stream.lowest_layer().m_desc.ensure_blocking_mode(); // Throws
+        char* begin = buffer;
+        char* end   = buffer + size;
+        char* curr  = begin;
+        for (;;) {
+            bool complete = rab.read(curr, end, delim, ec);
+            if (complete)
+                break;
+
+            rab.refill_sync(stream, ec);
+            if (REALM_UNLIKELY(ec))
+                break;
+        }
+        std::size_t n = (curr - begin);
+        return n;
+    }
+
+    // Synchronous read
+    static std::size_t read_some(S& stream, char* buffer, std::size_t size,
+                                 std::error_code& ec)
+    {
+        REALM_ASSERT(!stream.lowest_layer().m_read_oper ||
+                     !stream.lowest_layer().m_read_oper->in_use());
+        stream.lowest_layer().m_desc.ensure_blocking_mode(); // Throws
+        return stream.do_read_some_sync(buffer, size, ec);
+    }
+
+    // Synchronous write
+    static std::size_t write_some(S& stream, const char* data, std::size_t size,
+                                  std::error_code& ec)
+    {
+        REALM_ASSERT(!stream.lowest_layer().m_write_oper ||
+                     !stream.lowest_layer().m_write_oper->in_use());
+        stream.lowest_layer().m_desc.ensure_blocking_mode(); // Throws
+        return stream.do_write_some_sync(data, size, ec);
+    }
+
+    template<class H>
+    static void async_read(S& stream, char* buffer, std::size_t size, bool is_read_some, H handler)
+    {
+        char* begin = buffer;
+        char* end   = buffer + size;
+        LendersReadOperPtr op =
+            Service::alloc<ReadOper<H>>(stream.lowest_layer().m_read_oper, stream, is_read_some,
+                                        begin, end, std::move(handler)); // Throws
+        stream.lowest_layer().m_desc.initiate_oper(std::move(op)); // Throws
+    }
+
+    template<class H>
+    static void async_write(S& stream, const char* data, std::size_t size, bool is_write_some,
+                            H handler)
+    {
+        const char* begin = data;
+        const char* end   = data + size;
+        LendersWriteOperPtr op =
+            Service::alloc<WriteOper<H>>(stream.lowest_layer().m_write_oper, stream, is_write_some,
+                                         begin, end, std::move(handler)); // Throws
+        stream.lowest_layer().m_desc.initiate_oper(std::move(op)); // Throws
+    }
+
+    template<class H>
+    static void async_buffered_read(S& stream, char* buffer, std::size_t size, int delim,
+                                    ReadAheadBuffer& rab, H handler)
+    {
+        char* begin = buffer;
+        char* end   = buffer + size;
+        LendersBufferedReadOperPtr op =
+            Service::alloc<BufferedReadOper<H>>(stream.lowest_layer().m_read_oper, stream,
+                                                begin, end, delim, rab,
+                                                std::move(handler)); // Throws
+        stream.lowest_layer().m_desc.initiate_oper(std::move(op)); // Throws
+    }
+};
+
+template<class S> class Service::BasicStreamOps<S>::StreamOper : public IoOper {
+public:
+    StreamOper(std::size_t size, S& stream) noexcept :
+        IoOper{size},
+        m_stream{&stream}
+    {
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_stream;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_stream = nullptr;
+    }
+    Descriptor& descriptor() noexcept override final
+    {
+        return m_stream->lowest_layer().m_desc;
+    }
+protected:
+    S* m_stream;
+    std::error_code m_error_code;
+};
+
+template<class S> class Service::BasicStreamOps<S>::ReadOperBase : public StreamOper {
+public:
+    ReadOperBase(std::size_t size, S& stream, bool is_read_some, char* begin, char* end) noexcept :
+        StreamOper{size, stream},
+        m_is_read_some{is_read_some},
+        m_begin{begin},
+        m_end{end}
+    {
+    }
+    Want initiate()
+    {
+        auto& s = *this;
+        REALM_ASSERT(this == s.m_stream->lowest_layer().m_read_oper.get());
+        REALM_ASSERT(!s.is_complete());
+        REALM_ASSERT(s.m_curr <= s.m_end);
+        Want want = Want::nothing;
+        if (REALM_UNLIKELY(s.m_curr == s.m_end)) {
+            s.set_is_complete(true); // Success
+        }
+        else {
+            s.m_stream->lowest_layer().m_desc.ensure_nonblocking_mode(); // Throws
+            s.m_stream->do_init_read_async(s.m_error_code, want);
+            if (want == Want::nothing) {
+                if (REALM_UNLIKELY(s.m_error_code)) {
+                    s.set_is_complete(true); // Failure
+                }
+                else {
+                    want = advance();
+                }
+            }
+        }
+        return want;
+    }
+    Want advance() noexcept override final
+    {
+        auto& s = *this;
+        REALM_ASSERT(!s.is_complete());
+        REALM_ASSERT(!s.is_canceled());
+        REALM_ASSERT(!s.m_error_code);
+        REALM_ASSERT(s.m_curr < s.m_end);
+        REALM_ASSERT(!s.m_is_read_some || s.m_curr == m_begin);
+        for (;;) {
+            // Read into callers buffer
+            char* buffer = s.m_curr;
+            std::size_t size = std::size_t(s.m_end - s.m_curr);
+            Want want = Want::nothing;
+            std::size_t n = s.m_stream->do_read_some_async(buffer, size, s.m_error_code, want);
+            REALM_ASSERT(n > 0 || s.m_error_code || want != Want::nothing); // No busy loop, please
+            bool got_nothing = (n == 0);
+            if (got_nothing) {
+                if (REALM_UNLIKELY(s.m_error_code)) {
+                    s.set_is_complete(true); // Failure
+                    return Want::nothing;
+                }
+                // Got nothing, but want something
+                return want;
+            }
+            REALM_ASSERT(!s.m_error_code);
+            // Check for completion
+            REALM_ASSERT(n <= size);
+            s.m_curr += n;
+            if (s.m_is_read_some || s.m_curr == s.m_end) {
+                s.set_is_complete(true); // Success
+                return Want::nothing;
+            }
+            if (want != Want::nothing)
+                return want;
+            REALM_ASSERT(n < size);
+        }
+    }
+protected:
+    const bool m_is_read_some;
+    char* const m_begin;    // May be dangling after cancellation
+    char* const m_end;      // May be dangling after cancellation
+    char* m_curr = m_begin; // May be dangling after cancellation
+};
+
+template<class S> class Service::BasicStreamOps<S>::WriteOperBase : public StreamOper {
+public:
+    WriteOperBase(std::size_t size, S& stream, bool is_write_some,
+                  const char* begin, const char* end) noexcept :
+        StreamOper{size, stream},
+        m_is_write_some{is_write_some},
+        m_begin{begin},
+        m_end{end}
+    {
+    }
+    Want initiate()
+    {
+        auto& s = *this;
+        REALM_ASSERT(this == s.m_stream->lowest_layer().m_write_oper.get());
+        REALM_ASSERT(!s.is_complete());
+        REALM_ASSERT(s.m_curr <= s.m_end);
+        Want want = Want::nothing;
+        if (REALM_UNLIKELY(s.m_curr == s.m_end)) {
+            s.set_is_complete(true); // Success
+        }
+        else {
+            s.m_stream->lowest_layer().m_desc.ensure_nonblocking_mode(); // Throws
+            s.m_stream->do_init_write_async(s.m_error_code, want);
+            if (want == Want::nothing) {
+                if (REALM_UNLIKELY(s.m_error_code)) {
+                    s.set_is_complete(true); // Failure
+                }
+                else {
+                    want = advance();
+                }
+            }
+        }
+        return want;
+    }
+    Want advance() noexcept override final
+    {
+        auto& s = *this;
+        REALM_ASSERT(!s.is_complete());
+        REALM_ASSERT(!s.is_canceled());
+        REALM_ASSERT(!s.m_error_code);
+        REALM_ASSERT(s.m_curr < s.m_end);
+        REALM_ASSERT(!s.m_is_write_some || s.m_curr == s.m_begin);
+        for (;;) {
+            // Write from callers buffer
+            const char* data = s.m_curr;
+            std::size_t size = std::size_t(s.m_end - s.m_curr);
+            Want want = Want::nothing;
+            std::size_t n = s.m_stream->do_write_some_async(data, size, s.m_error_code, want);
+            REALM_ASSERT(n > 0 || s.m_error_code || want != Want::nothing); // No busy loop, please
+            bool wrote_nothing = (n == 0);
+            if (wrote_nothing) {
+                if (REALM_UNLIKELY(s.m_error_code)) {
+                    s.set_is_complete(true); // Failure
+                    return Want::nothing;
+                }
+                // Wrote nothing, but want something written
+                return want;
+            }
+            REALM_ASSERT(!s.m_error_code);
+            // Check for completion
+            REALM_ASSERT(n <= size);
+            s.m_curr += n;
+            if (s.m_is_write_some || s.m_curr == s.m_end) {
+                s.set_is_complete(true); // Success
+                return Want::nothing;
+            }
+            if (want != Want::nothing)
+                return want;
+            REALM_ASSERT(n < size);
+        }
+    }
+protected:
+    const bool m_is_write_some;
+    const char* const m_begin;    // May be dangling after cancellation
+    const char* const m_end;      // May be dangling after cancellation
+    const char* m_curr = m_begin; // May be dangling after cancellation
+};
+
+template<class S> class Service::BasicStreamOps<S>::BufferedReadOperBase : public StreamOper {
+public:
+    BufferedReadOperBase(std::size_t size, S& stream, char* begin, char* end, int delim,
+                         ReadAheadBuffer& rab) noexcept :
+        StreamOper{size, stream},
+        m_read_ahead_buffer{rab},
+        m_begin{begin},
+        m_end{end},
+        m_delim{delim}
+    {
+    }
+    Want initiate()
+    {
+        auto& s = *this;
+        REALM_ASSERT(this == s.m_stream->lowest_layer().m_read_oper.get());
+        REALM_ASSERT(!s.is_complete());
+        Want want = Want::nothing;
+        bool complete = s.m_read_ahead_buffer.read(s.m_curr, s.m_end, s.m_delim, s.m_error_code);
+        if (complete) {
+            s.set_is_complete(true); // Success or failure
+        }
+        else {
+            s.m_stream->lowest_layer().m_desc.ensure_nonblocking_mode(); // Throws
+            s.m_stream->do_init_read_async(s.m_error_code, want);
+            if (want == Want::nothing) {
+                if (REALM_UNLIKELY(s.m_error_code)) {
+                    s.set_is_complete(true); // Failure
+                }
+                else {
+                    want = advance();
+                }
+            }
+        }
+        return want;
+    }
+    Want advance() noexcept override final
+    {
+        auto& s = *this;
+        REALM_ASSERT(!s.is_complete());
+        REALM_ASSERT(!s.is_canceled());
+        REALM_ASSERT(!s.m_error_code);
+        REALM_ASSERT(s.m_read_ahead_buffer.empty());
+        REALM_ASSERT(s.m_curr < s.m_end);
+        for (;;) {
+            // Fill read-ahead buffer from stream (is empty now)
+            Want want = Want::nothing;
+            bool nonempty = s.m_read_ahead_buffer.refill_async(*s.m_stream, s.m_error_code, want);
+            REALM_ASSERT(nonempty || s.m_error_code ||
+                         want != Want::nothing); // No busy loop, please
+            bool got_nothing = !nonempty;
+            if (got_nothing) {
+                if (REALM_UNLIKELY(s.m_error_code)) {
+                    s.set_is_complete(true); // Failure
+                    return Want::nothing;
+                }
+                // Got nothing, but want something
+                return want;
+            }
+            // Transfer buffered data to callers buffer
+            bool complete =
+                s.m_read_ahead_buffer.read(s.m_curr, s.m_end, s.m_delim, s.m_error_code);
+            if (complete) {
+                s.set_is_complete(true); // Success or failure (delim_not_found)
+                return Want::nothing;
+            }
+            if (want != Want::nothing)
+                return want;
+        }
+    }
+protected:
+    ReadAheadBuffer& m_read_ahead_buffer; // May be dangling after cancellation
+    char* const m_begin;                  // May be dangling after cancellation
+    char* const m_end;                    // May be dangling after cancellation
+    char* m_curr = m_begin;               // May be dangling after cancellation
+    const int m_delim;
+};
+
+template<class S> template<class H>
+class Service::BasicStreamOps<S>::ReadOper : public ReadOperBase {
+public:
+    ReadOper(std::size_t size, S& stream, bool is_read_some, char* begin, char* end, H handler) :
+        ReadOperBase{size, stream, is_read_some, begin, end},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        auto& s = *this;
+        REALM_ASSERT(s.is_complete() || s.is_canceled());
+        REALM_ASSERT(s.is_complete() == (s.m_error_code || s.m_curr == s.m_end ||
+                                         (s.m_is_read_some && s.m_curr != s.m_begin)));
+        REALM_ASSERT(s.m_curr >= s.m_begin);
+        bool orphaned = !s.m_stream;
+        std::error_code ec = s.m_error_code;
+        if (s.is_canceled())
+            ec = error::operation_aborted;
+        std::size_t num_bytes_transferred = std::size_t(s.m_curr - s.m_begin);
+        // Note: do_recycle_and_execute() commits suicide.
+        s.template do_recycle_and_execute<H>(orphaned, s.m_handler, ec,
+                                             num_bytes_transferred); // Throws
+    }
+private:
+    H m_handler;
+};
+
+template<class S> template<class H>
+class Service::BasicStreamOps<S>::WriteOper : public WriteOperBase {
+public:
+    WriteOper(std::size_t size, S& stream, bool is_write_some,
+              const char* begin, const char* end, H handler) :
+        WriteOperBase{size, stream, is_write_some, begin, end},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        auto& s = *this;
+        REALM_ASSERT(s.is_complete() || s.is_canceled());
+        REALM_ASSERT(s.is_complete() == (s.m_error_code || s.m_curr == s.m_end ||
+                                         (s.m_is_write_some && s.m_curr != s.m_begin)));
+        REALM_ASSERT(s.m_curr >= s.m_begin);
+        bool orphaned = !s.m_stream;
+        std::error_code ec = s.m_error_code;
+        if (s.is_canceled())
+            ec = error::operation_aborted;
+        std::size_t num_bytes_transferred = std::size_t(s.m_curr - s.m_begin);
+        // Note: do_recycle_and_execute() commits suicide.
+        s.template do_recycle_and_execute<H>(orphaned, s.m_handler, ec,
+                                             num_bytes_transferred); // Throws
+    }
+private:
+    H m_handler;
+};
+
+template<class S> template<class H>
+class Service::BasicStreamOps<S>::BufferedReadOper : public BufferedReadOperBase {
+public:
+    BufferedReadOper(std::size_t size, S& stream, char* begin, char* end, int delim,
+                     ReadAheadBuffer& rab, H handler) :
+        BufferedReadOperBase{size, stream, begin, end, delim, rab},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        auto& s = *this;
+        REALM_ASSERT(s.is_complete() || (s.is_canceled() && !s.m_error_code));
+        REALM_ASSERT(s.is_canceled() || s.m_error_code ||
+                     (s.m_delim != std::char_traits<char>::eof() ?
+                      s.m_curr > s.m_begin && s.m_curr[-1] ==
+                      std::char_traits<char>::to_char_type(s.m_delim) :
+                      s.m_curr == s.m_end));
+        REALM_ASSERT(s.m_curr >= s.m_begin);
+        bool orphaned = !s.m_stream;
+        std::error_code ec = s.m_error_code;
+        if (s.is_canceled())
+            ec = error::operation_aborted;
+        std::size_t num_bytes_transferred = std::size_t(s.m_curr - s.m_begin);
+        // Note: do_recycle_and_execute() commits suicide.
+        s.template do_recycle_and_execute<H>(orphaned, s.m_handler, ec,
+                                             num_bytes_transferred); // Throws
+    }
+private:
+    H m_handler;
+};
+
+template<class H> inline void Service::post(H handler)
+{
+    do_post(&Service::post_oper_constr<H>, sizeof (PostOper<H>), &handler);
+}
+
+inline void Service::OwnersOperDeleter::operator()(AsyncOper* op) const noexcept
+{
+    if (op->in_use()) {
+        op->orphan();
+    }
+    else {
+        void* addr = op;
+        op->~AsyncOper();
+        delete[] static_cast<char*>(addr);
+    }
+}
+
+inline void Service::LendersOperDeleter::operator()(AsyncOper* op) const noexcept
+{
+    op->recycle(); // Suicide
+}
+
+template<class Oper, class... Args> std::unique_ptr<Oper, Service::LendersOperDeleter>
+Service::alloc(OwnersOperPtr& owners_ptr, Args&&... args)
+{
+    void* addr = owners_ptr.get();
+    std::size_t size;
+    if (REALM_LIKELY(addr)) {
+        REALM_ASSERT(!owners_ptr->in_use());
+        size = owners_ptr->m_size;
+        // We can use static dispatch in the destructor call here, since an
+        // object, that is not in use, is always an instance of UnusedOper.
+        REALM_ASSERT(dynamic_cast<UnusedOper*>(owners_ptr.get()));
+        static_cast<UnusedOper*>(owners_ptr.get())->UnusedOper::~UnusedOper();
+        if (REALM_UNLIKELY(size < sizeof (Oper))) {
+            owners_ptr.release();
+            delete[] static_cast<char*>(addr);
+            goto no_object;
+        }
+    }
+    else {
+      no_object:
+        addr = new char[sizeof (Oper)]; // Throws
+        size = sizeof (Oper);
+        owners_ptr.reset(static_cast<AsyncOper*>(addr));
+    }
+    std::unique_ptr<Oper, LendersOperDeleter> lenders_ptr;
+    try {
+        lenders_ptr.reset(new (addr) Oper(size, std::forward<Args>(args)...)); // Throws
+    }
+    catch (...) {
+        new (addr) UnusedOper(size); // Does not throw
+        throw;
+    }
+    return lenders_ptr;
+}
+
+template<class H> inline Service::PostOperBase*
+Service::post_oper_constr(void* addr, std::size_t size, Impl& service, void* cookie)
+{
+    H& handler = *static_cast<H*>(cookie);
+    return new (addr) PostOper<H>(size, service, std::move(handler)); // Throws
+}
+
+inline bool Service::AsyncOper::in_use() const noexcept
+{
+    return m_in_use;
+}
+
+inline bool Service::AsyncOper::is_complete() const noexcept
+{
+    return m_complete;
+}
+
+inline void Service::AsyncOper::cancel() noexcept
+{
+    REALM_ASSERT(m_in_use);
+    REALM_ASSERT(!m_canceled);
+    m_canceled = true;
+}
+
+inline Service::AsyncOper::AsyncOper(std::size_t size, bool is_in_use) noexcept :
+    m_size{size},
+    m_in_use{is_in_use}
+{
+}
+
+inline bool Service::AsyncOper::is_canceled() const noexcept
+{
+    return m_canceled;
+}
+
+inline void Service::AsyncOper::set_is_complete(bool value) noexcept
+{
+    REALM_ASSERT(!m_complete);
+    REALM_ASSERT(!value || m_in_use);
+    m_complete = value;
+}
+
+template<class H, class... Args>
+inline void Service::AsyncOper::do_recycle_and_execute(bool orphaned, H& handler, Args&&... args)
+{
+    // Recycle the operation object before the handler is exceuted, such that
+    // the memory is available for a new post operation that might be initiated
+    // during the execution of the handler.
+    bool was_recycled = false;
+    try {
+        // We need to copy or move all arguments to be passed to the handler,
+        // such that there is no risk of references to the recycled operation
+        // object being passed to the handler (the passed arguments may be
+        // references to members of the recycled operation object). The easiest
+        // way to achive this, is by forwarding the reference arguments (passed
+        // to this function) to a helper function whose arguments have
+        // nonreference type (`Args...` rather than `Args&&...`).
+        //
+        // Note that the copying and moving of arguments may throw, and it is
+        // important that the operation is still recycled even if that
+        // happens. For that reason, copying and moving of arguments must not
+        // happen until we are in a scope (this scope) that catches and deals
+        // correctly with such exceptions.
+        do_recycle_and_execute_helper(orphaned, was_recycled, std::move(handler),
+                                      std::forward<Args>(args)...); // Throws
+    }
+    catch (...) {
+        if (!was_recycled)
+            do_recycle(orphaned);
+        throw;
+    }
+}
+
+template<class H, class... Args>
+inline void Service::AsyncOper::do_recycle_and_execute_helper(bool orphaned, bool& was_recycled,
+                                                              H handler, Args... args)
+{
+    do_recycle(orphaned);
+    was_recycled = true;
+    handler(std::move(args)...); // Throws
+}
+
+inline void Service::AsyncOper::do_recycle(bool orphaned) noexcept
+{
+    REALM_ASSERT(in_use());
+    void* addr = this;
+    std::size_t size = m_size;
+    this->~AsyncOper(); // Suicide
+    if (orphaned) {
+        delete[] static_cast<char*>(addr);
+    }
+    else {
+        new (addr) UnusedOper(size);
+    }
+}
+
+// ---------------- Resolver ----------------
+
+template<class H> class Resolver::ResolveOper : public Service::ResolveOperBase {
+public:
+    ResolveOper(std::size_t size, Resolver& r, Query q, H handler) :
+        ResolveOperBase{size, r, std::move(q)},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        REALM_ASSERT(is_complete() || (is_canceled() && !m_error_code));
+        REALM_ASSERT(is_canceled() || m_error_code || !m_endpoints.empty());
+        bool orphaned = !m_resolver;
+        std::error_code ec = m_error_code;
+        if (is_canceled())
+            ec = error::operation_aborted;
+        // Note: do_recycle_and_execute() commits suicide.
+        do_recycle_and_execute<H>(orphaned, m_handler, ec, std::move(m_endpoints)); // Throws
+    }
+private:
+    H m_handler;
+};
+
+inline Resolver::Resolver(Service& service) :
+    m_service_impl{*service.m_impl}
+{
+}
+
+inline Resolver::~Resolver() noexcept
+{
+    cancel();
+}
+
+inline Endpoint::List Resolver::resolve(const Query& q)
+{
+    std::error_code ec;
+    Endpoint::List list = resolve(q, ec);
+    if (REALM_UNLIKELY(ec))
+        throw std::system_error(ec);
+    return list;
+}
+
+template<class H> void Resolver::async_resolve(Query query, H handler)
+{
+    Service::LendersResolveOperPtr op =
+        Service::alloc<ResolveOper<H>>(m_resolve_oper, *this,
+                                       std::move(query),
+                                       std::move(handler)); // Throws
+    initiate_oper(std::move(op)); // Throws
+}
+
+inline Resolver::Query::Query(std::string service_port, int init_flags) :
+    m_flags{init_flags},
+    m_service{service_port}
+{
+}
+
+inline Resolver::Query::Query(const StreamProtocol& prot, std::string service_port,
+                              int init_flags) :
+    m_flags{init_flags},
+    m_protocol{prot},
+    m_service{service_port}
+{
+}
+
+inline Resolver::Query::Query(std::string host_name, std::string service_port, int init_flags) :
+    m_flags{init_flags},
+    m_host{host_name},
+    m_service{service_port}
+{
+}
+
+inline Resolver::Query::Query(const StreamProtocol& prot, std::string host_name,
+                              std::string service_port, int init_flags) :
+    m_flags{init_flags},
+    m_protocol{prot},
+    m_host{host_name},
+    m_service{service_port}
+{
+}
+
+inline Resolver::Query::~Query() noexcept
+{
+}
+
+inline int Resolver::Query::flags() const
+{
+    return m_flags;
+}
+
+inline StreamProtocol Resolver::Query::protocol() const
+{
+    return m_protocol;
+}
+
+inline std::string Resolver::Query::host() const
+{
+    return m_host;
+}
+
+inline std::string Resolver::Query::service() const
+{
+    return m_service;
+}
+
+// ---------------- SocketBase ----------------
+
+inline SocketBase::SocketBase(Service& service) :
+    m_desc{*service.m_impl}
+{
+}
+
+inline SocketBase::~SocketBase() noexcept
+{
+    close();
+}
+
+inline bool SocketBase::is_open() const noexcept
+{
+    return m_desc.is_open();
+}
+
+inline auto SocketBase::native_handle() const noexcept -> native_handle_type
+{
+    return m_desc.native_handle();
+}
+
+inline void SocketBase::open(const StreamProtocol& prot)
+{
+    std::error_code ec;
+    if (open(prot, ec))
+        throw std::system_error(ec);
+}
+
+inline void SocketBase::close() noexcept
+{
+    if (!is_open())
+        return;
+    cancel();
+    m_desc.close();
+}
+
+template<class O>
+inline void SocketBase::get_option(O& opt) const
+{
+    std::error_code ec;
+    if (get_option(opt, ec))
+        throw std::system_error(ec);
+}
+
+template<class O>
+inline std::error_code SocketBase::get_option(O& opt, std::error_code& ec) const
+{
+    opt.get(*this, ec);
+    return ec;
+}
+
+template<class O>
+inline void SocketBase::set_option(const O& opt)
+{
+    std::error_code ec;
+    if (set_option(opt, ec))
+        throw std::system_error(ec);
+}
+
+template<class O>
+inline std::error_code SocketBase::set_option(const O& opt, std::error_code& ec)
+{
+    opt.set(*this, ec);
+    return ec;
+}
+
+inline void SocketBase::bind(const Endpoint& ep)
+{
+    std::error_code ec;
+    if (bind(ep, ec))
+        throw std::system_error(ec);
+}
+
+inline Endpoint SocketBase::local_endpoint() const
+{
+    std::error_code ec;
+    Endpoint ep = local_endpoint(ec);
+    if (ec)
+        throw std::system_error(ec);
+    return ep;
+}
+
+inline auto SocketBase::release_native_handle() noexcept -> native_handle_type
+{
+    if (is_open()) {
+        cancel();
+        return m_desc.release();
+    }
+    return m_desc.native_handle();
+}
+
+inline const StreamProtocol& SocketBase::get_protocol() const noexcept
+{
+    return m_protocol;
+}
+
+template<class T, int opt, class U>
+inline SocketBase::Option<T, opt, U>::Option(T init_value) :
+    m_value{init_value}
+{
+}
+
+template<class T, int opt, class U>
+inline T SocketBase::Option<T, opt, U>::value() const
+{
+    return m_value;
+}
+
+template<class T, int opt, class U>
+inline void SocketBase::Option<T, opt, U>::get(const SocketBase& sock, std::error_code& ec)
+{
+    union {
+        U value;
+        char strut[sizeof (U) + 1];
+    };
+    std::size_t value_size = sizeof strut;
+    sock.get_option(opt_enum(opt), &value, value_size, ec);
+    if (!ec) {
+        REALM_ASSERT(value_size == sizeof value);
+        m_value = T(value);
+    }
+}
+
+template<class T, int opt, class U>
+inline void SocketBase::Option<T, opt, U>::set(SocketBase& sock, std::error_code& ec) const
+{
+    U value_to_set = U(m_value);
+    sock.set_option(opt_enum(opt), &value_to_set, sizeof value_to_set, ec);
+}
+
+// ---------------- Socket ----------------
+
+class Socket::ConnectOperBase : public Service::IoOper {
+public:
+    ConnectOperBase(std::size_t size, Socket& sock) noexcept :
+        IoOper{size},
+        m_socket{&sock}
+    {
+    }
+    Want initiate(const Endpoint& ep)
+    {
+        REALM_ASSERT(this == m_socket->m_write_oper.get());
+        if (m_socket->initiate_async_connect(ep, m_error_code)) { // Throws
+            set_is_complete(true); // Failure, or immediate completion
+            return Want::nothing;
+        }
+        return Want::write;
+    }
+    Want advance() noexcept override final
+    {
+        REALM_ASSERT(!is_complete());
+        REALM_ASSERT(!is_canceled());
+        REALM_ASSERT(!m_error_code);
+        m_socket->finalize_async_connect(m_error_code);
+        set_is_complete(true);
+        return Want::nothing;
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_socket;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_socket = nullptr;
+    }
+    Service::Descriptor& descriptor() noexcept override final
+    {
+        return m_socket->m_desc;
+    }
+protected:
+    Socket* m_socket;
+    std::error_code m_error_code;
+};
+
+template<class H> class Socket::ConnectOper : public ConnectOperBase {
+public:
+    ConnectOper(std::size_t size, Socket& sock, H handler) :
+        ConnectOperBase{size, sock},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        REALM_ASSERT(is_complete() || (is_canceled() && !m_error_code));
+        bool orphaned = !m_socket;
+        std::error_code ec = m_error_code;
+        if (is_canceled())
+            ec = error::operation_aborted;
+        // Note: do_recycle_and_execute() commits suicide.
+        do_recycle_and_execute<H>(orphaned, m_handler, ec); // Throws
+    }
+private:
+    H m_handler;
+};
+
+inline Socket::Socket(Service& service) :
+    SocketBase{service}
+{
+}
+
+inline Socket::Socket(Service& service, const StreamProtocol& prot,
+                      native_handle_type native_socket) :
+    SocketBase{service}
+{
+    assign(prot, native_socket); // Throws
+}
+
+inline Socket::~Socket() noexcept
+{
+}
+
+inline void Socket::connect(const Endpoint& ep)
+{
+    std::error_code ec;
+    if (connect(ep, ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline std::size_t Socket::read(char* buffer, std::size_t size)
+{
+    std::error_code ec;
+    read(buffer, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return size;
+}
+
+inline std::size_t Socket::read(char* buffer, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::read(*this, buffer, size, ec); // Throws
+}
+
+inline std::size_t Socket::read(char* buffer, std::size_t size, ReadAheadBuffer& rab)
+{
+    std::error_code ec;
+    read(buffer, size, rab, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return size;
+}
+
+inline std::size_t Socket::read(char* buffer, std::size_t size, ReadAheadBuffer& rab,
+                                std::error_code& ec)
+{
+    int delim = std::char_traits<char>::eof();
+    return StreamOps::buffered_read(*this, buffer, size, delim, rab, ec); // Throws
+}
+
+inline std::size_t Socket::read_until(char* buffer, std::size_t size, char delim,
+                                      ReadAheadBuffer& rab)
+{
+    std::error_code ec;
+    std::size_t n = read_until(buffer, size, delim, rab, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return n;
+}
+
+inline std::size_t Socket::read_until(char* buffer, std::size_t size, char delim,
+                                      ReadAheadBuffer& rab, std::error_code& ec)
+{
+    int delim_2 = std::char_traits<char>::to_int_type(delim);
+    return StreamOps::buffered_read(*this, buffer, size, delim_2, rab, ec); // Throws
+}
+
+inline std::size_t Socket::write(const char* data, std::size_t size)
+{
+    std::error_code ec;
+    write(data, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return size;
+}
+
+inline std::size_t Socket::write(const char* data, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::write(*this, data, size, ec); // Throws
+}
+
+inline std::size_t Socket::read_some(char* buffer, std::size_t size)
+{
+    std::error_code ec;
+    std::size_t n = read_some(buffer, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return n;
+}
+
+inline std::size_t Socket::read_some(char* buffer, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::read_some(*this, buffer, size, ec); // Throws
+}
+
+inline std::size_t Socket::write_some(const char* data, std::size_t size)
+{
+    std::error_code ec;
+    std::size_t n = write_some(data, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return n;
+}
+
+inline std::size_t Socket::write_some(const char* data, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::write_some(*this, data, size, ec); // Throws
+}
+
+template<class H> inline void Socket::async_connect(const Endpoint& ep, H handler)
+{
+    LendersConnectOperPtr op =
+        Service::alloc<ConnectOper<H>>(m_write_oper, *this, std::move(handler)); // Throws
+    m_desc.initiate_oper(std::move(op), ep); // Throws
+}
+
+template<class H> inline void Socket::async_read(char* buffer, std::size_t size, H handler)
+{
+    bool is_read_some = false;
+    StreamOps::async_read(*this, buffer, size, is_read_some, std::move(handler)); // Throws
+}
+
+template<class H>
+inline void Socket::async_read(char* buffer, std::size_t size, ReadAheadBuffer& rab, H handler)
+{
+    int delim = std::char_traits<char>::eof();
+    StreamOps::async_buffered_read(*this, buffer, size, delim, rab, std::move(handler)); // Throws
+}
+
+template<class H>
+inline void Socket::async_read_until(char* buffer, std::size_t size, char delim,
+                                     ReadAheadBuffer& rab, H handler)
+{
+    int delim_2 = std::char_traits<char>::to_int_type(delim);
+    StreamOps::async_buffered_read(*this, buffer, size, delim_2, rab, std::move(handler)); // Throws
+}
+
+template<class H> inline void Socket::async_write(const char* data, std::size_t size, H handler)
+{
+    bool is_write_some = false;
+    StreamOps::async_write(*this, data, size, is_write_some, std::move(handler)); // Throws
+}
+
+template<class H> inline void Socket::async_read_some(char* buffer, std::size_t size, H handler)
+{
+    bool is_read_some = true;
+    StreamOps::async_read(*this, buffer, size, is_read_some, std::move(handler)); // Throws
+}
+
+template<class H>
+inline void Socket::async_write_some(const char* data, std::size_t size, H handler)
+{
+    bool is_write_some = true;
+    StreamOps::async_write(*this, data, size, is_write_some, std::move(handler)); // Throws
+}
+
+inline void Socket::shutdown(shutdown_type what)
+{
+    std::error_code ec;
+    if (shutdown(what, ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline void Socket::assign(const StreamProtocol& prot, native_handle_type native_socket)
+{
+    std::error_code ec;
+    if (assign(prot, native_socket, ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline std::error_code Socket::assign(const StreamProtocol& prot,
+                                      native_handle_type native_socket, std::error_code& ec)
+{
+    return do_assign(prot, native_socket, ec); // Throws
+}
+
+inline Socket& Socket::lowest_layer() noexcept
+{
+    return *this;
+}
+
+inline void Socket::do_init_read_async(std::error_code&, Want& want) noexcept
+{
+    want = Want::read; // Wait for read readiness before proceeding
+}
+
+inline void Socket::do_init_write_async(std::error_code&, Want& want) noexcept
+{
+    want = Want::write; // Wait for write readiness before proceeding
+}
+
+inline std::size_t Socket::do_read_some_sync(char* buffer, std::size_t size,
+                                             std::error_code& ec) noexcept
+{
+    return m_desc.read_some(buffer, size, ec);
+}
+
+inline std::size_t Socket::do_write_some_sync(const char* data, std::size_t size,
+                                              std::error_code& ec) noexcept
+{
+    return m_desc.write_some(data, size, ec);
+}
+
+inline std::size_t Socket::do_read_some_async(char* buffer, std::size_t size,
+                                              std::error_code& ec, Want& want) noexcept
+{
+    std::error_code ec_2;
+    std::size_t n = m_desc.read_some(buffer, size, ec_2);
+    bool success = (!ec_2 || ec_2 == error::resource_unavailable_try_again);
+    if (REALM_UNLIKELY(!success)) {
+        ec = ec_2;
+        want = Want::nothing; // Failure
+        return 0;
+    }
+    ec = std::error_code();
+    want = Want::read; // Success
+    return n;
+}
+
+inline std::size_t Socket::do_write_some_async(const char* data, std::size_t size,
+                                               std::error_code& ec, Want& want) noexcept
+{
+    std::error_code ec_2;
+    std::size_t n = m_desc.write_some(data, size, ec_2);
+    bool success = (!ec_2 || ec_2 == error::resource_unavailable_try_again);
+    if (REALM_UNLIKELY(!success)) {
+        ec = ec_2;
+        want = Want::nothing; // Failure
+        return 0;
+    }
+    ec = std::error_code();
+    want = Want::write; // Success
+    return n;
+}
+
+// ---------------- Acceptor ----------------
+
+class Acceptor::AcceptOperBase : public Service::IoOper {
+public:
+    AcceptOperBase(std::size_t size, Acceptor& a, Socket& s, Endpoint* e) :
+        IoOper{size},
+        m_acceptor{&a},
+        m_socket{s},
+        m_endpoint{e}
+    {
+    }
+    Want initiate()
+    {
+        REALM_ASSERT(this == m_acceptor->m_read_oper.get());
+        REALM_ASSERT(!is_complete());
+        m_acceptor->m_desc.ensure_nonblocking_mode(); // Throws
+        return Want::read;
+    }
+    Want advance() noexcept override final
+    {
+        REALM_ASSERT(!is_complete());
+        REALM_ASSERT(!is_canceled());
+        REALM_ASSERT(!m_error_code);
+        REALM_ASSERT(!m_socket.is_open());
+        Want want = m_acceptor->do_accept_async(m_socket, m_endpoint, m_error_code);
+        if (want == Want::nothing)
+            set_is_complete(true); // Success or failure
+        return want;
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_acceptor;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_acceptor = nullptr;
+    }
+    Service::Descriptor& descriptor() noexcept override final
+    {
+        return m_acceptor->m_desc;
+    }
+protected:
+    Acceptor* m_acceptor;
+    Socket& m_socket;           // May be dangling after cancellation
+    Endpoint* const m_endpoint; // May be dangling after cancellation
+    std::error_code m_error_code;
+};
+
+template<class H> class Acceptor::AcceptOper : public AcceptOperBase {
+public:
+    AcceptOper(std::size_t size, Acceptor& a, Socket& s, Endpoint* e, H handler) :
+        AcceptOperBase{size, a, s, e},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        REALM_ASSERT(is_complete() || (is_canceled() && !m_error_code));
+        REALM_ASSERT(is_canceled() || m_error_code || m_socket.is_open());
+        bool orphaned = !m_acceptor;
+        std::error_code ec = m_error_code;
+        if (is_canceled())
+            ec = error::operation_aborted;
+        // Note: do_recycle_and_execute() commits suicide.
+        do_recycle_and_execute<H>(orphaned, m_handler, ec); // Throws
+    }
+private:
+    H m_handler;
+};
+
+inline Acceptor::Acceptor(Service& service) :
+    SocketBase{service}
+{
+}
+
+inline Acceptor::~Acceptor() noexcept
+{
+}
+
+inline void Acceptor::listen(int backlog)
+{
+    std::error_code ec;
+    if (listen(backlog, ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline void Acceptor::accept(Socket& sock)
+{
+    std::error_code ec;
+    if (accept(sock, ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline void Acceptor::accept(Socket& sock, Endpoint& ep)
+{
+    std::error_code ec;
+    if (accept(sock, ep, ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline std::error_code Acceptor::accept(Socket& sock, std::error_code& ec)
+{
+    Endpoint* ep = nullptr;
+    return accept(sock, ep, ec); // Throws
+}
+
+inline std::error_code Acceptor::accept(Socket& sock, Endpoint& ep, std::error_code& ec)
+{
+    return accept(sock, &ep, ec); // Throws
+}
+
+template<class H> inline void Acceptor::async_accept(Socket& sock, H handler)
+{
+    Endpoint* ep = nullptr;
+    async_accept(sock, ep, std::move(handler)); // Throws
+}
+
+template<class H> inline void Acceptor::async_accept(Socket& sock, Endpoint& ep, H handler)
+{
+    async_accept(sock, &ep, std::move(handler)); // Throws
+}
+
+inline std::error_code Acceptor::accept(Socket& socket, Endpoint* ep, std::error_code& ec)
+{
+    REALM_ASSERT(!m_read_oper || !m_read_oper->in_use());
+    if (REALM_UNLIKELY(socket.is_open()))
+        throw util::runtime_error("Socket is already open");
+    m_desc.ensure_blocking_mode(); // Throws
+    m_desc.accept(socket.m_desc, m_protocol, ep, ec);
+    return ec;
+}
+
+inline Acceptor::Want Acceptor::do_accept_async(Socket& socket, Endpoint* ep,
+                                                std::error_code& ec) noexcept
+{
+    std::error_code ec_2;
+    m_desc.accept(socket.m_desc, m_protocol, ep, ec_2);
+    if (ec_2 == error::resource_unavailable_try_again)
+        return Want::read;
+    ec = ec_2;
+    return Want::nothing;
+}
+
+template<class H> inline void Acceptor::async_accept(Socket& sock, Endpoint* ep, H handler)
+{
+    if (REALM_UNLIKELY(sock.is_open()))
+        throw util::runtime_error("Socket is already open");
+    LendersAcceptOperPtr op = Service::alloc<AcceptOper<H>>(m_read_oper, *this, sock, ep,
+                                                            std::move(handler)); // Throws
+    m_desc.initiate_oper(std::move(op)); // Throws
+}
+
+// ---------------- DeadlineTimer ----------------
+
+template<class H>
+class DeadlineTimer::WaitOper : public Service::WaitOperBase {
+public:
+    WaitOper(std::size_t size, DeadlineTimer& timer, clock::time_point expiration_time,
+             H handler) :
+        Service::WaitOperBase{size, timer, expiration_time},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        bool orphaned = !m_timer;
+        std::error_code ec;
+        if (is_canceled())
+            ec = error::operation_aborted;
+        // Note: do_recycle_and_execute() commits suicide.
+        do_recycle_and_execute<H>(orphaned, m_handler, ec); // Throws
+    }
+private:
+    H m_handler;
+};
+
+inline DeadlineTimer::DeadlineTimer(Service& service) :
+    m_service_impl{*service.m_impl}
+{
+}
+
+inline DeadlineTimer::~DeadlineTimer() noexcept
+{
+    cancel();
+}
+
+template<class R, class P, class H>
+inline void DeadlineTimer::async_wait(std::chrono::duration<R,P> delay, H handler)
+{
+    clock::time_point now = clock::now();
+    // FIXME: This method of detecting overflow does not work. Comparison
+    // between distinct duration types is not overflow safe. Overflow easily
+    // happens in the implied conversion of arguments to the common duration
+    // type (std::common_type<>).
+    auto max_add = clock::time_point::max() - now;
+    if (delay > max_add)
+        throw util::overflow_error("Expiration time overflow");
+    clock::time_point expiration_time = now + delay;
+    Service::LendersWaitOperPtr op =
+        Service::alloc<WaitOper<H>>(m_wait_oper, *this, expiration_time,
+                                    std::move(handler)); // Throws
+    initiate_oper(std::move(op)); // Throws
+}
+
+// ---------------- Trigger ----------------
+
+template<class H>
+class Trigger::ExecOper : public Service::TriggerExecOperBase {
+public:
+    ExecOper(Service::Impl& service_impl, H handler) :
+        Service::TriggerExecOperBase{service_impl},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        REALM_ASSERT(in_use());
+        // Note: Potential suicide when `self` goes out of scope
+        util::bind_ptr<TriggerExecOperBase> self{this, bind_ptr_base::adopt_tag{}};
+        if (m_service) {
+            Service::reset_trigger_exec(*m_service, *this);
+            m_handler(); // Throws
+        }
+    }
+private:
+    H m_handler;
+};
+
+template<class H> inline Trigger::Trigger(Service& service, H handler) :
+    m_exec_oper{new ExecOper<H>{*service.m_impl, std::move(handler)}} // Throws
+{
+}
+
+inline Trigger::~Trigger() noexcept
+{
+    if (m_exec_oper)
+        m_exec_oper->orphan();
+}
+
+inline void Trigger::trigger() noexcept
+{
+    REALM_ASSERT(m_exec_oper);
+    m_exec_oper->trigger();
+}
+
+// ---------------- ReadAheadBuffer ----------------
+
+inline ReadAheadBuffer::ReadAheadBuffer() :
+    m_buffer{new char[s_size]} // Throws
+{
+}
+
+inline void ReadAheadBuffer::clear() noexcept
+{
+    m_begin = nullptr;
+    m_end   = nullptr;
+}
+
+inline bool ReadAheadBuffer::empty() const noexcept
+{
+    return (m_begin == m_end);
+}
+
+template<class S> inline void ReadAheadBuffer::refill_sync(S& stream, std::error_code& ec) noexcept
+{
+    char* buffer = m_buffer.get();
+    std::size_t size = s_size;
+    static_assert(noexcept(stream.do_read_some_sync(buffer, size, ec)), "");
+    std::size_t n = stream.do_read_some_sync(buffer, size, ec);
+    if (REALM_UNLIKELY(n == 0))
+        return;
+    REALM_ASSERT(!ec);
+    REALM_ASSERT(n <= size);
+    m_begin = m_buffer.get();
+    m_end   = m_begin + n;
+}
+
+template<class S>
+inline bool ReadAheadBuffer::refill_async(S& stream, std::error_code& ec, Want& want) noexcept
+{
+    char* buffer = m_buffer.get();
+    std::size_t size = s_size;
+    static_assert(noexcept(stream.do_read_some_async(buffer, size, ec, want)), "");
+    std::size_t n = stream.do_read_some_async(buffer, size, ec, want);
+    if (n == 0)
+        return false;
+    REALM_ASSERT(!ec);
+    REALM_ASSERT(n <= size);
+    m_begin = m_buffer.get();
+    m_end   = m_begin + n;
+    return true;
+}
+
+} // namespace network
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_NETWORK_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/network_ssl.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/network_ssl.hpp
new file mode 100644
index 0000000..3284bf8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/network_ssl.hpp
@@ -0,0 +1,1378 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_NETWORK_SSL_HPP
+#define REALM_UTIL_NETWORK_SSL_HPP
+
+#include <cstddef>
+#include <limits>
+#include <memory>
+#include <string>
+#include <exception>
+#include <system_error>
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/misc_errors.hpp>
+#include <realm/util/network.hpp>
+#include <realm/util/optional.hpp>
+#include <realm/util/logger.hpp>
+
+#if REALM_HAVE_OPENSSL
+#  include <openssl/ssl.h>
+#  include <openssl/err.h>
+#elif REALM_HAVE_SECURE_TRANSPORT
+#  include <realm/util/cf_ptr.hpp>
+#  include <Security/Security.h>
+#  include <Security/SecureTransport.h>
+
+#define REALM_HAVE_KEYCHAIN_APIS (TARGET_OS_MAC && !TARGET_OS_IPHONE)
+
+#endif
+
+// FIXME: Add necessary support for customizing the SSL server and client
+// configurations.
+
+// FIXME: Currently, the synchronous SSL operations (handshake, read, write,
+// shutdown) do not automatically retry if the underlying SSL function returns
+// with SSL_ERROR_WANT_READ or SSL_ERROR_WANT_WRITE. This normally never
+// happens, but it can happen according to the man pages, but in the case of
+// SSL_write(), only when a renegotiation has to take place. It is likely that
+// the solution is to to wrap the SSL calls inside a loop, such that they keep
+// retrying until they succeed, however, such a simple scheme will fail if the
+// synchronous operations were to be used with an underlying TCP socket in
+// nonblocking mode. Currently, the underlying TCP socket is always in blocking
+// mode when performing synchronous operations, but that may continue to be the
+// case in teh future.
+
+
+namespace realm {
+namespace util {
+namespace network {
+namespace ssl {
+
+enum class Errors {
+    certificate_rejected = 1,
+};
+
+class ErrorCategory : public std::error_category {
+public:
+    const char* name() const noexcept override final;
+    std::string message(int) const override final;
+    bool equivalent(const std::error_code&, int) const noexcept override final;
+};
+
+/// The error category associated with \ref Errors. The name of this category is
+/// `realm.util.network.ssl`.
+extern ErrorCategory error_category;
+
+inline std::error_code make_error_code(Errors err)
+{
+    return std::error_code(int(err), error_category);
+}
+
+inline std::error_condition make_error_condition(Errors err)
+{
+    return std::error_condition(int(err), error_category);
+}
+
+} // namespace ssl
+} // namespace network
+} // namespace util
+} // namespace realm
+
+namespace std {
+
+template<> class is_error_condition_enum<realm::util::network::ssl::Errors> {
+public:
+    static const bool value = true;
+};
+
+} // namespace std
+
+namespace realm {
+namespace util {
+namespace network {
+
+class OpensslErrorCategory : public std::error_category {
+public:
+    const char* name() const noexcept override final;
+    std::string message(int) const override final;
+};
+
+/// The error category associated with error codes produced by the third-party
+/// library, OpenSSL. The name of this category is `openssl`.
+extern OpensslErrorCategory openssl_error_category;
+
+class SecureTransportErrorCategory : public std::error_category {
+public:
+    const char* name() const noexcept override final;
+    std::string message(int) const override final;
+};
+
+/// The error category associated with error codes produced by Apple's
+/// SecureTransport library. The name of this category is `securetransport`.
+extern SecureTransportErrorCategory secure_transport_error_category;
+
+
+namespace ssl {
+
+class ProtocolNotSupported;
+
+
+/// `VerifyMode::none` corresponds to OpenSSL's `SSL_VERIFY_NONE`, and
+/// `VerifyMode::peer` to `SSL_VERIFY_PEER`.
+enum class VerifyMode { none, peer };
+
+
+class Context {
+public:
+    Context();
+    ~Context() noexcept;
+
+    /// File must be in PEM format. Corresponds to OpenSSL's
+    /// `SSL_CTX_use_certificate_chain_file()`.
+    void use_certificate_chain_file(const std::string& path);
+
+    /// File must be in PEM format. Corresponds to OpenSSL's
+    /// `SSL_CTX_use_PrivateKey_file()`.
+    void use_private_key_file(const std::string& path);
+
+    /// Calling use_default_verify() will make a client use the device
+    /// default certificates for server verification. For OpenSSL,
+    /// use_default_verify() corresponds to
+    /// SSL_CTX_set_default_verify_paths(SSL_CTX*);
+    void use_default_verify();
+
+    /// The verify file is a PEM file containing trust certificates that the
+    /// client will use to verify the server certificate. If use_verify_file()
+    /// is not called, the default device trust store will be used.
+    /// use_verify_file() corresponds roughly to OpenSSL's
+    /// SSL_CTX_load_verify_locations().
+    void use_verify_file(const std::string& path);
+
+private:
+    void ssl_init();
+    void ssl_destroy() noexcept;
+    void ssl_use_certificate_chain_file(const std::string& path, std::error_code&);
+    void ssl_use_private_key_file(const std::string& path, std::error_code&);
+    void ssl_use_default_verify(std::error_code&);
+    void ssl_use_verify_file(const std::string& path, std::error_code&);
+
+#if REALM_HAVE_OPENSSL
+    SSL_CTX* m_ssl_ctx = nullptr;
+
+#elif REALM_HAVE_SECURE_TRANSPORT
+
+#if REALM_HAVE_KEYCHAIN_APIS
+    std::error_code open_temporary_keychain_if_needed();
+    std::error_code update_identity_if_needed();
+
+    util::CFPtr<SecKeychainRef> m_keychain;
+    std::string m_keychain_path;
+
+    util::CFPtr<SecCertificateRef> m_certificate;
+    util::CFPtr<SecKeyRef> m_private_key;
+    util::CFPtr<SecIdentityRef> m_identity;
+
+    util::CFPtr<CFArrayRef> m_certificate_chain;
+
+#else
+    using SecKeychainRef = std::nullptr_t;
+
+#endif // REALM_HAVE_KEYCHAIN_APIS
+    static util::CFPtr<CFArrayRef> load_pem_file(const std::string& path, SecKeychainRef, std::error_code&);
+
+    util::CFPtr<CFArrayRef> m_trust_anchors;
+    util::CFPtr<CFDataRef> m_pinned_certificate;
+
+#endif
+
+    friend class Stream;
+};
+
+
+/// Switching between synchronous and asynchronous operations is allowed, but
+/// only in a nonoverlapping fashion. That is, a synchronous operation is not
+/// allowed to run concurrently with an asynchronous one on the same
+/// stream. Note that an asynchronous operation is considered to be running
+/// until its completion handler starts executing.
+class Stream {
+public:
+    using port_type = util::network::Endpoint::port_type;
+    using SSLVerifyCallback = bool(const std::string& server_address,
+                                   port_type server_port,
+                                   const char* pem_data,
+                                   size_t pem_size,
+                                   int preverify_ok,
+                                   int depth);
+
+    enum HandshakeType { client, server };
+
+    util::Logger* logger = nullptr;
+
+    Stream(Socket&, Context&, HandshakeType);
+    ~Stream() noexcept;
+
+    /// \brief set_logger() set a logger for the stream class. If
+    /// set_logger() is not called, no logging will take place by
+    /// the Stream class.
+    void set_logger(util::Logger*);
+
+    /// \brief Set the certificate verification mode for this SSL stream.
+    ///
+    /// Corresponds to OpenSSL's `SSL_set_verify()` with null passed as
+    /// `verify_callback`.
+    ///
+    /// Clients should always set it to `VerifyMode::peer`, such that the client
+    /// verifies the servers certificate. Servers should only set it to
+    /// `VerifyMode::peer` if they want to request a certificate from the
+    /// client. When testing with self-signed certificates, it is necessary to
+    /// set it to `VerifyMode::none` for clients too.
+    ///
+    /// It is an error if this function is called after the handshake operation
+    /// is initiated.
+    ///
+    /// The default verify mode is `VerifyMode::none`.
+    void set_verify_mode(VerifyMode);
+
+    /// \brief Check the certificate against a host_name.
+    ///
+    /// set_check_host() includes a host name check in the
+    /// certificate verification. It is typically used by clients
+    /// to secure that the received certificate has a common name
+    /// or subject alternative name that matches \param host_name.
+    ///
+    /// set_check_host() is only useful if verify_mode is
+    /// set to VerifyMode::peer.
+    void set_check_host(std::string host_name);
+    const std::string& get_host_name();
+
+    /// get_server_port() and set_server_port() are getter and setter for
+    /// the server port. They are only used by the verify callback function
+    /// below.
+    port_type get_server_port();
+    void set_server_port(port_type server_port);
+
+    /// If use_verify_callback() is called, the SSL certificate chain of
+    /// the server is presented to callback, one certificate at a time.
+    /// The SSL connection is accepted if and only if callback returns true
+    /// for all certificates.
+    /// The signature of \param callback is
+    ///
+    /// bool(const std::string& server_address,
+    ///      port_type server_port,
+    ///      const char* pem_data,
+    ///      size_t pem_size,
+    ///      int preverify_ok,
+    ///      int depth);
+    //
+    /// server address and server_port is the address and port of the server
+    /// that a SSL connection is being established to.
+    /// pem_data is the certificate of length pem_size in
+    /// the PEM format. preverify_ok is OpenSSL's preverification of the
+    /// certificate. preverify_ok is either 0, or 1. If preverify_ok is 1,
+    /// OpenSSL has accepted the certificate and it will generally be safe
+    /// to trust that certificate. depth represents the position of the
+    /// certificate in the certificate chain sent by the server. depth = 0
+    /// represents the actual server certificate that should contain the
+    /// host name(server address) of the server. The highest depth is the
+    /// root certificate.
+    /// The callback function will receive the certificates starting from
+    /// the root certificate and moving down the chain until it reaches the
+    /// server's own certificate with a host name. The depth of the last
+    /// certificate is 0. The depth of the first certificate is chain
+    /// length - 1.
+    ///
+    /// The return value of the callback function decides whether the
+    /// client accepts the certificate. If the return value is false, the
+    /// processing of the certificate chain is interrupted and the SSL
+    /// connection is rejected. If the return value is true, the verification
+    /// process continues. If the callback function returns true for all
+    /// presented certificates including the depth == 0 certificate, the
+    /// SSL connection is accepted.
+    ///
+    /// A recommended way of using the callback function is to return true
+    /// if preverify_ok = 1 and depth > 0,
+    /// always check the host name if depth = 0,
+    /// and use an independent verification step if preverify_ok = 0.
+    ///
+    /// Another possible way of using the callback is to collect all the
+    /// certificates until depth = 0, and present the entire chain for
+    /// independent verification.
+    void use_verify_callback(const std::function<SSLVerifyCallback>& callback);
+
+#ifdef REALM_INCLUDE_CERTS
+    /// use_included_certificates() loads a set of certificates that are
+    /// included in the header file src/realm/noinst/root_certs.hpp. By using
+    /// the included certificates, the client can verify a server in the case
+    /// where the relevant certificate cannot be found, or is absent, in the
+    /// system trust store. This function is only implemented for OpenSSL.
+    void use_included_certificates();
+#endif
+
+    /// @{
+    ///
+    /// Read and write operations behave the same way as they do on \ref
+    /// network::Socket, except that after cancellation of asynchronous
+    /// operations (`lowest_layer().cancel()`), the stream may be left in a bad
+    /// state (see below).
+    ///
+    /// The handshake operation must complete successfully before any read,
+    /// write, or shutdown operations are performed.
+    ///
+    /// The shutdown operation sends the shutdown alert to the peer, and
+    /// returns/completes as soon as the alert message has been written to the
+    /// underlying socket. It is an error if the shutdown operation is initiated
+    /// while there are read or write operations in progress. No read or write
+    /// operations are allowed to be initiated after the shutdown operation has
+    /// been initiated. When the shutdown operation has completed, it is safe to
+    /// close the underlying socket (`lowest_layer().close()`).
+    ///
+    /// If a write operation is executing while, or is initiated after a close
+    /// notify alert is received from the remote peer, the write operation will
+    /// fail with error::broken_pipe.
+    ///
+    /// Callback functions for async read and write operations must take two
+    /// arguments, an std::error_code(), and an integer of a type std::size_t
+    /// indicating the number of transferred bytes (other types are allowed as
+    /// long as implicit conversion can take place).
+    ///
+    /// Callback functions for async handshake and shutdown operations must take
+    /// a single argument of type std::error_code() (other types are allowed as
+    /// long as implicit conversion can take place).
+    ///
+    /// Resumption of stream operation after cancellation of asynchronous
+    /// operations is not supported (does not work). Since the shutdown
+    /// operation involves network communication, that operation is also not
+    /// allowed after cancellation. The only thing that is allowed, is to
+    /// destroy the stream object. Other stream objects are not affected.
+
+    void handshake();
+    std::error_code handshake(std::error_code&);
+
+    std::size_t read(char* buffer, std::size_t size);
+    std::size_t read(char* buffer, std::size_t size, std::error_code& ec);
+    std::size_t read(char* buffer, std::size_t size, ReadAheadBuffer&);
+    std::size_t read(char* buffer, std::size_t size, ReadAheadBuffer&, std::error_code& ec);
+    std::size_t read_until(char* buffer, std::size_t size, char delim, ReadAheadBuffer&);
+    std::size_t read_until(char* buffer, std::size_t size, char delim, ReadAheadBuffer&,
+                           std::error_code& ec);
+
+    std::size_t write(const char* data, std::size_t size);
+    std::size_t write(const char* data, std::size_t size, std::error_code& ec);
+
+    std::size_t read_some(char* buffer, std::size_t size);
+    std::size_t read_some(char* buffer, std::size_t size, std::error_code&);
+
+    std::size_t write_some(const char* data, std::size_t size);
+    std::size_t write_some(const char* data, std::size_t size, std::error_code&);
+
+    void shutdown();
+    std::error_code shutdown(std::error_code&);
+
+    template<class H> void async_handshake(H handler);
+
+    template<class H> void async_read(char* buffer, std::size_t size, H handler);
+    template<class H> void async_read(char* buffer, std::size_t size, ReadAheadBuffer&, H handler);
+    template<class H> void async_read_until(char* buffer, std::size_t size, char delim,
+                                            ReadAheadBuffer&, H handler);
+
+    template<class H> void async_write(const char* data, std::size_t size, H handler);
+
+    template<class H> void async_read_some(char* buffer, std::size_t size, H handler);
+
+    template<class H> void async_write_some(const char* data, std::size_t size, H handler);
+
+    template<class H> void async_shutdown(H handler);
+
+    /// @}
+
+    /// Returns a reference to the underlying socket.
+    Socket& lowest_layer() noexcept;
+
+private:
+    using Want = Service::Want;
+    using StreamOps = Service::BasicStreamOps<Stream>;
+
+    class HandshakeOperBase;
+    template<class H> class HandshakeOper;
+    class ShutdownOperBase;
+    template<class H> class ShutdownOper;
+
+    using LendersHandshakeOperPtr = std::unique_ptr<HandshakeOperBase, Service::LendersOperDeleter>;
+    using LendersShutdownOperPtr  = std::unique_ptr<ShutdownOperBase,  Service::LendersOperDeleter>;
+
+    Socket& m_tcp_socket;
+    Context& m_ssl_context;
+    const HandshakeType m_handshake_type;
+
+    // The host name that the certificate should be checked against.
+    // The host name is called server address in the certificate verify
+    // callback function.
+    std::string m_host_name;
+
+    // The port of the server which is used in the certificate verify
+    // callback function.
+    port_type m_server_port;
+
+    // The callback for certificate verification and an
+    // opaque argument that will be supplied to the callback.
+    const std::function<SSLVerifyCallback>* m_ssl_verify_callback = nullptr;
+
+    bool m_valid_certificate_in_chain = false;
+
+
+    // See Service::BasicStreamOps for details on these these 6 functions.
+    void do_init_read_async(std::error_code&, Want&) noexcept;
+    void do_init_write_async(std::error_code&, Want&) noexcept;
+    std::size_t do_read_some_sync(char* buffer, std::size_t size,
+                                  std::error_code&) noexcept;
+    std::size_t do_write_some_sync(const char* data, std::size_t size,
+                                   std::error_code&) noexcept;
+    std::size_t do_read_some_async(char* buffer, std::size_t size,
+                                   std::error_code&, Want&) noexcept;
+    std::size_t do_write_some_async(const char* data, std::size_t size,
+                                    std::error_code&, Want&) noexcept;
+
+    // The meaning of the arguments and return values of ssl_read() and
+    // ssl_write() are identical to do_read_some_async() and
+    // do_write_some_async() respectively, except that when the return value is
+    // nonzero, `want` is always `Want::nothing`, meaning that after bytes have
+    // been transferred, ssl_read() and ssl_write() must be called again to
+    // figure out whether it is necessary to wait for read or write readiness.
+    //
+    // The first invocation of ssl_shutdown() must send the shutdown alert to
+    // the peer. In blocking mode it must wait until the alert has been sent. In
+    // nonblocking mode, it must keep setting `want` to something other than
+    // `Want::nothing` until the alert has been sent. When the shutdown alert
+    // has been sent, it is safe to shut down the sending side of the underlying
+    // socket. On failure, ssl_shutdown() must set `ec` to something different
+    // than `std::error_code()` and return false. On success, it must set `ec`
+    // to `std::error_code()`, and return true if a shutdown alert from the peer
+    // has already been received, otherwise it must return false. When it sets
+    // `want` to something other than `Want::nothing`, it must set `ec` to
+    // `std::error_code()` and return false.
+    //
+    // The second invocation of ssl_shutdown() (after the first invocation
+    // completed) must wait for reception on the peers shutdown alert.
+    //
+    // Note: The semantics around the second invocation of shutdown is currently
+    // unused by the higher level API, because of a requirement of compatibility
+    // with Apple's Secure Transport API.
+    void ssl_init();
+    void ssl_destroy() noexcept;
+    void ssl_set_verify_mode(VerifyMode, std::error_code&);
+    void ssl_set_check_host(std::string, std::error_code&);
+    void ssl_use_verify_callback(const std::function<SSLVerifyCallback>&, std::error_code&);
+    void ssl_use_included_certificates(std::error_code&);
+
+    void ssl_handshake(std::error_code&, Want& want) noexcept;
+    bool ssl_shutdown(std::error_code& ec, Want& want) noexcept;
+    std::size_t ssl_read(char* buffer, std::size_t size,
+                         std::error_code&, Want& want) noexcept;
+    std::size_t ssl_write(const char* data, std::size_t size,
+                          std::error_code&, Want& want) noexcept;
+
+#if REALM_HAVE_OPENSSL
+    class BioMethod;
+    static BioMethod s_bio_method;
+    SSL* m_ssl = nullptr;
+    std::error_code m_bio_error_code;
+
+    int m_ssl_index = -1;
+
+    template<class Oper>
+    std::size_t ssl_perform(Oper oper, std::error_code& ec, Want& want) noexcept;
+
+    int do_ssl_accept() noexcept;
+    int do_ssl_connect() noexcept;
+    int do_ssl_shutdown() noexcept;
+    int do_ssl_read(char* buffer, std::size_t size) noexcept;
+    int do_ssl_write(const char* data, std::size_t size) noexcept;
+
+    static int bio_write(BIO*, const char*, int) noexcept;
+    static int bio_read(BIO*, char*, int) noexcept;
+    static int bio_puts(BIO*, const char*) noexcept;
+    static long bio_ctrl(BIO*, int, long, void*) noexcept;
+    static int bio_create(BIO*) noexcept;
+    static int bio_destroy(BIO*) noexcept;
+
+    // verify_callback_using_hostname is used as an argument to OpenSSL's SSL_set_verify function.
+    // verify_callback_using_hostname verifies that the certificate is valid and contains
+    // m_host_name as a Common Name or Subject Alternative Name.
+    static int verify_callback_using_hostname(int preverify_ok, X509_STORE_CTX *ctx) noexcept;
+
+    // verify_callback_using_delegate() is also used as an argument to OpenSSL's set_verify_function.
+    // verify_callback_using_delegate() calls out to the user supplied verify callback.
+    static int verify_callback_using_delegate(int preverify_ok, X509_STORE_CTX *ctx) noexcept;
+
+    // verify_callback_using_root_certs is used by OpenSSL to handle certificate verification
+    // using the included root certifictes.
+    static int verify_callback_using_root_certs(int preverify_ok, X509_STORE_CTX *ctx);
+#elif REALM_HAVE_SECURE_TRANSPORT
+    util::CFPtr<SSLContextRef> m_ssl;
+    VerifyMode m_verify_mode = VerifyMode::none;
+
+    enum class BlockingOperation {
+        read,
+        write,
+    };
+    util::Optional<BlockingOperation> m_last_operation;
+
+    // Details of the underlying I/O error that lead to errSecIO being returned
+    // from a SecureTransport function.
+    std::error_code m_last_error;
+
+    // The number of bytes accepted by SSWrite() but not yet confirmed to be
+    // written to the underlying socket.
+    std::size_t m_num_partially_written_bytes = 0;
+
+    template<class Oper>
+    std::size_t ssl_perform(Oper oper, std::error_code& ec, Want& want) noexcept;
+
+    std::pair<OSStatus, std::size_t> do_ssl_handshake() noexcept;
+    std::pair<OSStatus, std::size_t> do_ssl_shutdown() noexcept;
+    std::pair<OSStatus, std::size_t> do_ssl_read(char* buffer, std::size_t size) noexcept;
+    std::pair<OSStatus, std::size_t> do_ssl_write(const char* data, std::size_t size) noexcept;
+
+    static OSStatus tcp_read(SSLConnectionRef, void*, std::size_t* length) noexcept;
+    static OSStatus tcp_write(SSLConnectionRef, const void*, std::size_t* length) noexcept;
+
+    OSStatus tcp_read(void*, std::size_t* length) noexcept;
+    OSStatus tcp_write(const void*, std::size_t* length) noexcept;
+
+    OSStatus verify_peer() noexcept;
+#endif
+
+    friend class Service::BasicStreamOps<Stream>;
+    friend class network::ReadAheadBuffer;
+};
+
+
+// Implementation
+
+class ProtocolNotSupported : public std::exception {
+public:
+    const char* what() const noexcept override final;
+};
+
+inline Context::Context()
+{
+    ssl_init(); // Throws
+}
+
+inline Context::~Context() noexcept
+{
+    ssl_destroy();
+}
+
+inline void Context::use_certificate_chain_file(const std::string& path)
+{
+    std::error_code ec;
+    ssl_use_certificate_chain_file(path, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+}
+
+inline void Context::use_private_key_file(const std::string& path)
+{
+    std::error_code ec;
+    ssl_use_private_key_file(path, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+}
+
+inline void Context::use_default_verify()
+{
+    std::error_code ec;
+    ssl_use_default_verify(ec);
+    if (ec)
+        throw std::system_error(ec);
+}
+
+inline void Context::use_verify_file(const std::string& path)
+{
+    std::error_code ec;
+    ssl_use_verify_file(path, ec);
+    if (ec) {
+        throw std::system_error(ec);
+    }
+}
+
+class Stream::HandshakeOperBase : public Service::IoOper {
+public:
+    HandshakeOperBase(std::size_t size, Stream& stream) :
+        IoOper{size},
+        m_stream{&stream}
+    {
+    }
+    Want initiate()
+    {
+        REALM_ASSERT(this == m_stream->m_tcp_socket.m_read_oper.get());
+        REALM_ASSERT(!is_complete());
+        m_stream->m_tcp_socket.m_desc.ensure_nonblocking_mode(); // Throws
+        return advance();
+    }
+    Want advance() noexcept override final
+    {
+        REALM_ASSERT(!is_complete());
+        REALM_ASSERT(!is_canceled());
+        REALM_ASSERT(!m_error_code);
+        Want want = Want::nothing;
+        m_stream->ssl_handshake(m_error_code, want);
+        set_is_complete(want == Want::nothing);
+        return want;
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_stream;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_stream = nullptr;
+    }
+    Service::Descriptor& descriptor() noexcept override final
+    {
+        return m_stream->lowest_layer().m_desc;
+    }
+protected:
+    Stream* m_stream;
+    std::error_code m_error_code;
+};
+
+template<class H> class Stream::HandshakeOper : public HandshakeOperBase {
+public:
+    HandshakeOper(std::size_t size, Stream& stream, H handler) :
+        HandshakeOperBase{size, stream},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        REALM_ASSERT(is_complete() || is_canceled());
+        bool orphaned = !m_stream;
+        std::error_code ec = m_error_code;
+        if (is_canceled())
+            ec = error::operation_aborted;
+        // Note: do_recycle_and_execute() commits suicide.
+        do_recycle_and_execute<H>(orphaned, m_handler, ec); // Throws
+    }
+private:
+    H m_handler;
+};
+
+class Stream::ShutdownOperBase : public Service::IoOper {
+public:
+    ShutdownOperBase(std::size_t size, Stream& stream) :
+        IoOper{size},
+        m_stream{&stream}
+    {
+    }
+    Want initiate()
+    {
+        REALM_ASSERT(this == m_stream->m_tcp_socket.m_write_oper.get());
+        REALM_ASSERT(!is_complete());
+        m_stream->m_tcp_socket.m_desc.ensure_nonblocking_mode(); // Throws
+        return advance();
+    }
+    Want advance() noexcept override final
+    {
+        REALM_ASSERT(!is_complete());
+        REALM_ASSERT(!is_canceled());
+        REALM_ASSERT(!m_error_code);
+        Want want = Want::nothing;
+        m_stream->ssl_shutdown(m_error_code, want);
+        if (want == Want::nothing)
+            set_is_complete(true);
+        return want;
+    }
+    void recycle() noexcept override final
+    {
+        bool orphaned = !m_stream;
+        REALM_ASSERT(orphaned);
+        // Note: do_recycle() commits suicide.
+        do_recycle(orphaned);
+    }
+    void orphan() noexcept override final
+    {
+        m_stream = nullptr;
+    }
+    Service::Descriptor& descriptor() noexcept override final
+    {
+        return m_stream->lowest_layer().m_desc;
+    }
+protected:
+    Stream* m_stream;
+    std::error_code m_error_code;
+};
+
+template<class H> class Stream::ShutdownOper : public ShutdownOperBase {
+public:
+    ShutdownOper(std::size_t size, Stream& stream, H handler) :
+        ShutdownOperBase{size, stream},
+        m_handler{std::move(handler)}
+    {
+    }
+    void recycle_and_execute() override final
+    {
+        REALM_ASSERT(is_complete() || is_canceled());
+        bool orphaned = !m_stream;
+        std::error_code ec = m_error_code;
+        if (is_canceled())
+            ec = error::operation_aborted;
+        // Note: do_recycle_and_execute() commits suicide.
+        do_recycle_and_execute<H>(orphaned, m_handler, ec); // Throws
+    }
+private:
+    H m_handler;
+};
+
+inline Stream::Stream(Socket& socket, Context& context, HandshakeType type) :
+    m_tcp_socket{socket},
+    m_ssl_context{context},
+    m_handshake_type{type}
+{
+    ssl_init(); // Throws
+}
+
+inline Stream::~Stream() noexcept
+{
+    m_tcp_socket.cancel();
+    ssl_destroy();
+}
+
+inline void Stream::set_logger(util::Logger* logger)
+{
+    this->logger = logger;
+}
+
+inline void Stream::set_verify_mode(VerifyMode mode)
+{
+    std::error_code ec;
+    ssl_set_verify_mode(mode, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+}
+
+inline void Stream::set_check_host(std::string host_name)
+{
+    m_host_name = host_name;
+    std::error_code ec;
+    ssl_set_check_host(host_name, ec);
+    if (ec)
+        throw std::system_error(ec);
+}
+
+inline const std::string& Stream::get_host_name()
+{
+    return m_host_name;
+}
+
+inline Stream::port_type Stream::get_server_port()
+{
+    return m_server_port;
+}
+
+inline void Stream::set_server_port(port_type server_port)
+{
+    m_server_port = server_port;
+}
+
+inline void Stream::use_verify_callback(const std::function<SSLVerifyCallback>& callback)
+{
+    std::error_code ec;
+    ssl_use_verify_callback(callback, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+}
+
+#ifdef REALM_INCLUDE_CERTS
+inline void Stream::use_included_certificates()
+{
+    std::error_code ec;
+    ssl_use_included_certificates(ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+}
+#endif
+
+inline void Stream::handshake()
+{
+    std::error_code ec;
+    if (handshake(ec)) // Throws
+        throw std::system_error(ec);
+}
+
+inline std::size_t Stream::read(char* buffer, std::size_t size)
+{
+    std::error_code ec;
+    read(buffer, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return size;
+}
+
+inline std::size_t Stream::read(char* buffer, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::read(*this, buffer, size, ec); // Throws
+}
+
+inline std::size_t Stream::read(char* buffer, std::size_t size, ReadAheadBuffer& rab)
+{
+    std::error_code ec;
+    read(buffer, size, rab, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return size;
+}
+
+inline std::size_t Stream::read(char* buffer, std::size_t size, ReadAheadBuffer& rab,
+                                std::error_code& ec)
+{
+    int delim = std::char_traits<char>::eof();
+    return StreamOps::buffered_read(*this, buffer, size, delim, rab, ec); // Throws
+}
+
+inline std::size_t Stream::read_until(char* buffer, std::size_t size, char delim,
+                                      ReadAheadBuffer& rab)
+{
+    std::error_code ec;
+    std::size_t n = read_until(buffer, size, delim, rab, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return n;
+}
+
+inline std::size_t Stream::read_until(char* buffer, std::size_t size, char delim,
+                                      ReadAheadBuffer& rab, std::error_code& ec)
+{
+    int delim_2 = std::char_traits<char>::to_int_type(delim);
+    return StreamOps::buffered_read(*this, buffer, size, delim_2, rab, ec); // Throws
+}
+
+inline std::size_t Stream::write(const char* data, std::size_t size)
+{
+    std::error_code ec;
+    write(data, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return size;
+}
+
+inline std::size_t Stream::write(const char* data, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::write(*this, data, size, ec); // Throws
+}
+
+inline std::size_t Stream::read_some(char* buffer, std::size_t size)
+{
+    std::error_code ec;
+    std::size_t n = read_some(buffer, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return n;
+}
+
+inline std::size_t Stream::read_some(char* buffer, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::read_some(*this, buffer, size, ec); // Throws
+}
+
+inline std::size_t Stream::write_some(const char* data, std::size_t size)
+{
+    std::error_code ec;
+    std::size_t n = write_some(data, size, ec); // Throws
+    if (ec)
+        throw std::system_error(ec);
+    return n;
+}
+
+inline std::size_t Stream::write_some(const char* data, std::size_t size, std::error_code& ec)
+{
+    return StreamOps::write_some(*this, data, size, ec); // Throws
+}
+
+inline void Stream::shutdown()
+{
+    std::error_code ec;
+    if (shutdown(ec)) // Throws
+        throw std::system_error(ec);
+}
+
+template<class H> inline void Stream::async_handshake(H handler)
+{
+    LendersHandshakeOperPtr op =
+        Service::alloc<HandshakeOper<H>>(m_tcp_socket.m_read_oper, *this,
+                                         std::move(handler)); // Throws
+    m_tcp_socket.m_desc.initiate_oper(std::move(op)); // Throws
+}
+
+template<class H> inline void Stream::async_read(char* buffer, std::size_t size, H handler)
+{
+    bool is_read_some = false;
+    StreamOps::async_read(*this, buffer, size, is_read_some, std::move(handler)); // Throws
+}
+
+template<class H>
+inline void Stream::async_read(char* buffer, std::size_t size, ReadAheadBuffer& rab, H handler)
+{
+    int delim = std::char_traits<char>::eof();
+    StreamOps::async_buffered_read(*this, buffer, size, delim, rab, std::move(handler)); // Throws
+}
+
+template<class H>
+inline void Stream::async_read_until(char* buffer, std::size_t size, char delim,
+                                     ReadAheadBuffer& rab, H handler)
+{
+    int delim_2 = std::char_traits<char>::to_int_type(delim);
+    StreamOps::async_buffered_read(*this, buffer, size, delim_2, rab, std::move(handler)); // Throws
+}
+
+template<class H> inline void Stream::async_write(const char* data, std::size_t size, H handler)
+{
+    bool is_write_some = false;
+    StreamOps::async_write(*this, data, size, is_write_some, std::move(handler)); // Throws
+}
+
+template<class H> inline void Stream::async_read_some(char* buffer, std::size_t size, H handler)
+{
+    bool is_read_some = true;
+    StreamOps::async_read(*this, buffer, size, is_read_some, std::move(handler)); // Throws
+}
+
+template<class H> inline void Stream::async_write_some(const char* data, std::size_t size, H handler)
+{
+    bool is_write_some = true;
+    StreamOps::async_write(*this, data, size, is_write_some, std::move(handler)); // Throws
+}
+
+template<class H> inline void Stream::async_shutdown(H handler)
+{
+    LendersShutdownOperPtr op =
+        Service::alloc<ShutdownOper<H>>(m_tcp_socket.m_write_oper, *this,
+                                        std::move(handler)); // Throws
+    m_tcp_socket.m_desc.initiate_oper(std::move(op)); // Throws
+}
+
+inline void Stream::do_init_read_async(std::error_code&, Want& want) noexcept
+{
+    want = Want::nothing; // Proceed immediately unless there is an error
+}
+
+inline void Stream::do_init_write_async(std::error_code&, Want& want) noexcept
+{
+    want = Want::nothing; // Proceed immediately unless there is an error
+}
+
+inline std::size_t Stream::do_read_some_sync(char* buffer, std::size_t size,
+                                             std::error_code& ec) noexcept
+{
+    Want want = Want::nothing;
+    std::size_t n = do_read_some_async(buffer, size, ec, want);
+    if (n == 0 && want != Want::nothing)
+        ec = error::resource_unavailable_try_again;
+    return n;
+}
+
+inline std::size_t Stream::do_write_some_sync(const char* data, std::size_t size,
+                                              std::error_code& ec) noexcept
+{
+    Want want = Want::nothing;
+    std::size_t n = do_write_some_async(data, size, ec, want);
+    if (n == 0 && want != Want::nothing)
+        ec = error::resource_unavailable_try_again;
+    return n;
+}
+
+inline std::size_t Stream::do_read_some_async(char* buffer, std::size_t size,
+                                              std::error_code& ec, Want& want) noexcept
+{
+    return ssl_read(buffer, size, ec, want);
+}
+
+inline std::size_t Stream::do_write_some_async(const char* data, std::size_t size,
+                                               std::error_code& ec, Want& want) noexcept
+{
+    return ssl_write(data, size, ec, want);
+}
+
+inline Socket& Stream::lowest_layer() noexcept
+{
+    return m_tcp_socket;
+}
+
+
+#if REALM_HAVE_OPENSSL
+
+inline void Stream::ssl_handshake(std::error_code& ec, Want& want) noexcept
+{
+    auto perform = [this]() noexcept {
+        switch (m_handshake_type) {
+            case client:
+                return do_ssl_connect();
+            case server:
+                return do_ssl_accept();
+        }
+        REALM_ASSERT(false);
+        return 0;
+    };
+    std::size_t n = ssl_perform(std::move(perform), ec, want);
+    REALM_ASSERT(n == 0 || n == 1);
+    if (want == Want::nothing && n == 0 && !ec) {
+        // End of input on TCP socket
+        ec = MiscExtErrors::premature_end_of_input;
+    }
+}
+
+inline std::size_t Stream::ssl_read(char* buffer, std::size_t size,
+                                    std::error_code& ec, Want& want) noexcept
+{
+    auto perform = [this, buffer, size]() noexcept {
+        return do_ssl_read(buffer, size);
+    };
+    std::size_t n = ssl_perform(std::move(perform), ec, want);
+    if (want == Want::nothing && n == 0 && !ec) {
+        // End of input on TCP socket
+        if (SSL_get_shutdown(m_ssl) & SSL_RECEIVED_SHUTDOWN) {
+            ec = MiscExtErrors::end_of_input;
+        }
+        else {
+            ec = MiscExtErrors::premature_end_of_input;
+        }
+    }
+    return n;
+}
+
+inline std::size_t Stream::ssl_write(const char* data, std::size_t size,
+                                     std::error_code& ec, Want& want) noexcept
+{
+    // While OpenSSL is able to continue writing after we have received the
+    // close notify alert fro the remote peer, Apple's Secure Transport API is
+    // not, so to achieve common behaviour, we make sure that any such attempt
+    // will result in an `error::broken_pipe` error.
+    if ((SSL_get_shutdown(m_ssl) & SSL_RECEIVED_SHUTDOWN) != 0) {
+        ec = error::broken_pipe;
+        want = Want::nothing;
+        return 0;
+    }
+    auto perform = [this, data, size]() noexcept {
+        return do_ssl_write(data, size);
+    };
+    std::size_t n = ssl_perform(std::move(perform), ec, want);
+    if (want == Want::nothing && n == 0 && !ec) {
+        // End of input on TCP socket
+        ec = MiscExtErrors::premature_end_of_input;
+    }
+    return n;
+}
+
+inline bool Stream::ssl_shutdown(std::error_code& ec, Want& want) noexcept
+{
+    auto perform = [this]() noexcept {
+        return do_ssl_shutdown();
+    };
+    std::size_t n = ssl_perform(std::move(perform), ec, want);
+    REALM_ASSERT(n == 0 || n == 1);
+    if (want == Want::nothing && n == 0 && !ec) {
+        // The first invocation of SSL_shutdown() does not signal completion
+        // until the shutdown alert has been sent to the peer, or an error
+        // occurred (does not wait for acknowledgment).
+        //
+        // The second invocation (after a completed first invocation) does not
+        // signal completion until the peers shutdown alert has been received,
+        // or an error occurred.
+        //
+        // It is believed that:
+        //
+        // If this is the first time SSL_shutdown() is called, and
+        // `SSL_get_shutdown() & SSL_SENT_SHUTDOWN` evaluates to nonzero, then a
+        // zero return value means "partial success" (shutdown alert was sent,
+        // but the peers shutdown alert was not yet received), and 1 means "full
+        // success" (peers shutdown alert has already been received).
+        //
+        // If this is the first time SSL_shutdown() is called, and
+        // `SSL_get_shutdown() & SSL_SENT_SHUTDOWN` valuates to zero, then a
+        // zero return value means "premature end of input", and 1 is supposedly
+        // not a possibility.
+        //
+        // If this is the second time SSL_shutdown() is called (after the first
+        // call has returned zero), then a zero return value means "premature
+        // end of input", and 1 means "full success" (peers shutdown alert has
+        // now been received).
+        if ((SSL_get_shutdown(m_ssl) & SSL_SENT_SHUTDOWN) == 0)
+            ec = MiscExtErrors::premature_end_of_input;
+    }
+    return (n > 0);
+}
+
+// Provides a homogeneous, and mostly quirks-free interface across the OpenSSL
+// operations (handshake, read, write, shutdown).
+//
+// First of all, if the operation remains incomplete (neither successfully
+// completed, nor failed), ssl_perform() will set `ec` to `std::system_error()`,
+// `want` to something other than `Want::nothing`, and return zero. Note that
+// read and write operations are partial in the sense that they do not need to
+// read or write everything before completing successfully. They only need to
+// read or write at least one byte to complete successfully.
+//
+// Such a situation will normally only happen when the underlying TCP socket is
+// in nonblocking mode, and the read/write requirements of the operation could
+// not be immediately accommodated. However, as is noted in the SSL_write() man
+// page, it can also happen in blocking mode (at least while writing).
+//
+// If an error occurred, ssl_perform() will set `ec` to something other than
+// `std::system_error()`, `want` to `Want::nothing`, and return 0.
+//
+// If no error occurred, and the operation completed (`!ec && want ==
+// Want::nothing`), then the return value indicates the outcome of the
+// operation.
+//
+// In general, a nonzero value means "full" success, and a zero value means
+// "partial" success, however, a zero result can also generally mean "premature
+// end of input" / "unclean protocol termination".
+//
+// Assuming there is no premature end of input, then for reads and writes, the
+// returned value is the number of transferred bytes. Zero for read on end of
+// input. Never zero for write. For handshake it is always 1. For shutdown it is
+// 1 if the peer shutdown alert was already received, otherwise it is zero.
+//
+// ssl_read() should use `SSL_get_shutdown() & SSL_RECEIVED_SHUTDOWN` to
+// distinguish between the two possible meanings of zero.
+//
+// ssl_shutdown() should use `SSL_get_shutdown() & SSL_SENT_SHUTDOWN` to
+// distinguish between the two possible meanings of zero.
+template<class Oper>
+std::size_t Stream::ssl_perform(Oper oper, std::error_code& ec, Want& want) noexcept
+{
+    ERR_clear_error();
+    m_bio_error_code = std::error_code(); // Success
+    int ret = oper();
+    int ssl_error = SSL_get_error(m_ssl, ret);
+    int sys_error = int(ERR_get_error());
+
+    // Guaranteed by the documentation of SSL_get_error()
+    REALM_ASSERT((ret > 0) == (ssl_error == SSL_ERROR_NONE));
+
+    REALM_ASSERT(!m_bio_error_code || ssl_error == SSL_ERROR_SYSCALL);
+
+    // Judging from various comments in the man pages, and from experience with
+    // the API, it seems that,
+    //
+    //   ret=0, ssl_error=SSL_ERROR_SYSCALL, sys_error=0
+    //
+    // is supposed to be an indicator of "premature end of input" / "unclean
+    // protocol termination", while
+    //
+    //   ret=0, ssl_error=SSL_ERROR_ZERO_RETURN
+    //
+    // is supposed to be an indicator of the following success conditions:
+    //
+    //   - Mature end of input / clean protocol termination.
+    //
+    //   - Successful transmission of the shutdown alert, but no prior reception
+    //     of shutdown alert from peer.
+    //
+    // Unfortunately, as is also remarked in various places in the man pages,
+    // those two success conditions may actually result in `ret=0,
+    // ssl_error=SSL_ERROR_SYSCALL, sys_error=0` too, and it seems that they
+    // almost always do.
+    //
+    // This means that we cannot properly discriminate between these conditions
+    // in ssl_perform(), and will have to defer to the caller to interpret the
+    // situation. Since thay cannot be properly told apart, we report all
+    // `ret=0, ssl_error=SSL_ERROR_SYSCALL, sys_error=0` and `ret=0,
+    // ssl_error=SSL_ERROR_ZERO_RETURN` cases as the latter.
+    switch (ssl_error) {
+        case SSL_ERROR_NONE:
+            ec = std::error_code(); // Success
+            want = Want::nothing;
+            return std::size_t(ret); // ret > 0
+        case SSL_ERROR_ZERO_RETURN:
+            ec = std::error_code(); // Success
+            want = Want::nothing;
+            return 0;
+        case SSL_ERROR_WANT_READ:
+            ec = std::error_code(); // Success
+            want = Want::read;
+            return 0;
+        case SSL_ERROR_WANT_WRITE:
+            ec = std::error_code(); // Success
+            want = Want::write;
+            return 0;
+        case SSL_ERROR_SYSCALL:
+            if (REALM_UNLIKELY(sys_error != 0)) {
+                ec = make_basic_system_error_code(sys_error);
+            }
+            else if (REALM_UNLIKELY(m_bio_error_code)) {
+                ec = m_bio_error_code;
+            }
+            else if (ret == 0) {
+                // ret = 0, ssl_eror = SSL_ERROR_SYSCALL, sys_error = 0
+                //
+                // See remarks above!
+                ec = std::error_code(); // Success
+            }
+            else {
+                // ret = -1, ssl_eror = SSL_ERROR_SYSCALL, sys_error = 0
+                //
+                // This situation arises in OpenSSL version >= 1.1.
+                // It has been observed in the SSL_connect call if the
+                // other endpoint terminates the connection during
+                // SSL_connect. The OpenSSL documentation states
+                // that ret = -1 implies an underlying BIO error and
+                // that errno should be consulted. However,
+                // errno = 0(Undefined error) in the observed case.
+                // At the moment. we will report
+                // MiscExtErrors::premature_end_of_input.
+                // If we see this error case occurring in other situations in
+                // the future, we will have to update this case.
+                ec = MiscExtErrors::premature_end_of_input;
+            }
+            want = Want::nothing;
+            return 0;
+        case SSL_ERROR_SSL:
+            ec = std::error_code(sys_error, openssl_error_category);
+            want = Want::nothing;
+            return 0;
+        default:
+            break;
+    }
+    // We are not supposed to ever get here
+    REALM_ASSERT(false);
+    return 0;
+}
+
+inline int Stream::do_ssl_accept() noexcept
+{
+    int ret = SSL_accept(m_ssl);
+    return ret;
+}
+
+inline int Stream::do_ssl_connect() noexcept
+{
+    int ret = SSL_connect(m_ssl);
+    return ret;
+}
+
+inline int Stream::do_ssl_read(char* buffer, std::size_t size) noexcept
+{
+    int size_2 = int(size);
+    if (size > unsigned(std::numeric_limits<int>::max()))
+        size_2 = std::size_t(std::numeric_limits<int>::max());
+    int ret = SSL_read(m_ssl, buffer, size_2);
+    return ret;
+}
+
+inline int Stream::do_ssl_write(const char* data, std::size_t size) noexcept
+{
+    int size_2 = int(size);
+    if (size > unsigned(std::numeric_limits<int>::max()))
+        size_2 = std::size_t(std::numeric_limits<int>::max());
+    int ret = SSL_write(m_ssl, data, size_2);
+    return ret;
+}
+
+inline int Stream::do_ssl_shutdown() noexcept
+{
+    int ret = SSL_shutdown(m_ssl);
+    return ret;
+}
+
+#elif REALM_HAVE_SECURE_TRANSPORT
+
+// Provides a homogeneous, and mostly quirks-free interface across the SecureTransport
+// operations (handshake, read, write, shutdown).
+//
+// First of all, if the operation remains incomplete (neither successfully
+// completed, nor failed), ssl_perform() will set `ec` to `std::system_error()`,
+// `want` to something other than `Want::nothing`, and return zero.
+//
+// If an error occurred, ssl_perform() will set `ec` to something other than
+// `std::system_error()`, `want` to `Want::nothing`, and return 0.
+//
+// If no error occurred, and the operation completed (`!ec && want ==
+// Want::nothing`), then the return value indicates the outcome of the
+// operation.
+//
+// In general, a nonzero value means "full" success, and a zero value means
+// "partial" success, however, a zero result can also generally mean "premature
+// end of input" / "unclean protocol termination".
+//
+// Assuming there is no premature end of input, then for reads and writes, the
+// returned value is the number of transferred bytes. Zero for read on end of
+// input. Never zero for write. For handshake it is always 1. For shutdown it is
+// 1 if the peer shutdown alert was already received, otherwise it is zero.
+template<class Oper>
+std::size_t Stream::ssl_perform(Oper oper, std::error_code& ec, Want& want) noexcept
+{
+    OSStatus result;
+    std::size_t n;
+    std::tie(result, n) = oper();
+
+    if (result == noErr) {
+        ec = std::error_code();
+        want = Want::nothing;
+        return n;
+    }
+
+    if (result == errSSLWouldBlock) {
+        REALM_ASSERT(m_last_operation);
+        ec = std::error_code();
+        want = m_last_operation == BlockingOperation::read ? Want::read : Want::write;
+        m_last_operation = {};
+        return n;
+    }
+
+    if (result == errSSLClosedGraceful) {
+        ec = MiscExtErrors::end_of_input;
+        want = Want::nothing;
+        return n;
+    }
+
+    if (result == errSSLClosedAbort || result == errSSLClosedNoNotify) {
+        ec = MiscExtErrors::premature_end_of_input;
+        want = Want::nothing;
+        return n;
+    }
+
+    if (result == errSecIO) {
+        // A generic I/O error means something went wrong at a lower level. Use the error
+        // code we smuggled out of our lower-level functions to provide a more specific error.
+        REALM_ASSERT(m_last_error);
+        ec = m_last_error;
+        want = Want::nothing;
+        return n;
+    }
+
+    ec = std::error_code(result, secure_transport_error_category);
+    want = Want::nothing;
+    return 0;
+}
+#endif // REALM_HAVE_OPENSSL / REALM_HAVE_SECURE_TRANSPORT
+
+} // namespace ssl
+} // namespace network
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_NETWORK_SSL_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/optional.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/optional.hpp
new file mode 100644
index 0000000..57a2958
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/optional.hpp
@@ -0,0 +1,742 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#pragma once
+#ifndef REALM_UTIL_OPTIONAL_HPP
+#define REALM_UTIL_OPTIONAL_HPP
+
+#include <realm/util/features.h>
+#include <realm/util/backtrace.hpp>
+
+#include <stdexcept>  // std::logic_error
+#include <functional> // std::less
+
+namespace realm {
+namespace util {
+
+template <class T>
+class Optional;
+
+// some() should be the equivalent of the proposed C++17 `make_optional`.
+template <class T, class... Args>
+Optional<T> some(Args&&...);
+template <class T>
+struct Some;
+
+// Note: Should conform with the future std::nullopt_t and std::in_place_t.
+struct None {
+    constexpr explicit None(int)
+    {
+    }
+};
+static constexpr None none{0};
+struct InPlace {
+    constexpr InPlace()
+    {
+    }
+};
+static constexpr InPlace in_place;
+
+// Note: Should conform with the future std::bad_optional_access.
+struct BadOptionalAccess : ExceptionWithBacktrace<std::logic_error> {
+    using ExceptionWithBacktrace<std::logic_error>::ExceptionWithBacktrace;
+};
+
+} // namespace util
+
+namespace _impl {
+
+template <class T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorage;
+
+template <class T, class U>
+struct TypeIsAssignableToOptional {
+    // Constraints from [optional.object.assign.18]
+    static const bool value = (std::is_same<typename std::remove_reference<U>::type, T>::value &&
+                               std::is_constructible<T, U>::value && std::is_assignable<T&, U>::value);
+};
+
+} // namespace _impl
+
+namespace util {
+
+// Note: Should conform with the future std::optional.
+template <class T>
+class Optional : private _impl::OptionalStorage<T> {
+public:
+    using value_type = T;
+
+    constexpr Optional();
+    constexpr Optional(None);
+    Optional(Optional<T>&& other);
+    Optional(const Optional<T>& other);
+
+    constexpr Optional(T&& value);
+    constexpr Optional(const T& value);
+
+    template <class... Args>
+    constexpr Optional(InPlace tag, Args&&...);
+    // FIXME: std::optional specifies an std::initializer_list constructor overload as well.
+
+    Optional<T>& operator=(None);
+    Optional<T>& operator=(Optional<T>&& other);
+    Optional<T>& operator=(const Optional<T>& other);
+
+    template <class U, class = typename std::enable_if<_impl::TypeIsAssignableToOptional<T, U>::value>::type>
+    Optional<T>& operator=(U&& value);
+
+    explicit constexpr operator bool() const;
+    constexpr const T& value() const;      // Throws
+    T& value();                            // Throws, FIXME: Can be constexpr with C++14
+    constexpr const T& operator*() const;  // Throws
+    T& operator*();                        // Throws, FIXME: Can be constexpr with C++14
+    constexpr const T* operator->() const; // Throws
+    T* operator->();                       // Throws, FIXME: Can be constexpr with C++14
+
+    template <class U>
+    constexpr T value_or(U&& value) const &;
+
+    template <class U>
+    T value_or(U&& value) &&;
+
+    void swap(Optional<T>& other); // FIXME: Add noexcept() clause
+
+    template <class... Args>
+    void emplace(Args&&...);
+    // FIXME: std::optional specifies an std::initializer_list overload for `emplace` as well.
+private:
+    using Storage = _impl::OptionalStorage<T>;
+    using Storage::m_engaged;
+    using Storage::m_value;
+
+    constexpr bool is_engaged() const
+    {
+        return m_engaged;
+    }
+    void set_engaged(bool b)
+    {
+        m_engaged = b;
+    }
+    void clear();
+};
+
+
+/// An Optional<void> is functionally equivalent to a bool.
+/// Note: C++17 does not (yet) specify this specialization, but it is convenient
+/// as a "safer bool", especially in the presence of `fmap`.
+/// Disabled for compliance with std::optional.
+// template <>
+// class Optional<void> {
+// public:
+//     Optional() {}
+//     Optional(None) {}
+//     Optional(Optional<void>&&) = default;
+//     Optional(const Optional<void>&) = default;
+//     explicit operator bool() const { return m_engaged; }
+// private:
+//     bool m_engaged = false;
+//     friend struct Some<void>;
+// };
+
+/// An Optional<T&> is a non-owning nullable pointer that throws on dereference.
+// FIXME: Visual Studio 2015's constexpr support isn't sufficient to allow Optional<T&> to compile
+// in constexpr contexts.
+template <class T>
+class Optional<T&> {
+public:
+    using value_type = T&;
+    using target_type = typename std::decay<T>::type;
+
+    constexpr Optional()
+    {
+    }
+    constexpr Optional(None)
+    {
+    } // FIXME: Was a delegating constructor, but not fully supported in VS2015
+    Optional(const Optional<T&>& other) = default;
+    template <class U>
+    Optional(const Optional<U&>& other)
+        : m_ptr(other.m_ptr)
+    {
+    }
+    template <class U>
+    Optional(std::reference_wrapper<U> ref)
+        : m_ptr(&ref.get())
+    {
+    }
+
+    constexpr Optional(T& init_value)
+        : m_ptr(&init_value)
+    {
+    }
+    Optional(T&& value) = delete; // Catches accidental references to rvalue temporaries.
+
+    Optional<T&>& operator=(None)
+    {
+        m_ptr = nullptr;
+        return *this;
+    }
+    Optional<T&>& operator=(const Optional<T&>& other)
+    {
+        m_ptr = other.m_ptr;
+        return *this;
+    }
+
+    template <class U>
+    Optional<T&>& operator=(std::reference_wrapper<U> ref)
+    {
+        m_ptr = &ref.get();
+        return *this;
+    }
+
+    explicit constexpr operator bool() const
+    {
+        return m_ptr;
+    }
+    constexpr const target_type& value() const; // Throws
+    target_type& value();                       // Throws
+    constexpr const target_type& operator*() const
+    {
+        return value();
+    }
+    target_type& operator*()
+    {
+        return value();
+    }
+    constexpr const target_type* operator->() const
+    {
+        return &value();
+    }
+    target_type* operator->()
+    {
+        return &value();
+    }
+
+    void swap(Optional<T&> other); // FIXME: Add noexcept() clause
+private:
+    T* m_ptr = nullptr;
+
+    template <class U>
+    friend class Optional;
+};
+
+
+template <class T>
+struct RemoveOptional {
+    using type = T;
+};
+template <class T>
+struct RemoveOptional<Optional<T>> {
+    using type = typename RemoveOptional<T>::type; // Remove recursively
+};
+
+
+/// Implementation:
+
+template <class T>
+struct Some {
+    template <class... Args>
+    static Optional<T> some(Args&&... args)
+    {
+        return Optional<T>{std::forward<Args>(args)...};
+    }
+};
+
+/// Disabled for compliance with std::optional.
+// template <>
+// struct Some<void> {
+//     static Optional<void> some()
+//     {
+//         Optional<void> opt;
+//         opt.m_engaged = true;
+//         return opt;
+//     }
+// };
+
+template <class T, class... Args>
+Optional<T> some(Args&&... args)
+{
+    return Some<T>::some(std::forward<Args>(args)...);
+}
+
+
+template <class T>
+constexpr Optional<T>::Optional()
+    : Storage(none)
+{
+}
+
+template <class T>
+constexpr Optional<T>::Optional(None)
+    : Storage(none)
+{
+}
+
+template <class T>
+Optional<T>::Optional(Optional<T>&& other)
+    : Storage(none)
+{
+    if (other.m_engaged) {
+        new (&m_value) T(std::move(other.m_value));
+        m_engaged = true;
+    }
+}
+
+template <class T>
+Optional<T>::Optional(const Optional<T>& other)
+    : Storage(none)
+{
+    if (other.m_engaged) {
+        new (&m_value) T(other.m_value);
+        m_engaged = true;
+    }
+}
+
+template <class T>
+constexpr Optional<T>::Optional(T&& r_value)
+    : Storage(std::move(r_value))
+{
+}
+
+template <class T>
+constexpr Optional<T>::Optional(const T& l_value)
+    : Storage(l_value)
+{
+}
+
+template <class T>
+template <class... Args>
+constexpr Optional<T>::Optional(InPlace, Args&&... args)
+    : Storage(std::forward<Args>(args)...)
+{
+}
+
+template <class T>
+void Optional<T>::clear()
+{
+    if (m_engaged) {
+        m_value.~T();
+        m_engaged = false;
+    }
+}
+
+template <class T>
+Optional<T>& Optional<T>::operator=(None)
+{
+    clear();
+    return *this;
+}
+
+template <class T>
+Optional<T>& Optional<T>::operator=(Optional<T>&& other)
+{
+    if (m_engaged) {
+        if (other.m_engaged) {
+            m_value = std::move(other.m_value);
+        }
+        else {
+            clear();
+        }
+    }
+    else {
+        if (other.m_engaged) {
+            new (&m_value) T(std::move(other.m_value));
+            m_engaged = true;
+        }
+    }
+    return *this;
+}
+
+template <class T>
+Optional<T>& Optional<T>::operator=(const Optional<T>& other)
+{
+    if (m_engaged) {
+        if (other.m_engaged) {
+            m_value = other.m_value;
+        }
+        else {
+            clear();
+        }
+    }
+    else {
+        if (other.m_engaged) {
+            new (&m_value) T(other.m_value);
+            m_engaged = true;
+        }
+    }
+    return *this;
+}
+
+template <class T>
+template <class U, class>
+Optional<T>& Optional<T>::operator=(U&& r_value)
+{
+    if (m_engaged) {
+        m_value = std::forward<U>(r_value);
+    }
+    else {
+        new (&m_value) T(std::forward<U>(r_value));
+        m_engaged = true;
+    }
+    return *this;
+}
+
+template <class T>
+constexpr Optional<T>::operator bool() const
+{
+    return m_engaged;
+}
+
+template <class T>
+constexpr const T& Optional<T>::value() const
+{
+    return m_engaged ? m_value : (throw BadOptionalAccess{"bad optional access"}, m_value);
+}
+
+template <class T>
+T& Optional<T>::value()
+{
+    if (!m_engaged) {
+        throw BadOptionalAccess{"bad optional access"};
+    }
+    return m_value;
+}
+
+template <class T>
+constexpr const typename Optional<T&>::target_type& Optional<T&>::value() const
+{
+    return m_ptr ? *m_ptr : (throw BadOptionalAccess{"bad optional access"}, *m_ptr);
+}
+
+template <class T>
+typename Optional<T&>::target_type& Optional<T&>::value()
+{
+    if (!m_ptr) {
+        throw BadOptionalAccess{"bad optional access"};
+    }
+    return *m_ptr;
+}
+
+template <class T>
+constexpr const T& Optional<T>::operator*() const
+{
+    // Note: This differs from std::optional, which doesn't throw.
+    return value();
+}
+
+template <class T>
+T& Optional<T>::operator*()
+{
+    // Note: This differs from std::optional, which doesn't throw.
+    return value();
+}
+
+template <class T>
+constexpr const T* Optional<T>::operator->() const
+{
+    // Note: This differs from std::optional, which doesn't throw.
+    return &value();
+}
+
+template <class T>
+T* Optional<T>::operator->()
+{
+    // Note: This differs from std::optional, which doesn't throw.
+    return &value();
+}
+
+template <class T>
+template <class U>
+constexpr T Optional<T>::value_or(U&& otherwise) const &
+{
+    return m_engaged ? T{m_value} : T{std::forward<U>(otherwise)};
+}
+
+template <class T>
+template <class U>
+T Optional<T>::value_or(U&& otherwise) &&
+{
+    if (is_engaged()) {
+        return T(std::move(m_value));
+    }
+    else {
+        return T(std::forward<U>(otherwise));
+    }
+}
+
+template <class T>
+void Optional<T>::swap(Optional<T>& other)
+{
+    // FIXME: This might be optimizable.
+    Optional<T> tmp = std::move(other);
+    other = std::move(*this);
+    *this = std::move(tmp);
+}
+
+template <class T>
+template <class... Args>
+void Optional<T>::emplace(Args&&... args)
+{
+    clear();
+    new (&m_value) T(std::forward<Args>(args)...);
+    m_engaged = true;
+}
+
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value)
+{
+    using Type = typename std::decay<T>::type;
+    return some<Type>(std::forward<T>(value));
+}
+
+template <class T>
+bool operator==(const Optional<T>& lhs, const Optional<T>& rhs)
+{
+    if (!lhs && !rhs) {
+        return true;
+    }
+    if (lhs && rhs) {
+        return *lhs == *rhs;
+    }
+    return false;
+}
+
+template <class T>
+bool operator!=(const Optional<T>& lhs, const Optional<T>& rhs)
+{
+    return !(lhs == rhs);
+}
+
+template <class T>
+bool operator<(const Optional<T>& lhs, const Optional<T>& rhs)
+{
+    if (!rhs) {
+        return false;
+    }
+    if (!lhs) {
+        return true;
+    }
+    return std::less<T>{}(*lhs, *rhs);
+}
+
+template <class T>
+bool operator>(const util::Optional<T>& lhs, const util::Optional<T>& rhs)
+{
+    if (!lhs) {
+        return false;
+    }
+    if (!rhs) {
+        return true;
+    }
+    return std::greater<T>{}(*lhs, *rhs);
+}
+
+template <class T>
+bool operator==(const Optional<T>& lhs, None)
+{
+    return !bool(lhs);
+}
+
+template <class T>
+bool operator!=(const Optional<T>& lhs, None)
+{
+    return bool(lhs);
+}
+
+template <class T>
+bool operator<(const Optional<T>& lhs, None)
+{
+    static_cast<void>(lhs);
+    return false;
+}
+
+template <class T>
+bool operator==(None, const Optional<T>& rhs)
+{
+    return !bool(rhs);
+}
+
+template <class T>
+bool operator!=(None, const Optional<T>& rhs)
+{
+    return bool(rhs);
+}
+
+template <class T>
+bool operator<(None, const Optional<T>& rhs)
+{
+    return bool(rhs);
+}
+
+template <class T, class U>
+bool operator==(const Optional<T>& lhs, const U& rhs)
+{
+    return lhs ? *lhs == rhs : false;
+}
+
+template <class T>
+bool operator<(const Optional<T>& lhs, const T& rhs)
+{
+    return lhs ? std::less<T>{}(*lhs, rhs) : true;
+}
+
+template <class T, class U>
+bool operator==(const T& lhs, const Optional<U>& rhs)
+{
+    return rhs ? lhs == *rhs : false;
+}
+
+template <class T>
+bool operator<(const T& lhs, const Optional<T>& rhs)
+{
+    return rhs ? std::less<T>{}(lhs, *rhs) : false;
+}
+
+template <class T, class F>
+auto operator>>(Optional<T> lhs, F&& rhs) -> decltype(fmap(lhs, std::forward<F>(rhs)))
+{
+    return fmap(lhs, std::forward<F>(rhs));
+}
+
+template <class OS, class T>
+OS& operator<<(OS& os, const Optional<T>& rhs)
+{
+    if (rhs) {
+        os << "some(" << *rhs << ")";
+    }
+    else {
+        os << "none";
+    }
+    return os;
+}
+
+template <class T>
+T unwrap(T&& value)
+{
+    return value;
+}
+
+template <class T>
+T unwrap(util::Optional<T>&& value)
+{
+    return *value;
+}
+
+template <class T>
+T unwrap(const util::Optional<T>& value)
+{
+    return *value;
+}
+
+template <class T>
+T unwrap(util::Optional<T>& value)
+{
+    return *value;
+}
+
+} // namespace util
+
+namespace _impl {
+
+// T is trivially destructible.
+template <class T>
+struct OptionalStorage<T, true> {
+    union {
+        T m_value;
+        char m_null_state;
+    };
+    bool m_engaged = false;
+
+    constexpr OptionalStorage(realm::util::None)
+        : m_null_state()
+    {
+    }
+    constexpr OptionalStorage(T&& value)
+        : m_value(std::move(value))
+        , m_engaged(true)
+    {
+    }
+
+    template <class... Args>
+    constexpr OptionalStorage(Args&&... args)
+        : m_value(args...)
+        , m_engaged(true)
+    {
+    }
+};
+
+// T is not trivially destructible.
+template <class T>
+struct OptionalStorage<T, false> {
+    union {
+        T m_value;
+        char m_null_state;
+    };
+    bool m_engaged = false;
+
+    constexpr OptionalStorage(realm::util::None)
+        : m_null_state()
+    {
+    }
+    constexpr OptionalStorage(T&& value)
+        : m_value(std::move(value))
+        , m_engaged(true)
+    {
+    }
+
+    template <class... Args>
+    constexpr OptionalStorage(Args&&... args)
+        : m_value(args...)
+        , m_engaged(true)
+    {
+    }
+
+    ~OptionalStorage()
+    {
+        if (m_engaged)
+            m_value.~T();
+    }
+};
+
+} // namespace _impl
+
+using util::none;
+
+} // namespace realm
+
+
+// for convienence, inject a default hash implementation into the std namespace
+namespace std
+{
+    template<typename T>
+    struct hash<realm::util::Optional<T>>
+    {
+        std::size_t operator()(realm::util::Optional<T> const& o) const noexcept
+        {
+            if (bool(o) == false) {
+                return 0; // any choice will collide with some std::hash
+            } else {
+                return std::hash<T>{}(*o);
+            }
+        }
+    };
+}
+
+
+#endif // REALM_UTIL_OPTIONAL_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/overload.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/overload.hpp
new file mode 100644
index 0000000..49188ae
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/overload.hpp
@@ -0,0 +1,70 @@
+/*************************************************************************
+ *
+ * Copyright 2017 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_OVERLOAD_HPP
+#define REALM_UTIL_OVERLOAD_HPP
+
+#include <utility>
+
+namespace realm {
+
+namespace _impl {
+
+template<typename Fn, typename... Fns>
+struct Overloaded;
+
+} // namespace _impl
+
+
+namespace util {
+
+// Declare an overload set using lambdas or other function objects.
+// A minimal version of C++ Library Evolution Working Group proposal P0051R2.
+
+template<typename... Fns>
+_impl::Overloaded<Fns...> overload(Fns&&... f)
+{
+    return _impl::Overloaded<Fns...>(std::forward<Fns>(f)...);
+}
+
+} // namespace util
+
+
+namespace _impl {
+
+template<typename Fn, typename... Fns>
+struct Overloaded : Fn, Overloaded<Fns...> {
+    template<typename U, typename... Rest>
+    Overloaded(U&& fn, Rest&&... rest) : Fn(std::forward<U>(fn)), Overloaded<Fns...>(std::forward<Rest>(rest)...) { }
+
+    using Fn::operator();
+    using Overloaded<Fns...>::operator();
+};
+
+template<typename Fn>
+struct Overloaded<Fn> : Fn {
+    template<typename U>
+    Overloaded(U&& fn) : Fn(std::forward<U>(fn)) { }
+
+    using Fn::operator();
+};
+
+} // namespace _impl
+} // namespace realm
+
+#endif // REALM_UTIL_OVERLOAD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/parent_dir.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/parent_dir.hpp
new file mode 100644
index 0000000..0e74e22
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/parent_dir.hpp
@@ -0,0 +1,37 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_PARENT_DIR_HPP
+#define REALM_UTIL_PARENT_DIR_HPP
+
+#include <string>
+
+namespace realm {
+namespace util {
+
+/// Same effect as std::filesystem::path::parent_path().
+///
+/// FIXME: This function ought to be moved to <realm/util/file.hpp> in the
+/// realm-core repository.
+std::string parent_dir(const std::string& path);
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_PARENT_DIR_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/platform_info.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/platform_info.hpp
new file mode 100644
index 0000000..16ae43a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/platform_info.hpp
@@ -0,0 +1,64 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_PLATFORM_INFO_HPP
+#define REALM_UTIL_PLATFORM_INFO_HPP
+
+#include <string>
+
+
+namespace realm {
+namespace util {
+
+/// Get a description of the current system platform.
+///
+/// Returns a space-separated concatenation of `osname`, `sysname`, `release`,
+/// `version`, and `machine` as returned by get_platform_info(PlatformInfo&).
+std::string get_platform_info();
+
+
+struct PlatformInfo {
+    std::string osname;  ///< Equivalent to `uname -o` (Linux).
+    std::string sysname; ///< Equivalent to `uname -s`.
+    std::string release; ///< Equivalent to `uname -r`.
+    std::string version; ///< Equivalent to `uname -v`.
+    std::string machine; ///< Equivalent to `uname -m`.
+};
+
+/// Get a description of the current system platform.
+void get_platform_info(PlatformInfo&);
+
+
+
+
+// Implementation
+
+inline std::string get_platform_info()
+{
+    PlatformInfo info;
+    get_platform_info(info); // Throws
+    return (info.osname + " " + info.sysname + " " + info.release + " " + info.version + " " +
+            info.machine); // Throws
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_PLATFORM_INFO_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/priority_queue.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/priority_queue.hpp
new file mode 100644
index 0000000..a2a28c8
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/priority_queue.hpp
@@ -0,0 +1,304 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+
+#pragma once
+#ifndef REALM_UTIL_PRIORITY_QUEUE_HPP
+#define REALM_UTIL_PRIORITY_QUEUE_HPP
+
+#include <vector>
+#include <functional>
+#include <algorithm>
+
+namespace realm {
+namespace util {
+
+
+/// PriorityQueue corresponds exactly to `std::priority_queue`, but has the extra feature
+/// of allowing iteration and erasure of elements in the queue.
+///
+/// PriorityQueue only allows const access to its elements, because non-const access
+/// would open up the risk of changing the ordering of the elements.
+///
+/// Note: As opposed to `std::priority_queue`, this does not store elements in a heap
+/// internally. Instead, elements are stored in sorted order. Users of this class are
+/// allowed to operate on this assumption.
+template <class T, class Container = std::vector<T>, class Compare = std::less<typename Container::value_type>>
+class PriorityQueue : private Compare {
+public:
+    using container_type = Container;
+    using value_type = typename Container::value_type;
+    using size_type = typename Container::size_type;
+    using reference = typename Container::reference;
+    using const_reference = typename Container::const_reference;
+    using const_reverse_iterator = typename Container::const_reverse_iterator;
+    using const_iterator = typename Container::const_iterator;
+
+    //@{
+    /// Construct a PriorityQueue, optionally providing a comparator object.
+    PriorityQueue(const Compare& comparator, const Container& cont);
+
+    explicit PriorityQueue(const Compare& comparator = Compare{}, Container&& cont = Container{});
+
+    template <class InputIt>
+    PriorityQueue(InputIt first, InputIt last, const Compare& comparator, const Container& cont);
+
+    template <class InputIt>
+    PriorityQueue(InputIt first, InputIt last, const Compare& comparator = Compare{}, Container&& cont = Container{});
+    //@}
+    // Skipping Allocator-specific template constructors.
+
+    PriorityQueue(const PriorityQueue&) = default;
+    PriorityQueue(PriorityQueue&&) = default;
+    PriorityQueue& operator=(const PriorityQueue&) = default;
+    PriorityQueue& operator=(PriorityQueue&&) = default;
+
+    bool empty() const;
+    size_type size() const;
+
+    //@{
+    /// Push an element to the priority queue.
+    ///
+    /// If insertion to the underlying `Container` invalidates
+    /// iterators and references, any iterators and references into this
+    /// priority queue are also invalidated. By default, this is the case.
+    void push(const T& value);
+    void push(T&& value);
+    //@}
+
+    /// Pop the largest element from the priority queue.
+    ///
+    /// If `pop_back` on the underlying `Container` invalidates
+    /// iterators and references, any iterators and reference into this
+    /// priority queue are also invalidated. By default, this is *NOT* the case.
+    ///
+    /// Calling `pop()` on an empty priority queue is undefined.
+    void pop();
+
+    /// Return a reference to the largest element of the priority queue.
+    ///
+    /// Calling `top()` on an empty priority queue is undefined.
+    const_reference top() const;
+
+    /// Pop the top of the queue and return it by moving it out of the queue.
+    ///
+    /// Note: This method does not exist in `std::priority_queue`.
+    ///
+    /// Calling `pop_top()` on an empty priorty queue is undefined.
+    value_type pop_top();
+
+    // FIXME: emplace() deliberately omitted for simplicity.
+
+    /// Swap the contents of this priority queue with the contents of \a other.
+    void swap(PriorityQueue& other);
+
+    // Not in std::priority_queue:
+
+    /// Return an iterator to the beginning of the queue (smallest element first).
+    const_iterator begin() const;
+
+    /// Return an iterator to the end of the queue (largest element last);
+    const_iterator end() const;
+
+    /// Return a reverse iterator into the priority queue (largest element first).
+    const_reverse_iterator rbegin() const;
+
+    /// Return a reverse iterator representing the end of the priority queue (smallest element last).
+    const_reverse_iterator rend() const;
+
+    /// Erase element pointed to by \a it.
+    ///
+    /// Note: This function differs from `std::priority_queue` by returning the erased
+    /// element using move semantics.
+    ///
+    /// Calling `erase()` with a beyond-end iterator (such as what is returned by `end()`)
+    /// is undefined.
+    value_type erase(const_iterator it);
+
+    /// Remove all elements from the priority queue.
+    void clear();
+
+    /// Calls `reserve()` on the underlying `Container`.
+    void reserve(size_type);
+
+private:
+    Container m_queue;
+
+    const Compare& compare() const;
+    Compare& compare();
+};
+
+
+/// Implementation
+
+template <class T, class Container, class Compare>
+PriorityQueue<T, Container, Compare>::PriorityQueue(const Compare& comparator, const Container& cont)
+    : Compare(comparator)
+    , m_queue(cont)
+{
+}
+
+template <class T, class Container, class Compare>
+PriorityQueue<T, Container, Compare>::PriorityQueue(const Compare& comparator, Container&& cont)
+    : Compare(comparator)
+    , m_queue(std::move(cont))
+{
+}
+
+template <class T, class Container, class Compare>
+template <class InputIt>
+PriorityQueue<T, Container, Compare>::PriorityQueue(InputIt first, InputIt last, const Compare& comparator,
+                                                    const Container& cont)
+    : Compare(comparator)
+    , m_queue(cont)
+{
+    for (auto it = first; it != last; ++it) {
+        push(*it);
+    }
+}
+
+template <class T, class Container, class Compare>
+template <class InputIt>
+PriorityQueue<T, Container, Compare>::PriorityQueue(InputIt first, InputIt last, const Compare& comparator,
+                                                    Container&& cont)
+    : Compare(comparator)
+    , m_queue(std::move(cont))
+{
+    for (auto it = first; it != last; ++it) {
+        push(*it);
+    }
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::size_type PriorityQueue<T, Container, Compare>::size() const
+{
+    return m_queue.size();
+}
+
+template <class T, class Container, class Compare>
+bool PriorityQueue<T, Container, Compare>::empty() const
+{
+    return m_queue.empty();
+}
+
+template <class T, class Container, class Compare>
+void PriorityQueue<T, Container, Compare>::push(const T& element)
+{
+    auto it = std::lower_bound(m_queue.begin(), m_queue.end(), element, compare());
+    m_queue.insert(it, element);
+}
+
+template <class T, class Container, class Compare>
+void PriorityQueue<T, Container, Compare>::push(T&& element)
+{
+    auto it = std::lower_bound(m_queue.begin(), m_queue.end(), element, compare());
+    m_queue.insert(it, std::move(element));
+}
+
+template <class T, class Container, class Compare>
+void PriorityQueue<T, Container, Compare>::pop()
+{
+    m_queue.pop_back();
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::const_reference PriorityQueue<T, Container, Compare>::top() const
+{
+    return m_queue.back();
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::value_type PriorityQueue<T, Container, Compare>::pop_top()
+{
+    value_type value = std::move(m_queue.back());
+    m_queue.pop_back();
+    return value;
+}
+
+template <class T, class Container, class Compare>
+Compare& PriorityQueue<T, Container, Compare>::compare()
+{
+    return *this;
+}
+
+template <class T, class Container, class Compare>
+const Compare& PriorityQueue<T, Container, Compare>::compare() const
+{
+    return *this;
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::const_iterator PriorityQueue<T, Container, Compare>::begin() const
+{
+    return m_queue.begin();
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::const_iterator PriorityQueue<T, Container, Compare>::end() const
+{
+    return m_queue.end();
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::const_reverse_iterator
+PriorityQueue<T, Container, Compare>::rbegin() const
+{
+    return m_queue.rbegin();
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::const_reverse_iterator
+PriorityQueue<T, Container, Compare>::rend() const
+{
+    return m_queue.rend();
+}
+
+template <class T, class Container, class Compare>
+typename PriorityQueue<T, Container, Compare>::value_type
+PriorityQueue<T, Container, Compare>::erase(const_iterator it)
+{
+    // Convert to non-const iterator:
+    auto non_const_iterator = m_queue.begin() + (it - m_queue.begin());
+    value_type value = std::move(*non_const_iterator);
+    m_queue.erase(non_const_iterator);
+    return value;
+}
+
+template <class T, class Container, class Compare>
+void PriorityQueue<T, Container, Compare>::clear()
+{
+    m_queue.clear();
+}
+
+template <class T, class Container, class Compare>
+void PriorityQueue<T, Container, Compare>::reserve(size_type sz)
+{
+    m_queue.reserve(sz);
+}
+
+template <class T, class Container, class Compare>
+void PriorityQueue<T, Container, Compare>::swap(PriorityQueue& other)
+{
+    using std::swap;
+    swap(m_queue, other.m_queue);
+    swap(compare(), other.compare());
+}
+}
+}
+
+#endif // REALM_UTIL_PRIORITY_QUEUE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/quote.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/quote.hpp
new file mode 100644
index 0000000..7959a44
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/quote.hpp
@@ -0,0 +1,175 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_QUOTE_HPP
+#define REALM_UTIL_QUOTE_HPP
+
+#include <realm/util/string_view.hpp>
+
+namespace realm {
+namespace util {
+
+template<class C, class T> struct Quote {
+    bool smart;
+    util::BasicStringView<C, T> view;
+};
+
+
+/// Mark text for quotation during output to stream.
+///
+/// If `out` is an output stream, and `str` is a string (e.g., an std::string),
+/// then
+///
+///     out << quoted(str)
+///
+/// will write `str` in quoted form to `out`.
+///
+/// Quotation involves bracketing the text in double quotes (`"`), and escaping
+/// special characters according to the rules of C/C++ string literals. In this
+/// case, the special characters are `"` and `\` as well as those that are not
+/// printable (!std::isprint()).
+///
+/// Quotation happens as the string is written to a stream, so there is no
+/// intermediate representation of the quoted string.
+template<class C, class T> Quote<C, T> quoted(util::BasicStringView<C, T>) noexcept;
+
+
+/// Same as quoted(), except that in this case, quotation is elided when the
+/// specified string consists of a single printable word. Or, to be more
+/// precise, quotation is elided if the string is nonempty, consists entirely of
+/// printable charcters (std::isprint()), does not contain space (` `), and does
+/// not conatian quotation (`"`) or backslash (`\`).
+template<class C, class T> Quote<C, T> smart_quoted(util::BasicStringView<C, T>) noexcept;
+
+
+template<class C, class T>
+std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>&, Quote<C, T>);
+
+
+
+
+
+// Implementation
+
+template<class C, class T> inline Quote<C, T> quoted(util::BasicStringView<C, T> view) noexcept
+{
+    bool smart = false;
+    return {smart, view};
+}
+
+template<class C, class T>
+inline Quote<C, T> smart_quoted(util::BasicStringView<C, T> view) noexcept
+{
+    bool smart = true;
+    return {smart, view};
+}
+
+template<class C, class T>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out, Quote<C, T> quoted)
+{
+    std::locale loc = out.getloc();
+    const std::ctype<C>& ctype = std::use_facet<std::ctype<C>>(loc);
+    util::BasicStringView<C, T> view = quoted.view;
+    if (quoted.smart && !view.empty()) {
+        for (C ch : view) {
+            if (ch == '"' || ch == '\\' || !ctype.is(ctype.graph, ch))
+                goto quote;
+        }
+        return out << view; // Throws
+    }
+  quote:
+    typename std::basic_ostream<C, T>::sentry sentry{out};
+    if (REALM_LIKELY(sentry)) {
+        C dquote = ctype.widen('"');
+        C bslash = ctype.widen('\\');
+        out.put(dquote); // Throws
+        bool follows_hex = false;
+        for (C ch : view) {
+            if (REALM_LIKELY(ctype.is(ctype.print, ch))) {
+                if (REALM_LIKELY(!follows_hex || !ctype.is(ctype.xdigit, ch))) {
+                    if (REALM_LIKELY(ch != '"' || ch != '\\'))
+                        goto put_char;
+                    goto escape_char;
+                }
+            }
+            switch (ch) {
+                case '\a':
+                    ch = ctype.widen('a');
+                    goto escape_char;
+                case '\b':
+                    ch = ctype.widen('b');
+                    goto escape_char;
+                case '\f':
+                    ch = ctype.widen('f');
+                    goto escape_char;
+                case '\n':
+                    ch = ctype.widen('n');
+                    goto escape_char;
+                case '\r':
+                    ch = ctype.widen('r');
+                    goto escape_char;
+                case '\t':
+                    ch = ctype.widen('t');
+                    goto escape_char;
+                case '\v':
+                    ch = ctype.widen('v');
+                    goto escape_char;
+            }
+            goto numeric;
+          escape_char:
+            out.put(bslash); // Throws
+          put_char:
+            out.put(ch); // Throws
+          next:
+            follows_hex = false;
+            continue;
+          numeric:
+            out.put(bslash); // Throws
+            using D = typename std::make_unsigned<C>::type;
+            char digits[] = {
+                '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'
+            };
+            D val = ch;
+            if (val < 512) {
+                out.put(ctype.widen(digits[val / 64    ])); // Throws
+                out.put(ctype.widen(digits[val % 64 / 8])); // Throws
+                out.put(ctype.widen(digits[val      % 8])); // Throws
+                goto next;
+            }
+            out.put(ctype.widen('x')); // Throws
+            const int max_hex_digits = (std::numeric_limits<D>::digits + 3) / 4;
+            C buffer[max_hex_digits];
+            int i = max_hex_digits;
+            while (val != 0) {
+                buffer[--i] = ctype.widen(digits[val % 16]);
+                val /= 16;
+            }
+            out.write(buffer + i, max_hex_digits - i); // Throws
+            follows_hex = true;
+        }
+        out.put(dquote); // Throws
+    }
+    return out;
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_QUOTE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/random.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/random.hpp
new file mode 100644
index 0000000..d0c7fe9
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/random.hpp
@@ -0,0 +1,137 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_RANDOM_HPP
+#define REALM_UTIL_RANDOM_HPP
+
+#include <stddef.h>
+#include <limits>
+#include <array>
+#include <random>
+#include <algorithm>
+#include <functional>
+
+namespace realm {
+namespace util {
+
+/// Perform a nondeterministc seeding of the specified pseudo random number
+/// generator.
+///
+/// \tparam Engine A type that satisfies UniformRandomBitGenerator as defined by
+/// the C++ standard.
+///
+/// \tparam state_size The number of words of type Engine::result_type that make
+/// up the engine state.
+///
+/// Thread-safe.
+///
+/// FIXME: Move this to core repo, as it is generally useful.
+template<class Engine, size_t state_size = Engine::state_size>
+void seed_prng_nondeterministically(Engine&);
+
+template<class Engine>
+std::string generate_random_lower_case_string(Engine& engine, size_t size);
+
+
+// Implementation
+
+} // namespace util
+
+namespace _impl {
+
+void get_extra_seed_entropy(unsigned int& extra_entropy_1, unsigned int& extra_entropy_2,
+                            unsigned int& extra_entropy_3);
+
+} // namespace _impl
+
+namespace util {
+
+template<class Engine, size_t state_size> void seed_prng_nondeterministically(Engine& engine)
+{
+    // This implementation was informed and inspired by
+    // http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0205r0.html.
+    //
+    // The number of bits of entropy needed is `state_size *
+    // std::numeric_limits<typename Engine::result_type>::digits` (assuming that
+    // the engine uses all available bits in each word).
+    //
+    // Each invocation of `std::random_device::operator()` gives us
+    // `std::numeric_limits<unsigned int>::digits` bits (assuming maximum
+    // entropy). Note that `std::random_device::result_type` must be `unsigned
+    // int`, `std::random_device::min()` must return zero, and
+    // `std::random_device::max()` must return `std::numeric_limits<unsigned
+    // int>::max()`.
+    //
+    // Ideally, we could have used `std::random_device::entropy()` as the actual
+    // number of bits of entropy produced per invocation of
+    // `std::random_device::operator()`, however, it is incorrectly implemented
+    // on many platform. Also, it is supposed to return zero when
+    // `std::random_device` is just a PRNG, but that would leave us with no way
+    // to continue.
+    //
+    // When the actual entropy from `std::random_device` is less than maximum,
+    // the seeding will be less than optimal. For example, if the actual entropy
+    // is only half of the maximum, then the seeding will only produce half the
+    // entrpy that it ought to, but that will generally still be a good seeding.
+    //
+    // For the (assumed) rare cases where `std::random_device` is a PRGN that is
+    // not nondeterministically seeded, we include a bit of extra entropy taken
+    // from such places as the current time and the ID of the executing process
+    // (when available).
+
+    constexpr long seed_bits_needed = state_size *
+        long(std::numeric_limits<typename Engine::result_type>::digits);
+    constexpr int seed_bits_per_device_invocation =
+        std::numeric_limits<unsigned int>::digits;
+    constexpr size_t seed_words_needed =
+        size_t((seed_bits_needed + (seed_bits_per_device_invocation - 1)) /
+               seed_bits_per_device_invocation); // Rounding up
+    constexpr int num_extra = 3;
+    std::array<std::random_device::result_type, seed_words_needed+num_extra> seed_values;
+    std::random_device rnddev;
+    std::generate(seed_values.begin(), seed_values.end()-num_extra, std::ref(rnddev));
+
+    unsigned int extra_entropy[3];
+    _impl::get_extra_seed_entropy(extra_entropy[0], extra_entropy[1], extra_entropy[2]);
+    static_assert(num_extra == sizeof extra_entropy / sizeof extra_entropy[0], "Mismatch");
+    std::copy(extra_entropy, extra_entropy+num_extra, seed_values.end()-num_extra);
+
+    std::seed_seq seed_seq(seed_values.begin(), seed_values.end());
+    engine.seed(seed_seq);
+}
+
+template<class Engine>
+std::string generate_random_lower_case_string(Engine& engine, size_t size)
+{
+    std::uniform_int_distribution<short> dist(0, 25);
+    std::string str;
+    str.reserve(size);
+    for (size_t i = 0; i < size; ++i) {
+        short val = dist(engine);
+        char c = 'a' + char(val);
+        str.push_back(c);
+    }
+    return str;
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_RANDOM_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/resource_limits.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/resource_limits.hpp
new file mode 100644
index 0000000..858624a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/resource_limits.hpp
@@ -0,0 +1,83 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_RESOURCE_LIMITS_HPP
+#define REALM_UTIL_RESOURCE_LIMITS_HPP
+
+namespace realm {
+namespace util {
+
+
+enum class Resource {
+    /// The maximum size, in bytes, of the core file produced when the memory
+    /// image of this process is dumped. If the memory image is larger than the
+    /// limit, the core file will not be created. Same as `RLIMIT_CORE` of
+    /// POSIX.
+    core_dump_size,
+
+    /// The maximum CPU time, in seconds, available to this process. If the
+    /// limit is exceeded, the process will be killed. Same as `RLIMIT_CPU` of
+    /// POSIX.
+    cpu_time,
+
+    /// The maximum size, in bytes, of the data segment of this process. If the
+    /// limit is exceede, std::malloc() will fail with `errno` equal to
+    /// `ENOMEM`. Same as `RLIMIT_DATA` of POSIX.
+    data_segment_size,
+
+    /// The maximum size, in bytes, of a file that is modified by this
+    /// process. If the limit is exceede, the process will be killed. Same as
+    /// `RLIMIT_FSIZE` of POSIX.
+    file_size,
+
+    /// One plus the maximum file descriptor value that can be opened by this
+    /// process. Same as `RLIMIT_NOFILE` of POSIX.
+    num_open_files,
+
+    /// The maximum size, in bytes, of the stack of the main thread of this
+    /// process. If the limit is exceede, the process is killed. Same as
+    /// `RLIMIT_STACK` of POSIX.
+    stack_size,
+
+    /// The maximum size, in bytes, of the process's virtual memory (address
+    /// space). If the limit is exceeded due to heap allocation, std::malloc()
+    /// will fail with `errno` equal to `ENOMEM`. If the limit is exceeded due
+    /// to explicit memory mapping, mmap() will fail with `errno` equal to
+    /// `ENOMEM`. If the limit is exceeded due to stack expansion, the process
+    /// will be killed.  Same as `RLIMIT_AS` of POSIX.
+    virtual_memory_size
+};
+
+
+bool system_has_rlimit(Resource) noexcept;
+
+
+//@{
+/// Get or set resouce limits. A negative value means 'unlimited', both when
+/// getting and when setting.
+long get_hard_rlimit(Resource);
+long get_soft_rlimit(Resource);
+void set_soft_rlimit(Resource, long value);
+//@}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_RESOURCE_LIMITS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/safe_int_ops.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/safe_int_ops.hpp
new file mode 100644
index 0000000..15030ad
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/safe_int_ops.hpp
@@ -0,0 +1,623 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_SAFE_INT_OPS_HPP
+#define REALM_UTIL_SAFE_INT_OPS_HPP
+
+#ifdef _WIN32
+#undef max // collides with numeric_limits::max called later in this header file
+#undef min // collides with numeric_limits::min called later in this header file
+#endif
+
+#include <limits>
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/type_traits.hpp>
+
+namespace realm {
+namespace util {
+
+
+/// Perform integral or floating-point promotion on the argument. This
+/// is useful for example when printing a number of arbitrary numeric
+/// type to 'stdout', since it will convert values of character-like
+/// types to regular integer types, which will then be printed as
+/// numbers rather characters.
+template <class T>
+typename Promote<T>::type promote(T value) noexcept;
+
+
+/// This function allows you to test for a negative value in any
+/// numeric type, even when the type is unsigned. Normally, when the
+/// type is unsigned, such a test will produce a compiler warning.
+template <class T>
+bool is_negative(T value) noexcept;
+
+
+/// Cast the specified value to the specified unsigned type reducing
+/// the value (or in case of negative values, the two's complement
+/// representation) modulo `2**N` where `N` is the number of value
+/// bits (or digits) in the unsigned target type. This is usefull in
+/// cases where the target type may be `bool`, but need not be `bool`.
+template <class To, class From>
+To cast_to_unsigned(From) noexcept;
+
+
+//@{
+
+/// Compare two integers of the same, or of different type, and
+/// produce the expected result according to the natural
+/// interpretation of the operation.
+///
+/// Note that in general a standard comparison between a signed and an
+/// unsigned integer type is unsafe, and it often generates a compiler
+/// warning. An example is a 'less than' comparison between a negative
+/// value of type 'int' and a small positive value of type
+/// 'unsigned'. In this case the negative value will be converted to
+/// 'unsigned' producing a large positive value which, in turn, will
+/// lead to the counter intuitive result of 'false'.
+///
+/// Please note that these operation incur absolutely no overhead when
+/// the two types have the same signedness.
+///
+/// These functions check at compile time that both types have valid
+/// specializations of std::numeric_limits<> and that both are indeed
+/// integers.
+///
+/// These functions make absolutely no assumptions about the platform
+/// except that it complies with at least C++03.
+
+template <class A, class B>
+inline bool int_equal_to(A, B) noexcept;
+template <class A, class B>
+inline bool int_not_equal_to(A, B) noexcept;
+template <class A, class B>
+inline bool int_less_than(A, B) noexcept;
+template <class A, class B>
+inline bool int_less_than_or_equal(A, B) noexcept;
+template <class A, class B>
+inline bool int_greater_than(A, B) noexcept;
+template <class A, class B>
+inline bool int_greater_than_or_equal(A, B) noexcept;
+
+//@}
+
+
+//@{
+
+/// Check for overflow in integer variable `lval` while adding integer
+/// `rval` to it, or while subtracting integer `rval` from it. Returns
+/// true on positive or negative overflow.
+///
+/// Both `lval` and `rval` must be of an integer type for which a
+/// specialization of std::numeric_limits<> exists. The two types need
+/// not be the same, in particular, one can be signed and the other
+/// one can be unsigned.
+///
+/// These functions are especially well suited for cases where \a rval
+/// is a compile-time constant.
+///
+/// These functions check at compile time that both types have valid
+/// specializations of std::numeric_limits<> and that both are indeed
+/// integers.
+///
+/// These functions make absolutely no assumptions about the platform
+/// except that it complies with at least C++03.
+
+template <class L, class R>
+inline bool int_add_with_overflow_detect(L& lval, R rval) noexcept;
+
+template <class L, class R>
+inline bool int_subtract_with_overflow_detect(L& lval, R rval) noexcept;
+
+//@}
+
+
+/// Check for positive overflow when multiplying two positive integers
+/// of the same, or of different type. Returns true on overflow.
+///
+/// \param lval Must not be negative. Both signed and unsigned types
+/// can be used.
+///
+/// \param rval Must be stricly greater than zero. Both signed and
+/// unsigned types can be used.
+///
+/// This function is especially well suited for cases where \a rval is
+/// a compile-time constant.
+///
+/// This function checks at compile time that both types have valid
+/// specializations of std::numeric_limits<> and that both are indeed
+/// integers.
+///
+/// This function makes absolutely no assumptions about the platform
+/// except that it complies with at least C++03.
+template <class L, class R>
+inline bool int_multiply_with_overflow_detect(L& lval, R rval) noexcept;
+
+
+/// Checks for positive overflow when performing a bitwise shift to
+/// the left on a non-negative value of arbitrary integer
+/// type. Returns true on overflow.
+///
+/// \param lval Must not be negative. Both signed and unsigned types
+/// can be used.
+///
+/// \param i Must be non-negative and such that <tt>L(1)>>i</tt> has a
+/// value that is defined by the C++03 standard. In particular, the
+/// value of i must not exceed the number of bits of storage type T as
+/// shifting by this amount is not defined by the standard.
+///
+/// This function makes absolutely no assumptions about the platform
+/// except that it complies with at least C++03.
+template <class T>
+inline bool int_shift_left_with_overflow_detect(T& lval, int i) noexcept;
+
+
+//@{
+
+/// Check for overflow when casting an integer value from one type to
+/// another. While the first function is a mere check, the second one
+/// also carries out the cast, but only when there is no
+/// overflow. Both return true on overflow.
+///
+/// These functions check at compile time that both types have valid
+/// specializations of std::numeric_limits<> and that both are indeed
+/// integers.
+///
+/// These functions make absolutely no assumptions about the platform
+/// except that it complies with at least C++03.
+
+template <class To, class From>
+bool int_cast_has_overflow(From from) noexcept;
+
+template <class To, class From>
+bool int_cast_with_overflow_detect(From from, To& to) noexcept;
+
+//@}
+
+
+/// Convert negative values from two's complement representation to the
+/// platforms native representation.
+///
+/// If `To` is an unsigned type, this function does nothing beyond casting the
+/// specified value to `To`. Otherwise, `To` is a signed type, and negative
+/// values will be converted from two's complement representation in unsigned
+/// `From` to the platforms native representation in `To`.
+///
+/// For signed `To` the result is well-defined if, and only if the value with
+/// the specified two's complement representation is representable in the
+/// specified signed type. While this is generally the case when using
+/// corresponding signed/unsigned type pairs, it is not guaranteed by the
+/// standard. However, if you know that the signed type has at least as many
+/// value bits as the unsigned type, then the result is always
+/// well-defined. Note that a 'value bit' in this context is the same as a
+/// 'digit' from the point of view of `std::numeric_limits`.
+///
+/// On platforms that use two's complement representation of negative values,
+/// this function is expected to be completely optimized away. This has been
+/// observed to be true with both GCC 4.8 and Clang 3.2.
+///
+/// Note that the **opposite** direction (from the platforms native
+/// representation to two's complement) is trivially handled by casting the
+/// signed value to a value of a sufficiently wide unsigned integer type. An
+/// unsigned type will be sufficiently wide if it has at least one more value
+/// bit than the signed type.
+///
+/// Interestingly, the C++ language offers no direct way of doing what this
+/// function does, yet, this function is implemented in a way that makes no
+/// assumption about the underlying platform except what is guaranteed by C++11.
+///
+/// \tparam From The unsigned type used to store the two's complement
+/// representation.
+///
+/// \tparam To A signed or unsigned integer type.
+template <class To, class From>
+To from_twos_compl(From twos_compl) noexcept;
+
+
+// Implementation:
+
+template <class T>
+inline typename Promote<T>::type promote(T value) noexcept
+{
+    typedef typename Promote<T>::type promoted_type;
+    promoted_type value_2 = promoted_type(value);
+    return value_2;
+}
+
+} // namespace util
+
+namespace _impl {
+
+template <class T, bool is_signed>
+struct IsNegative {
+    static bool test(T value) noexcept
+    {
+        return value < 0;
+    }
+};
+template <class T>
+struct IsNegative<T, false> {
+    static bool test(T) noexcept
+    {
+        return false;
+    }
+};
+
+template <class To>
+struct CastToUnsigned {
+    template <class From>
+    static To cast(From value) noexcept
+    {
+        return To(value);
+    }
+};
+template <>
+struct CastToUnsigned<bool> {
+    template <class From>
+    static bool cast(From value) noexcept
+    {
+        return bool(unsigned(value) & 1);
+    }
+};
+
+template <class L, class R, bool l_signed, bool r_signed>
+struct SafeIntBinopsImpl {
+};
+
+// (unsigned, unsigned) (all size combinations)
+//
+// This implementation utilizes the fact that overflow in unsigned
+// arithmetic is guaranteed to be handled by reduction modulo 2**N
+// where N is the number of bits in the unsigned type. The purpose of
+// the bitwise 'and' with lim_l::max() is to make a cast to bool
+// behave the same way as casts to other unsigned integer types.
+// Finally, this implementation uses the fact that if modular addition
+// overflows, then the result must be a value that is less than both
+// operands. Also, if modular subtraction overflows, then the result
+// must be a value that is greater than the first operand.
+template <class L, class R>
+struct SafeIntBinopsImpl<L, R, false, false> {
+    typedef std::numeric_limits<L> lim_l;
+    typedef std::numeric_limits<R> lim_r;
+    static const int needed_bits_l = lim_l::digits;
+    static const int needed_bits_r = lim_r::digits;
+    static const int needed_bits = needed_bits_l >= needed_bits_r ? needed_bits_l : needed_bits_r;
+    typedef typename util::FastestUnsigned<needed_bits>::type common_unsigned;
+    static bool equal(L l, R r) noexcept
+    {
+        return common_unsigned(l) == common_unsigned(r);
+    }
+    static bool less(L l, R r) noexcept
+    {
+        return common_unsigned(l) < common_unsigned(r);
+    }
+    static bool add(L& lval, R rval) noexcept
+    {
+        L lval_2 = util::cast_to_unsigned<L>(lval + rval);
+        bool overflow = common_unsigned(lval_2) < common_unsigned(rval);
+        if (REALM_UNLIKELY(overflow))
+            return true;
+        lval = lval_2;
+        return false;
+    }
+    static bool sub(L& lval, R rval) noexcept
+    {
+        common_unsigned lval_2 = common_unsigned(lval) - common_unsigned(rval);
+        bool overflow = lval_2 > common_unsigned(lval);
+        if (REALM_UNLIKELY(overflow))
+            return true;
+        lval = util::cast_to_unsigned<L>(lval_2);
+        return false;
+    }
+};
+
+// (unsigned, signed) (all size combinations)
+template <class L, class R>
+struct SafeIntBinopsImpl<L, R, false, true> {
+    typedef std::numeric_limits<L> lim_l;
+    typedef std::numeric_limits<R> lim_r;
+    static const int needed_bits_l = lim_l::digits;
+    static const int needed_bits_r = lim_r::digits + 1;
+    static const int needed_bits = needed_bits_l >= needed_bits_r ? needed_bits_l : needed_bits_r;
+    typedef typename util::FastestUnsigned<needed_bits>::type common_unsigned;
+    typedef std::numeric_limits<common_unsigned> lim_cu;
+    static bool equal(L l, R r) noexcept
+    {
+        return (lim_l::digits > lim_r::digits) ? r >= 0 && l == util::cast_to_unsigned<L>(r) : R(l) == r;
+    }
+    static bool less(L l, R r) noexcept
+    {
+        return (lim_l::digits > lim_r::digits) ? r >= 0 && l < util::cast_to_unsigned<L>(r) : R(l) < r;
+    }
+    static bool add(L& lval, R rval) noexcept
+    {
+        common_unsigned lval_2 = lval + common_unsigned(rval);
+        bool overflow;
+        if (lim_l::digits < lim_cu::digits) {
+            overflow = common_unsigned(lval_2) > common_unsigned(lim_l::max());
+        }
+        else {
+            overflow = (lval_2 < common_unsigned(lval)) == (rval >= 0);
+        }
+        if (REALM_UNLIKELY(overflow))
+            return true;
+        lval = util::cast_to_unsigned<L>(lval_2);
+        return false;
+    }
+    static bool sub(L& lval, R rval) noexcept
+    {
+        common_unsigned lval_2 = lval - common_unsigned(rval);
+        bool overflow;
+        if (lim_l::digits < lim_cu::digits) {
+            overflow = common_unsigned(lval_2) > common_unsigned(lim_l::max());
+        }
+        else {
+            overflow = (common_unsigned(lval_2) > common_unsigned(lval)) == (rval >= 0);
+        }
+        if (REALM_UNLIKELY(overflow))
+            return true;
+        lval = util::cast_to_unsigned<L>(lval_2);
+        return false;
+    }
+};
+
+// (signed, unsigned) (all size combinations)
+template <class L, class R>
+struct SafeIntBinopsImpl<L, R, true, false> {
+    typedef std::numeric_limits<L> lim_l;
+    typedef std::numeric_limits<R> lim_r;
+    static const int needed_bits_l = lim_l::digits + 1;
+    static const int needed_bits_r = lim_r::digits;
+    static const int needed_bits = needed_bits_l >= needed_bits_r ? needed_bits_l : needed_bits_r;
+    typedef typename util::FastestUnsigned<needed_bits>::type common_unsigned;
+    static bool equal(L l, R r) noexcept
+    {
+        return (lim_l::digits < lim_r::digits) ? l >= 0 && util::cast_to_unsigned<R>(l) == r : l == L(r);
+    }
+    static bool less(L l, R r) noexcept
+    {
+        return (lim_l::digits < lim_r::digits) ? l < 0 || util::cast_to_unsigned<R>(l) < r : l < L(r);
+    }
+    static bool add(L& lval, R rval) noexcept
+    {
+        common_unsigned max_add = common_unsigned(lim_l::max()) - common_unsigned(lval);
+        bool overflow = common_unsigned(rval) > max_add;
+        if (REALM_UNLIKELY(overflow))
+            return true;
+        lval = util::from_twos_compl<L>(common_unsigned(lval) + rval);
+        return false;
+    }
+    static bool sub(L& lval, R rval) noexcept
+    {
+        common_unsigned max_sub = common_unsigned(lval) - common_unsigned(lim_l::min());
+        bool overflow = common_unsigned(rval) > max_sub;
+        if (REALM_UNLIKELY(overflow))
+            return true;
+        lval = util::from_twos_compl<L>(common_unsigned(lval) - rval);
+        return false;
+    }
+};
+
+// (signed, signed) (all size combinations)
+template <class L, class R>
+struct SafeIntBinopsImpl<L, R, true, true> {
+    typedef std::numeric_limits<L> lim_l;
+    static bool equal(L l, R r) noexcept
+    {
+        return l == r;
+    }
+    static bool less(L l, R r) noexcept
+    {
+        return l < r;
+    }
+    static bool add(L& lval, R rval) noexcept
+    {
+        // Note that both subtractions below occur in a signed type
+        // that is at least as wide as both of the two types. Note
+        // also that any signed type guarantees that there is no
+        // overflow when subtracting two negative values or two
+        // non-negative value. See C99 (adopted as subset of C++11)
+        // section 6.2.6.2 "Integer types" paragraph 2.
+        if (rval < 0) {
+            if (REALM_UNLIKELY(lval < lim_l::min() - rval))
+                return true;
+        }
+        else {
+            if (REALM_UNLIKELY(lval > lim_l::max() - rval))
+                return true;
+        }
+        // The following statement has exactly the same effect as
+        // `lval += rval`.
+        lval = L(lval + rval);
+        return false;
+    }
+    static bool sub(L& lval, R rval) noexcept
+    {
+        // Note that both subtractions below occur in a signed type
+        // that is at least as wide as both of the two types. Note
+        // also that there can be no overflow when adding a negative
+        // value to a non-negative value, or when adding a
+        // non-negative value to a negative one.
+        if (rval < 0) {
+            if (REALM_UNLIKELY(lval > lim_l::max() + rval))
+                return true;
+        }
+        else {
+            if (REALM_UNLIKELY(lval < lim_l::min() + rval))
+                return true;
+        }
+        // The following statement has exactly the same effect as
+        // `lval += rval`.
+        lval = L(lval - rval);
+        return false;
+    }
+};
+
+template <class L, class R>
+struct SafeIntBinops : SafeIntBinopsImpl<L, R, std::numeric_limits<L>::is_signed, std::numeric_limits<R>::is_signed> {
+    typedef std::numeric_limits<L> lim_l;
+    typedef std::numeric_limits<R> lim_r;
+    static_assert(lim_l::is_specialized && lim_r::is_specialized,
+                  "std::numeric_limits<> must be specialized for both types");
+    static_assert(lim_l::is_integer && lim_r::is_integer, "Both types must be integers");
+};
+
+} // namespace _impl
+
+namespace util {
+
+template <class T>
+inline bool is_negative(T value) noexcept
+{
+    return _impl::IsNegative<T, std::numeric_limits<T>::is_signed>::test(value);
+}
+
+template <class To, class From>
+inline To cast_to_unsigned(From value) noexcept
+{
+    return _impl::CastToUnsigned<To>::cast(value);
+}
+
+template <class A, class B>
+inline bool int_equal_to(A a, B b) noexcept
+{
+    return _impl::SafeIntBinops<A, B>::equal(a, b);
+}
+
+template <class A, class B>
+inline bool int_not_equal_to(A a, B b) noexcept
+{
+    return !_impl::SafeIntBinops<A, B>::equal(a, b);
+}
+
+template <class A, class B>
+inline bool int_less_than(A a, B b) noexcept
+{
+    return _impl::SafeIntBinops<A, B>::less(a, b);
+}
+
+template <class A, class B>
+inline bool int_less_than_or_equal(A a, B b) noexcept
+{
+    return !_impl::SafeIntBinops<B, A>::less(b, a); // Not greater than
+}
+
+template <class A, class B>
+inline bool int_greater_than(A a, B b) noexcept
+{
+    return _impl::SafeIntBinops<B, A>::less(b, a);
+}
+
+template <class A, class B>
+inline bool int_greater_than_or_equal(A a, B b) noexcept
+{
+    return !_impl::SafeIntBinops<A, B>::less(a, b); // Not less than
+}
+
+template <class L, class R>
+inline bool int_add_with_overflow_detect(L& lval, R rval) noexcept
+{
+    return _impl::SafeIntBinops<L, R>::add(lval, rval);
+}
+
+template <class L, class R>
+inline bool int_subtract_with_overflow_detect(L& lval, R rval) noexcept
+{
+    return _impl::SafeIntBinops<L, R>::sub(lval, rval);
+}
+
+template <class L, class R>
+inline bool int_multiply_with_overflow_detect(L& lval, R rval) noexcept
+{
+    // FIXME: Check if the following optimizes better (if it works at all):
+    // L lval_2 = L(lval * rval);
+    // bool overflow  =  rval != 0  &&  (lval_2 / rval) != lval;
+    typedef std::numeric_limits<L> lim_l;
+    typedef std::numeric_limits<R> lim_r;
+    static_assert(lim_l::is_specialized && lim_r::is_specialized,
+                  "std::numeric_limits<> must be specialized for both types");
+    static_assert(lim_l::is_integer && lim_r::is_integer, "Both types must be integers");
+    REALM_ASSERT(int_greater_than_or_equal(lval, 0));
+    REALM_ASSERT(int_greater_than(rval, 0));
+    if (int_less_than(lim_l::max() / rval, lval))
+        return true;
+    lval = L(lval * rval);
+    return false;
+}
+
+template <class T>
+inline bool int_shift_left_with_overflow_detect(T& lval, int i) noexcept
+{
+    typedef std::numeric_limits<T> lim;
+    static_assert(lim::is_specialized, "std::numeric_limits<> must be specialized for T");
+    static_assert(lim::is_integer, "T must be an integer type");
+    REALM_ASSERT(int_greater_than_or_equal(lval, 0));
+    if ((lim::max() >> i) < lval)
+        return true;
+    lval <<= i;
+    return false;
+}
+
+template <class To, class From>
+inline bool int_cast_has_overflow(From from) noexcept
+{
+    typedef std::numeric_limits<To> lim_to;
+    return int_less_than(from, lim_to::min()) || int_less_than(lim_to::max(), from);
+}
+
+template <class To, class From>
+inline bool int_cast_with_overflow_detect(From from, To& to) noexcept
+{
+    if (REALM_LIKELY(!int_cast_has_overflow<To>(from))) {
+        to = To(from);
+        return false;
+    }
+    return true;
+}
+
+template <class To, class From>
+inline To from_twos_compl(From twos_compl) noexcept
+{
+    typedef std::numeric_limits<From> lim_f;
+    typedef std::numeric_limits<To> lim_t;
+    static_assert(lim_f::is_specialized && lim_t::is_specialized,
+                  "std::numeric_limits<> must be specialized for both types");
+    static_assert(lim_f::is_integer && lim_t::is_integer, "Both types must be integers");
+    static_assert(!lim_f::is_signed, "`From` must be unsigned");
+    To native;
+    int sign_bit_pos = lim_f::digits - 1;
+    From sign_bit = From(1) << sign_bit_pos;
+    bool non_negative = !lim_t::is_signed || (twos_compl & sign_bit) == 0;
+    if (non_negative) {
+        // Non-negative value
+        native = To(twos_compl);
+    }
+    else {
+        // Negative value
+        native = To(-1 - To(From(-1) - twos_compl));
+    }
+    return native;
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_SAFE_INT_OPS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/scope_exit.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/scope_exit.hpp
new file mode 100644
index 0000000..5410d19
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/scope_exit.hpp
@@ -0,0 +1,72 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_SCOPE_EXIT_HPP
+#define REALM_UTIL_SCOPE_EXIT_HPP
+
+#include <type_traits>
+#include <utility>
+
+#include <realm/util/optional.hpp>
+
+namespace realm {
+namespace util {
+
+template <class H>
+class ScopeExit {
+public:
+    explicit ScopeExit(const H& handler) noexcept(std::is_nothrow_copy_constructible<H>::value)
+        : m_handler(handler)
+    {
+    }
+
+    explicit ScopeExit(H&& handler) noexcept(std::is_nothrow_move_constructible<H>::value)
+        : m_handler(std::move(handler))
+    {
+    }
+
+    ScopeExit(ScopeExit&& se) noexcept(std::is_nothrow_move_constructible<H>::value)
+        : m_handler(std::move(se.m_handler))
+    {
+        se.m_handler = none;
+    }
+
+    ~ScopeExit() noexcept
+    {
+        if (m_handler)
+            (*m_handler)();
+    }
+
+    static_assert(noexcept(std::declval<H>()()), "Handler must be nothrow executable");
+    static_assert(std::is_nothrow_destructible<H>::value, "Handler must be nothrow destructible");
+
+private:
+    util::Optional<H> m_handler;
+};
+
+template <class H>
+ScopeExit<typename std::remove_reference<H>::type> make_scope_exit(H&& handler) noexcept(
+    noexcept(ScopeExit<typename std::remove_reference<H>::type>(std::forward<H>(handler))))
+{
+    return ScopeExit<typename std::remove_reference<H>::type>(std::forward<H>(handler));
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_SCOPE_EXIT_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/serializer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/serializer.hpp
new file mode 100644
index 0000000..5f7fc03
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/serializer.hpp
@@ -0,0 +1,92 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_SERIALIZER_HPP
+#define REALM_UTIL_SERIALIZER_HPP
+
+#include <realm/table_ref.hpp>
+#include <realm/util/optional.hpp>
+
+#include <string>
+#include <sstream>
+#include <vector>
+
+namespace realm {
+
+class BinaryData;
+struct null;
+struct RowIndex;
+class StringData;
+class Timestamp;
+class LinkMap;
+
+namespace util {
+namespace serializer {
+
+
+// Definitions
+template <typename T>
+std::string print_value(T value);
+
+template <typename T>
+std::string print_value(Optional<T> value);
+
+const static std::string value_separator = ".";
+
+// Specializations declared here to be defined in the cpp file
+template <> std::string print_value<>(BinaryData);
+template <> std::string print_value<>(bool);
+template <> std::string print_value<>(realm::null);
+template <> std::string print_value<>(StringData);
+template <> std::string print_value<>(realm::Timestamp);
+template <> std::string print_value<>(realm::RowIndex);
+
+// General implementation for most types
+template <typename T>
+std::string print_value(T value)
+{
+    std::stringstream ss;
+    ss << value;
+    return ss.str();
+}
+
+template <typename T>
+std::string print_value(Optional<T> value)
+{
+    if (bool(value)) {
+        return print_value(*value);
+    } else {
+        return "NULL";
+    }
+}
+
+struct SerialisationState
+{
+    std::string describe_column(ConstTableRef table, size_t col_ndx);
+    std::string describe_columns(const LinkMap& link_map, size_t target_col_ndx);
+    std::string get_column_name(ConstTableRef table, size_t col_ndx);
+    std::string get_backlink_column_name(ConstTableRef from, size_t col_ndx);
+    std::string get_variable_name(ConstTableRef table);
+    std::vector<std::string> subquery_prefix_list;
+};
+
+} // namespace serializer
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_SERIALIZER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/shared_ptr.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/shared_ptr.hpp
new file mode 100644
index 0000000..1a34701
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/shared_ptr.hpp
@@ -0,0 +1,131 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_SHARED_PTR_HPP
+#define REALM_SHARED_PTR_HPP
+
+#include <cstdlib> // size_t
+
+namespace realm {
+namespace util {
+
+template <class T>
+class SharedPtr {
+public:
+    SharedPtr(T* p)
+    {
+        init(p);
+    }
+
+    SharedPtr()
+    {
+        init(0);
+    }
+
+    ~SharedPtr()
+    {
+        decref();
+    }
+
+    SharedPtr(const SharedPtr<T>& o)
+        : m_ptr(o.m_ptr)
+        , m_count(o.m_count)
+    {
+        incref();
+    }
+
+    SharedPtr<T>& operator=(const SharedPtr<T>& o)
+    {
+        // if (m_ptr == o.m_ptr)
+        if (this == &o)
+            return *this;
+        decref();
+        m_ptr = o.m_ptr;
+        m_count = o.m_count;
+        incref();
+        return *this;
+    }
+
+    T* operator->() const
+    {
+        return m_ptr;
+    }
+
+    T& operator*() const
+    {
+        return *m_ptr;
+    }
+
+    T* get() const
+    {
+        return m_ptr;
+    }
+
+    bool operator==(const SharedPtr<T>& o) const
+    {
+        return m_ptr == o.m_ptr;
+    }
+
+    bool operator!=(const SharedPtr<T>& o) const
+    {
+        return m_ptr != o.m_ptr;
+    }
+
+    bool operator<(const SharedPtr<T>& o) const
+    {
+        return m_ptr < o.m_ptr;
+    }
+
+    size_t ref_count() const
+    {
+        return *m_count;
+    }
+
+private:
+    void init(T* p)
+    {
+        m_ptr = p;
+        try {
+            m_count = new size_t(1);
+        }
+        catch (...) {
+            delete p;
+            throw;
+        }
+    }
+
+    void decref()
+    {
+        if (--(*m_count) == 0) {
+            delete m_ptr;
+            delete m_count;
+        }
+    }
+
+    void incref()
+    {
+        ++(*m_count);
+    }
+
+    T* m_ptr;
+    size_t* m_count;
+};
+}
+}
+
+#endif
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/signal_blocker.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/signal_blocker.hpp
new file mode 100644
index 0000000..bb1489b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/signal_blocker.hpp
@@ -0,0 +1,79 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_SIGNAL_BLOCKER_HPP
+#define REALM_UTIL_SIGNAL_BLOCKER_HPP
+
+#include <csignal>
+
+#include <realm/util/config.h>
+
+
+namespace realm {
+namespace util {
+
+/// \brief Block all signals from being delivered to the instantiating thread.
+///
+/// On platforms that support POSIX signals, the constructor will set the signal
+/// mask such that all signals are blocked from being delivered to the calling
+/// thread, and the destructor will restore the signal mask to its original
+/// value.
+///
+/// This scheme assumes that it is always the same thread that constructs and
+/// destroys a particular instance of SignalBlocker, and that, for a particular
+/// thread, two SignalBlocker objects never overlap in time, and the signal mask
+/// is never modified by other means while a SignalBlocker object exists.
+class SignalBlocker {
+public:
+    SignalBlocker() noexcept;
+    ~SignalBlocker() noexcept;
+
+private:
+#ifndef _WIN32
+    ::sigset_t m_orig_mask;
+#endif
+};
+
+
+
+// Implementation
+
+inline SignalBlocker::SignalBlocker() noexcept
+{
+#ifndef _WIN32
+    ::sigset_t mask;
+    sigfillset(&mask);
+    int ret = ::pthread_sigmask(SIG_BLOCK, &mask, &m_orig_mask);
+    REALM_ASSERT(ret == 0);
+#endif
+}
+
+inline SignalBlocker::~SignalBlocker() noexcept
+{
+#ifndef _WIN32
+    int ret = ::pthread_sigmask(SIG_SETMASK, &m_orig_mask, nullptr);
+    REALM_ASSERT(ret == 0);
+#endif
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_SIGNAL_BLOCKER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/string_buffer.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/string_buffer.hpp
new file mode 100644
index 0000000..71736bd
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/string_buffer.hpp
@@ -0,0 +1,209 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_STRING_BUFFER_HPP
+#define REALM_UTIL_STRING_BUFFER_HPP
+
+#include <cstddef>
+#include <cstring>
+#include <string>
+
+#include <realm/util/features.h>
+#include <realm/util/buffer.hpp>
+
+namespace realm {
+namespace util {
+
+
+// FIXME: In C++17, this can be replaced with std::string (since
+// std::string::data() can return a mutable pointer in C++17).
+template <class Allocator = DefaultAllocator>
+class BasicStringBuffer {
+public:
+    BasicStringBuffer() noexcept;
+
+    std::string str() const;
+
+    /// Returns the current size of the string in this buffer. This
+    /// size does not include the terminating zero.
+    size_t size() const noexcept;
+
+    /// Gives read and write access to the bytes of this buffer. The
+    /// caller may read and write from *c_str() up to, but not
+    /// including, *(c_str()+size()).
+    char* data() noexcept;
+
+    /// Gives read access to the bytes of this buffer. The caller may
+    /// read from *c_str() up to, but not including,
+    /// *(c_str()+size()).
+    const char* data() const noexcept;
+
+    /// Guarantees that the returned string is zero terminated, that
+    /// is, *(c_str()+size()) is zero. The caller may read from
+    /// *c_str() up to and including *(c_str()+size()).
+    const char* c_str() const noexcept;
+
+    void append(const std::string&);
+
+    void append(const char* append_data, size_t append_size);
+
+    /// Append a zero-terminated string to this buffer.
+    void append_c_str(const char* c_string);
+
+    /// The specified size is understood as not including the
+    /// terminating zero. If the specified size is less than the
+    /// current size, then the string is truncated accordingly. If the
+    /// specified size is greater than the current size, then the
+    /// extra characters will have undefined values, however, there
+    /// will be a terminating zero at *(c_str()+size()), and the
+    /// original terminating zero will also be left in place such that
+    /// from the point of view of c_str(), the size of the string is
+    /// unchanged.
+    void resize(size_t new_size);
+
+    /// The specified minimum capacity is understood as not including
+    /// the terminating zero. This operation does not change the size
+    /// of the string in the buffer as returned by size(). If the
+    /// specified capacity is less than the current capacity, this
+    /// operation has no effect.
+    void reserve(size_t min_capacity);
+
+    /// Set size to zero. The capacity remains unchanged.
+    void clear() noexcept;
+
+private:
+    util::Buffer<char, Allocator> m_buffer;
+    size_t m_size; // Excluding the terminating zero
+    void reallocate(size_t min_capacity);
+};
+
+using StringBuffer = BasicStringBuffer<DefaultAllocator>;
+
+
+// Implementation:
+
+template <class A>
+BasicStringBuffer<A>::BasicStringBuffer() noexcept
+    : m_size(0)
+{
+}
+
+template <class A>
+std::string BasicStringBuffer<A>::str() const
+{
+    return std::string(m_buffer.data(), m_size);
+}
+
+template <class A>
+size_t BasicStringBuffer<A>::size() const noexcept
+{
+    return m_size;
+}
+
+template <class A>
+char* BasicStringBuffer<A>::data() noexcept
+{
+    return m_buffer.data();
+}
+
+template <class A>
+const char* BasicStringBuffer<A>::data() const noexcept
+{
+    return m_buffer.data();
+}
+
+template <class A>
+const char* BasicStringBuffer<A>::c_str() const noexcept
+{
+    static const char zero = 0;
+    const char* d = data();
+    return d ? d : &zero;
+}
+
+template <class A>
+void BasicStringBuffer<A>::append(const std::string& s)
+{
+    return append(s.data(), s.size());
+}
+
+template <class A>
+void BasicStringBuffer<A>::append_c_str(const char* c_string)
+{
+    append(c_string, std::strlen(c_string));
+}
+
+template <class A>
+void BasicStringBuffer<A>::reserve(size_t min_capacity)
+{
+    size_t capacity = m_buffer.size();
+    if (capacity == 0 || capacity - 1 < min_capacity)
+        reallocate(min_capacity);
+}
+
+template <class A>
+void BasicStringBuffer<A>::resize(size_t new_size)
+{
+    reserve(new_size);
+    // Note that even reserve(0) will attempt to allocate a
+    // buffer, so we can safely write the truncating zero at this
+    // time.
+    m_size = new_size;
+    m_buffer[new_size] = 0;
+}
+
+template <class A>
+void BasicStringBuffer<A>::clear() noexcept
+{
+    if (m_buffer.size() == 0)
+        return;
+    m_size = 0;
+    m_buffer[0] = 0;
+}
+
+template <class A>
+void BasicStringBuffer<A>::append(const char* append_data, size_t append_data_size)
+{
+    size_t new_size = m_size;
+    if (int_add_with_overflow_detect(new_size, append_data_size))
+        throw util::BufferSizeOverflow();
+    reserve(new_size); // Throws
+    realm::safe_copy_n(append_data, append_data_size, m_buffer.data() + m_size);
+    m_size = new_size;
+    m_buffer[new_size] = 0; // Add zero termination
+}
+
+
+template <class A>
+void BasicStringBuffer<A>::reallocate(size_t min_capacity)
+{
+    size_t min_capacity_2 = min_capacity;
+    // Make space for zero termination
+    if (int_add_with_overflow_detect(min_capacity_2, 1))
+        throw util::BufferSizeOverflow();
+    size_t new_capacity = m_buffer.size();
+    if (int_multiply_with_overflow_detect(new_capacity, 2))
+        new_capacity = std::numeric_limits<size_t>::max(); // LCOV_EXCL_LINE
+    if (new_capacity < min_capacity_2)
+        new_capacity = min_capacity_2;
+    m_buffer.resize(new_capacity, 0, m_size, 0); // Throws
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_STRING_BUFFER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/string_view.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/string_view.hpp
new file mode 100644
index 0000000..74fdcb6
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/string_view.hpp
@@ -0,0 +1,478 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_STRING_VIEW_HPP
+#define REALM_UTIL_STRING_VIEW_HPP
+
+#include <cstddef>
+#include <type_traits>
+#include <algorithm>
+#include <iterator>
+#include <stdexcept>
+#include <string>
+#include <ostream>
+
+#include <realm/util/features.h>
+
+
+namespace realm {
+namespace util {
+
+template<class C, class T = std::char_traits<C>> class BasicStringView {
+public:
+    using value_type             = C;
+    using traits_type            = T;
+    using pointer                = C*;
+    using const_pointer          = const C*;
+    using reference              = C&;
+    using const_reference        = const C&;
+    using iterator               = const_pointer;
+    using const_iterator         = const_pointer;
+    using reverse_iterator       = std::reverse_iterator<iterator>;
+    using const_reverse_iterator = std::reverse_iterator<const_iterator>;
+    using size_type              = std::size_t;
+    using difference_type        = std::ptrdiff_t;
+
+    static constexpr size_type npos = size_type(-1);
+
+    BasicStringView() noexcept;
+    BasicStringView(const std::basic_string<C, T>&) noexcept;
+    BasicStringView(const char* data, size_type size) noexcept;
+    BasicStringView(const char* c_str) noexcept;
+
+    explicit operator std::basic_string<C, T>() const;
+
+    const_iterator begin() const noexcept;
+    const_iterator end() const noexcept;
+    const_iterator cbegin() const noexcept;
+    const_iterator cend() const noexcept;
+
+    const_reverse_iterator rbegin() const noexcept;
+    const_reverse_iterator rend() const noexcept;
+    const_reverse_iterator crbegin() const noexcept;
+    const_reverse_iterator crend() const noexcept;
+
+    const_reference operator[](size_type i) const noexcept;
+    const_reference at(size_type i) const;
+    const_reference front() const noexcept;
+    const_reference back() const noexcept;
+
+    const_pointer data() const noexcept;
+    size_type size() const noexcept;
+    bool empty() const noexcept;
+
+    BasicStringView substr(size_type i = 0, size_type n = npos) const;
+    int compare(BasicStringView other) const noexcept;
+    size_type find(BasicStringView<C, T>, size_type i = 0) const noexcept;
+    size_type find(C ch, size_type i = 0) const noexcept;
+    size_type find_first_of(BasicStringView<C, T>, size_type i = 0) const noexcept;
+    size_type find_first_of(C ch, size_type i = 0) const noexcept;
+    size_type find_first_not_of(BasicStringView<C, T>, size_type i = 0) const noexcept;
+    size_type find_first_not_of(C ch, size_type i = 0) const noexcept;
+
+private:
+    const char* m_data = nullptr;
+    std::size_t m_size = 0;
+};
+
+template<class C, class T> bool operator==(BasicStringView<C, T>, BasicStringView<C, T>) noexcept;
+template<class C, class T> bool operator!=(BasicStringView<C, T>, BasicStringView<C, T>) noexcept;
+template<class C, class T> bool operator< (BasicStringView<C, T>, BasicStringView<C, T>) noexcept;
+template<class C, class T> bool operator> (BasicStringView<C, T>, BasicStringView<C, T>) noexcept;
+template<class C, class T> bool operator<=(BasicStringView<C, T>, BasicStringView<C, T>) noexcept;
+template<class C, class T> bool operator>=(BasicStringView<C, T>, BasicStringView<C, T>) noexcept;
+
+template<class C, class T>
+bool operator==(std::decay_t<BasicStringView<C, T>>, BasicStringView<C, T>) noexcept;
+template<class C, class T>
+bool operator!=(std::decay_t<BasicStringView<C, T>>, BasicStringView<C, T>) noexcept;
+template<class C, class T>
+bool operator< (std::decay_t<BasicStringView<C, T>>, BasicStringView<C, T>) noexcept;
+template<class C, class T>
+bool operator> (std::decay_t<BasicStringView<C, T>>, BasicStringView<C, T>) noexcept;
+template<class C, class T>
+bool operator<=(std::decay_t<BasicStringView<C, T>>, BasicStringView<C, T>) noexcept;
+template<class C, class T>
+bool operator>=(std::decay_t<BasicStringView<C, T>>, BasicStringView<C, T>) noexcept;
+
+template<class C, class T>
+bool operator==(BasicStringView<C, T>, std::decay_t<BasicStringView<C, T>>) noexcept;
+template<class C, class T>
+bool operator!=(BasicStringView<C, T>, std::decay_t<BasicStringView<C, T>>) noexcept;
+template<class C, class T>
+bool operator< (BasicStringView<C, T>, std::decay_t<BasicStringView<C, T>>) noexcept;
+template<class C, class T>
+bool operator> (BasicStringView<C, T>, std::decay_t<BasicStringView<C, T>>) noexcept;
+template<class C, class T>
+bool operator<=(BasicStringView<C, T>, std::decay_t<BasicStringView<C, T>>) noexcept;
+template<class C, class T>
+bool operator>=(BasicStringView<C, T>, std::decay_t<BasicStringView<C, T>>) noexcept;
+
+
+template<class C, class T>
+std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>&, BasicStringView<C, T>);
+
+
+using StringView = BasicStringView<char>;
+
+
+
+
+
+// Implementation
+
+template<class C, class T>
+inline BasicStringView<C, T>::BasicStringView() noexcept
+{
+}
+
+template<class C, class T>
+inline BasicStringView<C, T>::BasicStringView(const std::basic_string<C, T>& str) noexcept :
+    m_data{str.data()},
+    m_size{str.size()}
+{
+}
+
+template<class C, class T>
+inline BasicStringView<C, T>::BasicStringView(const char* data, size_type size) noexcept :
+    m_data{data},
+    m_size{size}
+{
+}
+
+template<class C, class T>
+inline BasicStringView<C, T>::BasicStringView(const char* c_str) noexcept :
+    m_data{c_str},
+    m_size{T::length(c_str)}
+{
+}
+
+template<class C, class T>
+inline BasicStringView<C, T>::operator std::basic_string<C, T>() const
+{
+    return {m_data, m_size}; // Throws
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::begin() const noexcept -> const_iterator
+{
+    return m_data;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::end() const noexcept -> const_iterator
+{
+    return m_data + m_size;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::cbegin() const noexcept -> const_iterator
+{
+    return begin();
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::cend() const noexcept -> const_iterator
+{
+    return end();
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::rbegin() const noexcept -> const_reverse_iterator
+{
+    return const_reverse_iterator{end()};
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::rend() const noexcept -> const_reverse_iterator
+{
+    return const_reverse_iterator{begin()};
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::crbegin() const noexcept -> const_reverse_iterator
+{
+    return rbegin();
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::crend() const noexcept -> const_reverse_iterator
+{
+    return rend();
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::operator[](size_type i) const noexcept -> const_reference
+{
+    return m_data[i];
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::at(size_type i) const -> const_reference
+{
+    if (REALM_LIKELY(i < m_size))
+        return m_data[i];
+    throw std::out_of_range("index");
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::front() const noexcept -> const_reference
+{
+    return m_data[0];
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::back() const noexcept -> const_reference
+{
+    return m_data[m_size - 1];
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::data() const noexcept -> const_pointer
+{
+    return m_data;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::size() const noexcept -> size_type
+{
+    return m_size;
+}
+
+template<class C, class T>
+inline bool BasicStringView<C, T>::empty() const noexcept
+{
+    return (size() == 0);
+}
+
+template<class C, class T>
+inline BasicStringView<C, T> BasicStringView<C, T>::substr(size_type i, size_type n) const
+{
+    if (REALM_LIKELY(i <= m_size)) {
+        size_type m = std::min(n, m_size - i);
+        return BasicStringView{m_data + i, m};
+    }
+    throw std::out_of_range("index");
+}
+
+template<class C, class T>
+inline int BasicStringView<C, T>::compare(BasicStringView other) const noexcept
+{
+    size_type n = std::min(m_size, other.m_size);
+    int ret = T::compare(m_data, other.m_data, n);
+    if (REALM_LIKELY(ret != 0))
+        return ret;
+    if (m_size < other.m_size)
+        return -1;
+    if (m_size > other.m_size)
+        return 1;
+    return 0;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::find(BasicStringView<C, T> v, size_type i) const noexcept ->
+    size_type
+{
+    if (REALM_LIKELY(!v.empty())) {
+        if (REALM_LIKELY(i < m_size)) {
+            const C* p = std::search(begin() + i, end(), v.begin(), v.end());
+            if (p != end())
+                return size_type(p - begin());
+        }
+        return npos;
+    }
+    return i;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::find(C ch, size_type i) const noexcept -> size_type
+{
+    if (REALM_LIKELY(i < m_size)) {
+        const C* p = std::find(begin() + i, end(), ch);
+        if (p != end())
+            return size_type(p - begin());
+    }
+    return npos;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::find_first_of(BasicStringView<C, T> v,
+                                                 size_type i) const noexcept -> size_type
+{
+    for (size_type j = i; j < m_size; ++j) {
+        if (REALM_LIKELY(v.find(m_data[j]) == npos))
+            continue;
+        return j;
+    }
+    return npos;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::find_first_of(C ch, size_type i) const noexcept -> size_type
+{
+    for (size_type j = i; j < m_size; ++j) {
+        if (REALM_UNLIKELY(m_data[j] == ch))
+            return j;
+    }
+    return npos;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::find_first_not_of(BasicStringView<C, T> v,
+                                                     size_type i) const noexcept -> size_type
+{
+    for (size_type j = i; j < m_size; ++j) {
+        if (REALM_UNLIKELY(v.find(m_data[j]) == npos))
+            return j;
+    }
+    return npos;
+}
+
+template<class C, class T>
+inline auto BasicStringView<C, T>::find_first_not_of(C ch, size_type i) const noexcept -> size_type
+{
+    for (size_type j = i; j < m_size; ++j) {
+        if (REALM_UNLIKELY(m_data[j] != ch))
+            return j;
+    }
+    return npos;
+}
+
+template<class C, class T>
+inline bool operator==(BasicStringView<C, T> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) == 0);
+}
+
+template<class C, class T>
+inline bool operator!=(BasicStringView<C, T> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) != 0);
+}
+
+template<class C, class T>
+inline bool operator<(BasicStringView<C, T> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) < 0);
+}
+
+template<class C, class T>
+inline bool operator>(BasicStringView<C, T> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) > 0);
+}
+
+template<class C, class T>
+inline bool operator<=(BasicStringView<C, T> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) <= 0);
+}
+
+template<class C, class T>
+inline bool operator>=(BasicStringView<C, T> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) >= 0);
+}
+
+template<class C, class T>
+inline bool operator==(std::decay_t<BasicStringView<C, T>> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) == 0);
+}
+
+template<class C, class T>
+inline bool operator!=(std::decay_t<BasicStringView<C, T>> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) != 0);
+}
+
+template<class C, class T>
+inline bool operator<(std::decay_t<BasicStringView<C, T>> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) < 0);
+}
+
+template<class C, class T>
+inline bool operator>(std::decay_t<BasicStringView<C, T>> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) > 0);
+}
+
+template<class C, class T>
+inline bool operator<=(std::decay_t<BasicStringView<C, T>> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) <= 0);
+}
+
+template<class C, class T>
+inline bool operator>=(std::decay_t<BasicStringView<C, T>> lhs, BasicStringView<C, T> rhs) noexcept
+{
+    return (lhs.compare(rhs) >= 0);
+}
+
+template<class C, class T>
+inline bool operator==(BasicStringView<C, T> lhs, std::decay_t<BasicStringView<C, T>> rhs) noexcept
+{
+    return (lhs.compare(rhs) == 0);
+}
+
+template<class C, class T>
+inline bool operator!=(BasicStringView<C, T> lhs, std::decay_t<BasicStringView<C, T>> rhs) noexcept
+{
+    return (lhs.compare(rhs) != 0);
+}
+
+template<class C, class T>
+inline bool operator<(BasicStringView<C, T> lhs, std::decay_t<BasicStringView<C, T>> rhs) noexcept
+{
+    return (lhs.compare(rhs) < 0);
+}
+
+template<class C, class T>
+inline bool operator>(BasicStringView<C, T> lhs, std::decay_t<BasicStringView<C, T>> rhs) noexcept
+{
+    return (lhs.compare(rhs) > 0);
+}
+
+template<class C, class T>
+inline bool operator<=(BasicStringView<C, T> lhs, std::decay_t<BasicStringView<C, T>> rhs) noexcept
+{
+    return (lhs.compare(rhs) <= 0);
+}
+
+template<class C, class T>
+inline bool operator>=(BasicStringView<C, T> lhs, std::decay_t<BasicStringView<C, T>> rhs) noexcept
+{
+    return (lhs.compare(rhs) >= 0);
+}
+
+template<class C, class T>
+inline std::basic_ostream<C, T>& operator<<(std::basic_ostream<C, T>& out,
+                                            BasicStringView<C, T> view)
+{
+    typename std::basic_ostream<C, T>::sentry sentry{out};
+    if (REALM_LIKELY(sentry))
+        out.write(view.data(), view.size());
+    return out;
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_STRING_VIEW_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/substitute.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/substitute.hpp
new file mode 100644
index 0000000..b551f31
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/substitute.hpp
@@ -0,0 +1,373 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_SUBSTITUTE_HPP
+#define REALM_UTIL_SUBSTITUTE_HPP
+
+#include <type_traits>
+#include <utility>
+#include <functional>
+#include <stdexcept>
+#include <vector>
+#include <map>
+#include <locale>
+#include <ostream>
+#include <sstream>
+
+#include <realm/util/optional.hpp>
+#include <realm/util/string_view.hpp>
+#include <realm/util/logger.hpp>
+
+
+namespace realm {
+namespace util {
+namespace _private {
+
+class SubstituterBase {
+protected:
+    template<class, class...> struct FindArg1;
+    template<class, bool, class, class...> struct FindArg2;
+    static StderrLogger s_default_logger;
+};
+
+} // namespace _private
+
+
+struct SubstituterConfig {
+    /// Allow parsing to be considered successful even when syntax errors are
+    /// detected. When enabled, logging will happen on `warn`, instead of
+    /// `error` level.
+    bool lenient = false;
+
+    /// The logger to be used by default. If left unspecified, the default
+    /// logger is one that logs to STDERR. In any case, logging happens only
+    /// during parsing.
+    Logger* logger = nullptr;
+};
+
+
+/// Perform variable substitutions in text.
+///
+/// A variable reference generally has the form `@{<name>}`, where `<name>` is
+/// the variable name. For example, if the variable name is `x`, then `@{x}` is
+/// a reference to that variable. If the variable name consists of a single
+/// letter, then a shorter form of reference, `@<name>` is available, i.e.,
+/// since `x` is a single letter, `@x` is a reference to `x`. As a special rule,
+/// `@@` is substituted by `@`.
+///
+/// Example of use:
+///
+///     struct CtxA { int y = 0; };
+///     struct CtxB { int x = 0; };
+///     using Subst = Substituter<const CtxA&, const CtxB&>;
+///     Subst subst;
+///     subst["x"] = &CtxB::x;
+///     subst["y"] = [](std::ostream& out, const CtxA& a, const CtxB&) {
+///         out << a.y;
+///     };
+///     Subst::Template templ;
+///     if (subst.parse("<@x:@y>\n", templ)) {
+///         CtxA a;
+///         CtxB b;
+///         for (int i = 0; i < 3; ++i) {
+///             templ.expand(std::cout, a, b);
+///             a.y += 1;
+///             b.x += 2;
+///         }
+///     }
+///
+/// This code should write
+///
+///     <0:0>
+///     <2:1>
+///     <4:2>
+///
+/// to STDOUT.
+template<class... A> class Substituter : private _private::SubstituterBase {
+public:
+    using EvalFunc = void(std::ostream&, A&...);
+    class ProtoDef;
+    class Template;
+
+    Substituter(SubstituterConfig = {}) noexcept;
+
+    ProtoDef operator[](const char* name) noexcept;
+
+    bool expand(StringView text, std::ostream&, A&&...) const;
+
+    bool parse(StringView text, Template&) const;
+    bool parse(StringView text, Template&, Logger&) const;
+
+private:
+    using size_type = StringView::size_type;
+    struct Substitution;
+
+    const bool m_lenient;
+    Logger& m_logger;
+
+    using Variables = std::map<StringView, std::function<EvalFunc>>;
+    Variables m_variables;
+
+    void define(const char* name, std::function<EvalFunc>);
+};
+
+
+
+template<class... A> class Substituter<A...>::ProtoDef {
+public:
+    template<class T> void operator=(T*);
+    template<class T, class C> void operator=(T C::*);
+    void operator=(std::function<EvalFunc>);
+
+private:
+    Substituter& m_substituter;
+    const char* m_name;
+
+    ProtoDef(Substituter& substituter, const char* name) noexcept;
+
+    friend class Substituter;
+};
+
+
+
+template<class... A> class Substituter<A...>::Template {
+public:
+    /// Uses std::locale::classic().
+    std::string expand(A&&...) const;
+
+    void expand(std::ostream&, A...) const;
+
+    bool refers_to(const char* name) const noexcept;
+
+private:
+    StringView m_text;
+    std::vector<Substitution> m_substitutions;
+
+    friend class Substituter;
+};
+
+
+
+
+
+// Implementation
+
+namespace _private {
+
+template<class T, bool, class A, class... B> struct SubstituterBase::FindArg2 {
+    static const T& find(const A&, const B&... b) noexcept
+    {
+        return FindArg1<T, B...>::find(b...);
+    }
+};
+
+template<class T, class A, class... B>
+struct SubstituterBase::FindArg2<T, true, A, B...> {
+    static const T& find(const A& a, const B&...) noexcept
+    {
+        return a;
+    }
+};
+
+template<class T, class A, class... B> struct SubstituterBase::FindArg1<T, A, B...> {
+    static const T& find(const A& a, const B&... b) noexcept
+    {
+        using P = typename std::remove_reference<A>::type*;
+        return FindArg2<T, std::is_convertible<P, const T*>::value, A, B...>::find(a, b...);
+    }
+};
+
+} // namespace _private
+
+template<class... A> struct Substituter<A...>::Substitution {
+    size_type begin, end;
+    const typename Variables::value_type* var_def;
+};
+
+template<class... A> inline Substituter<A...>::Substituter(SubstituterConfig config) noexcept :
+    m_lenient{config.lenient},
+    m_logger{config.logger ? *config.logger : s_default_logger}
+{
+}
+
+template<class... A> inline auto Substituter<A...>::operator[](const char* name) noexcept -> ProtoDef
+{
+    return ProtoDef{*this, name};
+}
+
+template<class... A>
+inline bool Substituter<A...>::expand(StringView text, std::ostream& out, A&&... arg) const
+{
+    Template templ;
+    if (parse(text, templ)) { // Throws
+        templ.expand(out, std::forward<A>(arg)...); // Throws
+        return true;
+    }
+    return false;
+}
+
+template<class... A> inline bool Substituter<A...>::parse(StringView text, Template& templ) const
+{
+    return parse(text, templ, m_logger); // Throws
+}
+
+template<class... A>
+bool Substituter<A...>::parse(StringView text, Template& templ, Logger& logger) const
+{
+    bool error = false;
+    Logger::Level log_level = (m_lenient ? Logger::Level::warn : Logger::Level::error);
+    std::vector<Substitution> substitutions;
+    StringView var_name;
+    size_type curr = 0;
+    size_type end  = text.size();
+    for (;;) {
+        size_type i = text.find('@', curr);
+        if (i == StringView::npos)
+            break;
+        if (i + 1 == end) {
+            logger.log(log_level, "Unterminated `@` at end of text"); // Throws
+            error = true;
+            break;
+        }
+        char ch = text[i + 1];
+        if (ch == '{') {
+            size_type j = text.find('}', i + 2);
+            if (j == StringView::npos) {
+                logger.log(log_level, "Unterminated `@{`"); // Throws
+                error = true;
+                curr = i + 2;
+                continue;
+            }
+            var_name = text.substr(i + 2, j - (i + 2));
+            curr = j + 1;
+        }
+        else {
+            var_name = text.substr(i + 1, 1); // Throws
+            curr = i + 2;
+        }
+        const typename Variables::value_type* var_def = nullptr;
+        if (ch != '@') {
+            auto k = m_variables.find(var_name);
+            if (k == m_variables.end()) {
+                logger.log(log_level, "Undefined variable `%1` in substitution `%2`", var_name,
+                           text.substr(i, curr - i)); // Throws
+                error = true;
+                continue;
+            }
+            var_def = &*k;
+        }
+        substitutions.push_back({i, curr, var_def}); // Throws
+    }
+    if (error && !m_lenient)
+        return false;
+    templ.m_text = text;
+    templ.m_substitutions = std::move(substitutions);
+    return true;
+}
+
+template<class... A>
+inline void Substituter<A...>::define(const char* name, std::function<EvalFunc> func)
+{
+    auto p = m_variables.emplace(name, std::move(func)); // Throws
+    bool was_inserted = p.second;
+    if (!was_inserted)
+        throw std::runtime_error("Multiple definitions for same variable name");
+}
+
+template<class... A> template<class T> inline void Substituter<A...>::ProtoDef::operator=(T* var)
+{
+    *this = [var](std::ostream& out, const A&...) {
+        out << *var; // Throws
+    };
+}
+
+template<class... A>
+template<class T, class C> inline void Substituter<A...>::ProtoDef::operator=(T C::* var)
+{
+    *this = [var](std::ostream& out, const A&... arg) {
+        const C& obj = FindArg1<C, A...>::find(arg...);
+        out << obj.*var; // Throws
+    };
+}
+
+template<class... A>
+inline void Substituter<A...>::ProtoDef::operator=(std::function<EvalFunc> func)
+{
+    m_substituter.define(m_name, std::move(func)); // Throws
+}
+
+template<class... A>
+inline Substituter<A...>::ProtoDef::ProtoDef(Substituter& substituter, const char* name) noexcept :
+    m_substituter{substituter},
+    m_name{name}
+{
+}
+
+template<class... A> std::string Substituter<A...>::Template::expand(A&&... arg) const
+{
+    std::ostringstream out;
+    out.imbue(std::locale::classic());
+    expand(out, std::forward<A>(arg)...); // Throws
+    std::string str = std::move(out).str(); // Throws
+    return str;
+}
+
+template<class... A> void Substituter<A...>::Template::expand(std::ostream& out, A... arg) const
+{
+    std::ios_base::fmtflags flags = out.flags();
+    try {
+        size_type curr = 0;
+        for (const Substitution& subst: m_substitutions) {
+            out << m_text.substr(curr, subst.begin - curr); // Throws
+            if (subst.var_def) {
+                const std::function<EvalFunc>& eval_func = subst.var_def->second;
+                eval_func(out, arg...); // Throws
+                out.flags(flags);
+            }
+            else {
+                out << "@"; // Throws
+            }
+            curr = subst.end;
+        }
+        out << m_text.substr(curr); // Throws
+    }
+    catch (...) {
+        out.flags(flags);
+        throw;
+    }
+}
+
+template<class... A>
+inline bool Substituter<A...>::Template::refers_to(const char* name) const noexcept
+{
+    StringView name_2 = name;
+    for (const auto& subst: m_substitutions) {
+        if (subst.var_def) {
+            if (name_2 != subst.var_def->first)
+                continue;
+            return true;
+        }
+    }
+    return false;
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_SUBSTITUTE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/system_process.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/system_process.hpp
new file mode 100644
index 0000000..c84addd
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/system_process.hpp
@@ -0,0 +1,204 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_SYSTEM_PROCESS_HPP
+#define REALM_UTIL_SYSTEM_PROCESS_HPP
+
+#include <string>
+#include <vector>
+#include <map>
+#include <thread>
+
+#include <realm/util/logger.hpp>
+
+
+namespace realm {
+namespace util {
+namespace sys_proc {
+
+using Environment = std::map<std::string, std::string>;
+
+/// This function is safe to call only when the caller can be sure that there
+/// are no threads that modify the environment concurrently.
+///
+/// When possible, call this function from the main thread before any other
+/// threads are created, such as early in `main()`.
+Environment copy_local_environment();
+
+
+struct ExitInfo {
+    /// If nonzero, the process was killed by a signal. The value is the
+    /// signal number.
+    int killed_by_signal = 0;
+
+    /// Zero if the process was killed by a signal, otherwise this is the value
+    /// returned by the `main()` function, or passed to `exit()`.
+    ///
+    /// On a POSIX system, if an error occurs during ::execve(), that is, after
+    /// ::fork(), an exit status of 127 will be used (aligned with
+    /// ::posix_spawn()).
+    int status = 0;
+
+    /// In some cases, ChildHandle::join() will set `signal_name` when it sets
+    /// `killed_by_signal` to a non-zero value. In those cases, `signal_name` is
+    /// set to point to a null-terminated string specifying the name of the
+    /// signal that killed the child process.
+    const char* signal_name = nullptr;
+
+    /// Returns true if, and only if both `killed_by_signal` and `status` are
+    /// zero.
+    explicit operator bool() const noexcept;
+};
+
+
+struct SpawnConfig {
+    /// When set to true, the child process will be able to use a
+    /// ParentDeathGuard to detect the destruction of the SystemProcess object
+    /// in the parent process, even when this happens implicitly due to abrupt
+    /// termination of the parent process.
+    bool parent_death_guard = false;
+
+    /// If a logger is specified here, the child process will be able to
+    /// instantiate a ParentLogger object, and messages logged through that
+    /// ParentLogger object will be transported to the parent process and
+    /// submitted to the logger pointed to by `logger`. The specified logger is
+    /// guaranteed to only be accessed while ChildHandle::join() is executing,
+    /// and only by the thread that executes ChildHandle::join(). See
+    /// ParentLogger for further details.
+    Logger* logger = nullptr;
+};
+
+
+class ChildHandle {
+public:
+    /// Wait for the child process to exit.
+    ///
+    /// If a logger was passed to spawn() (SpawnConfig::logger), then this
+    /// function will also transport log messages from the child to the parent
+    /// process while waiting for the child process to exit. See ParentLogger
+    /// for details.
+    ExitInfo join();
+
+    ChildHandle(ChildHandle&&) noexcept;
+    ~ChildHandle() noexcept;
+
+private:
+    class Impl;
+    std::unique_ptr<Impl> m_impl;
+
+    ChildHandle(Impl*) noexcept;
+
+    friend ChildHandle spawn(const std::string&, const std::vector<std::string>&,
+                             const Environment&, const SpawnConfig&);
+};
+
+
+/// Returns true if, and only if the spawn() functions work on this platform. If
+/// this function returns false, the spawn() functions will throw.
+bool is_spawn_supported() noexcept;
+
+
+//@{
+/// Spawn a child process.
+ChildHandle spawn(const std::string& path, const std::vector<std::string>& args = {},
+                  const Environment& = {});
+ChildHandle spawn(const std::string& path, const std::vector<std::string>& args,
+                  const Environment&, const SpawnConfig&);
+//@}
+
+
+/// Force a child process to terminate immediately if the parent process is
+/// terminated, or if the parent process destroys the ChildHandle object
+/// representing the child process.
+///
+/// If a child process instantiates an object of this type, and keeps it alive,
+/// and the child process was spawned with support for detection of parent
+/// termination (SpawnConfig::parent_death_guard), then the child process will
+/// be killed shortly after the parent destroys its ChildHandle object, even
+/// when this happens implicitly due to abrupt termination of the parent
+/// process.
+///
+/// If a child process instantiates an object of this type, that object must be
+/// instantiated by the main thread, and before any other thread is spawned in
+/// the child process.
+///
+/// In order for the guard to have the intended effect, it must be instantiated
+/// immediately in the child process, and be kept alive for as long as the child
+/// process is running.
+class ParentDeathGuard {
+public:
+    ParentDeathGuard();
+    ~ParentDeathGuard() noexcept;
+
+private:
+    std::thread m_thread;
+    int m_stop_pipe_write = -1;
+};
+
+
+/// A logger that can transport log messages from the child to the parent
+/// process.
+///
+/// If the parent process specifies a logger when spawning a child process
+/// (SpawnConfig::logger), then that child process can instantiate a
+/// ParentLogger object, and messages logged through it will be transported to
+/// the parent process. While the parent process is executing
+/// ChildHandle::join(), those messages will be written to the logger specified
+/// by the parent process.
+///
+/// If a child process instantiates an object of this type, that object must be
+/// instantiated by the main thread, and before any other thread is spawned in
+/// the child process.
+///
+/// At most one ParentLogger object may be instantiated per child process.
+///
+/// This logger is **not** thread-safe.
+class ParentLogger : public RootLogger {
+public:
+    ParentLogger();
+    ~ParentLogger() noexcept;
+
+protected:
+    void do_log(Level, std::string) override final;
+
+private:
+    int m_pipe_write = -1;
+};
+
+
+
+
+// Implementation
+
+inline ExitInfo::operator bool() const noexcept
+{
+    return (killed_by_signal == 0 && status == 0);
+}
+
+inline ChildHandle spawn(const std::string& path, const std::vector<std::string>& args,
+                         const Environment& env)
+{
+    return spawn(path, args, env, SpawnConfig{}); // Throws
+}
+
+} // namespace sys_proc
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_SYSTEM_PROCESS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/terminate.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/terminate.hpp
new file mode 100644
index 0000000..4e6034e
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/terminate.hpp
@@ -0,0 +1,59 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TERMINATE_HPP
+#define REALM_UTIL_TERMINATE_HPP
+
+#include <cstdlib>
+
+#include <realm/util/features.h>
+#include <realm/util/to_string.hpp>
+#include <realm/version.hpp>
+
+#define REALM_TERMINATE(msg) realm::util::terminate((msg), __FILE__, __LINE__)
+
+namespace realm {
+namespace util {
+
+REALM_NORETURN void terminate(const char* message, const char* file, long line,
+                              std::initializer_list<Printable>&& = {}) noexcept;
+REALM_NORETURN void terminate_with_info(const char* message, const char* file, long line,
+                                        const char* interesting_names,
+                                        std::initializer_list<Printable>&& = {}) noexcept;
+
+// LCOV_EXCL_START
+template <class... Ts>
+REALM_NORETURN void terminate(const char* message, const char* file, long line, Ts... infos) noexcept
+{
+    static_assert(sizeof...(infos) == 2 || sizeof...(infos) == 4 || sizeof...(infos) == 6,
+                  "Called realm::util::terminate() with wrong number of arguments");
+    terminate(message, file, line, {Printable(infos)...});
+}
+
+template <class... Args>
+REALM_NORETURN void terminate_with_info(const char* assert_message, int line, const char* file,
+                                        const char* interesting_names, Args&&... interesting_values) noexcept
+{
+    terminate_with_info(assert_message, file, line, interesting_names, {Printable(interesting_values)...});
+}
+// LCOV_EXCL_STOP
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TERMINATE_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/thread.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/thread.hpp
new file mode 100644
index 0000000..8ca5e38
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/thread.hpp
@@ -0,0 +1,759 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_THREAD_HPP
+#define REALM_UTIL_THREAD_HPP
+
+#include <exception>
+
+#ifdef _WIN32
+#include <thread>
+#include <condition_variable> // for windows non-interprocess condvars we use std::condition_variable
+#include <Windows.h>
+#include <process.h> // _getpid()
+#else
+#include <pthread.h>
+#endif
+
+// Use below line to enable a thread bug detection tool. Note: Will make program execution slower.
+// #include <../test/pthread_test.hpp>
+
+#include <cerrno>
+#include <cstddef>
+#include <string>
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/terminate.hpp>
+#include <memory>
+
+#include <atomic>
+
+namespace realm {
+namespace util {
+
+
+/// A separate thread of execution.
+///
+/// This class is a C++03 compatible reproduction of a subset of std::thread
+/// from C++11 (when discounting Thread::start(), Thread::set_name(), and
+/// Thread::get_name()).
+class Thread {
+public:
+    Thread();
+    ~Thread() noexcept;
+
+    template <class F>
+    explicit Thread(F func);
+
+    // Disable copying. It is an error to copy this Thread class.
+    Thread(const Thread&) = delete;
+    Thread& operator=(const Thread&) = delete;
+
+    Thread(Thread&&);
+
+    /// This method is an extension of the API provided by
+    /// std::thread. This method exists because proper move semantics
+    /// is unavailable in C++03. If move semantics had been available,
+    /// calling `start(func)` would have been equivalent to `*this =
+    /// Thread(func)`. Please see std::thread::operator=() for
+    /// details.
+    template <class F>
+    void start(F func);
+
+    bool joinable() noexcept;
+
+    void join();
+
+    // If supported by the platform, set the name of the calling thread (mainly
+    // for debugging purposes). The name will be silently clamped to whatever
+    // limit the platform places on these names. Linux places a limit of 15
+    // characters for these names.
+    static void set_name(const std::string&);
+
+    // If supported by the platform, this function assigns the name of the
+    // calling thread to \a name, and returns true, otherwise it does nothing
+    // and returns false.
+    static bool get_name(std::string& name);
+
+private:
+
+#ifdef _WIN32
+    std::thread m_std_thread;
+#else    
+    pthread_t m_id;
+#endif
+    bool m_joinable;
+    typedef void* (*entry_func_type)(void*);
+
+    void start(entry_func_type, void* arg);
+
+    template <class>
+    static void* entry_point(void*) noexcept;
+
+    REALM_NORETURN static void create_failed(int);
+    REALM_NORETURN static void join_failed(int);
+};
+
+
+/// Low-level mutual exclusion device.
+class Mutex {
+public:
+    Mutex();
+    ~Mutex() noexcept;
+
+    struct process_shared_tag {
+    };
+    /// Initialize this mutex for use across multiple processes. When
+    /// constructed this way, the instance may be placed in memory
+    /// shared by multiple processes, as well as in a memory mapped
+    /// file. Such a mutex remains valid even after the constructing
+    /// process terminates. Deleting the instance (freeing the memory
+    /// or deleting the file) without first calling the destructor is
+    /// legal and will not cause any system resources to be leaked.
+    Mutex(process_shared_tag);
+
+    // Disable copying.
+    Mutex(const Mutex&) = delete;
+    Mutex& operator=(const Mutex&) = delete;
+
+    friend class LockGuard;
+    friend class UniqueLock;
+    friend class InterprocessCondVar;
+
+    void lock() noexcept;
+    bool try_lock() noexcept;
+    void unlock() noexcept;
+
+protected:
+#ifdef _WIN32
+    // Used for non-process-shared mutex. We only know at runtime whether or not to use it, depending on if we call
+    // Mutex::Mutex(process_shared_tag)
+    CRITICAL_SECTION m_critical_section;
+#else
+    pthread_mutex_t m_impl = PTHREAD_MUTEX_INITIALIZER;
+#endif
+
+    struct no_init_tag {
+    };
+    Mutex(no_init_tag)
+    {
+    }
+
+    void init_as_regular();
+    void init_as_process_shared(bool robust_if_available);
+
+    REALM_NORETURN static void init_failed(int);
+    REALM_NORETURN static void attr_init_failed(int);
+    REALM_NORETURN static void destroy_failed(int) noexcept;
+    REALM_NORETURN static void lock_failed(int) noexcept;
+
+private:
+    friend class CondVar;
+    friend class RobustMutex;
+};
+
+
+/// A simple mutex ownership wrapper.
+class LockGuard {
+public:
+    LockGuard(Mutex&) noexcept;
+    ~LockGuard() noexcept;
+
+private:
+    Mutex& m_mutex;
+    friend class CondVar;
+};
+
+
+/// See UniqueLock.
+struct defer_lock_tag {
+};
+
+/// A general-purpose mutex ownership wrapper supporting deferred
+/// locking as well as repeated unlocking and relocking.
+class UniqueLock {
+public:
+    UniqueLock(Mutex&) noexcept;
+    UniqueLock(Mutex&, defer_lock_tag) noexcept;
+    ~UniqueLock() noexcept;
+
+    void lock() noexcept;
+    void unlock() noexcept;
+    bool holds_lock() noexcept;
+
+private:
+    Mutex* m_mutex;
+    bool m_is_locked;
+};
+
+
+/// A robust version of a process-shared mutex.
+///
+/// A robust mutex is one that detects whether a thread (or process)
+/// has died while holding a lock on the mutex.
+///
+/// When the present platform does not offer support for robust
+/// mutexes, this mutex class behaves as a regular process-shared
+/// mutex, which means that if a thread dies while holding a lock, any
+/// future attempt at locking will block indefinitely.
+class RobustMutex : private Mutex {
+public:
+    RobustMutex();
+    ~RobustMutex() noexcept;
+
+    static bool is_robust_on_this_platform() noexcept;
+
+    class NotRecoverable;
+
+    /// \param recover_func If the present platform does not support
+    /// robust mutexes, this function is never called. Otherwise it is
+    /// called if, and only if a thread has died while holding a
+    /// lock. The purpose of the function is to reestablish a
+    /// consistent shared state. If it fails to do this by throwing an
+    /// exception, the mutex enters the 'unrecoverable' state where
+    /// any future attempt at locking it will fail and cause
+    /// NotRecoverable to be thrown. This function is advised to throw
+    /// NotRecoverable when it fails, but it may throw any exception.
+    ///
+    /// \throw NotRecoverable If thrown by the specified recover
+    /// function, or if the mutex has entered the 'unrecoverable'
+    /// state due to a different thread throwing from its recover
+    /// function.
+    template <class Func>
+    void lock(Func recover_func);
+
+    template <class Func>
+    bool try_lock(Func recover_func);
+
+    void unlock() noexcept;
+
+    /// Low-level locking of robust mutex.
+    ///
+    /// If the present platform does not support robust mutexes, this
+    /// function always returns true. Otherwise it returns false if,
+    /// and only if a thread has died while holding a lock.
+    ///
+    /// \note Most application should never call this function
+    /// directly. It is called automatically when using the ordinary
+    /// lock() function.
+    ///
+    /// \throw NotRecoverable If this mutex has entered the "not
+    /// recoverable" state. It enters this state if
+    /// mark_as_consistent() is not called between a call to
+    /// robust_lock() that returns false and the corresponding call to
+    /// unlock().
+    bool low_level_lock();
+
+    /// Low-level try-lock of robust mutex
+    ///
+    /// If the present platform does not support robust mutexes, this
+    /// function always returns 0 or 1. Otherwise it returns -1 if,
+    /// and only if a thread has died while holding a lock.
+    ///
+    /// Returns 1 if the lock is succesfully obtained.
+    /// Returns 0 if the lock is held by somebody else (not obtained)
+    /// Returns -1 if a thread has died while holding a lock.
+    ///
+    /// \note Most application should never call this function
+    /// directly. It is called automatically when using the ordinary
+    /// lock() function.
+    ///
+    /// \throw NotRecoverable If this mutex has entered the "not
+    /// recoverable" state. It enters this state if
+    /// mark_as_consistent() is not called between a call to
+    /// robust_lock() that returns false and the corresponding call to
+    /// unlock().
+    int try_low_level_lock();
+
+    /// Pull this mutex out of the 'inconsistent' state.
+    ///
+    /// Must be called only after low_level_lock() has returned false.
+    ///
+    /// \note Most application should never call this function
+    /// directly. It is called automatically when using the ordinary
+    /// lock() function.
+    void mark_as_consistent() noexcept;
+
+    /// Attempt to check if this mutex is a valid object.
+    ///
+    /// This attempts to trylock() the mutex, and if that fails returns false if
+    /// the return value indicates that the low-level mutex is invalid (which is
+    /// distinct from 'inconsistent'). Although pthread_mutex_trylock() may
+    /// return EINVAL if the argument is not an initialized mutex object, merely
+    /// attempting to check if an arbitrary blob of memory is a mutex object may
+    /// involve undefined behavior, so it is only safe to assume that this
+    /// function will run correctly when it is known that the mutex object is
+    /// valid.
+    bool is_valid() noexcept;
+
+    friend class CondVar;
+};
+
+class RobustMutex::NotRecoverable : public std::exception {
+public:
+    const char* what() const noexcept override
+    {
+        return "Failed to recover consistent state of shared memory";
+    }
+};
+
+
+/// A simple robust mutex ownership wrapper.
+class RobustLockGuard {
+public:
+    /// \param m the mutex to guard
+    /// \param func See RobustMutex::lock().
+    template <class TFunc>
+    RobustLockGuard(RobustMutex& m, TFunc func);
+    ~RobustLockGuard() noexcept;
+
+private:
+    RobustMutex& m_mutex;
+    friend class CondVar;
+};
+
+
+/// Condition variable for use in synchronization monitors.
+class CondVar {
+public:
+    CondVar();
+    ~CondVar() noexcept;
+
+    struct process_shared_tag {
+    };
+
+    /// Initialize this condition variable for use across multiple
+    /// processes. When constructed this way, the instance may be
+    /// placed in memory shared by multimple processes, as well as in
+    /// a memory mapped file. Such a condition variable remains valid
+    /// even after the constructing process terminates. Deleting the
+    /// instance (freeing the memory or deleting the file) without
+    /// first calling the destructor is legal and will not cause any
+    /// system resources to be leaked.
+    CondVar(process_shared_tag);
+
+    /// Wait for another thread to call notify() or notify_all().
+    void wait(LockGuard& l) noexcept;
+    template <class Func>
+    void wait(RobustMutex& m, Func recover_func, const struct timespec* tp = nullptr);
+
+    /// If any threads are wating for this condition, wake up at least
+    /// one.
+    void notify() noexcept;
+
+    /// Wake up every thread that is currently wating on this
+    /// condition.
+    void notify_all() noexcept;
+
+private:
+#ifdef _WIN32
+    CONDITION_VARIABLE m_condvar = CONDITION_VARIABLE_INIT;
+#else
+    pthread_cond_t m_impl;
+#endif
+
+    REALM_NORETURN static void init_failed(int);
+    REALM_NORETURN static void attr_init_failed(int);
+    REALM_NORETURN static void destroy_failed(int) noexcept;
+    void handle_wait_error(int error);
+};
+
+
+// Implementation:
+
+inline Thread::Thread()
+    : m_joinable(false)
+{
+}
+
+template <class F>
+inline Thread::Thread(F func)
+    : m_joinable(true)
+{
+    std::unique_ptr<F> func2(new F(func));       // Throws
+    start(&Thread::entry_point<F>, func2.get()); // Throws
+    func2.release();
+}
+
+inline Thread::Thread(Thread&& thread)
+{
+#ifndef _WIN32
+    m_id = thread.m_id;
+    m_joinable = thread.m_joinable;
+    thread.m_joinable = false;
+#endif
+}
+
+template <class F>
+inline void Thread::start(F func)
+{
+    if (m_joinable)
+        std::terminate();
+    std::unique_ptr<F> func2(new F(func));       // Throws
+    start(&Thread::entry_point<F>, func2.get()); // Throws
+    func2.release();
+    m_joinable = true;
+}
+
+inline Thread::~Thread() noexcept
+{
+    if (m_joinable)
+        REALM_TERMINATE("Destruction of joinable thread");
+}
+
+inline bool Thread::joinable() noexcept
+{
+    return m_joinable;
+}
+
+inline void Thread::start(entry_func_type entry_func, void* arg)
+{
+#ifdef _WIN32
+    m_std_thread = std::thread(entry_func, arg);
+#else
+    const pthread_attr_t* attr = nullptr; // Use default thread attributes
+    int r = pthread_create(&m_id, attr, entry_func, arg);
+    if (REALM_UNLIKELY(r != 0))
+        create_failed(r); // Throws
+#endif
+}
+
+template <class F>
+inline void* Thread::entry_point(void* cookie) noexcept
+{
+    std::unique_ptr<F> func(static_cast<F*>(cookie));
+    try {
+        (*func)();
+    }
+    catch (...) {
+        std::terminate();
+    }
+    return 0;
+}
+
+
+inline Mutex::Mutex()
+{
+    init_as_regular();
+}
+
+inline Mutex::Mutex(process_shared_tag)
+{
+    bool robust_if_available = false;
+    init_as_process_shared(robust_if_available);
+}
+
+inline Mutex::~Mutex() noexcept
+{
+#ifndef _WIN32
+    int r = pthread_mutex_destroy(&m_impl);
+    if (REALM_UNLIKELY(r != 0))
+        destroy_failed(r);
+#else
+    DeleteCriticalSection(&m_critical_section);
+#endif
+}
+
+inline void Mutex::init_as_regular()
+{
+#ifndef _WIN32
+    int r = pthread_mutex_init(&m_impl, 0);
+    if (REALM_UNLIKELY(r != 0))
+        init_failed(r);
+#else
+    InitializeCriticalSection(&m_critical_section);
+#endif
+}
+
+inline void Mutex::lock() noexcept
+{
+#ifdef _WIN32
+    EnterCriticalSection(&m_critical_section);
+#else
+    int r = pthread_mutex_lock(&m_impl);
+    if (REALM_LIKELY(r == 0))
+        return;
+    lock_failed(r);
+#endif
+}
+
+inline bool Mutex::try_lock() noexcept
+{
+#ifdef _WIN32
+    return TryEnterCriticalSection(&m_critical_section);
+#else
+    int r = pthread_mutex_trylock(&m_impl);
+    if (r == EBUSY) {
+        return false;
+    }
+    else if (r == 0) {
+        return true;
+    }
+    lock_failed(r);
+#endif
+}
+
+inline void Mutex::unlock() noexcept
+{
+#ifdef _WIN32
+    LeaveCriticalSection(&m_critical_section);
+#else
+    int r = pthread_mutex_unlock(&m_impl);
+    REALM_ASSERT(r == 0);
+#endif
+}
+
+
+inline LockGuard::LockGuard(Mutex& m) noexcept
+    : m_mutex(m)
+{
+    m_mutex.lock();
+}
+
+inline LockGuard::~LockGuard() noexcept
+{
+    m_mutex.unlock();
+}
+
+
+inline UniqueLock::UniqueLock(Mutex& m) noexcept
+    : m_mutex(&m)
+{
+    m_mutex->lock();
+    m_is_locked = true;
+}
+
+inline UniqueLock::UniqueLock(Mutex& m, defer_lock_tag) noexcept
+    : m_mutex(&m)
+{
+    m_is_locked = false;
+}
+
+inline UniqueLock::~UniqueLock() noexcept
+{
+    if (m_is_locked)
+        m_mutex->unlock();
+}
+
+inline bool UniqueLock::holds_lock() noexcept
+{
+    return m_is_locked;
+}
+
+inline void UniqueLock::lock() noexcept
+{
+    m_mutex->lock();
+    m_is_locked = true;
+}
+
+inline void UniqueLock::unlock() noexcept
+{
+    m_mutex->unlock();
+    m_is_locked = false;
+}
+
+template <typename TFunc>
+inline RobustLockGuard::RobustLockGuard(RobustMutex& m, TFunc func)
+    : m_mutex(m)
+{
+    m_mutex.lock(func);
+}
+
+inline RobustLockGuard::~RobustLockGuard() noexcept
+{
+    m_mutex.unlock();
+}
+
+
+inline RobustMutex::RobustMutex()
+    : Mutex(no_init_tag())
+{
+    bool robust_if_available = true;
+    init_as_process_shared(robust_if_available);
+}
+
+inline RobustMutex::~RobustMutex() noexcept
+{
+}
+
+template <class Func>
+inline void RobustMutex::lock(Func recover_func)
+{
+    bool no_thread_has_died = low_level_lock(); // Throws
+    if (REALM_LIKELY(no_thread_has_died))
+        return;
+    try {
+        recover_func(); // Throws
+        mark_as_consistent();
+        // If we get this far, the protected memory has been
+        // brought back into a consistent state, and the mutex has
+        // been notified about this. This means that we can safely
+        // enter the applications critical section.
+    }
+    catch (...) {
+        // Unlocking without first calling mark_as_consistent()
+        // means that the mutex enters the "not recoverable"
+        // state, which will cause all future attempts at locking
+        // to fail.
+        unlock();
+        throw;
+    }
+}
+
+template <class Func>
+inline bool RobustMutex::try_lock(Func recover_func)
+{
+    int lock_result = try_low_level_lock(); // Throws
+    if (lock_result == 0) return false;
+    bool no_thread_has_died = lock_result == 1;
+    if (REALM_LIKELY(no_thread_has_died))
+        return true;
+    try {
+        recover_func(); // Throws
+        mark_as_consistent();
+        // If we get this far, the protected memory has been
+        // brought back into a consistent state, and the mutex has
+        // been notified aboit this. This means that we can safely
+        // enter the applications critical section.
+    }
+    catch (...) {
+        // Unlocking without first calling mark_as_consistent()
+        // means that the mutex enters the "not recoverable"
+        // state, which will cause all future attempts at locking
+        // to fail.
+        unlock();
+        throw;
+    }
+    return true;
+}
+
+inline void RobustMutex::unlock() noexcept
+{
+    Mutex::unlock();
+}
+
+
+inline CondVar::CondVar()
+{
+#ifndef _WIN32
+    int r = pthread_cond_init(&m_impl, 0);
+    if (REALM_UNLIKELY(r != 0))
+        init_failed(r);
+#endif
+}
+
+inline CondVar::~CondVar() noexcept
+{
+#ifndef _WIN32
+    int r = pthread_cond_destroy(&m_impl);
+    if (REALM_UNLIKELY(r != 0))
+        destroy_failed(r);
+#endif
+}
+
+inline void CondVar::wait(LockGuard& l) noexcept
+{
+#ifdef _WIN32
+    SleepConditionVariableCS(&m_condvar, &l.m_mutex.m_critical_section, INFINITE);
+#else
+    int r = pthread_cond_wait(&m_impl, &l.m_mutex.m_impl);
+    if (REALM_UNLIKELY(r != 0))
+        REALM_TERMINATE("pthread_cond_wait() failed");
+#endif
+}
+
+template <class Func>
+inline void CondVar::wait(RobustMutex& m, Func recover_func, const struct timespec* tp)
+{
+    int r;
+
+    if (!tp) {
+#ifdef _WIN32
+        if (!SleepConditionVariableCS(&m_condvar, &m.m_critical_section, INFINITE))
+            r = GetLastError();
+        else
+            r = 0;
+#else
+        r = pthread_cond_wait(&m_impl, &m.m_impl);
+#endif
+    }
+    else {
+#ifdef _WIN32
+        if (!SleepConditionVariableCS(&m_condvar, &m.m_critical_section, tp->tv_sec / 1000)) {
+            r = GetLastError();
+            if (r == ERROR_TIMEOUT)
+                return;
+        } else {
+            r = 0
+        }
+#else
+        r = pthread_cond_timedwait(&m_impl, &m.m_impl, tp);
+        if (r == ETIMEDOUT)
+            return;
+#endif
+    }
+
+    if (REALM_LIKELY(r == 0))
+        return;
+
+    handle_wait_error(r);
+
+    try {
+        recover_func(); // Throws
+        m.mark_as_consistent();
+        // If we get this far, the protected memory has been
+        // brought back into a consistent state, and the mutex has
+        // been notified aboit this. This means that we can safely
+        // enter the applications critical section.
+    }
+    catch (...) {
+        // Unlocking without first calling mark_as_consistent()
+        // means that the mutex enters the "not recoverable"
+        // state, which will cause all future attempts at locking
+        // to fail.
+        m.unlock();
+        throw;
+    }
+}
+
+inline void CondVar::notify() noexcept
+{
+#ifdef _WIN32
+    WakeConditionVariable(&m_condvar);
+#else
+    int r = pthread_cond_signal(&m_impl);
+    REALM_ASSERT(r == 0);
+#endif
+}
+
+inline void CondVar::notify_all() noexcept
+{
+#ifdef _WIN32
+    WakeAllConditionVariable(&m_condvar);
+#else
+    int r = pthread_cond_broadcast(&m_impl);
+    REALM_ASSERT(r == 0);
+#endif
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_THREAD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/thread_exec_guard.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/thread_exec_guard.hpp
new file mode 100644
index 0000000..b779e5a
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/thread_exec_guard.hpp
@@ -0,0 +1,334 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_THREAD_EXEC_GUARD_HPP
+#define REALM_UTIL_THREAD_EXEC_GUARD_HPP
+
+#include <exception>
+#include <utility>
+#include <string>
+
+#include <realm/util/thread.hpp>
+#include <realm/util/signal_blocker.hpp>
+
+
+namespace realm {
+namespace util {
+
+/// Execute a `R::run()` using a managed thread.
+///
+/// \tparam R The type of the runnable object. This type must satisfy the
+/// requirements of the Runnable concept. See ThreadExecGuardWithParent.
+template<class R> class ThreadExecGuard {
+public:
+    explicit ThreadExecGuard(R& runnable);
+
+    ThreadExecGuard(ThreadExecGuard&&) = default;
+
+    /// If start() or start_with_signals_blocked() was successfully executed,
+    /// and stop_and_rethrow() has not been called, call `R::stop()`, and then
+    /// wait for the thread to terminate (join).
+    ~ThreadExecGuard() noexcept = default;
+
+    // @{
+    /// Launch a thread and make it execute `R::run()` of the associated
+    /// "runnable" object.
+    ///
+    /// At most one of these functions are allowed to be called on a particular
+    /// guard object, and it must only be called once.
+    void start();
+    void start(const std::string& thread_name);
+    void start_with_signals_blocked();
+    void start_with_signals_blocked(const std::string& thread_name);
+    // @}
+
+    /// If start() or start_with_signals_blocked() was successfully executed,
+    /// call `R::stop()`, wait for the thread to terminate (join), and then, if
+    /// an exception was thrown by `R::run()`, rethrow it.
+    void stop_and_rethrow();
+
+private:
+    struct State {
+        R& runnable;
+        util::Thread thread;
+        std::exception_ptr exception;
+        State(R&) noexcept;
+        ~State() noexcept;
+        void start(const std::string* thread_name);
+        void stop_and_rethrow();
+    };
+
+    std::unique_ptr<State> m_state;
+};
+
+
+/// Execute a `R::run()` using a managed thread.
+///
+/// \tparam R The type of the runnable object. This type must satisfy the
+/// requirements of the Runnable concept. See below.
+///
+/// \tparam P The type of the object representing the parent thread. This type
+/// must satisfy the requirements of the Stoppable concept. See below.
+///
+/// A type satisfies the requirements of the *Stoppable* concept, if
+///  - it has a nonthrowing member function named `stop()`, and
+///  - `stop()` is thread-safe, and
+///  - `stop()` is idempotent (can be called multiple times).
+///
+/// A type satisfies the requirements of the *Runnable* concept, if
+///  - it satisfies the requirements of the Stoppable concept, and
+///  - it has a member function named `run()`, and
+///  - `run()` will stop executing within a reasonable amount of time after
+///    `stop()` has been called.
+///
+template<class R, class P> class ThreadExecGuardWithParent {
+public:
+    explicit ThreadExecGuardWithParent(R& runnable, P& parent);
+
+    ThreadExecGuardWithParent(ThreadExecGuardWithParent&&) = default;
+
+    /// If start() or start_with_signals_blocked() was successfully executed,
+    /// and stop_and_rethrow() has not been called, call `R::stop()`, and then
+    /// wait for the thread to terminate (join).
+    ~ThreadExecGuardWithParent() noexcept = default;
+
+    // @{
+    /// Launch a thread and make it execute `R::run()` of the associated
+    /// "runnable" object.
+    ///
+    /// If `R::run()` throws, call `P::stop()` on the specified parent.
+    ///
+    /// At most one of these functions are allowed to be called on a particular
+    /// guard object, and it must only be called once.
+    void start();
+    void start(const std::string& thread_name);
+    void start_with_signals_blocked();
+    void start_with_signals_blocked(const std::string& thread_name);
+    // @}
+
+    /// If start() or start_with_signals_blocked() was successfully executed,
+    /// call `R::stop()`, wait for the thread to terminate (join), and then, if
+    /// an exception was thrown by `R::run()`, rethrow it.
+    void stop_and_rethrow();
+
+private:
+    struct State {
+        R& runnable;
+        P& parent;
+        util::Thread thread;
+        std::exception_ptr exception;
+        State(R&, P&) noexcept;
+        ~State() noexcept;
+        void start(const std::string* thread_name);
+        void stop_and_rethrow();
+    };
+
+    std::unique_ptr<State> m_state;
+};
+
+
+template<class R> ThreadExecGuard<R> make_thread_exec_guard(R& runnable);
+
+template<class R, class P>
+ThreadExecGuardWithParent<R, P> make_thread_exec_guard(R& runnable, P& parent);
+
+
+
+
+// Implementation
+
+template<class R> inline ThreadExecGuard<R>::ThreadExecGuard(R& runnable) :
+    m_state{std::make_unique<State>(runnable)} // Throws
+{
+}
+
+template<class R> inline void ThreadExecGuard<R>::start()
+{
+    const std::string* thread_name = nullptr;
+    m_state->start(thread_name); // Throws
+}
+
+template<class R> inline void ThreadExecGuard<R>::start(const std::string& thread_name)
+{
+    m_state->start(&thread_name); // Throws
+}
+
+template<class R> inline void ThreadExecGuard<R>::start_with_signals_blocked()
+{
+    SignalBlocker sb;
+    const std::string* thread_name = nullptr;
+    m_state->start(thread_name); // Throws
+}
+
+template<class R>
+inline void ThreadExecGuard<R>::start_with_signals_blocked(const std::string& thread_name)
+{
+    SignalBlocker sb;
+    m_state->start(&thread_name); // Throws
+}
+
+template<class R> inline void ThreadExecGuard<R>::stop_and_rethrow()
+{
+    m_state->stop_and_rethrow(); // Throws
+}
+
+template<class R> inline ThreadExecGuard<R>::State::State(R& r) noexcept :
+    runnable{r}
+{
+}
+
+template<class R> inline ThreadExecGuard<R>::State::~State() noexcept
+{
+    if (thread.joinable()) {
+        runnable.stop();
+        thread.join();
+    }
+}
+
+template<class R> inline void ThreadExecGuard<R>::State::start(const std::string* thread_name)
+{
+    bool set_thread_name = false;
+    std::string thread_name_2;
+    if (thread_name) {
+        set_thread_name = true;
+        thread_name_2 = *thread_name; // Throws (copy)
+    }
+    auto run = [this, set_thread_name, thread_name=std::move(thread_name_2)]() noexcept {
+        try {
+            if (set_thread_name)
+                util::Thread::set_name(thread_name); // Throws
+            runnable.run(); // Throws
+        }
+        catch (...) {
+            exception = std::current_exception();
+        }
+    };
+    thread.start(std::move(run)); // Throws
+}
+
+template<class R> inline void ThreadExecGuard<R>::State::stop_and_rethrow()
+{
+    if (thread.joinable()) {
+        runnable.stop();
+        thread.join();
+        if (exception)
+            std::rethrow_exception(exception); // Throws
+    }
+}
+
+template<class R, class P>
+inline ThreadExecGuardWithParent<R, P>::ThreadExecGuardWithParent(R& runnable, P& parent) :
+    m_state{std::make_unique<State>(runnable, parent)} // Throws
+{
+}
+
+template<class R, class P> inline void ThreadExecGuardWithParent<R, P>::start()
+{
+    const std::string* thread_name = nullptr;
+    m_state->start(thread_name); // Throws
+}
+
+template<class R, class P>
+inline void ThreadExecGuardWithParent<R, P>::start(const std::string& thread_name)
+{
+    m_state->start(&thread_name); // Throws
+}
+
+template<class R, class P> inline void ThreadExecGuardWithParent<R, P>::start_with_signals_blocked()
+{
+    SignalBlocker sb;
+    const std::string* thread_name = nullptr;
+    m_state->start(thread_name); // Throws
+}
+
+template<class R, class P>
+inline void ThreadExecGuardWithParent<R, P>::start_with_signals_blocked(const std::string& thread_name)
+{
+    SignalBlocker sb;
+    m_state->start(&thread_name); // Throws
+}
+
+template<class R, class P> inline void ThreadExecGuardWithParent<R, P>::stop_and_rethrow()
+{
+    m_state->stop_and_rethrow(); // Throws
+}
+
+template<class R, class P>
+inline ThreadExecGuardWithParent<R, P>::State::State(R& r, P& p) noexcept :
+    runnable{r},
+    parent{p}
+{
+}
+
+template<class R, class P> inline ThreadExecGuardWithParent<R, P>::State::~State() noexcept
+{
+    if (thread.joinable()) {
+        runnable.stop();
+        thread.join();
+    }
+}
+
+template<class R, class P>
+inline void ThreadExecGuardWithParent<R, P>::State::start(const std::string* thread_name)
+{
+    bool set_thread_name = false;
+    std::string thread_name_2;
+    if (thread_name) {
+        set_thread_name = true;
+        thread_name_2 = *thread_name; // Throws (copy)
+    }
+    auto run = [this, set_thread_name, thread_name=std::move(thread_name_2)]() noexcept {
+        try {
+            if (set_thread_name)
+                util::Thread::set_name(thread_name); // Throws
+            runnable.run(); // Throws
+        }
+        catch (...) {
+            exception = std::current_exception();
+            parent.stop();
+        }
+    };
+    thread.start(std::move(run)); // Throws
+}
+
+template<class R, class P> inline void ThreadExecGuardWithParent<R, P>::State::stop_and_rethrow()
+{
+    if (thread.joinable()) {
+        runnable.stop();
+        thread.join();
+        if (exception)
+            std::rethrow_exception(exception); // Throws
+    }
+}
+
+template<class R> inline ThreadExecGuard<R> make_thread_exec_guard(R& runnable)
+{
+    return ThreadExecGuard<R>{runnable}; // Throws
+}
+
+template<class R, class P>
+inline ThreadExecGuardWithParent<R, P> make_thread_exec_guard(R& runnable, P& parent)
+{
+    return ThreadExecGuardWithParent<R, P>{runnable, parent}; // Throws
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_THREAD_EXEC_GUARD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/time.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/time.hpp
new file mode 100644
index 0000000..75d9861
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/time.hpp
@@ -0,0 +1,94 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TIME_HPP
+#define REALM_UTIL_TIME_HPP
+
+#include <cstring>
+#include <ctime>
+#include <iterator>
+#include <locale>
+#include <ostream>
+#include <sstream>
+
+
+namespace realm {
+namespace util {
+
+/// Thread safe version of std::localtime(). Uses localtime_r() on POSIX.
+std::tm localtime(std::time_t);
+
+/// Thread safe version of std::gmtime(). Uses gmtime_r() on POSIX.
+std::tm gmtime(std::time_t);
+
+/// Similar to std::put_time() from <iomanip>. See std::put_time() for
+/// information about the format string. This function is provided because
+/// std::put_time() is unavailable in GCC 4. This function is thread safe.
+///
+/// The default format is ISO 8601 date and time.
+template<class C, class T>
+void put_time(std::basic_ostream<C,T>&, const std::tm&, const C* format = "%FT%T%z");
+
+// @{
+/// These functions combine localtime() or gmtime() with put_time() and
+/// std::ostringstream. For detals on the format string, see
+/// std::put_time(). These function are thread safe.
+std::string format_local_time(std::time_t, const char* format = "%FT%T%z");
+std::string format_utc_time(std::time_t, const char* format = "%FT%T%z");
+// @}
+
+/// The local time since the epoch in microseconds.
+///
+/// FIXME: This function has nothing to do with local time.
+double local_time_microseconds();
+
+
+
+
+// Implementation
+
+template<class C, class T>
+inline void put_time(std::basic_ostream<C,T>& out, const std::tm& tm, const C* format)
+{
+    const auto& facet = std::use_facet<std::time_put<C>>(out.getloc()); // Throws
+    facet.put(std::ostreambuf_iterator<C>(out), out, ' ', &tm,
+              format, format + T::length(format)); // Throws
+}
+
+inline std::string format_local_time(std::time_t time, const char* format)
+{
+    std::tm tm = util::localtime(time);
+    std::ostringstream out;
+    util::put_time(out, tm, format); // Throws
+    return out.str(); // Throws
+}
+
+inline std::string format_utc_time(std::time_t time, const char* format)
+{
+    std::tm tm = util::gmtime(time);
+    std::ostringstream out;
+    util::put_time(out, tm, format); // Throws
+    return out.str(); // Throws
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TIME_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/timestamp_formatter.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/timestamp_formatter.hpp
new file mode 100644
index 0000000..47e4ce3
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/timestamp_formatter.hpp
@@ -0,0 +1,110 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TIMESTAMP_FORMATTER_HPP
+#define REALM_UTIL_TIMESTAMP_FORMATTER_HPP
+
+#include <ctime>
+#include <chrono>
+#include <utility>
+#include <string>
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/string_view.hpp>
+#include <realm/util/memory_stream.hpp>
+
+
+namespace realm {
+namespace util {
+
+class TimestampFormatter {
+public:
+    using char_type = char;
+    using string_view_type = util::BasicStringView<char_type>;
+
+    enum class Precision { seconds, milliseconds, microseconds, nanoseconds };
+
+    /// Default configuration for corresponds to local time in ISO 8601 date and
+    /// time format.
+    struct Config {
+        Config() {}
+
+        bool utc_time = false;
+
+        Precision precision = Precision::seconds;
+
+        /// The format of the timestamp as understood by std::put_time(), except
+        /// that the first occurrence of `%S` (also taking into account the `%S`
+        /// that is an implicit part of `%T`) is expanded to `SS.fff` if \ref
+        /// precision is Precision::milliseconds, or to `SS.ffffff` if \ref
+        /// precision is Precision::microseconds, or to `SS.fffffffff` if \ref
+        /// precision is Precision::nanoseconds, where `SS` is what `%S` expands
+        /// to conventionally.
+        const char* format = "%FT%T%z";
+    };
+
+    TimestampFormatter(Config = {});
+
+    // FIXME: Use std::timespec in C++17.
+    string_view_type format(std::time_t time, long nanoseconds);
+
+    template<class B> string_view_type format(std::chrono::time_point<B>);
+
+private:
+    using memory_output_stream_type = util::MemoryOutputStream;
+    using format_segments_type = std::pair<std::string, const char*>;
+
+    const bool m_utc_time;
+    const Precision m_precision;
+    const format_segments_type m_format_segments;
+    char_type m_buffer[64];
+    memory_output_stream_type m_out;
+
+    static format_segments_type make_format_segments(const Config&);
+};
+
+
+
+
+
+// Implementation
+
+template<class B>
+inline auto TimestampFormatter::format(std::chrono::time_point<B> time) -> string_view_type
+{
+    using clock_type = B;
+    using time_point_type = std::chrono::time_point<B>;
+    std::time_t time_2 = clock_type::to_time_t(time);
+    time_point_type time_3 = clock_type::from_time_t(time_2);
+    if (REALM_UNLIKELY(time_3 > time)) {
+        --time_2;
+        time_3 = clock_type::from_time_t(time_2);
+    }
+    long nanoseconds =
+        int(std::chrono::duration_cast<std::chrono::nanoseconds>(time - time_3).count());
+    REALM_ASSERT(nanoseconds >= 0 && nanoseconds < 1000000000);
+    return format(time_2, nanoseconds); // Throws
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TIMESTAMP_FORMATTER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/timestamp_logger.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/timestamp_logger.hpp
new file mode 100644
index 0000000..a9789a5
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/timestamp_logger.hpp
@@ -0,0 +1,49 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TIMESTAMP_LOGGER_HPP
+#define REALM_UTIL_TIMESTAMP_LOGGER_HPP
+
+#include <realm/util/logger.hpp>
+#include <realm/util/timestamp_formatter.hpp>
+
+
+namespace realm {
+namespace util {
+
+class TimestampStderrLogger : public RootLogger {
+public:
+    using Precision = TimestampFormatter::Precision;
+    using Config    = TimestampFormatter::Config;
+
+    explicit TimestampStderrLogger(Config = {});
+
+protected:
+    void do_log(Logger::Level, std::string message) override;
+
+private:
+    TimestampFormatter m_formatter;
+};
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TIMESTAMP_LOGGER_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/to_string.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/to_string.hpp
new file mode 100644
index 0000000..c3fac65
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/to_string.hpp
@@ -0,0 +1,126 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TO_STRING_HPP
+#define REALM_UTIL_TO_STRING_HPP
+
+#include <iosfwd>
+#include <string>
+
+namespace realm {
+namespace util {
+
+class Printable {
+public:
+    Printable(bool value)
+        : m_type(Type::Bool)
+        , m_uint(value)
+    {
+    }
+    Printable(unsigned char value)
+        : m_type(Type::Uint)
+        , m_uint(value)
+    {
+    }
+    Printable(unsigned int value)
+        : m_type(Type::Uint)
+        , m_uint(value)
+    {
+    }
+    Printable(unsigned long value)
+        : m_type(Type::Uint)
+        , m_uint(value)
+    {
+    }
+    Printable(unsigned long long value)
+        : m_type(Type::Uint)
+        , m_uint(value)
+    {
+    }
+    Printable(char value)
+        : m_type(Type::Int)
+        , m_int(value)
+    {
+    }
+    Printable(int value)
+        : m_type(Type::Int)
+        , m_int(value)
+    {
+    }
+    Printable(long value)
+        : m_type(Type::Int)
+        , m_int(value)
+    {
+    }
+    Printable(long long value)
+        : m_type(Type::Int)
+        , m_int(value)
+    {
+    }
+    Printable(const char* value)
+        : m_type(Type::String)
+        , m_string(value)
+    {
+    }
+    Printable(std::string const& value)
+        : m_type(Type::String)
+        , m_string(value.c_str())
+    {
+    }
+
+
+    void print(std::ostream& out, bool quote) const;
+    std::string str() const;
+
+    static void print_all(std::ostream& out, const std::initializer_list<Printable>& values, bool quote);
+
+private:
+    enum class Type {
+        Bool,
+        Int,
+        Uint,
+        String,
+    } m_type;
+
+    union {
+        uintmax_t m_uint;
+        intmax_t m_int;
+        const char* m_string;
+    };
+};
+
+
+template <class T>
+std::string to_string(const T& v)
+{
+    return Printable(v).str();
+}
+
+std::string format(const char* fmt, std::initializer_list<Printable>);
+
+template<typename... Args>
+std::string format(const char* fmt, Args&&... args)
+{
+    return format(fmt, {Printable(args)...});
+}
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TO_STRING_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/type_list.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/type_list.hpp
new file mode 100644
index 0000000..da847c7
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/type_list.hpp
@@ -0,0 +1,244 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TYPE_LIST_HPP
+#define REALM_UTIL_TYPE_LIST_HPP
+
+namespace realm {
+namespace util {
+
+
+/// The 'cons' operator for building lists of types.
+///
+/// \tparam H The head of the list, that is, the first type in the
+/// list.
+///
+/// \tparam T The tail of the list, that is, the list of types
+/// following the head. It is 'void' if nothing follows the head,
+/// otherwise it matches TypeCons<H2,T2>.
+///
+/// Note that 'void' is interpreted as a zero-length list.
+template <class H, class T>
+struct TypeCons {
+    typedef H head;
+    typedef T tail;
+};
+
+
+/// Append a type the the end of a type list. The resulting type list
+/// is available as TypeAppend<List, T>::type.
+///
+/// \tparam List A list of types constructed using TypeCons<>. Note
+/// that 'void' is interpreted as a zero-length list.
+///
+/// \tparam T The new type to be appended.
+template <class List, class T>
+struct TypeAppend {
+    typedef TypeCons<typename List::head, typename TypeAppend<typename List::tail, T>::type> type;
+};
+/// Base case for empty type list.
+template <class T>
+struct TypeAppend<void, T> {
+    typedef TypeCons<T, void> type;
+};
+
+
+/// Get an element from the specified list of types. The result is
+/// available as TypeAt<List, i>::type.
+///
+/// \tparam List A list of types constructed using TypeCons<>. Note
+/// that 'void' is interpreted as a zero-length list.
+///
+/// \tparam i The index of the list element to get.
+template <class List, int i>
+struct TypeAt {
+    typedef typename TypeAt<typename List::tail, i - 1>::type type;
+};
+/// Base case for empty type list.
+template <class List>
+struct TypeAt<List, 0> {
+    typedef typename List::head type;
+};
+
+
+/// Count the number of elements in the specified list of types. The
+/// result is available as TypeCount<List>::value.
+///
+/// \tparam List The list of types, constructed using TypeCons<>. Note
+/// that 'void' is interpreted as a zero-length list.
+template <class List>
+struct TypeCount {
+    static const int value = 1 + TypeCount<typename List::tail>::value;
+};
+/// Base case for empty type list.
+template <>
+struct TypeCount<void> {
+    static const int value = 0;
+};
+
+
+/// Find the first type in the specified list that satisfies the
+/// specified predicate.
+///
+/// \tparam List The list of types, constructed using TypeCons<>. Note
+/// that 'void' is interpreted as a zero-length list.
+///
+/// \tparam Pred Must be such that `Pred<T>::%value` is true if, and
+/// only if the predicate is satisfied for `T`.
+template <class List, template <class> class Pred>
+struct FindType {
+private:
+    typedef typename List::head type_1;
+    typedef typename FindType<typename List::tail, Pred>::type type_2;
+
+public:
+    typedef typename std::conditional<Pred<type_1>::value, type_1, type_2>::type type;
+};
+/// Base case for empty type list.
+template <template <class> class Pred>
+struct FindType<void, Pred> {
+    typedef void type;
+};
+
+
+/// Execute an action for each element in the specified list of types.
+///
+/// \tparam List The list of types, constructed using TypeCons<>. Note
+/// that 'void' is interpreted as a zero-length list.
+template <class List, template <class T, int i> class Op, int i = 0>
+struct ForEachType {
+    /// Execute the `Op<T,i>::%exec()` for each type `T` at index `i`
+    /// in `List`.
+    static void exec()
+    {
+        Op<typename List::head, i>::exec();
+        ForEachType<typename List::tail, Op, i + 1>::exec();
+    }
+    /// Execute the `Op<T,i>::%exec(a)` for each type `T` at index `i`
+    /// in `List`.
+    template <class A>
+    static void exec(const A& a)
+    {
+        Op<typename List::head, i>::exec(a);
+        ForEachType<typename List::tail, Op, i + 1>::exec(a);
+    }
+    /// Execute the `Op<T,i>::%exec(a,b)` for each type `T` at index
+    /// `i` in `List`.
+    template <class A, class B>
+    static void exec(const A& a, const B& b)
+    {
+        Op<typename List::head, i>::exec(a, b);
+        ForEachType<typename List::tail, Op, i + 1>::exec(a, b);
+    }
+    /// Execute the `Op<T,i>::%exec(a,b,c)` for each type `T` at index
+    /// `i` in `List`.
+    template <class A, class B, class C>
+    static void exec(const A& a, const B& b, const C& c)
+    {
+        Op<typename List::head, i>::exec(a, b, c);
+        ForEachType<typename List::tail, Op, i + 1>::exec(a, b, c);
+    }
+};
+/// Base case for empty type list.
+template <template <class T, int i> class Op, int i>
+struct ForEachType<void, Op, i> {
+    static void exec()
+    {
+    }
+    template <class A>
+    static void exec(const A&)
+    {
+    }
+    template <class A, class B>
+    static void exec(const A&, const B&)
+    {
+    }
+    template <class A, class B, class C>
+    static void exec(const A&, const B&, const C&)
+    {
+    }
+};
+
+
+/// Execute a predicate for each element in the specified list of
+/// types, and return true if, and only if the predicate returns true
+/// for at least one of those elements. Iteration over the type list
+/// is terminated as soon as a predicate returns true.
+///
+/// \tparam List The list of types, constructed using TypeCons<>. Note
+/// that 'void' is interpreted as a zero-length list.
+template <class List, template <class T, int i> class Pred, int i = 0>
+struct HasType {
+    /// Execute the `Op<T,i>::%exec()` for each type `T` at index `i`
+    /// in `List`.
+    static bool exec()
+    {
+        return Pred<typename List::head, i>::exec() || HasType<typename List::tail, Pred, i + 1>::exec();
+    }
+    /// Execute the `Op<T,i>::%exec(a)` for each type `T` at index `i`
+    /// in `List`.
+    template <class A>
+    static bool exec(const A& a)
+    {
+        return Pred<typename List::head, i>::exec(a) || HasType<typename List::tail, Pred, i + 1>::exec(a);
+    }
+    /// Execute the `Op<T,i>::%exec(a,b)` for each type `T` at index
+    /// `i` in `List`.
+    template <class A, class B>
+    static bool exec(const A& a, const B& b)
+    {
+        return Pred<typename List::head, i>::exec(a, b) || HasType<typename List::tail, Pred, i + 1>::exec(a, b);
+    }
+    /// Execute the `Op<T,i>::%exec(a,b,c)` for each type `T` at index
+    /// `i` in `List`.
+    template <class A, class B, class C>
+    static bool exec(const A& a, const B& b, const C& c)
+    {
+        return Pred<typename List::head, i>::exec(a, b, c) ||
+               HasType<typename List::tail, Pred, i + 1>::exec(a, b, c);
+    }
+};
+/// Base case for empty type list.
+template <template <class T, int i> class Pred, int i>
+struct HasType<void, Pred, i> {
+    static bool exec()
+    {
+        return false;
+    }
+    template <class A>
+    static bool exec(const A&)
+    {
+        return false;
+    }
+    template <class A, class B>
+    static bool exec(const A&, const B&)
+    {
+        return false;
+    }
+    template <class A, class B, class C>
+    static bool exec(const A&, const B&, const C&)
+    {
+        return false;
+    }
+};
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TYPE_LIST_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/type_traits.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/type_traits.hpp
new file mode 100644
index 0000000..cedbe05
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/type_traits.hpp
@@ -0,0 +1,161 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_TYPE_TRAITS_HPP
+#define REALM_UTIL_TYPE_TRAITS_HPP
+
+#include <cstdint>
+#include <climits>
+#include <cwchar>
+#include <limits>
+#include <type_traits>
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/type_list.hpp>
+
+namespace realm {
+namespace util {
+
+template <class From, class To>
+struct CopyConst {
+private:
+    typedef typename std::remove_const<To>::type type_1;
+
+public:
+    typedef typename std::conditional<std::is_const<From>::value, const type_1, type_1>::type type;
+};
+
+
+/// Member `type` is the type resulting from integral or
+/// floating-point promotion of a value of type `T`.
+///
+/// \note Enum types are supported only when the compiler supports the
+/// C++11 'decltype' feature.
+template <class T>
+struct Promote;
+
+
+/// Member `type` is the type of the result of a binary arithmetic (or
+/// bitwise) operation (+, -, *, /, %, |, &, ^) when applied to
+/// operands of type `A` and `B` respectively. The type of the result
+/// of a shift operation (<<, >>) can instead be found as the type
+/// resulting from integral promotion of the left operand. The type of
+/// the result of a unary arithmetic (or bitwise) operation can be
+/// found as the type resulting from integral promotion of the
+/// operand.
+///
+/// \note Enum types are supported only when the compiler supports the
+/// C++11 'decltype' feature.
+template <class A, class B>
+struct ArithBinOpType;
+
+
+/// Member `type` is `B` if `B` has more value bits than `A`,
+/// otherwise is is `A`.
+template <class A, class B>
+struct ChooseWidestInt;
+
+
+/// Member `type` is the first of `unsigned char`, `unsigned short`,
+/// `unsigned int`, `unsigned long`, and `unsigned long long` that has
+/// at least `bits` value bits.
+template <int bits>
+struct LeastUnsigned;
+
+
+/// Member `type` is `unsigned` if `unsigned` has at least `bits`
+/// value bits, otherwise it is the same as
+/// `LeastUnsigned<bits>::%type`.
+template <int bits>
+struct FastestUnsigned;
+
+
+// Implementation
+
+
+template <class T>
+struct Promote {
+    typedef decltype(+T()) type; // FIXME: This is not performing floating-point promotion.
+};
+
+
+template <class A, class B>
+struct ArithBinOpType {
+    typedef decltype(A() + B()) type;
+};
+
+
+template <class A, class B>
+struct ChooseWidestInt {
+private:
+    typedef std::numeric_limits<A> lim_a;
+    typedef std::numeric_limits<B> lim_b;
+    static_assert(lim_a::is_specialized && lim_b::is_specialized,
+                  "std::numeric_limits<> must be specialized for both types");
+    static_assert(lim_a::is_integer && lim_b::is_integer, "Both types must be integers");
+
+public:
+    typedef typename std::conditional<(lim_a::digits >= lim_b::digits), A, B>::type type;
+};
+
+
+template <int bits>
+struct LeastUnsigned {
+private:
+    typedef void types_0;
+    typedef TypeAppend<types_0, unsigned char>::type types_1;
+    typedef TypeAppend<types_1, unsigned short>::type types_2;
+    typedef TypeAppend<types_2, unsigned int>::type types_3;
+    typedef TypeAppend<types_3, unsigned long>::type types_4;
+    typedef TypeAppend<types_4, unsigned long long>::type types_5;
+    typedef types_5 types;
+    // The `dummy<>` template is there to work around a bug in
+    // VisualStudio (seen in versions 2010 and 2012). Without the
+    // `dummy<>` template, The C++ compiler in Visual Studio would
+    // attempt to instantiate `FindType<type, pred>` before the
+    // instantiation of `LeastUnsigned<>` which obviously fails
+    // because `pred` depends on `bits`.
+    template <int>
+    struct dummy {
+        template <class T>
+        struct pred {
+            static const bool value = std::numeric_limits<T>::digits >= bits;
+        };
+    };
+
+public:
+    typedef typename FindType<types, dummy<bits>::template pred>::type type;
+    static_assert(!(std::is_same<type, void>::value), "No unsigned type is that wide");
+};
+
+
+template <int bits>
+struct FastestUnsigned {
+private:
+    typedef typename util::LeastUnsigned<bits>::type least_unsigned;
+
+public:
+    typedef typename util::ChooseWidestInt<unsigned, least_unsigned>::type type;
+};
+
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_TYPE_TRAITS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/uri.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/uri.hpp
new file mode 100644
index 0000000..2b39da5
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/uri.hpp
@@ -0,0 +1,251 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_URI_HPP
+#define REALM_UTIL_URI_HPP
+
+#include <string>
+
+namespace realm {
+namespace util {
+
+
+/// \brief A decomposed URI reference.
+///
+/// A Uri object contains a URI reference decomposed into its 5 main component
+/// parts (scheme, authority, path, query, and fragment identifier).
+///
+/// The decomposition process (as carried out by the constructor) performs a
+/// maximally lenient parsing of the specified URI reference. It does that
+/// according to the following regular expression (copied verbatimly from
+/// http://tools.ietf.org/html/rfc3986#appendix-B):
+///
+///     ^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?
+///      12            3  4          5       6  7        8 9
+///
+///     Group
+///     ------------------------
+///     1       Scheme part
+///     3       Authority part
+///     5       Path part
+///     6       Query part
+///     8       Fragment identifier part
+///
+/// NOTE: Since this regular expression maches every string, every string is
+/// decomposable.
+///
+/// NOTE: This class does not attempt to perform any level of validation of URI
+/// references against the grammer specified in the RFC. Such validation could
+/// be added later, for example through a new `Uri::validate()`.
+///
+/// For example, the decomposition of
+/// "http://www.ietf.org/rfc/rfc2396.txt?foo=bar#chp3" is:
+///
+/// <pre>
+///
+///   scheme -> "http:"
+///   auth   -> "//www.ietf.org"
+///   path   -> "/rfc/rfc2396.txt"
+///   query  -> "?foo=bar"
+///   frag   -> "#chp3"
+///
+/// </pre>
+///
+/// This class also provides recomposition of a URI references from their
+/// component parts, where the parts can be specified individually, or be a
+/// result of URI resoultion.
+///
+/// It is important to understand, however, that certain restrictions need to
+/// apply to each component part in order that the URI reference as a whole is
+/// self consistent. More concretely, it is necessary to require that the
+/// component parts at any time must have values that will be preserved across a
+/// recomposition -> decomposition cycle.
+///
+/// The actual restrictions on each component part is specified for the
+/// corresponding setter-method (e.g., set_scheme()).
+///
+/// Note that component parts resulting from decomposition, canonicalize, or
+/// from resolution (resolve()) will automatically (by design of the underlying
+/// algorithm) adhere to these rules.
+///
+/// Decomposition, recomposition, conanonicalization, and resolution algorithms
+/// are taken from RFC 3986.
+///
+/// \sa http://tools.ietf.org/html/rfc3986
+class Uri {
+public:
+    Uri();
+
+    /// Decompose the specified URI reference into its five main parts.
+    Uri(const std::string&);
+
+    /// Reconstruct a URI reference from its 5 components.
+    std::string recompose() const;
+
+/*
+    /// Resolve this URI reference against the specified base URI reference
+    /// according to the rules described in section 5.2 of RFC 3986.
+    ///
+    /// Be aware that a fragment identifier on the base URI reference is never
+    /// carried over to the result. This is in accordance with the RFC.
+    void resolve(const Uri& base, bool strict = true);
+*/
+
+    /// Remove empty URI components. Also, for URI references having either a
+    /// scheme part or an authority part, replace an absent path with "/".
+    void canonicalize();
+
+    /// Get the scheme part of this URI reference including the trailing ":", or
+    /// the empty tring if there is no scheme part.
+    const std::string& get_scheme() const;
+
+    /// Get the authority part of this URI reference including the leading "//",
+    /// or the empty tring if there is no authority part.
+    const std::string& get_auth() const;
+
+    /// Same as get_auth() (with no arguments), but parse the authority component
+    /// into userinfo, host, and port subcomponents.
+    ///
+    /// \return True if, and only if the authority component was present (i.e.,
+    /// not the empty string). When false is returned, none of the specified
+    /// strings will have been modified.
+    bool get_auth(std::string& userinfo, std::string& host, std::string& port) const;
+
+    /// Get the path part of this URI reference, or the empty tring if there is
+    /// no path part.
+    const std::string& get_path() const;
+
+    /// Get the query part of this URI reference including the leading "?", or
+    /// the empty tring if there is no query part.
+    const std::string& get_query() const;
+
+    /// Get the fragment identifier of this URI reference including the leading
+    /// "#", or the empty tring if there is no fragment identifier.
+    const std::string& get_frag() const;
+
+    /// The specified string must either be empty or have a final ":". Also, it
+    /// must not contain "/", "?", or "#", nor may it contain more than one ":".
+    ///
+    /// \throw std::invalid_argument If the specified string is not valid
+    /// according to the specified rules.
+    void set_scheme(const std::string&);
+
+    /// The specified string must either be empty or have "//" as a
+    /// prefix. Also, it must not contain "?" or "#", nor may it contain "/"
+    /// beyond the first two.
+    ///
+    /// \throw std::invalid_argument If the specified string is not valid
+    /// according to the specified rules.
+    void set_auth(const std::string&);
+
+    /// The specified string must not contain "?" or "#".
+    ///
+    /// \throw std::invalid_argument If the specified string is not valid
+    /// according to the specified rules.
+    void set_path(const std::string&);
+
+    /// The specified string must either be empty or have a leading "?". Also,
+    /// it must not contain "#".
+    ///
+    /// \throw std::invalid_argument If the specified string is not valid
+    /// according to the specified rules.
+    void set_query(const std::string&);
+
+/*
+    /// Set the query string to the serialized form of the specified set of
+    /// query parameters. This is slightly faster than set_query(q.encode())
+    /// because it avoids the validity check on the string.
+    void set_query(const Params&);
+*/
+
+    /// The specified string must either be empty or have a leading "#".
+    ///
+    /// \throw std::invalid_argument If the specified string is not valid
+    /// according to the specified rules.
+    void set_frag(const std::string&);
+
+    bool is_absolute() const;
+
+private:
+    std::string m_scheme, m_auth, m_path, m_query, m_frag;
+};
+
+
+/// uri_percent_encode() uri encodes a string as defined in according to
+/// https://tools.ietf.org/html/rfc3986#section-2.1
+/// The unescaped input must be UTF-8 encoded. uri_percent_encode() works
+/// by replacing each UTF-8 character by three charatcers.
+/// pct-encoded = "%" HEXDIG HEXDIG
+/// where HEXDIG HEXDIG is the hexadecimal value of the character.
+/// HEXDIG is a capital letter for A - F.
+/// Unreserved chracters are not encoded.
+/// unreseved = ALPHA / DIGIT / "-" / "." / "_" / "~"
+///
+/// uri_percent_decode() is the inverse of uri_percent_encode().
+/// uri_percent_decode() throws std::runtime_error if the input
+/// is invalid and cannot be decoded.
+std::string uri_percent_encode(const std::string& unescaped);
+std::string uri_percent_decode(const std::string& escaped);
+
+
+// Implementation
+
+inline Uri::Uri()
+{
+}
+
+inline std::string Uri::recompose() const
+{
+    return m_scheme + m_auth + m_path + m_query + m_frag;
+}
+
+inline const std::string& Uri::get_scheme() const
+{
+    return m_scheme;
+}
+
+inline const std::string& Uri::get_auth() const
+{
+    return m_auth;
+}
+
+inline const std::string& Uri::get_path() const
+{
+    return m_path;
+}
+
+inline const std::string& Uri::get_query() const
+{
+    return m_query;
+}
+
+inline const std::string& Uri::get_frag() const
+{
+    return m_frag;
+}
+
+inline bool Uri::is_absolute() const
+{
+    return !m_scheme.empty();
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_URI_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/utf8.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/utf8.hpp
new file mode 100644
index 0000000..02be1d5
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/utf8.hpp
@@ -0,0 +1,380 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_UTF8_HPP
+#define REALM_UTIL_UTF8_HPP
+
+#include <cstdint>
+#include <string>
+
+#include <realm/util/safe_int_ops.hpp>
+#include <realm/string_data.hpp>
+#include <realm/util/features.h>
+#include <realm/utilities.hpp>
+
+namespace realm {
+namespace util {
+
+
+/// Transcode between UTF-8 and UTF-16.
+///
+/// \tparam Char16 Must be an integral type with at least 16 bits.
+///
+/// \tparam Traits16 Must define to_int_type() and to_char_type() for
+/// \a Char16.
+template <class Char16, class Traits16 = std::char_traits<Char16>>
+struct Utf8x16 {
+    /// Transcode as much as possible of the specified UTF-8 input, to
+    /// UTF-16. Returns true if all input characters were transcoded, or
+    /// transcoding stopped because the next character did not fit into the
+    /// output buffer. Returns false if transcoding stopped due to invalid
+    /// input. It is not specified whether this function returns true or false
+    /// if invalid input occurs at the same time as the output buffer runs
+    /// full. In any case, upon return, \a in_begin and \a out_begin are
+    /// advanced to the position where transcoding stopped.
+    ///
+    /// Throws only if Traits16::to_char_type() throws.
+    static bool to_utf16(const char*& in_begin, const char* in_end, Char16*& out_begin, Char16* out_end);
+
+    /// Same as to_utf16(), but in reverse.
+    ///
+    /// Throws only if Traits16::to_int_type() throws.
+    static bool to_utf8(const Char16*& in_begin, const Char16* in_end, char*& out_begin, char* out_end);
+
+    /// Summarize the number of UTF-16 elements needed to hold the result of
+    /// transcoding the specified UTF-8 string. Upon return, if \a in_begin !=
+    /// \a in_end, then the summation stopped due to invalid UTF-8 input. The
+    /// returned size then reflects the number of UTF-16 elements needed to hold
+    /// the result of transcoding the part of the input that was examined. This
+    /// function will only detect a few UTF-8 validity issues, and can therefore
+    /// not be used for general UTF-8 validation.
+    static size_t find_utf16_buf_size(const char*& in_begin, const char* in_end);
+
+    /// Summarize the number of UTF-8 bytes needed to hold the result of
+    /// transcoding the specified UTF-16 string. Upon return, if \a in_begin !=
+    /// \a in_end, then the summation stopped due to invalid UTF-16 input, or to
+    /// prevent the returned \c size_t value from overflowing. The returned size
+    /// then reflects the number of UTF-8 bytes needed to hold the result of
+    /// transcoding the part of the input that was examined. This function will
+    /// only detect a few UTF-16 validity issues, and can therefore not be used
+    /// for general UTF-16 validation.
+    static size_t find_utf8_buf_size(const Char16*& in_begin, const Char16* in_end);
+};
+
+
+// Implementation:
+
+// Adapted from reference implementation.
+// http://www.unicode.org/resources/utf8.html
+// http://www.bsdua.org/files/unicode.tar.gz
+template <class Char16, class Traits16>
+inline bool Utf8x16<Char16, Traits16>::to_utf16(const char*& in_begin, const char* const in_end, Char16*& out_begin,
+                                                Char16* const out_end)
+{
+    typedef std::char_traits<char> traits8;
+    bool invalid = false;
+    const char* in = in_begin;
+    Char16* out = out_begin;
+    while (in != in_end) {
+        if (REALM_UNLIKELY(out == out_end)) {
+            break; // Need space in output buffer
+        }
+        REALM_ASSERT(&in[0] >= in_begin && &in[0] < in_end);
+        uint_fast16_t v1 = uint_fast16_t(traits8::to_int_type(in[0]));
+        if (REALM_LIKELY(v1 < 0x80)) { // One byte
+            // UTF-8 layout: 0xxxxxxx
+            *out++ = Traits16::to_char_type(v1);
+            in += 1;
+            continue;
+        }
+        if (REALM_UNLIKELY(v1 < 0xC0)) {
+            invalid = true;
+            break; // Invalid first byte of UTF-8 sequence
+        }
+        if (REALM_LIKELY(v1 < 0xE0)) { // Two bytes
+            if (REALM_UNLIKELY(in_end - in < 2)) {
+                invalid = true;
+                break; // Incomplete UTF-8 sequence
+            }
+            REALM_ASSERT(&in[1] >= in_begin && &in[1] < in_end);
+            uint_fast16_t v2 = uint_fast16_t(traits8::to_int_type(in[1]));
+            // UTF-8 layout: 110xxxxx 10xxxxxx
+            if (REALM_UNLIKELY((v2 & 0xC0) != 0x80)) {
+                invalid = true;
+                break; // Invalid continuation byte
+            }
+            uint_fast16_t v = uint_fast16_t(((v1 & 0x1F) << 6) | ((v2 & 0x3F) << 0));
+            if (REALM_UNLIKELY(v < 0x80)) {
+                invalid = true;
+                break; // Overlong encoding is invalid
+            }
+            *out++ = Traits16::to_char_type(v);
+            in += 2;
+            continue;
+        }
+        if (REALM_LIKELY(v1 < 0xF0)) { // Three bytes
+            if (REALM_UNLIKELY(in_end - in < 3)) {
+                invalid = true;
+                break; // Incomplete UTF-8 sequence
+            }
+            REALM_ASSERT(&in[1] >= in_begin && &in[2] < in_end);
+            uint_fast16_t v2 = uint_fast16_t(traits8::to_int_type(in[1]));
+            uint_fast16_t v3 = uint_fast16_t(traits8::to_int_type(in[2]));
+            // UTF-8 layout: 1110xxxx 10xxxxxx 10xxxxxx
+            if (REALM_UNLIKELY((v2 & 0xC0) != 0x80 || (v3 & 0xC0) != 0x80)) {
+                invalid = true;
+                break; // Invalid continuation byte
+            }
+            uint_fast16_t v = uint_fast16_t(((v1 & 0x0F) << 12) | ((v2 & 0x3F) << 6) | ((v3 & 0x3F) << 0));
+            if (REALM_UNLIKELY(v < 0x800)) {
+                invalid = true;
+                break; // Overlong encoding is invalid
+            }
+            if (REALM_UNLIKELY(0xD800 <= v && v < 0xE000)) {
+                invalid = true;
+                break; // Illegal code point range (reserved for UTF-16 surrogate pairs)
+            }
+            *out++ = Traits16::to_char_type(v);
+            in += 3;
+            continue;
+        }
+        if (REALM_UNLIKELY(out + 1 == out_end)) {
+            break; // Need space in output buffer for surrogate pair
+        }
+        if (REALM_LIKELY(v1 < 0xF8)) { // Four bytes
+            if (REALM_UNLIKELY(in_end - in < 4)) {
+                invalid = true;
+                break; // Incomplete UTF-8 sequence
+            }
+            uint_fast32_t w1 = uint_fast32_t(v1); // 16 bit -> 32 bit
+            REALM_ASSERT(&in[1] >= in_begin && &in[3] < in_end);
+            uint_fast32_t v2 = uint_fast32_t(traits8::to_int_type(in[1])); // 32 bit intended
+            uint_fast16_t v3 = uint_fast16_t(traits8::to_int_type(in[2])); // 16 bit intended
+            uint_fast16_t v4 = uint_fast16_t(traits8::to_int_type(in[3])); // 16 bit intended
+            // UTF-8 layout: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
+            if (REALM_UNLIKELY((v2 & 0xC0) != 0x80 || (v3 & 0xC0) != 0x80 || (v4 & 0xC0) != 0x80)) {
+                invalid = true;
+                break; // Invalid continuation byte
+            }
+            uint_fast32_t v = uint_fast32_t(((w1 & 0x07) << 18) | // Parenthesis is 32 bit partial result
+                                            ((v2 & 0x3F) << 12) | // Parenthesis is 32 bit partial result
+                                            ((v3 & 0x3F) << 6) |  // Parenthesis is 16 bit partial result
+                                            ((v4 & 0x3F) << 0));  // Parenthesis is 16 bit partial result
+            if (REALM_UNLIKELY(v < 0x10000)) {
+                invalid = true;
+                break; // Overlong encoding is invalid
+            }
+            if (REALM_UNLIKELY(0x110000 <= v)) {
+                invalid = true;
+                break; // Code point too big for UTF-16
+            }
+            v -= 0x10000l;
+            *out++ = Traits16::to_char_type(0xD800 + (v / 0x400));
+            *out++ = Traits16::to_char_type(0xDC00 + (v % 0x400));
+            in += 4;
+            continue;
+        }
+        // Invalid first byte of UTF-8 sequence, or code point too big for UTF-16
+        invalid = true;
+        break;
+    }
+
+    REALM_ASSERT(in >= in_begin && in <= in_end);
+    REALM_ASSERT(out >= out_begin && out <= out_end);
+    in_begin = in;
+    out_begin = out;
+    return !invalid;
+}
+
+
+template <class Char16, class Traits16>
+inline size_t Utf8x16<Char16, Traits16>::find_utf16_buf_size(const char*& in_begin, const char* const in_end)
+{
+    typedef std::char_traits<char> traits8;
+    size_t num_out = 0;
+    const char* in = in_begin;
+    while (in != in_end) {
+        REALM_ASSERT(&in[0] >= in_begin && &in[0] < in_end);
+        uint_fast16_t v1 = uint_fast16_t(traits8::to_int_type(in[0]));
+        if (REALM_LIKELY(v1 < 0x80)) { // One byte
+            num_out += 1;
+            in += 1;
+            continue;
+        }
+        if (REALM_UNLIKELY(v1 < 0xC0)) {
+            break; // Invalid first byte of UTF-8 sequence
+        }
+        if (REALM_LIKELY(v1 < 0xE0)) { // Two bytes
+            if (REALM_UNLIKELY(in_end - in < 2)) {
+                break; // Incomplete UTF-8 sequence
+            }
+            num_out += 1;
+            in += 2;
+            continue;
+        }
+        if (REALM_LIKELY(v1 < 0xF0)) { // Three bytes
+            if (REALM_UNLIKELY(in_end - in < 3)) {
+                break; // Incomplete UTF-8 sequence
+            }
+            num_out += 1;
+            in += 3;
+            continue;
+        }
+        if (REALM_LIKELY(v1 < 0xF8)) { // Four bytes
+            if (REALM_UNLIKELY(in_end - in < 4)) {
+                break; // Incomplete UTF-8 sequence
+            }
+            num_out += 2; // Surrogate pair
+            in += 4;
+            continue;
+        }
+        // Invalid first byte of UTF-8 sequence, or code point too big for UTF-16
+        break;
+    }
+
+    REALM_ASSERT(in >= in_begin && in <= in_end);
+    in_begin = in;
+    return num_out;
+}
+
+
+// Adapted from reference implementation.
+// http://www.unicode.org/resources/utf8.html
+// http://www.bsdua.org/files/unicode.tar.gz
+template <class Char16, class Traits16>
+inline bool Utf8x16<Char16, Traits16>::to_utf8(const Char16*& in_begin, const Char16* const in_end, char*& out_begin,
+                                               char* const out_end)
+{
+    typedef std::char_traits<char> traits8;
+    typedef typename traits8::int_type traits8_int_type;
+    bool invalid = false;
+    const Char16* in = in_begin;
+    char* out = out_begin;
+    while (in != in_end) {
+        REALM_ASSERT(&in[0] >= in_begin && &in[0] < in_end);
+        uint_fast16_t v1 = uint_fast16_t(Traits16::to_int_type(in[0]));
+        if (REALM_LIKELY(v1 < 0x80)) {
+            if (REALM_UNLIKELY(out == out_end)) {
+                break; // Not enough output buffer space
+            }
+            // UTF-8 layout: 0xxxxxxx
+            REALM_ASSERT(out >= out_begin && out < out_end);
+            *out++ = traits8::to_char_type(traits8_int_type(v1));
+            in += 1;
+            continue;
+        }
+        if (REALM_LIKELY(v1 < 0x800)) {
+            if (REALM_UNLIKELY(out_end - out < 2)) {
+                break; // Not enough output buffer space
+            }
+            // UTF-8 layout: 110xxxxx 10xxxxxx
+            *out++ = traits8::to_char_type(traits8_int_type(0xC0 + v1 / 0x40));
+            REALM_ASSERT(out >= out_begin && out < out_end);
+            *out++ = traits8::to_char_type(traits8_int_type(0x80 + v1 % 0x40));
+            in += 1;
+            continue;
+        }
+        if (REALM_LIKELY(v1 < 0xD800 || 0xE000 <= v1)) {
+            if (REALM_UNLIKELY(out_end - out < 3)) {
+                break; // Not enough output buffer space
+            }
+            // UTF-8 layout: 1110xxxx 10xxxxxx 10xxxxxx
+            REALM_ASSERT(out >= out_begin && out + 2 < out_end);
+            *out++ = traits8::to_char_type(traits8_int_type(0xE0 + v1 / 0x1000));
+            *out++ = traits8::to_char_type(traits8_int_type(0x80 + v1 / 0x40 % 0x40));
+            *out++ = traits8::to_char_type(traits8_int_type(0x80 + v1 % 0x40));
+            in += 1;
+            continue;
+        }
+
+        // Surrogate pair
+        if (REALM_UNLIKELY(out_end - out < 4)) {
+            break; // Not enough output buffer space
+        }
+        if (REALM_UNLIKELY(0xDC00 <= v1)) {
+            invalid = true;
+            break; // Invalid first half of surrogate pair
+        }
+        if (REALM_UNLIKELY(in + 1 == in_end)) {
+            invalid = true;
+            break; // Incomplete surrogate pair
+        }
+        REALM_ASSERT(&in[1] >= in_begin && &in[1] < in_end);
+        uint_fast16_t v2 = uint_fast16_t(Traits16::to_int_type(in[1]));
+        if (REALM_UNLIKELY(v2 < 0xDC00 || 0xE000 <= v2)) {
+            invalid = true;
+            break; // Invalid second half of surrogate pair
+        }
+        uint_fast32_t v = 0x10000l + (uint_fast32_t(v1 - 0xD800) * 0x400 + (v2 - 0xDC00));
+        // UTF-8 layout: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
+        REALM_ASSERT(out >= out_begin && out + 3 < out_end);
+        *out++ = traits8::to_char_type(traits8_int_type(0xF0 + v / 0x40000));
+        *out++ = traits8::to_char_type(traits8_int_type(0x80 + v / 0x1000 % 0x40));
+        *out++ = traits8::to_char_type(traits8_int_type(0x80 + v / 0x40 % 0x40));
+        *out++ = traits8::to_char_type(traits8_int_type(0x80 + v % 0x40));
+        in += 2;
+    }
+
+    REALM_ASSERT(in >= in_begin && in <= in_end);
+    REALM_ASSERT(out >= out_begin && out <= out_end);
+    in_begin = in;
+    out_begin = out;
+    return !invalid;
+}
+
+
+template <class Char16, class Traits16>
+inline size_t Utf8x16<Char16, Traits16>::find_utf8_buf_size(const Char16*& in_begin, const Char16* const in_end)
+{
+    size_t num_out = 0;
+    const Char16* in = in_begin;
+    while (in != in_end) {
+        REALM_ASSERT(&in[0] >= in_begin && &in[0] < in_end);
+        uint_fast16_t v = uint_fast16_t(Traits16::to_int_type(in[0]));
+        if (REALM_LIKELY(v < 0x80)) {
+            if (REALM_UNLIKELY(int_add_with_overflow_detect(num_out, 1)))
+                break; // Avoid overflow
+            in += 1;
+        }
+        else if (REALM_LIKELY(v < 0x800)) {
+            if (REALM_UNLIKELY(int_add_with_overflow_detect(num_out, 2)))
+                break; // Avoid overflow
+            in += 1;
+        }
+        else if (REALM_LIKELY(v < 0xD800 || 0xE000 <= v)) {
+            if (REALM_UNLIKELY(int_add_with_overflow_detect(num_out, 3)))
+                break; // Avoid overflow
+            in += 1;
+        }
+        else {
+            if (REALM_UNLIKELY(in + 1 == in_end)) {
+                break; // Incomplete surrogate pair
+            }
+            if (REALM_UNLIKELY(int_add_with_overflow_detect(num_out, 4)))
+                break; // Avoid overflow
+            in += 2;
+        }
+    }
+    REALM_ASSERT(in >= in_begin && in <= in_end);
+    in_begin = in;
+    return num_out;
+}
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_UTF8_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/value_reset_guard.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/value_reset_guard.hpp
new file mode 100644
index 0000000..2dc6419
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/value_reset_guard.hpp
@@ -0,0 +1,92 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2015] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+#ifndef REALM_UTIL_VALUE_RESET_GUARD_HPP
+#define REALM_UTIL_VALUE_RESET_GUARD_HPP
+
+#include <utility>
+
+namespace realm {
+namespace util {
+
+template<class T, class U> class ValueResetGuard {
+public:
+    ValueResetGuard(T& var, U val);
+    ValueResetGuard(ValueResetGuard&&);
+    ~ValueResetGuard();
+
+private:
+    T* m_var;
+    U m_val;
+};
+
+
+/// Set \a var to `T{}` when the returned object is destroyed.
+template<class T> ValueResetGuard<T, T> make_value_reset_guard(T& var);
+
+/// Set \a var to \a val when the returned object is destroyed.
+template<class T, class U> ValueResetGuard<T, U> make_value_reset_guard(T& var, U val);
+
+/// Set \a var to \a val_1 immediately, and then to \a val_2 when the returned
+/// object is destroyed.
+template<class T, class U> ValueResetGuard<T, U> make_temp_assign(T& var, U val_1, U val_2 = {});
+
+
+
+// Implementation
+
+template<class T, class U> inline ValueResetGuard<T, U>::ValueResetGuard(T& var, U val) :
+    m_var{&var},
+    m_val{std::move(val)}
+{
+}
+
+template<class T, class U> inline ValueResetGuard<T, U>::ValueResetGuard(ValueResetGuard&& other) :
+    m_var{other.m_var},
+    m_val{std::move(other.m_val)}
+{
+    other.m_var = nullptr;
+}
+
+template<class T, class U> inline ValueResetGuard<T, U>::~ValueResetGuard()
+{
+    if (m_var)
+        *m_var = std::move(m_val);
+}
+
+template<class T> inline ValueResetGuard<T, T> make_value_reset_guard(T& var)
+{
+    return ValueResetGuard<T, T>(var, T{});
+}
+
+template<class T, class U> inline ValueResetGuard<T, U> make_value_reset_guard(T& var, U val)
+{
+    return ValueResetGuard<T, U>(var, std::move(val));
+}
+
+template<class T, class U> inline ValueResetGuard<T, U> make_temp_assign(T& var, U val_1, U val_2)
+{
+    var = std::move(val_1);
+    return make_value_reset_guard(var, std::move(val_2));
+}
+
+} // namespace util
+} // namespace realm
+
+#endif // REALM_UTIL_VALUE_RESET_GUARD_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/util/websocket.hpp b/node_modules/realm/vendor/realm-ios/include/realm/util/websocket.hpp
new file mode 100644
index 0000000..8090bb5
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/util/websocket.hpp
@@ -0,0 +1,264 @@
+/*************************************************************************
+ *
+ * REALM CONFIDENTIAL
+ * __________________
+ *
+ *  [2011] - [2016] Realm Inc
+ *  All Rights Reserved.
+ *
+ * NOTICE:  All information contained herein is, and remains
+ * the property of Realm Incorporated and its suppliers,
+ * if any.  The intellectual and technical concepts contained
+ * herein are proprietary to Realm Incorporated
+ * and its suppliers and may be covered by U.S. and Foreign Patents,
+ * patents in process, and are protected by trade secret or copyright law.
+ * Dissemination of this information or reproduction of this material
+ * is strictly forbidden unless prior written permission is obtained
+ * from Realm Incorporated.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTIL_WEBSOCKET_HPP
+#define REALM_UTIL_WEBSOCKET_HPP
+
+#include <random>
+#include <system_error>
+#include <map>
+
+#include <realm/util/string_view.hpp>
+#include <realm/util/logger.hpp>
+#include <realm/util/http.hpp>
+
+
+namespace realm {
+namespace util {
+namespace websocket {
+
+using WriteCompletionHandler =
+    std::function<void(std::error_code, size_t num_bytes_transferred)>;
+using ReadCompletionHandler =
+    std::function<void(std::error_code, size_t num_bytes_transferred)>;
+
+class Config {
+public:
+    virtual ~Config() {}
+
+    /// The Socket uses the caller supplied logger for logging.
+    virtual util::Logger& websocket_get_logger() noexcept = 0;
+
+    /// The Socket needs random numbers to satisfy the Websocket protocol.
+    /// The caller must supply a random number generator.
+    virtual std::mt19937_64& websocket_get_random() noexcept = 0;
+
+    //@{
+    /// The three functions below are used by the Socket to read and write to the underlying
+    /// stream. The functions will typically be implemented as wrappers to a TCP/TLS stream,
+    /// but could also map to pure memory streams. These functions abstract away the details of
+    /// the underlying sockets.
+    /// The functions have the same semantics as util::Socket.
+    ///
+    /// FIXME: Require that implementations ensure no callback reentrance, i.e.,
+    /// that the completion handler is never called from within the execution of
+    /// async_write(), async_read(), or async_read_until(). This guarantee is
+    /// provided by both network::Socket and network::ssl::Stream.
+    virtual void async_write(const char* data, size_t size, WriteCompletionHandler handler) = 0;
+    virtual void async_read(char* buffer, size_t size, ReadCompletionHandler handler) = 0;
+    virtual void async_read_until(char* buffer, size_t size, char delim, ReadCompletionHandler handler) = 0;
+    //@}
+
+    /// websocket_handshake_completion_handler() is called when the websocket is connected, .i.e.
+    /// after the handshake is done. It is not allowed to send messages on the socket before the
+    /// handshake is done. No message_received callbacks will be called before the handshake is done.
+    virtual void websocket_handshake_completion_handler(const HTTPHeaders&) = 0;
+
+    //@{
+    /// websocket_read_error_handler() and websocket_write_error_handler() are called when an
+    /// error occurs on the underlying stream given by the async_read and async_write functions above.
+    /// The error_code is passed through.
+    ///
+    /// websocket_handshake_error_handler() will be called when there is an error in the handshake
+    /// such as "404 Not found".
+    ///
+    /// websocket_protocol_error_handler() is called when there is an protocol error in the incoming
+    /// websocket messages.
+    ///
+    /// After calling any of these error callbacks, the Socket will move into the stopped state, and
+    /// no more messages should be sent, or will be received.
+    /// It is safe to destroy the WebSocket object in these handlers.
+    virtual void websocket_read_error_handler(std::error_code) = 0;
+    virtual void websocket_write_error_handler(std::error_code) = 0;
+    virtual void websocket_handshake_error_handler(std::error_code, const HTTPHeaders*,
+                                                   const util::StringView* body) = 0;
+    virtual void websocket_protocol_error_handler(std::error_code) = 0;
+    //@}
+
+    //@{
+    /// The five callback functions below are called whenever a full message has arrived.
+    /// The Socket defragments fragmented messages internally and delivers a full message.
+    /// The message is delivered in the buffer \param data of size \param size.
+    /// The buffer is only valid until the function returns.
+    /// The return value designates whether the WebSocket object should continue
+    /// processing messages. The normal return value is true. False must be returned if the
+    /// websocket object is destroyed during execution of the function.
+    virtual bool websocket_text_message_received(const char* data, size_t size);
+    virtual bool websocket_binary_message_received(const char* data, size_t size);
+    virtual bool websocket_close_message_received(const char* data, size_t size);
+    virtual bool websocket_ping_message_received(const char* data, size_t size);
+    virtual bool websocket_pong_message_received(const char* data, size_t size);
+    //@}
+};
+
+
+enum class Opcode {
+    continuation =  0,
+    text         =  1,
+    binary       =  2,
+    close        =  8,
+    ping         =  9,
+    pong         = 10
+};
+
+
+class Socket {
+public:
+    Socket(Config&);
+    Socket(Socket&&) noexcept;
+    ~Socket() noexcept;
+
+    /// initiate_client_handshake() starts the Socket in client mode. The Socket
+    /// will send the HTTP request that initiates the WebSocket protocol and
+    /// wait for the HTTP response from the server. The HTTP request will
+    /// contain the \param request_uri in the HTTP request line. The \param host
+    /// will be sent as the value in a HTTP Host header line.
+    /// \param sec_websocket_protocol will be set as header value for
+    /// Sec-WebSocket-Protocol. Extra HTTP headers can be provided in \a headers.
+    ///
+    /// When the server responds with a valid HTTP response, the callback
+    /// function websocket_handshake_completion_handler() is called. Messages
+    /// can only be sent and received after the handshake has completed.
+    void initiate_client_handshake(const std::string& request_uri,
+                                   const std::string& host,
+                                   const std::string& sec_websocket_protocol,
+                                   HTTPHeaders headers = HTTPHeaders{});
+
+    /// initiate_server_handshake() starts the Socket in server mode. It will
+    /// wait for a HTTP request from a client and respond with a HTTP response.
+    /// After sending a HTTP response, websocket_handshake_completion_handler()
+    /// is called. Messages can only be sent and received after the handshake
+    /// has completed.
+    void initiate_server_handshake();
+
+    /// initiate_server_websocket_after_handshake() starts the Socket in a state
+    /// where it will read and write WebSocket messages but it will expect the
+    /// handshake to have been completed by the caller. The use of this
+    /// function is to perform HTTP routing externally and then start the
+    /// WebSocket in case the HTTP request is an Upgrade to WebSocket.
+    /// Typically, the caller will have used make_http_response() to send the
+    /// HTTP response itself.
+    void initiate_server_websocket_after_handshake();
+
+    /// The async_write_* functions send frames. Only one frame should be sent at a time,
+    /// meaning that the user must wait for the handler to be called before sending the next frame.
+    /// The handler is type std::function<void()> and is called when the frame has been successfully
+    /// sent. In case of errors, the Config::websocket_write_error_handler() is called.
+
+    /// async_write_frame() sends a single frame with the fin bit set to 0 or 1 from \param fin, and the opcode
+    /// set by \param opcode. The frame payload is taken from \param data of size \param size. \param handler is
+    /// called when the frame has been successfully sent. Error s are reported through
+    /// websocket_write_error_handler() in Config.
+    /// This function is rather low level and should only be used with knowledge of the WebSocket protocol.
+    /// The five utility functions below are recommended for message sending.
+    ///
+    /// FIXME: Guarantee no callback reentrance, i.e., that the completion
+    /// handler, or the error handler in case an error occurs, is never called
+    /// from within the execution of async_write_frame().
+    void async_write_frame(bool fin, Opcode opcode, const char* data, size_t size, std::function<void()> handler);
+
+    //@{
+    /// Five utility functions used to send whole messages. These five
+    /// functions are implemented in terms of async_write_frame(). These
+    /// functions send whole unfragmented messages. These functions should be
+    /// preferred over async_write_frame() for most use cases.
+    ///
+    /// FIXME: Guarantee no callback reentrance, i.e., that the completion
+    /// handler, or the error handler in case an error occurs, is never called
+    /// from within the execution of async_write_text(), and its friends. This
+    /// is already assumed by the client and server implementations of the sync
+    /// protocol.
+    void async_write_text(const char* data, size_t size, std::function<void()> handler);
+    void async_write_binary(const char* data, size_t size, std::function<void()> handler);
+    void async_write_close(const char* data, size_t size, std::function<void()> handler);
+    void async_write_ping(const char* data, size_t size, std::function<void()> handler);
+    void async_write_pong(const char* data, size_t size, std::function<void()> handler);
+    //@}
+
+    /// stop() stops the socket. The socket will stop processing incoming data,
+    /// sending data, and calling callbacks.  It is an error to attempt to send
+    /// a message after stop() has been called. stop() will typically be called
+    /// before the underlying TCP/TLS connection is closed. The Socket can be
+    /// restarted with initiate_client_handshake() and
+    /// initiate_server_handshake().
+    void stop() noexcept;
+
+private:
+    class Impl;
+    std::unique_ptr<Impl> m_impl;
+};
+
+
+/// read_sec_websocket_protocol() returns the value of the
+/// header Sec-WebSocket-Protocol in the http request \a request.
+/// None is returned if the header Sec-WebSocket-Protocol is absent
+/// in the request.
+util::Optional<std::string> read_sec_websocket_protocol(const HTTPRequest& request);
+
+/// make_http_response() takes \a request as a WebSocket handshake request,
+/// validates it, and makes a HTTP response. If the request is invalid, the
+/// return value is None, and ec is set to Error::bad_request_header_*.
+util::Optional<HTTPResponse> make_http_response(const HTTPRequest& request,
+                                                const std::string& sec_websocket_protocol,
+                                                std::error_code& ec);
+
+enum class Error {
+    bad_request_malformed_http,
+    bad_request_header_upgrade,
+    bad_request_header_connection,
+    bad_request_header_websocket_version,
+    bad_request_header_websocket_key,
+    bad_response_invalid_http,
+    bad_response_2xx_successful,
+    bad_response_200_ok,
+    bad_response_3xx_redirection,
+    bad_response_301_moved_permanently,
+    bad_response_4xx_client_errors,
+    bad_response_401_unauthorized,
+    bad_response_403_forbidden,
+    bad_response_404_not_found,
+    bad_response_410_gone,
+    bad_response_5xx_server_error,
+    bad_response_500_internal_server_error,
+    bad_response_502_bad_gateway,
+    bad_response_503_service_unavailable,
+    bad_response_504_gateway_timeout,
+    bad_response_unexpected_status_code,
+    bad_response_header_protocol_violation,
+    bad_message
+};
+
+const std::error_category& error_category() noexcept;
+
+std::error_code make_error_code(Error) noexcept;
+
+} // namespace websocket
+} // namespace util
+} // namespace realm
+
+namespace std {
+
+template<> struct is_error_code_enum<realm::util::websocket::Error> {
+    static const bool value = true;
+};
+
+} // namespace std
+
+#endif // REALM_UTIL_WEBSOCKET_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/utilities.hpp b/node_modules/realm/vendor/realm-ios/include/realm/utilities.hpp
new file mode 100644
index 0000000..cd05aea
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/utilities.hpp
@@ -0,0 +1,312 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_UTILITIES_HPP
+#define REALM_UTILITIES_HPP
+
+#include <cstdint>
+#include <cstdlib>
+#include <cstdlib> // size_t
+#include <cstdio>
+#include <algorithm>
+#include <functional>
+#include <time.h>
+
+#ifdef _WIN32
+
+#include <WinSock2.h>
+#include <intrin.h>
+#include <BaseTsd.h>
+
+#if !defined(_SSIZE_T_) && !defined(_SSIZE_T_DEFINED)
+typedef SSIZE_T ssize_t;
+#define _SSIZE_T_
+#define _SSIZE_T_DEFINED
+#endif
+
+#endif // _WIN32
+
+#include <realm/util/features.h>
+#include <realm/util/assert.hpp>
+#include <realm/util/safe_int_ops.hpp>
+
+// GCC defines __i386__ and __x86_64__
+#if (defined(__X86__) || defined(__i386__) || defined(i386) || defined(_M_IX86) || defined(__386__) ||               \
+     defined(__x86_64__) || defined(_M_X64))
+#define REALM_X86_OR_X64
+#define REALM_X86_OR_X64_TRUE true
+#else
+#define REALM_X86_OR_X64_TRUE false
+#endif
+
+// GCC defines __arm__
+#ifdef __arm__
+#define REALM_ARCH_ARM
+#endif
+
+#if defined _LP64 || defined __LP64__ || defined __64BIT__ || defined _ADDR64 || defined _WIN64 ||                   \
+    defined __arch64__ || (defined(__WORDSIZE) && __WORDSIZE == 64) || (defined __sparc && defined __sparcv9) ||     \
+    defined __x86_64 || defined __amd64 || defined __x86_64__ || defined _M_X64 || defined _M_IA64 ||                \
+    defined __ia64 || defined __IA64__
+#define REALM_PTR_64
+#endif
+
+
+#if defined(REALM_PTR_64) && defined(REALM_X86_OR_X64)
+#define REALM_COMPILER_SSE // Compiler supports SSE 4.2 through __builtin_ accessors or back-end assembler
+#define REALM_COMPILER_AVX
+#endif
+
+namespace realm {
+
+using StringCompareCallback = std::function<bool(const char* string1, const char* string2)>;
+
+extern signed char sse_support;
+extern signed char avx_support;
+
+template <int version>
+REALM_FORCEINLINE bool sseavx()
+{
+    /*
+    Return whether or not SSE 3.0 (if version = 30) or 4.2 (for version = 42) is supported. Return value
+    is based on the CPUID instruction.
+
+    sse_support = -1: No SSE support
+    sse_support = 0: SSE3
+    sse_support = 1: SSE42
+
+    avx_support = -1: No AVX support
+    avx_support = 0: AVX1 supported
+    sse_support = 1: AVX2 supported (not yet implemented for detection in our cpuid_init(), todo)
+
+    This lets us test very rapidly at runtime because we just need 1 compare instruction (with 0) to test both for
+    SSE 3 and 4.2 by caller (compiler optimizes if calls are concecutive), and can decide branch with ja/jl/je because
+    sse_support is signed type. Also, 0 requires no immediate operand. Same for AVX.
+
+    We runtime-initialize sse_support in a constructor of a static variable which is not guaranteed to be called
+    prior to cpu_sse(). So we compile-time initialize sse_support to -2 as fallback.
+    */
+    static_assert(version == 1 || version == 2 || version == 30 || version == 42,
+                  "Only version == 1 (AVX), 2 (AVX2), 30 (SSE 3) and 42 (SSE 4.2) are supported for detection");
+#ifdef REALM_COMPILER_SSE
+    if (version == 30)
+        return (sse_support >= 0);
+    else if (version == 42)
+        return (sse_support > 0); // faster than == 1 (0 requres no immediate operand)
+    else if (version == 1)        // avx
+        return (avx_support >= 0);
+    else if (version == 2) // avx2
+        return (avx_support > 0);
+    else
+        return false;
+#else
+    return false;
+#endif
+}
+
+void cpuid_init();
+void* round_up(void* p, size_t align);
+void* round_down(void* p, size_t align);
+size_t round_up(size_t p, size_t align);
+size_t round_down(size_t p, size_t align);
+void millisleep(unsigned long milliseconds);
+
+#ifdef _WIN32
+int gettimeofday(struct timeval * tp, struct timezone * tzp);
+#endif
+
+int64_t platform_timegm(tm time);
+
+#ifdef REALM_SLAB_ALLOC_TUNE
+void process_mem_usage(double& vm_usage, double& resident_set);
+#endif
+// popcount
+int fast_popcount32(int32_t x);
+int fast_popcount64(int64_t x);
+uint64_t fastrand(uint64_t max = 0xffffffffffffffffULL, bool is_seed = false);
+
+// log2 - returns -1 if x==0, otherwise log2(x)
+inline int log2(size_t x)
+{
+    if (x == 0)
+        return -1;
+#if defined(__GNUC__)
+#ifdef REALM_PTR_64
+    return 63 - __builtin_clzll(x); // returns int
+#else
+    return 31 - __builtin_clz(x); // returns int
+#endif
+#elif defined(_WIN32)
+    unsigned long index = 0;
+#ifdef REALM_PTR_64
+    unsigned char c = _BitScanReverse64(&index, x); // outputs unsigned long
+#else
+    unsigned char c = _BitScanReverse(&index, x); // outputs unsigned long
+#endif
+    return static_cast<int>(index);
+#else // not __GNUC__ and not _WIN32
+    int r = 0;
+    while (x >>= 1) {
+        r++;
+    }
+    return r;
+#endif
+}
+
+// Implementation:
+
+// Safe cast from 64 to 32 bits on 32 bit architecture. Differs from to_ref() by not testing alignment and
+// REF-bitflag.
+inline size_t to_size_t(int_fast64_t v) noexcept
+{
+    REALM_ASSERT_DEBUG(!util::int_cast_has_overflow<size_t>(v));
+    return size_t(v);
+}
+
+
+template <typename ReturnType, typename OriginalType>
+ReturnType type_punning(OriginalType variable) noexcept
+{
+    union Both {
+        OriginalType in;
+        ReturnType out;
+    };
+    Both both;
+    both.out = ReturnType(); // Clear all bits in case ReturnType is larger than OriginalType
+    both.in = variable;
+    return both.out;
+}
+
+// Also see the comments in Array::index_string()
+enum FindRes {
+    // Indicate that no results were found in the search
+    FindRes_not_found,
+    // Indicates a single result is found
+    FindRes_single,
+    // Indicates more than one result is found and they are stored in a column
+    FindRes_column
+};
+
+enum IndexMethod {
+    index_FindFirst,
+    index_FindAll_nocopy,
+    index_Count,
+};
+
+// Combined result of the index_FindAll_nocopy operation. The column returned
+// can contain results that are not matches but all matches are within the
+// returned start_ndx and end_ndx.
+struct InternalFindResult {
+    // Reference to a IntegerColumn containing result rows, or a single row
+    // value if the result is FindRes_single.
+    size_t payload;
+    // Offset into the result column to start at.
+    size_t start_ndx;
+    // Offset index in the result column to end at.
+    size_t end_ndx;
+};
+
+
+// realm::is_any<T, U1, U2, U3, ...> ==
+// std::is_same<T, U1>::value || std::is_same<T, U2>::value || std::is_same<T, U3>::value ...
+template <typename... T>
+struct is_any : std::false_type {
+};
+
+template <typename T, typename... Ts>
+struct is_any<T, T, Ts...> : std::true_type {
+};
+
+template <typename T, typename U, typename... Ts>
+struct is_any<T, U, Ts...> : is_any<T, Ts...> {
+};
+
+
+// Use realm::safe_equal() instead of std::equal() if one of the parameters can be a null pointer.
+template <class InputIterator1, class InputIterator2>
+bool safe_equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2)
+{
+#if defined(_MSC_VER)
+    // VS has a special check in debug mode against passing a null pointer std::equal(); it will give a warning
+    // at runtime if this is observed.
+    // It's uncertain if this is allowed by the C++ standard. For details, see
+    // http://stackoverflow.com/questions/19120779/is-char-p-0-stdequalp-p-p-well-defined-according-to-the-c-standard.
+    // So we use a safe C++14 method instead that takes two range pairs.
+    size_t len = last1 - first1;
+    return std::equal(first1, last1, first2, first2 + len);
+#else
+    return std::equal(first1, last1, first2);
+#endif
+}
+
+// Use realm::safe_copy_n() instead of std::copy_n() if one of the parameters can be a null pointer. See the
+// explanation of safe_equal() above; same things apply.
+template< class InputIt, class Size, class OutputIt>
+OutputIt safe_copy_n(InputIt first, Size count, OutputIt result)
+{
+#if defined(_MSC_VER)
+    // This loop and the method prototype is copy pasted
+    // from "Possible implementation" on http://en.cppreference.com/w/cpp/algorithm/copy_n
+    if (count > 0) {
+        *result++ = *first;
+        for (Size i = 1; i < count; ++i) {
+            *result++ = *++first;
+        }
+    }
+    return result;
+#else
+    return std::copy_n(first, count, result);
+#endif
+}
+
+
+template <class T>
+struct Wrap {
+    Wrap(const T& v)
+        : m_value(v)
+    {
+    }
+    operator T() const
+    {
+        return m_value;
+    }
+
+private:
+    T m_value;
+};
+
+// PlacementDelete is intended for use with std::unique_ptr when it holds an object allocated with
+// placement new. It simply calls the object's destructor without freeing the memory.
+struct PlacementDelete {
+    template <class T>
+    void operator()(T* v) const
+    {
+        v->~T();
+    }
+};
+
+#ifdef _WIN32
+typedef void* FileDesc;
+#else
+typedef int FileDesc;
+#endif
+
+
+} // namespace realm
+
+#endif // REALM_UTILITIES_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/version.hpp b/node_modules/realm/vendor/realm-ios/include/realm/version.hpp
new file mode 100644
index 0000000..eb6d8f7
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/version.hpp
@@ -0,0 +1,55 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_VERSION_HPP
+#define REALM_VERSION_HPP
+
+#include <string>
+
+#ifndef REALM_VERSION_MAJOR
+#include <realm/version_numbers.hpp>
+#endif
+
+#define REALM_PRODUCT_NAME "realm-core"
+#define REALM_VER_CHUNK "[" REALM_PRODUCT_NAME "-" REALM_VERSION_STRING "]"
+
+namespace realm {
+
+enum Feature {
+    feature_Debug,
+    feature_Replication,
+};
+
+class StringData;
+
+class Version {
+public:
+    static int get_major() { return REALM_VERSION_MAJOR; }
+    static int get_minor() { return REALM_VERSION_MINOR; }
+    static int get_patch() { return REALM_VERSION_PATCH; }
+    static StringData get_extra();
+    static std::string get_version();
+    static bool is_at_least(int major, int minor, int patch, StringData extra);
+    static bool is_at_least(int major, int minor, int patch);
+    static bool has_feature(Feature feature);
+};
+
+
+} // namespace realm
+
+#endif // REALM_VERSION_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/version_id.hpp b/node_modules/realm/vendor/realm-ios/include/realm/version_id.hpp
new file mode 100644
index 0000000..807146b
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/version_id.hpp
@@ -0,0 +1,72 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_VERSION_ID_HPP
+#define REALM_VERSION_ID_HPP
+
+#if defined(_WIN32) && !defined(__STDC_LIMIT_MACROS)
+#define __STDC_LIMIT_MACROS
+#endif
+
+#include <limits>
+
+namespace realm {
+
+struct VersionID {
+    using version_type = uint_fast64_t;
+    version_type version = std::numeric_limits<version_type>::max();
+    uint_fast32_t index = 0;
+
+    VersionID()
+    {
+    }
+    VersionID(version_type initial_version, uint_fast32_t initial_index)
+    {
+        version = initial_version;
+        index = initial_index;
+    }
+
+    bool operator==(const VersionID& other) const
+    {
+        return version == other.version;
+    }
+    bool operator!=(const VersionID& other) const
+    {
+        return version != other.version;
+    }
+    bool operator<(const VersionID& other) const
+    {
+        return version < other.version;
+    }
+    bool operator<=(const VersionID& other) const
+    {
+        return version <= other.version;
+    }
+    bool operator>(const VersionID& other) const
+    {
+        return version > other.version;
+    }
+    bool operator>=(const VersionID& other) const
+    {
+        return version >= other.version;
+    }
+};
+
+} // namespace realm
+
+#endif // REALM_VERSION_ID_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/version_numbers.hpp b/node_modules/realm/vendor/realm-ios/include/realm/version_numbers.hpp
new file mode 100644
index 0000000..9ce91fd
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/version_numbers.hpp
@@ -0,0 +1,30 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_VERSION_NUMBERS_HPP
+#define REALM_VERSION_NUMBERS_HPP
+
+// Do not use `cmakedefine` here, as certain versions can be 0, which CMake
+// interprets as being undefined.
+#define REALM_VERSION_MAJOR 5
+#define REALM_VERSION_MINOR 23
+#define REALM_VERSION_PATCH 7
+#define REALM_VERSION_EXTRA ""
+#define REALM_VERSION_STRING "5.23.7"
+
+#endif // REALM_VERSION_NUMBERS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/include/realm/views.hpp b/node_modules/realm/vendor/realm-ios/include/realm/views.hpp
new file mode 100644
index 0000000..ee54c6f
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/include/realm/views.hpp
@@ -0,0 +1,290 @@
+/*************************************************************************
+ *
+ * Copyright 2016 Realm Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ **************************************************************************/
+
+#ifndef REALM_VIEWS_HPP
+#define REALM_VIEWS_HPP
+
+#include <realm/column.hpp>
+#include <realm/handover_defs.hpp>
+#include <realm/util/optional.hpp>
+
+#include <vector>
+#include <unordered_set>
+
+namespace realm {
+
+const int64_t detached_ref = -1;
+
+class RowIndexes;
+
+class BaseDescriptor {
+public:
+    BaseDescriptor() = default;
+    virtual ~BaseDescriptor() = default;
+    virtual bool is_valid() const noexcept = 0;
+    virtual std::string get_description(ConstTableRef attached_table) const = 0;
+    virtual std::unique_ptr<BaseDescriptor> clone() const = 0;
+    virtual DescriptorExport export_for_handover() const = 0;
+    virtual DescriptorType get_type() const = 0;
+};
+
+// Forward declaration needed for deleted ColumnsDescriptor constructor
+class SortDescriptor;
+
+struct LinkPathPart {
+    LinkPathPart(size_t col_ndx)
+        : column_ndx(col_ndx)
+    {
+    }
+
+    LinkPathPart(size_t col_ndx, ConstTableRef source)
+        : column_ndx(col_ndx)
+        , from(source)
+    {
+    }
+
+    size_t column_ndx;
+    // "from" is omitted for forward links, if it is valid then
+    // this path describes a backlink originating from the column from[column_ndx]
+    ConstTableRef from;
+};
+
+// ColumnsDescriptor encapsulates a reference to a set of columns (possibly over
+// links), which is used to indicate the criteria columns for sort and distinct.
+// Although the input is column indices, it does not rely on those indices
+// remaining stable as long as the columns continue to exist.
+class ColumnsDescriptor : public BaseDescriptor {
+public:
+    ColumnsDescriptor() = default;
+    // Enforce type saftey to prevent automatic conversion of derived class
+    // SortDescriptor into ColumnsDescriptor at compile time.
+    ColumnsDescriptor(const SortDescriptor&) = delete;
+    virtual ~ColumnsDescriptor() = default;
+
+    // Create a descriptor for the given columns on the given table.
+    // Each vector in `column_indices` represents a chain of columns, where
+    // all but the last are Link columns (n.b.: LinkList and Backlink are not
+    // supported), and the final is any column type that can be sorted on.
+    // `column_indices` must be non-empty, and each vector within it must also
+    // be non-empty.
+    ColumnsDescriptor(Table const& table, std::vector<std::vector<size_t>> column_indices);
+    std::unique_ptr<BaseDescriptor> clone() const override;
+
+    // returns whether this descriptor is valid and can be used to sort
+    bool is_valid() const noexcept override
+    {
+        return !m_columns.empty();
+    }
+    DescriptorType get_type() const override
+    {
+        return DescriptorType::Distinct;
+    }
+
+    struct IndexPair {
+        size_t index_in_column;
+        size_t index_in_view;
+    };
+    class Sorter;
+    virtual Sorter sorter(std::vector<IndexPair> const& rows) const;
+
+    // handover support
+    DescriptorExport export_for_handover() const override;
+
+    std::string get_description(ConstTableRef attached_table) const override;
+
+protected:
+    std::string description_for_prefix(std::string prefix, ConstTableRef attached_table) const;
+
+    std::vector<std::vector<const ColumnBase*>> m_columns;
+};
+
+class IncludeDescriptor : public ColumnsDescriptor {
+public:
+    IncludeDescriptor() = default;
+    // This constructor may throw an InvalidPathError exception if the path is not valid.
+    // A valid path consists of any number of connected link/list/backlink paths and always ends with a backlink
+    // column.
+    IncludeDescriptor(const Table& table, const std::vector<std::vector<LinkPathPart>>& column_indices);
+    ~IncludeDescriptor() = default;
+    std::string get_description(ConstTableRef attached_table) const override;
+    std::unique_ptr<BaseDescriptor> clone() const override;
+    DescriptorExport export_for_handover() const override;
+    DescriptorType get_type() const override
+    {
+        return DescriptorType::Include;
+    }
+    void append(const IncludeDescriptor& other);
+    void
+    report_included_backlinks(const Table* origin, size_t row_ndx,
+                              std::function<void(const Table*, const std::unordered_set<size_t>&)> reporter) const;
+
+private:
+    std::vector<std::vector<ConstTableRef>> m_backlink_sources; // stores a detached TableRef for non-backlink columns
+};
+
+class SortDescriptor : public ColumnsDescriptor {
+public:
+    // Create a sort descriptor for the given columns on the given table.
+    // See ColumnsDescriptor for restrictions on `column_indices`.
+    // The sort order can be specified by using `ascending` which must either be
+    // empty or have one entry for each column index chain.
+    SortDescriptor(Table const& table, std::vector<std::vector<size_t>> column_indices,
+                   std::vector<bool> ascending = {});
+    SortDescriptor() = default;
+    ~SortDescriptor() = default;
+    std::unique_ptr<BaseDescriptor> clone() const override;
+    DescriptorType get_type() const override
+    {
+        return DescriptorType::Sort;
+    }
+
+    void merge_with(SortDescriptor&& other);
+
+    Sorter sorter(std::vector<IndexPair> const& rows) const override;
+
+    // handover support
+    DescriptorExport export_for_handover() const override;
+    std::string get_description(ConstTableRef attached_table) const override;
+
+private:
+    std::vector<bool> m_ascending;
+};
+
+class LimitDescriptor : public BaseDescriptor {
+public:
+    LimitDescriptor(size_t limit);
+    virtual ~LimitDescriptor() = default;
+    bool is_valid() const noexcept override { return true; }
+    std::string get_description(ConstTableRef attached_table) const override;
+    std::unique_ptr<BaseDescriptor> clone() const override;
+    DescriptorExport export_for_handover() const override;
+    size_t get_limit() const noexcept { return m_limit; }
+    DescriptorType get_type() const override
+    {
+        return DescriptorType::Limit;
+    }
+
+private:
+    size_t m_limit = 0;
+};
+
+
+// Distinct uses the same syntax as sort except that the order is meaningless.
+typedef ColumnsDescriptor DistinctDescriptor;
+
+class DescriptorOrdering {
+public:
+    DescriptorOrdering() = default;
+    DescriptorOrdering(const DescriptorOrdering&);
+    DescriptorOrdering(DescriptorOrdering&&) = default;
+    DescriptorOrdering& operator=(const DescriptorOrdering&);
+    DescriptorOrdering& operator=(DescriptorOrdering&&) = default;
+
+    void append_sort(SortDescriptor sort);
+    void append_distinct(DistinctDescriptor distinct);
+    void append_limit(LimitDescriptor limit);
+    void append_include(IncludeDescriptor include);
+
+    /// Remove all LIMIT statements from this descriptor ordering, returning the
+    /// minimum LIMIT value that existed. If there was no LIMIT statement,
+    /// returns `none`.
+    util::Optional<size_t> remove_all_limits();
+
+    bool descriptor_is_sort(size_t index) const;
+    bool descriptor_is_distinct(size_t index) const;
+    bool descriptor_is_limit(size_t index) const;
+    bool descriptor_is_include(size_t index) const;
+
+    DescriptorType get_type(size_t index) const;
+    bool is_empty() const { return m_descriptors.empty(); }
+    size_t size() const { return m_descriptors.size(); }
+    const BaseDescriptor* operator[](size_t ndx) const;
+    bool will_apply_sort() const;
+    bool will_apply_distinct() const;
+    bool will_apply_limit() const;
+    bool will_apply_include() const;
+    realm::util::Optional<size_t> get_min_limit() const;
+    bool will_limit_to_zero() const;
+    IncludeDescriptor compile_included_backlinks() const;
+    std::string get_description(ConstTableRef target_table) const;
+
+    // handover support
+    using HandoverPatch = std::unique_ptr<DescriptorOrderingHandoverPatch>;
+    static void generate_patch(DescriptorOrdering const&, HandoverPatch&);
+    static DescriptorOrdering create_from_and_consume_patch(HandoverPatch&, Table const&);
+
+private:
+    std::vector<std::unique_ptr<BaseDescriptor>> m_descriptors;
+};
+
+// This class is for common functionality of ListView and LinkView which inherit from it. Currently it only
+// supports sorting and distinct.
+class RowIndexes {
+public:
+    RowIndexes(IntegerColumn::unattached_root_tag urt, realm::Allocator& alloc);
+    RowIndexes(IntegerColumn&& col);
+    RowIndexes(const RowIndexes& source, ConstSourcePayload mode);
+    RowIndexes(RowIndexes& source, MutableSourcePayload mode);
+
+    virtual ~RowIndexes()
+    {
+#ifdef REALM_COOKIE_CHECK
+        m_debug_cookie = 0x7765697633333333; // 0x77656976 = 'view'; 0x33333333 = '3333' = destructed
+#endif
+    }
+
+    // Disable copying, this is not supported.
+    RowIndexes& operator=(const RowIndexes&) = delete;
+    RowIndexes(const RowIndexes&) = delete;
+
+    // Return a column of the table that m_row_indexes are pointing at (which is the target table for LinkList and
+    // parent table for TableView)
+    virtual const ColumnBase& get_column_base(size_t index) const = 0;
+
+    virtual size_t size() const = 0;
+    // Get the number of total results which have been filtered out because a number of "LIMIT" operations have
+    // been applied. This number only applies to the last sync.
+    virtual size_t get_num_results_excluded_by_limit() const noexcept { return m_limit_count; }
+
+    // These two methods are overridden by TableView and LinkView.
+    virtual uint_fast64_t sync_if_needed() const = 0;
+    virtual bool is_in_sync() const
+    {
+        return true;
+    }
+
+    void check_cookie() const
+    {
+#ifdef REALM_COOKIE_CHECK
+        REALM_ASSERT_RELEASE(m_debug_cookie == cookie_expected);
+#endif
+    }
+
+    IntegerColumn m_row_indexes;
+
+protected:
+    void do_sort(const DescriptorOrdering& ordering);
+
+    static const uint64_t cookie_expected = 0x7765697677777777ull; // 0x77656976 = 'view'; 0x77777777 = '7777' = alive
+    size_t m_limit_count = 0;
+    uint64_t m_debug_cookie;
+};
+
+} // namespace realm
+
+#endif // REALM_VIEWS_HPP
diff --git a/node_modules/realm/vendor/realm-ios/librealm-ios-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-ios-dbg.a
new file mode 100644
index 0000000..4c40c2c
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-ios-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-ios.a b/node_modules/realm/vendor/realm-ios/librealm-ios.a
new file mode 100644
index 0000000..c0875e5
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-ios.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-maccatalyst-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-maccatalyst-dbg.a
new file mode 100644
index 0000000..e134a99
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-maccatalyst-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-maccatalyst.a b/node_modules/realm/vendor/realm-ios/librealm-maccatalyst.a
new file mode 100644
index 0000000..b51b1b2
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-maccatalyst.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-macosx-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-macosx-dbg.a
new file mode 100644
index 0000000..69faca7
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-macosx-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-macosx.a b/node_modules/realm/vendor/realm-ios/librealm-macosx.a
new file mode 100644
index 0000000..2b0fe46
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-macosx.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-ios-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-parser-ios-dbg.a
new file mode 100644
index 0000000..cda3088
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-ios-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-ios.a b/node_modules/realm/vendor/realm-ios/librealm-parser-ios.a
new file mode 100644
index 0000000..9e2a4b7
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-ios.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-maccatalyst-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-parser-maccatalyst-dbg.a
new file mode 100644
index 0000000..9f9686f
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-maccatalyst-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-maccatalyst.a b/node_modules/realm/vendor/realm-ios/librealm-parser-maccatalyst.a
new file mode 100644
index 0000000..e6daab1
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-maccatalyst.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-macosx-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-parser-macosx-dbg.a
new file mode 100644
index 0000000..f042ea3
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-macosx-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-macosx.a b/node_modules/realm/vendor/realm-ios/librealm-parser-macosx.a
new file mode 100644
index 0000000..f1f0f90
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-macosx.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-tvos-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-parser-tvos-dbg.a
new file mode 100644
index 0000000..d4e3b17
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-tvos-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-tvos.a b/node_modules/realm/vendor/realm-ios/librealm-parser-tvos.a
new file mode 100644
index 0000000..be20b50
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-tvos.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-watchos-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-parser-watchos-dbg.a
new file mode 100644
index 0000000..fa35fcc
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-watchos-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-parser-watchos.a b/node_modules/realm/vendor/realm-ios/librealm-parser-watchos.a
new file mode 100644
index 0000000..78a905f
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-parser-watchos.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-tvos-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-tvos-dbg.a
new file mode 100644
index 0000000..a0f317a
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-tvos-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-tvos.a b/node_modules/realm/vendor/realm-ios/librealm-tvos.a
new file mode 100644
index 0000000..893d45d
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-tvos.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-watchos-dbg.a b/node_modules/realm/vendor/realm-ios/librealm-watchos-dbg.a
new file mode 100644
index 0000000..6303100
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-watchos-dbg.a differ
diff --git a/node_modules/realm/vendor/realm-ios/librealm-watchos.a b/node_modules/realm/vendor/realm-ios/librealm-watchos.a
new file mode 100644
index 0000000..cebc9cb
Binary files /dev/null and b/node_modules/realm/vendor/realm-ios/librealm-watchos.a differ
diff --git a/node_modules/realm/vendor/realm-ios/version.txt b/node_modules/realm/vendor/realm-ios/version.txt
new file mode 100644
index 0000000..5b341fd
--- /dev/null
+++ b/node_modules/realm/vendor/realm-ios/version.txt
@@ -0,0 +1 @@
+4.9.1
